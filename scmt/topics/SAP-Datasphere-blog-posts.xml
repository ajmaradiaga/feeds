<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/SAP-Datasphere-blog-posts.xml</id>
  <title>SAP Community - SAP Datasphere</title>
  <updated>2025-10-31T12:16:17.987168+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/SAP Datasphere/pd-p/73555000100800002141" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>SAP Datasphere blog posts in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/how-to-connect-to-sap-ibp-from-sap-datasphere-using-odata/ba-p/14233734</id>
    <title>How to Connect to SAP IBP from SAP Datasphere using OData</title>
    <updated>2025-10-08T05:55:17.590000+02:00</updated>
    <author>
      <name>Raghav_S</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1839733</uri>
    </author>
    <content>&lt;H1 id="toc-hId-1632768490"&gt;&lt;STRONG&gt;How to Connect to the SAP IBP System from SAP Datasphere using OData APIs&lt;/STRONG&gt;&lt;/H1&gt;&lt;P&gt;Use case - In our organization, we use IBP mainly for Demand Planning and Supply Planning. We needed some reporting to track the forecast accuracy, monitoring KPIs and especially the exception management. Inorder to achieve this, we wanted to store the snapshot of IBP data in our datasphere.&amp;nbsp;&lt;/P&gt;&lt;P&gt;SAP Datasphere doesnt have a direct connection to SAP IBP and we also cannot use the API which is used for SAP Analytics Cloud (/odata/IBP/EXTRACT_ODATA_SRV). So, to solve this, we used the below steps.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;We can use the following APIs based on our use case.&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;H4 id="toc-hId-1823503142"&gt;&lt;STRONG&gt;Master Data&lt;/STRONG&gt;: /IBP/MASTER_DATA_API_SRV&lt;/H4&gt;&lt;/LI&gt;&lt;LI&gt;&lt;H4 id="toc-hId-1626989637"&gt;&lt;STRONG&gt;Key Figures&lt;/STRONG&gt;: /IBP/PLANNING_DATA_API_SRV&lt;/H4&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Please follow the steps outlined below:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Part 1 – IBP Configuration&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Create a &lt;STRONG&gt;Communication User&lt;/STRONG&gt; within the IBP system. This user ID will be required when configuring the OData connection in Datasphere.&lt;/LI&gt;&lt;LI&gt;Navigate to Communication Arrangement and identify the scenario &lt;STRONG&gt;SAP_COM_&lt;/STRONG&gt;0720.&lt;/LI&gt;&lt;LI&gt;Under Inbound Communications, assign the newly created communication user.&lt;/LI&gt;&lt;LI&gt;Assign a reference business user under Corresponding Business User.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;(Ensure that the reference business user is granted all necessary permissions to access relevant IBP data)&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Raghav_S_0-1759430697781.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/322389i8C240D93654A5EFE/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Raghav_S_0-1759430697781.png" alt="Raghav_S_0-1759430697781.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Part 2 – Datasphere&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Create a Generic OData connection.&lt;/LI&gt;&lt;LI&gt;Go to &lt;STRONG&gt;Connections → New&lt;/STRONG&gt;, select &lt;STRONG&gt;Generic OData&lt;/STRONG&gt;.&lt;UL&gt;&lt;LI&gt;Enter the service URL (e.g., .../ PLANNING_DATA_API_SRV), and upload the server certificate if required (only for remote table and replication flows; not needed for data flows).&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;Set Version to V2.&lt;/LI&gt;&lt;LI&gt;Set Authentication Type to Username and Password, using the new communication user ID and password from IBP.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Part 3 – Creating the data flow in datasphere.&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Go to data builder and create a new data flow.&lt;/LI&gt;&lt;LI&gt;Go to source and select the right connection – This should show the list of planning areas that are visible based on the authorization.&lt;/LI&gt;&lt;LI&gt;Select the desired planning area and hit add selection - Now you should see the source node in your data flow.&lt;/LI&gt;&lt;LI&gt;Under OData parameters, create a select parameter line and type in the required dimensions – use the exact technical names of the field from the source node.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Raghav_S_1-1759430697782.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/322387iFDD5AC93C879EAB9/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Raghav_S_1-1759430697782.png" alt="Raghav_S_1-1759430697782.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;5. Under Source filters, input the required Unit of Measure or other mandatory inputs for your planning area. (Also, include other filters based on your need)&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Raghav_S_2-1759430697783.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/322388iF0ED347C39647004/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Raghav_S_2-1759430697783.png" alt="Raghav_S_2-1759430697783.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;6. Add a target table to your data flow or do the necessary transformations based on your needs.&lt;/P&gt;&lt;P&gt;Once you’ve completed the configuration steps outlined above, you’ll be able to seamlessly preview and pull data from your planning area into SAP Datasphere. This ensures that your data integration is both efficient and secure, empowering you to make the most of your SAP IBP and Datasphere environments. Happy data modeling!&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/how-to-connect-to-sap-ibp-from-sap-datasphere-using-odata/ba-p/14233734"/>
    <published>2025-10-08T05:55:17.590000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/step-by-step-implementing-generative-ai-with-sap-hana-cloud/ba-p/14231548</id>
    <title>Step-by-Step: Implementing Generative AI with SAP HANA Cloud</title>
    <updated>2025-10-08T06:09:32.763000+02:00</updated>
    <author>
      <name>saravananc2</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1281625</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;Introduction:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;This blog walks through building an AI Sales Assistant on SAP HANA Cloud calculation views. The assistant enables users to ask natural-language questions such as &lt;/SPAN&gt;&lt;I&gt;&lt;SPAN&gt;“Which product category had the highest sales in Q2?”&lt;/SPAN&gt;&lt;/I&gt;&lt;SPAN&gt; and receive contextual answers generated directly from enterprise data.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The solution uses the Retrieval-Augmented Generation (RAG) pattern, where sales transactions stored in HANA are enriched with embeddings and combined with a Large Language Model (LLM) to deliver precise, business&lt;/SPAN&gt;&lt;SPAN&gt;-aware responses. This approach extends the analytical power of HANA Cloud with conversational intelligence- effectively bringing AI integration to your calculation views without moving the data out of HANA.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;We’ll cover the concepts, high-level architecture, and detailed implementation steps so you can replicate this setup on your own HANA Cloud system and make the most of your existing calculation views.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;High Level Architecture:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="saravananc2_0-1759231056738.png" style="width: 630px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/321560i86EA370AC94C7442/image-dimensions/630x182/is-moderation-mode/true?v=v2" width="630" height="182" role="button" title="saravananc2_0-1759231056738.png" alt="saravananc2_0-1759231056738.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Key Concepts:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Retrieval-Augmented Generation:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;It’s an AI pattern where a language model (like GPT) is not used in isolation, but is “augmented” with external knowledge retrieved from a database or document store.&lt;/P&gt;&lt;P&gt;It has two main steps:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Retrieval&lt;/STRONG&gt; – Find the most relevant documents/data from a knowledge source (e.g., database, embeddings index, vector store).&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Generation&lt;/STRONG&gt; – Pass both the retrieved data + the user’s query into the LLM so the response is grounded in actual facts instead of just relying on the LLM’s training data.&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;SAP HANA Cloud:&lt;BR /&gt;&lt;/STRONG&gt;&lt;SPAN&gt;The foundation of this project is SAP HANA Cloud. HANA calculation view serves as the source for the RAG (Retrieval-Augmented Generation) application. With the new HANA Cloud Vector Engine, we can now store and query embeddings directly inside HANA eliminating the need for external vector databases. For this setup, we create a dedicated embeddings table to persist vector representations of the sales data.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Flask API:&lt;BR /&gt;&lt;/STRONG&gt;&lt;SPAN&gt;For the backend, I used Flask, a lightweight Python web framework.Flask allows Python code to be exposed as REST APIs or lightweight web applications. In this project, the Flask API connects to the HANA calculation view, retrieves data, and interacts with the OpenAI API. OpenAI generates embeddings for the data, which are then stored in the embeddings table in HANA Cloud. The same API also handles user prompts: it takes queries from the frontend, searches the embeddings table, and returns contextual answers.&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Streamlit:&lt;BR /&gt;&lt;/STRONG&gt;&lt;SPAN&gt;The frontend is built with Streamlit, a Python framework for creating simple yet powerful user interfaces. It provides a chat-like interface where users can enter questions. The prompts are passed to the Flask API, which handles retrieval and reasoning. While Streamlit makes prototyping easy, this frontend could also be replaced with SAP Fiori or any Web frontend.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Implementation steps:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Let’s see step by step on how to develop this framework for existing calculation views.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Prerequisites:&amp;nbsp;&lt;/STRONG&gt;Python 3.9+, BAS environment, CF CLI, HANA DB instance, OpenAI API key.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;SPAN&gt;I have two projects in BAS: one containing the HANA calculation views, and the other containing the Flask backend (referred to as the Flask app). Below is the output of the calculation view.&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="saravananc2_1-1759441361241.png" style="width: 584px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/322407i2E3A4C28AA3D0687/image-dimensions/584x164?v=v2" width="584" height="164" role="button" title="saravananc2_1-1759441361241.png" alt="saravananc2_1-1759441361241.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 2.We need to convert the hana data into embeddings and store them in HANA tables. Create embeddings table in HANA cloud. Below is the sql for that.&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE TABLE SALES_EMBEDDINGS (
    TRANSACTION_ID NVARCHAR(50),
    TEXT NVARCHAR(5000),
    EMBEDDING REAL_VECTOR(1536)
);&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;3.&amp;nbsp;&lt;SPAN&gt;To generate embeddings using a LLM we need access. In my case i have used LLM from Open AI. Create an account in Open AI and register for Open API key.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;4. Create a python file (eg : generate_embeddings.py) in your flask project to generate embeddings based on your calculation view data and store in HANA cloud table created above. Have your credentials in the env file for testing. Make sure your BAS dev space is in the same region as your HANA cloud instance otherwise connection fails.&amp;nbsp; This step makes sure we are able to connect to HANA convert calculation view(CV) data into text and generate embeddings for it. Run this file separately and see if data is inserted into HANA cloud table.&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import os
from hdbcli import dbapi
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Connect to SAP HANA Cloud
conn = dbapi.connect(
    address=os.getenv("HANA_HOST"),   # e.g. yourhana.hana.prod-us10.hanacloud.ondemand.com
    port=int(os.getenv("HANA_PORT", "443")),
    user=os.getenv("HANA_USER"),
    password=os.getenv("HANA_PASSWORD")
)

cursor = conn.cursor()

# Fetch sales transactions
cursor.execute("""
    SELECT TRANSACTION_ID, REGION, PRODUCT, SALES_AMOUNT, SALE_DATE 
    FROM schema name."cv_sales_test"
""")
rows = cursor.fetchall()

# 5. Generate embeddings and insert into HANA
for row in rows:
    transaction_id, region, product, sales_amount, sales_date = row
    text = f"Transaction {transaction_id} in {region} sold {product} for {sales_amount} on {sales_date}"

    embedding = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    ).data[0].embedding

    cursor.execute("""
        INSERT INTO "schemaname"."SALES_EMBEDDINGS" (TRANSACTION_ID, TEXT, EMBEDDING)
        VALUES (?, ?, ?)
    """, (transaction_id, text, embedding))

conn.commit()
cursor.close()
conn.close()

print("Embeddings inserted into SALES_EMBEDDINGS table in HANA Cloud.")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Sales embeddings table output:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="saravananc2_0-1759441104364.png" style="width: 538px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/322404i5E3AFED41C0E6FA5/image-dimensions/538x113?v=v2" width="538" height="113" role="button" title="saravananc2_0-1759441104364.png" alt="saravananc2_0-1759441104364.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;5. Now let's implement RAG on embeddings. Create a new file for RAG query code. This function connects to HANA cloud and fetches stored vector representations of the transactions. The user's question is passed to OpenAI embeddings API and question is converted into numerical vector. We compute cosine similarity between the query embedding and stored transaction embeddings. The top results are combined with the user’s original question to form a prompt, which is then sent to the LLM to generate a contextual answer.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import os
import json
import struct
import numpy as np
from hdbcli import dbapi
from openai import OpenAI
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv

load_dotenv()


# --------------------------
# Get HANA credentials (VCAP aware)
# --------------------------
def get_hana_credentials(debug=False):
    vcap_services = os.environ.get("VCAP_SERVICES")
    if vcap_services:
        try:
            vcap = json.loads(vcap_services)
            for key in vcap:
                if "hana" in key.lower():  # find any hana service
                    creds = vcap[key][0]["credentials"]
                    if debug:
                        print("Found HANA credentials from VCAP_SERVICES:", creds)
                    return {
                        "host": creds.get("host"),
                        "port": creds.get("port"),
                        "user": creds.get("user"),
                        "password": creds.get("password")
                    }
        except Exception as e:
            if debug:
                print("Error parsing VCAP_SERVICES:", e)

    # fallback to env vars
    creds = {
        "host": os.environ.get("HANA_HOST"),
        "port": os.environ.get("HANA_PORT"),
        "user": os.environ.get("HANA_USER"),
        "password": os.environ.get("HANA_PASSWORD")
    }
    if debug:
        print("Using HANA credentials from environment variables:", creds)
    return creds

# --------------------------
# Run RAG query
# --------------------------

def run_rag_query(user_query, top_k=5, debug=False):

    openai_api_key = os.environ.get("OPENAI_API_KEY")
    if not openai_api_key:
        raise Exception("OPENAI_API_KEY environment variable not set")
    openai_client = OpenAI(api_key=openai_api_key)

    hana_creds = get_hana_credentials(debug=debug)
   
    conn = None
    cursor = None
    try:
        conn = dbapi.connect(
            address=hana_creds["host"],
            port=int(hana_creds["port"]),
            user=hana_creds["user"],
            password=hana_creds["password"]
        )
        cursor = conn.cursor()

        # Fetch embeddings from HANA
        cursor.execute('SELECT TRANSACTION_ID, TEXT, EMBEDDING FROM "schemaname"."SALES_EMBEDDINGS"')
        rows = cursor.fetchall()

        if not rows:
            context = "No transactions available."
        else:
            # Compute query embedding
            embedding_resp = openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=user_query
            )
            query_embedding = np.array(embedding_resp.data[0].embedding, dtype=np.float32)
            query_dim = len(query_embedding)

            texts, embedding_list = [], []
            for row in rows:
                text = row[1]
                blob = row[2]
                if len(blob) &amp;lt; query_dim * 4:
                    continue
                embedding = np.array(struct.unpack('f' * query_dim, blob[:query_dim*4]), dtype=np.float32)
                texts.append(text)
                embedding_list.append(embedding)

            if not embedding_list:
                context = "No valid transactions found."
            else:
                similarities = [cosine_similarity(query_embedding.reshape(1, -1), e.reshape(1, -1))[0][0] for e in embedding_list]
                top_indices = np.argsort(similarities)[-top_k:][::-1]
                context = "\n".join([texts[i] for i in top_indices])

        # GPT completion: summarize transactions
        prompt = f"""
You are a helpful sales analyst assistant.
Based on the following transactions:

{context}

Answer the user's question in **natural language**, summarizing key insights if possible.
Question: {user_query}
Please keep your answer concise.
"""

        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"Error in run_rag_query: {str(e)}"

    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;6.&amp;nbsp;&amp;nbsp;&lt;SPAN&gt;Wrap the above RAG query code in a function and use it in Flask. Install Flask if not already available.&amp;nbsp;Now Flask API is directly using RAG logic. Frontend application can call this API and get a response. Ensure the Flask API works locally and returns expected results before deploying to Cloud Foundry.&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;pip install flask&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from flask import Flask, request, jsonify
from hdbcli import dbapi
from openai import OpenAI
import numpy as np
import struct
import os
import json
from sklearn.metrics.pairwise import cosine_similarity as sk_cos_sim
from dotenv import load_dotenv

load_dotenv()

app = Flask(__name__)

# --------------------------
# Cosine similarity
# --------------------------
def cosine_similarity(a, b):
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    if norm_a == 0 or norm_b == 0:
        return -1
    return np.dot(a, b) / (norm_a * norm_b)

# --------------------------
# Get HANA credentials
# --------------------------
def get_hana_credentials():
    vcap_services = os.environ.get("VCAP_SERVICES")
    if vcap_services:
        try:
            vcap = json.loads(vcap_services)

            # Look for a service whose name includes "hana"
            for service_name, service_defs in vcap.items():
                if service_name.lower() == "hdi_db":
                    creds = service_defs[0]["credentials"]
                    host = creds.get("host")
                    port = creds.get("port")
                    user = creds.get("user")
                    password = creds.get("password")

                    if host and port and user and password:
                        print(f"Using HANA service from VCAP: {service_name}")
                        return {
                            "host": host,
                            "port": port,
                            "user": user,
                            "password": password
                        }
                    else:
                        print(f"HANA service in VCAP missing user/password. Falling back to manual env vars.")

        except Exception as e:
            print(f"Failed to parse VCAP_SERVICES: {e}")

    # Fallback to manual env vars
    print("Using manual HANA_* environment variables")
    return {
        "host": os.environ.get("HANA_HOST"),
        "port": os.environ.get("HANA_PORT"),
        "user": os.environ.get("HANA_USER"),
        "password": os.environ.get("HANA_PASSWORD")
    }

# --------------------------
# RAG query
# --------------------------
#
# " Your RAG Query here"

# --------------------------
# Health check route
# --------------------------
@app.route("/")
def index():
    return "Flask API is running!"

# --------------------------
# Query route
# --------------------------
@app.route("/query", methods=["POST"])
def query_rag_route():
    data = request.get_json()
    user_query = data.get("query", "")
    if not user_query:
        return jsonify({"error": "Query missing"}), 400

    # Run RAG query
    results = run_rag_query(user_query, top_k=5, debug=False)

    # Return in a format that Streamlit expects
    return jsonify({"results": results})

if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=int(os.environ.get("PORT", 5000)))&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Once you run flask API code ,it will start REST API server. It should return "Flask API is running".&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;http://&amp;lt;your-BAS-workspace-url&amp;gt;:5000/query&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 7. Deploy the Flask app on SAP BTP Cloud Foundry and you will see a URL assigned. Deploying it on cloud foundry frees the dependency on BAS dev space and our frontend app can always call the Flask API. Bind it to the HANA service instance so that cloud foundry injects credentials into the app's environment (VCAP_SERVICES) so the running code can connect to HANA. This makes sure our Flask API will have HANA credentials at runtime. After binding check environment and logs.&lt;/P&gt;&lt;P&gt;Check for services and push your app to CF.&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;cf services
cf push "app name" -f manifest.yml&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;For binding app to HANA service:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;cf bind-service "app name" "hana service"
cf restage "app name"&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Verify environment and logs&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;cf env "your app name"
cf logs "your app name" --recent&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Test it using curl. See the response in results section.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="saravananc2_0-1759402166392.png" style="width: 645px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/322254iDAD0F1033C5615D5/image-dimensions/645x50?v=v2" width="645" height="50" role="button" title="saravananc2_0-1759402166392.png" alt="saravananc2_0-1759402166392.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;8. For UI, I have implemented using streamlit on my local machine. In Command line run 'pip install streamlit requests' . Run the program file that contains the code.&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="saravananc2_1-1759403793526.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/322259iC51774A929ABBF93/image-size/medium?v=v2&amp;amp;px=400" role="button" title="saravananc2_1-1759403793526.png" alt="saravananc2_1-1759403793526.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Your browser will open at :&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;http://localhost:8501&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Type in any question and it will return a contextual response like below.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="saravananc2_4-1759403982209.png" style="width: 572px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/322262i9F1742B2795B9449/image-dimensions/572x337?v=v2" width="572" height="337" role="button" title="saravananc2_4-1759403982209.png" alt="saravananc2_4-1759403982209.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Key Advantages:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Leverage Existing SAP Data assets-&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;Reuse of existing HDI Containers and calculation views.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Secured and Enabled -&amp;nbsp; Access to HANA data remains within the SAP security framework.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Scalable and extensible - The architecture can support multiple use cases like Finance, HR, and Logistics.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Enhanced insights - Combines structured data retrieval with natural-language summarization.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Conclusion:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;By integrating SAP HANA Cloud with a Large Language Model using the Retrieval-Augmented Generation (RAG) approach, we’ve transformed standard calculation views into an AI-powered sales assistant . This demonstrates&amp;nbsp;how modern AI capabilities can be layered on top of established enterprise data systems, opening the door to smarter, faster, and more interactive business decision-making.&lt;/P&gt;&lt;P&gt;Thank you,&lt;/P&gt;&lt;P&gt;Saravanan Chinnaswamy.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/step-by-step-implementing-generative-ai-with-sap-hana-cloud/ba-p/14231548"/>
    <published>2025-10-08T06:09:32.763000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555</id>
    <title>SAP Business Data Cloud - Create a custom Data Product based on a replication Flow</title>
    <updated>2025-10-08T18:05:24.272000+02:00</updated>
    <author>
      <name>aelbouayadi</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/564557</uri>
    </author>
    <content>&lt;P&gt;&lt;ul =""&gt;&lt;li style="list-style-type:disc; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555#toc-hId-1761998305"&gt;1- Create aSAP HANA Data Lake Files(HDLF) Space in Datasphere&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555#toc-hId-1565484800"&gt;2- Create a replication Flow from your source (in this blog we'll use SAP S/4HANA) to the created HDLF Space.&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555#toc-hId-1368971295"&gt;3- Create Data Provider Profile in Datasphere&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555#toc-hId-1172457790"&gt;4- Create and list a Data product&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555#toc-hId-975944285"&gt;5- List the Data product&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555#toc-hId-779430780"&gt;6- Share the Data product from the BDC cockpit.&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555#toc-hId-582917275"&gt;7 - Check the Data Product in SAP Databricks&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555#toc-hId-386403770"&gt;Summary&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/P&gt;&lt;P&gt;In this Blog, we'll demonstrate how to create a custom data product from a replication flow that can be delta-shared with SAP Databricks or BDC connect.&lt;/P&gt;&lt;P&gt;There are few steps to follow:&lt;/P&gt;&lt;P&gt;1- Create a&amp;nbsp;&lt;SPAN&gt;SAP HANA Data Lake Files&lt;/SPAN&gt;&amp;nbsp;(HDLF) Space in Datasphere&lt;/P&gt;&lt;P&gt;2- Create a replication Flow from your source (in this blog we'll use SAP S/4HANA) to the created HDLF Space.&lt;/P&gt;&lt;P&gt;3- Create Data Provider Profile in Datasphere&lt;/P&gt;&lt;P&gt;4- Create and list a Data product&lt;/P&gt;&lt;P&gt;5- List the Data product&lt;/P&gt;&lt;P&gt;6- Share the Data product from the BDC cockpit&lt;/P&gt;&lt;P&gt;7- Check the Data product from the BDC cockpit&lt;/P&gt;&lt;H2 id="toc-hId-1761998305"&gt;&lt;SPAN&gt;1- Create a&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;SAP HANA Data Lake Files&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;(HDLF) Space in Datasphere&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;From the space management, you need to create a new space (HDLF)&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2.png" style="width: 341px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324776iE18F0B580B1DD5E5/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="2.png" alt="2.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324778i1C867FF664C746C9/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="2.png" alt="2.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;This step can be skipped if you already have an HDLF space.&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;Once the space is created, you need to establish the connection to the source system (supporting replication flows) that you need.&lt;/P&gt;&lt;H2 id="toc-hId-1565484800"&gt;2- Create a replication Flow from your source (in this blog we'll use SAP S/4HANA) to the created HDLF Space.&lt;/H2&gt;&lt;P&gt;Once the space an the right connection are done, we can start creating our replication flow=&lt;/P&gt;&lt;P&gt;For this scenario, I will use the CDS view I_CUSTOMER:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="3.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324779i6896D35E7002F9E1/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="3.png" alt="3.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;As you can see, I enabled Initial and delta, so my data product well be refreshed as soon as a delta is loaded (it may take some refresh time to be reflected on the data product)&lt;/P&gt;&lt;P&gt;As a result of this replication flow, I will get a local table :&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="4.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324780i42BDA90226B77575/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="4.png" alt="4.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;This table will be the source of our Data Product.&lt;/STRONG&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1368971295"&gt;3- Create Data Provider Profile in Datasphere&lt;/H2&gt;&lt;P&gt;In this step we need to create our data profile provider.&lt;/P&gt;&lt;P&gt;Data Sharing Cockpit -&amp;gt; My Data Provider Profile -&amp;gt; Create Data Provider Profile&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="5.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324781iF1A4D885E69C33F0/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="5.png" alt="5.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;You can follow this help page to create your Data Provider Profile:&lt;A href="http://&amp;nbsp;https://help.sap.com/docs/SAP_DATASPHERE/e4059f908d16406492956e5dbcf142dc/4d298f8654fe4a6c9b6a4399a9e14c77.html" target="_self" rel="nofollow noopener noreferrer"&gt;&amp;nbsp;&lt;/A&gt;&lt;/SPAN&gt;&lt;A href="http://&amp;nbsp;https://help.sap.com/docs/SAP_DATASPHERE/e4059f908d16406492956e5dbcf142dc/4d298f8654fe4a6c9b6a4399a9e14c77.html" target="_self" rel="nofollow noopener noreferrer"&gt;&lt;SPAN&gt;https://help.sap.com/docs/SAP_DATASPHERE/e4059f908d16406492956e5dbcf142dc/4d298f8654fe4a6c9b6a4399a9e14c77.html&lt;/SPAN&gt;&lt;/A&gt;&lt;/P&gt;&lt;P&gt;In Order to be able to share the data product within BDC, you &lt;STRONG&gt;MUST&lt;/STRONG&gt; set the "Data Provider / Data Product Visibility" to &lt;STRONG&gt;Formations&lt;/STRONG&gt;.&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="6.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324782iEA081D06F20BB9F9/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="6.png" alt="6.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now, you will be able to create Data Products.&lt;/P&gt;&lt;H2 id="toc-hId-1172457790"&gt;4- Create and list a Data product&lt;/H2&gt;&lt;P&gt;In this step we'll use our Data Provider Profile to create the Data products.&lt;/P&gt;&lt;P&gt;Data Sharing Cockpit -&amp;gt; My Data Products -&amp;gt; Create Data Product&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="7.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324783iD3866886A655ECBA/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="7.png" alt="7.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;This link is helpful to create the Data Product:&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/e4059f908d16406492956e5dbcf142dc/bbcbf42b0cb541529e63628d95f394c8.html" target="_self" rel="noopener noreferrer"&gt;&lt;SPAN&gt;https://help.sap.com/docs/SAP_DATASPHERE/e4059f908d16406492956e5dbcf142dc/bbcbf42b0cb541529e63628d95f394c8.html&lt;/SPAN&gt;&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;But Here are some of the important field that you need to fill:&lt;/P&gt;&lt;OL class="lia-list-style-type-lower-alpha"&gt;&lt;LI&gt;Artifact Space: &lt;STRONG&gt;the HANA Data Lake File space created in the first step and used for replication&lt;/STRONG&gt;&lt;STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="8.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324785iD5C2D37F1C133A26/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="8.png" alt="8.png" /&gt;&lt;/span&gt;&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;Data category: you need to choose a category of your data product. In this example, I choose "Company Data"&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="9.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324787i582AE1A9855857FB/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="9.png" alt="9.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;&amp;nbsp;Product Artifacts: Here is where we add our local table to the data product.&lt;/LI&gt;&lt;/OL&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="10.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324788iC53445ECB45897DF/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="10.png" alt="10.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;You have the possibility to add multiple tables to your data product.&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;You will see the added artifacts to your DP.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="13.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324792i90391463FD82169F/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="13.png" alt="13.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Last, you need to save the changes for your data product.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-975944285"&gt;5- List the Data product&lt;/H2&gt;&lt;P&gt;After saving the Data product, you will be able to see your DP like this:&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="14.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324797i83F3433C64099FD5/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="14.png" alt="14.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In order, to share the DP within BDC you need to List your DP :&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Switch Status -&amp;gt; List&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="15.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324798i67EAAEEE8CEB5DA9/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="15.png" alt="15.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The status will change to:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="16.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324799iCDD21A142B5828E0/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="16.png" alt="16.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;The Data Product will be available in the BDC cockpit after the next synchronisation job is done&lt;/STRONG&gt;&lt;/P&gt;&lt;H2 id="toc-hId-779430780"&gt;6- Share the Data product from the BDC cockpit.&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;Now we will switch to the BDC cockpit.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;From the menu we Navigate to "Catalog &amp;amp; Marketplace" -&amp;gt; Search&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;And we can search for our Data Product " CustomerDataP"&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="18.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324802i5605BC9A1A5EFE7D/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="18.png" alt="18.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;From here we can &lt;STRONG&gt;share&lt;/STRONG&gt; our Data Product and see it's &lt;STRONG&gt;lineage.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="19.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324803i67EAB8FEA81B70A3/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="19.png" alt="19.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;- Share -&amp;gt; Add Target :&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;- Choose your target(SAP BDC or BDC Connect), In this Scenario, we'll choose SAP Databricks:&lt;/P&gt;&lt;P&gt;Then we add a Share Name : "customerdp", specify the Workspace in SAP Databricks, and Share&lt;/P&gt;&lt;P&gt;Once shared, you will se a notification telling you so.&lt;/P&gt;&lt;H2 id="toc-hId-582917275"&gt;7 - Check the Data Product in SAP Databricks&lt;/H2&gt;&lt;P&gt;In this step we'll check our shared data product in SAP Databricks.&lt;/P&gt;&lt;P&gt;From the previous screen, once the shared is completed we can open our data product in SAP Databricks:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="22.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324810i74A3901E61CD959B/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="22.png" alt="22.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In SAP Databricks' Catalog, we can see our shared data product&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="23.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324812i9E1C448AF15AD0E5/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="23.png" alt="23.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;From here we can visualize a sample data :&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="24.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/324814i78C40BA1A63DE6E3/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="24.png" alt="24.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;From here, it is up to your creativity in Databricks&amp;nbsp;&lt;span class="lia-unicode-emoji" title=":winking_face:"&gt;😉&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-386403770"&gt;Summary&lt;/H2&gt;&lt;P&gt;In this blog, we saw how we can create custom Data Products in SAP business Data Cloud. We started from a creating a replication flow in Datasphere to a HANA Data Lake File space, we created a Data Provider Profile that allowed us to created a Data Product from the local table (result of the rep flow). Then we were able to list tha data product so we can find it in the BDC cockpit catalog and finally share it with SAP Databrick.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;I hope this will help you create you custom data products from Datasphere.&lt;/P&gt;&lt;P&gt;Kind regards,&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555"/>
    <published>2025-10-08T18:05:24.272000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/unlocking-the-next-chapter-of-seamless-planning-in-sap-business-data-cloud/ba-p/14243864</id>
    <title>Unlocking the Next Chapter of Seamless Planning in SAP Business Data Cloud with Live Versions</title>
    <updated>2025-10-14T20:34:01.157000+02:00</updated>
    <author>
      <name>Max_Gander</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14553</uri>
    </author>
    <content>&lt;H2 id="toc-hId-1762775784"&gt;Introduction&lt;/H2&gt;&lt;P&gt;Seamless planning is generally available since Q1 2025. Since then, plan data resides directly in SAP Datasphere and with that, in the core of SAP Business Data Cloud. We are now thrilled to announce the release of live versions with QRC4 2025 (fast track wave 20.2025) that bring fact data into planning models without replication! Learn how this works, why it brings many planning use cases to a new level and how it benefits from the data product architecture of BDC.&amp;nbsp;&lt;/P&gt;&lt;P&gt;I also want to highlight more features that we are introducing in this context:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Seamless planning support for SAP Analytics Cloud compass incl. support for live versions (&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-analytics-cloud-compass-support-of-seamless-planning-amp-live-version/ba-p/14245059?emcs_t=S2h8ZW1haWx8bWVudGlvbl9zdWJzY3JpcHRpb258TUdTOUlXNk5SRlBORUZ8MTQyNDUwNTl8QVRfTUVOVElPTlN8aEs" target="_blank"&gt;Check out this great blogpost &lt;/A&gt;&amp;nbsp;from&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/46487"&gt;@ChenNee&lt;/a&gt;)&lt;/LI&gt;&lt;LI&gt;Detection of mismatches between fact and master data (postings on dimension members that are not part of your dimension tables)&lt;/LI&gt;&lt;LI&gt;Planning on live versions from other sources (e.g., Google BigQuery; not applicable for seamless planning; &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/live-versions-from-an-sql-source-for-sap-analytics-cloud-planning/ba-p/14245675#M185464" target="_blank"&gt;check out this blogpost&lt;/A&gt;&amp;nbsp;)&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Watch out for more blogposts to come in the next weeks!&lt;/P&gt;&lt;H2 id="toc-hId-1566262279"&gt;Use cases &amp;amp; benefits&lt;/H2&gt;&lt;P&gt;You cannot plan in a data vacuum. Plans rely on reference data and input. That can be actual data, other plan data, external influencer data etc. &amp;nbsp;Until now, you were required to physically bring this data into your planning models using import jobs, uploads or data actions. Hence, live versions represent an advanced paradigm to data management and offer benefits in core planning scenarios for different personas.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Accurate forecasts &amp;amp; plans&lt;/STRONG&gt;: Live versions pull actuals, and external drivers directly from SAP Datasphere into your planning models - without replication. This removes latency and reconciliation work, so forecasts are built on the latest, governed facts from a single source of truth. Rolling forecasts and variance analysis become immediate and more reliable, reducing forecast bias and improving plan quality. Live versions can even feed SAP Analytics Cloud predictive scenarios with live data!&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Extended Planning and Analysis: &lt;/STRONG&gt;Cross-functional teams (finance, supply chain, sales, HR) consume the same governed facts directly from SAP Datasphere. Plans, assumptions and driver changes propagate instantly across domains, enabling end-to-end scenarios, consistent KPIs, and accelerating aligned decisions.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Operating a planning solution&lt;/STRONG&gt;: No more nightly imports, manual uploads, or complex data actions to keep models current. Live versions reduce data movement &amp;amp; data footprint, simplify model building &amp;amp; operations, and lower TCO. Furthermore, the graphical modeling interface in SAP Datasphere lets you define joins, mappings, transformations etc. to bring data into the exact shape that you need for your planning model.&amp;nbsp;&lt;/P&gt;&lt;P&gt;SAP Business Data Cloud's data product architecture augments this opportunity.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Use SAP-managed data products and base planning models directly on curated data from SAP applications.&lt;/LI&gt;&lt;LI&gt;Use customer-managed data products from SAP BW PCE to support hybrid planning architectures while transitioning from BPC to planning in BDC.&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;Integrate results from SAP Databricks via SAP Datasphere&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-1369748774"&gt;How does it work?&lt;/H2&gt;&lt;H3 id="toc-hId-1302317988"&gt;Add data to an existing model&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;In your model details, you will find a new entry in the ‘Data’ section which is called ‘External Live Version Data Sources’&lt;/LI&gt;&lt;LI&gt;Here, ‘Connect External Data Source’&lt;/LI&gt;&lt;LI&gt;Choose an existing target version for the data source or create a blank version&lt;/LI&gt;&lt;LI&gt;Choose your fact view from your model’s SAP Datasphere space&lt;/LI&gt;&lt;LI&gt;Map the data source columns to your model’s columns&lt;UL&gt;&lt;LI&gt;Not all source columns need to be mapped&lt;/LI&gt;&lt;LI&gt;Not all target columns need to be mapped&lt;UL&gt;&lt;LI&gt;Measures can be &lt;EM&gt;NULL&lt;/EM&gt;&lt;/LI&gt;&lt;LI&gt;Dimensions can receive a default member&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;Certain data type differences can be handled&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;If we detect a mismatch between the live version and your master data, we will notify you and you can add missing dimension members directly (not shown in the video)&lt;/LI&gt;&lt;LI&gt;You’re done! You can add more sources to the model, if you want&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adding a live version to a model" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/327483i1D3D3E0DF1214EC6/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="ExtVersion_Blog.gif" alt="Adding a live version to a model" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;Adding a live version to a model&lt;/span&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1105804483"&gt;Build a model from an SAP Datasphere view&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;Create a new model&lt;/LI&gt;&lt;LI&gt;‘Start with data’&lt;/LI&gt;&lt;LI&gt;Select SAP Datasphere as data storage location (=use seamless planning)&lt;/LI&gt;&lt;LI&gt;Select a space. The view you want to use as basis for the planning model must be in the same space or shared with the space&lt;/LI&gt;&lt;LI&gt;Select SAP Datasphere as datasource&lt;/LI&gt;&lt;LI&gt;Select your view&lt;/LI&gt;&lt;LI&gt;You now already see the live connection to the source view data&lt;/LI&gt;&lt;LI&gt;Create dimension tables as needed&lt;/LI&gt;&lt;LI&gt;Save the model&lt;/LI&gt;&lt;LI&gt;You’re done!&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Creating a model from an SAP Datasphere view" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/327484i51C5F095BEE2534E/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="ExtVersion_Blog2.gif" alt="Creating a model from an SAP Datasphere view" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;Creating a model from an SAP Datasphere view&lt;/span&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-780208259"&gt;A usage example&lt;/H2&gt;&lt;P&gt;In the following example, we add headcount (full-time equivalent / FTE) data to the previously created sales planning model because we want to add a calculation of revenue generated per sales employee.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;We have an FTE planning model which is deployed to our SAP Datasphere space. Note that the fact table is exposed in the data builder.&lt;/LI&gt;&lt;LI&gt;We create a view on the fact table with a filter on sales employees in SAP Datasphere&lt;/LI&gt;&lt;LI&gt;We add the view to our sales planning model, do the mappings and add a calculation&lt;/LI&gt;&lt;LI&gt;In the story, we see the live data from the FTE planning model and the calculation result&lt;/LI&gt;&lt;LI&gt;When we change data in the FTE planning and publish it, the calculation in the sales model is refreshed in real-time&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Referring to data from another planning model" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/327485iA68D040563AB2725/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="ExtVers_Blog_FTE.gif" alt="Referring to data from another planning model" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;Referring to data from another planning model&lt;/span&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-583694754"&gt;FAQ&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;Where can I use this feature?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This feature is available for SAP Analytics Cloud models that use SAP Datasphere as data storage location (=seamless planning models).&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Can I use any fact table/view from SAP Datasphere?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;You can use fact views that are exposed for consumption. They must be available in the space that your model is deployed to. They can be shared with the space as well.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Can I also add data from other planning models?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;You can add data from other seamless planning models if they are deployed and exposed in the same space or if the exposed data has been shared from another space. You need to create a view on top of the tables which is exposed for consumption.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;What can I do with live versions? (And what can I not do?)&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;You can display the live version data in the model data foundation and in tables, charts, etc. in stories.&lt;/P&gt;&lt;P&gt;You can reference the live version data in model and story calculations as well as data actions (incl. advanced formulas).&lt;/P&gt;&lt;P&gt;You cannot write back into the referenced views (or rather their underlying tables). You can copy the live version data into planning versions via copy/paste in the table, data actions and version management.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;How do I see if data is live or not?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;In models, a live version is highlighted in the data preview. In the version dimension, you see the data source per version. &amp;nbsp;&lt;/P&gt;&lt;P&gt;In tables, live version data is locked for data entry and formatted accordingly. Reasons for unplannable data give accurate information.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Is SAP Datasphere Data Access Control considered?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Yes, it is.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Do planners need to have certain roles in SAP Datasphere?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Only if a user has a consumer role for the underlying space, he will be able to see live version data. Otherwise, he can use the planning model but will not see live version data.&lt;/P&gt;&lt;P&gt;Data access control applies as well.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;What about live access to master data?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Live access to master data is future enhancement with high priority.&lt;/P&gt;&lt;H2 id="toc-hId-387181249"&gt;Conclusion&lt;/H2&gt;&lt;P&gt;Live versions bring seamless planning to the next level and unlock a lot of value for planning in SAP Business Data Cloud. I am delighted to announce the general availability in Q4 2025.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/unlocking-the-next-chapter-of-seamless-planning-in-sap-business-data-cloud/ba-p/14243864"/>
    <published>2025-10-14T20:34:01.157000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/sap-bdc-enhance-a-bw-data-product-with-sap-databricks/ba-p/14242606</id>
    <title>SAP BDC - Enhance a BW Data product with SAP Databricks</title>
    <updated>2025-10-15T09:14:54.994000+02:00</updated>
    <author>
      <name>daniele_cortopassi</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/662700</uri>
    </author>
    <content>&lt;P&gt;This two-part blog series — created by the Italian Solution Advisory team — provides an end-to-end guide for SAP BW customers looking to modernize their analytics landscape using SAP Business Data Cloud (BDC).&lt;/P&gt;&lt;P&gt;The following diagram summarizes the overall workflow of the activities:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_0-1760369423014.png" style="width: 865px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326860iF5DFAB48C4FF1D99/image-dimensions/865x785?v=v2" width="865" height="785" role="button" title="daniele_cortopassi_0-1760369423014.png" alt="daniele_cortopassi_0-1760369423014.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The first chapter of the series is structured as follows:&lt;/P&gt;&lt;P&gt;1 - Create a data product subscription to a custom BW infoprovider and replicate the data into SAP BDC&lt;BR /&gt;2 - Govern the custom data product access by data catalog sharing&lt;/P&gt;&lt;P&gt;The second one will be available shortly with this content:&lt;/P&gt;&lt;P&gt;3 - Derive insights by leveraging SAP Databricks ML capabilities&lt;BR /&gt;4 - Incorporate results to support business decisions&lt;/P&gt;&lt;P&gt;Our goal is to demonstrate how SAP BDC can accelerate BW modernization — delivering a state-of-the-art, end-to-end data management and analytics experience.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Prerequisites&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The BW Data Product Generator requires at least the following product versions:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;SAP BW 7.50 SP24 PCE&lt;/LI&gt;&lt;LI&gt;SAP BW/4HANA 2021 SP4 PCE&lt;/LI&gt;&lt;LI&gt;SAP BW/4HANA 2023 SP00 PCE&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Our Suggested product version as of September 2025 (to include SAP NOTE &lt;A href="https://me.sap.com/notes/3596356" target="_blank" rel="noopener noreferrer"&gt;3596356&lt;/A&gt; and &lt;A href="https://me.sap.com/notes/3628590" target="_blank" rel="noopener noreferrer"&gt;3628590&lt;/A&gt;) are the followings:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;SAP BW 7.50 SP34&lt;/LI&gt;&lt;LI&gt;SAP BW/4HANA 2021 SP13&lt;/LI&gt;&lt;LI&gt;SAP BW/4HANA 2023 SP06&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt; This blog does not cover configuration steps — we assume the system has been set up according to the guidance in&amp;nbsp;&lt;SPAN&gt;SAP Note&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://me.sap.com/notes/3590400/E" target="_blank" rel="noopener noreferrer"&gt;3590400&lt;/A&gt;&lt;/P&gt;&lt;P&gt;In our example we will use as source SAP BW/4HANA 2023 SP03&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Create a data product subscription to custom BW infoprovider and replicate the data into SAP BDC&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;In BW/4HANA, we’ve created a very simple model to collect data from the FI_GL_4 datasource connected to SAP S/4HANA, then a straightforward Composite Provider (ZIT_CFGLI) on top of the persistent ADSO&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_0-1760365304865.png" style="width: 259px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326812iFA053A4143ECCD61/image-dimensions/259x225?v=v2" width="259" height="225" role="button" title="daniele_cortopassi_0-1760365304865.png" alt="daniele_cortopassi_0-1760365304865.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;We developed also a process chain to provision the data periodically:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_1-1760365316157.png" style="width: 800px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326813iA37B8C53AADE72AA/image-dimensions/800x172?v=v2" width="800" height="172" role="button" title="daniele_cortopassi_1-1760365316157.png" alt="daniele_cortopassi_1-1760365316157.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;We’ll use the Data product Generator (DPG) on the Composite provider&lt;/P&gt;&lt;P&gt;To start, open the BW/4HANA Cockpit. If your user has the role&lt;STRONG&gt; SAP_BW4_MODELER_FOR_BDC&lt;/STRONG&gt; you’ll see a dedicated tab with giving access to the &lt;STRONG&gt;Data Subscription&lt;/STRONG&gt; app:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_2-1760365394060.png" style="width: 777px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326815i230AE4DFC8639C26/image-dimensions/777x169?v=v2" width="777" height="169" role="button" title="daniele_cortopassi_2-1760365394060.png" alt="daniele_cortopassi_2-1760365394060.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The app lists all the current subscriptions (including attempted ones) and provide an overall status:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_3-1760365425370.png" style="width: 770px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326816iE694A86734DEBB03/image-dimensions/770x102?v=v2" width="770" height="102" role="button" title="daniele_cortopassi_3-1760365425370.png" alt="daniele_cortopassi_3-1760365425370.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;To create a new subscription just hit o the Create button and in the following form select the BW infoprovider you want to subscribe to:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_4-1760365447187.png" style="width: 769px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326817i0D1F2187CF6B5786/image-dimensions/769x210?v=v2" width="769" height="210" role="button" title="daniele_cortopassi_4-1760365447187.png" alt="daniele_cortopassi_4-1760365447187.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Depending on the BW version the supported infoproviders are:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Physical providers: Infocubes, DSO and ADSO, InfoObjects&lt;/LI&gt;&lt;LI&gt;Virtual providers: Composite provider and Multiprovider&lt;/LI&gt;&lt;LI&gt;Query as infoprovider&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Once the source infoprovider is selected just click on Save at the bottom&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_5-1760365471899.png" style="width: 892px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326819i7A774A7EED53B277/image-dimensions/892x116?v=v2" width="892" height="116" role="button" title="daniele_cortopassi_5-1760365471899.png" alt="daniele_cortopassi_5-1760365471899.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;At this stage, nothing is generated. To generate the target artifact in SAP Datasphere, it is necessary to activate the subscription&lt;STRONG&gt;.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Before activating, here aresome details about the current options available with the DPG:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;EM&gt;Settings Tab&lt;/EM&gt;:&lt;UL&gt;&lt;LI&gt;It allows to select between Full or Delta execution mode, currently Delta and Streaming mode is not supported.&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_6-1760365666722.png" style="width: 455px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326822i8BF7B5DD990CD863/image-dimensions/455x201?v=v2" width="455" height="201" role="button" title="daniele_cortopassi_6-1760365666722.png" alt="daniele_cortopassi_6-1760365666722.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;it allows to set filters&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_7-1760365666724.png" style="width: 642px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326823i45BFA300A9D397BA/image-dimensions/642x121?v=v2" width="642" height="121" role="button" title="daniele_cortopassi_7-1760365666724.png" alt="daniele_cortopassi_7-1760365666724.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;it allows to link a process chain variant:&lt;P&gt;A specific process variant: Data Provisioning Subscription (in section Load Process and Postprocessing) allow to link the update of the data in the data product with the execution of a process chain&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_8-1760365724209.png" style="width: 655px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326824iFAF0D12BBB4A73EC/image-dimensions/655x320?v=v2" width="655" height="320" role="button" title="daniele_cortopassi_8-1760365724209.png" alt="daniele_cortopassi_8-1760365724209.png" /&gt;&lt;/span&gt;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_9-1760365724210.png" style="width: 633px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326825iAB88875872F35418/image-dimensions/633x223?v=v2" width="633" height="223" role="button" title="daniele_cortopassi_9-1760365724210.png" alt="daniele_cortopassi_9-1760365724210.png" /&gt;&lt;/span&gt;&lt;UL&gt;&lt;LI&gt;&lt;EM&gt;Projections Tab&lt;/EM&gt;&lt;UL&gt;&lt;LI&gt;it allows to exclude some columns from the visibility in the Data product&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_10-1760365724213.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326826i75DB96F7C0D3B4F2/image-size/medium?v=v2&amp;amp;px=400" role="button" title="daniele_cortopassi_10-1760365724213.png" alt="daniele_cortopassi_10-1760365724213.png" /&gt;&lt;/span&gt;&lt;UL&gt;&lt;LI&gt;&lt;EM&gt;Local table Tab&lt;/EM&gt;&lt;UL&gt;&lt;LI&gt;it contains log information available after the Run&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_11-1760365724215.png" style="width: 675px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326827iA5A1E2ADBB883FBD/image-dimensions/675x186?v=v2" width="675" height="186" role="button" title="daniele_cortopassi_11-1760365724215.png" alt="daniele_cortopassi_11-1760365724215.png" /&gt;&lt;/span&gt;&lt;P&gt;With the activation a new artifact will be deployed in a dedicated Datasphere Space the deploys data on SAP HANA Data lake files&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_12-1760365967279.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326830iB5CC9023C392851B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="daniele_cortopassi_12-1760365967279.png" alt="daniele_cortopassi_12-1760365967279.png" /&gt;&lt;/span&gt;&lt;P&gt;This space doesn’t allow&amp;nbsp; any transformation of data or further modeling. It is designed to receive the BW infoprovider metadata and data and make it shareable with other spaces in SAP Datasphere, in details:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;You cannot change the properties of the local tables (file) generated from&amp;nbsp;SAP BW.&lt;/LI&gt;&lt;LI&gt;Delta capture is either OFF or ON, and you can't change it. If it's OFF, it won't track the delta capture changes, but it will keep historical snapshot versions.&lt;/LI&gt;&lt;LI&gt;Restoring to a previous version is not possible. You can only display a previous version.&lt;/LI&gt;&lt;LI&gt;If partitions were defined on the&amp;nbsp;SAP BW&amp;nbsp;side at table creation, you can see them (but you can't change them or create new ones).&lt;/LI&gt;&lt;LI&gt;Find and Replace&amp;nbsp;is not available.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;At this stage we can activate our subscription with the Activate button at the bottom&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_13-1760365967280.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326831iD0D7AF95C01A54A4/image-size/medium?v=v2&amp;amp;px=400" role="button" title="daniele_cortopassi_13-1760365967280.png" alt="daniele_cortopassi_13-1760365967280.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;A background job in SAP Datasphere will be responsible for creating and deploying a Local Table (File) in the BW target space, this will take a couple of minutes.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;This is the reference architecture available from the&amp;nbsp;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/be5967d099974c69b77f4549425ca4c0/72a055fc7dad40079efa442ddd4b998e.html" target="_self" rel="noopener noreferrer"&gt;help.sap.com&lt;/A&gt;&amp;nbsp; &amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_14-1760366114452.png" style="width: 743px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326834iA0DDE054D5D15DA2/image-dimensions/743x489?v=v2" width="743" height="489" role="button" title="daniele_cortopassi_14-1760366114452.png" alt="daniele_cortopassi_14-1760366114452.png" /&gt;&lt;/span&gt;&lt;P&gt;What you can then see in SAP Datasphere in the BW target space is the following:&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_15-1760366146397.png" style="width: 580px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326836iAE7B511F745FEC4F/image-dimensions/580x548?v=v2" width="580" height="548" role="button" title="daniele_cortopassi_15-1760366146397.png" alt="daniele_cortopassi_15-1760366146397.png" /&gt;&lt;/span&gt;&lt;P&gt;With the Activation we’ve create the structure of the target table, no data have been replicated yet, to do so is necessary to run the job that provisions the data:&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_16-1760366146399.png" style="width: 772px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326835iD6172EA7E873BC27/image-dimensions/772x83?v=v2" width="772" height="83" role="button" title="daniele_cortopassi_16-1760366146399.png" alt="daniele_cortopassi_16-1760366146399.png" /&gt;&lt;/span&gt;&lt;P&gt;The run starts an asynchronous job that transfers all the data, based on the settings that have been defined.&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_17-1760366206421.png" style="width: 780px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326837i3E214CFB5F5F90C7/image-dimensions/780x160?v=v2" width="780" height="160" role="button" title="daniele_cortopassi_17-1760366206421.png" alt="daniele_cortopassi_17-1760366206421.png" /&gt;&lt;/span&gt;&lt;P&gt;Depending on the amount of data, you’ll then see your records in the Datasphere table:&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_18-1760366206424.png" style="width: 778px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326838i175AAA294EEEBF8F/image-dimensions/778x249?v=v2" width="778" height="249" role="button" title="daniele_cortopassi_18-1760366206424.png" alt="daniele_cortopassi_18-1760366206424.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Govern the Custom data product access by data catalog sharing&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Now that the BW data is available in SAP Datasphere, we can create a Data Product — making it shareable and consumable across other BDC services.&lt;/P&gt;&lt;P&gt;To create the Data product, we’ll use the Data Sharing Cockpit in Datasphere.&lt;/P&gt;&lt;P&gt;In this section, we’ll focus only on the key steps to complete the workflow. For detailed guidance on the Data Sharing Cockpit, refer to the official SAP documentation.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_0-1760366486979.png" style="width: 808px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326840i9F0CB0F83D8B3AC5/image-dimensions/808x404?v=v2" width="808" height="404" role="button" title="daniele_cortopassi_0-1760366486979.png" alt="daniele_cortopassi_0-1760366486979.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;First of all make sure to have a valid Data Provider profile enabled or create a new one (&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/e4059f908d16406492956e5dbcf142dc/4d298f8654fe4a6c9b6a4399a9e14c77.html" target="_blank" rel="noopener noreferrer"&gt;link&lt;/A&gt;)&lt;/P&gt;&lt;P&gt;The fundamental property that is necessary to set in the profile is the Data provider\Data product visibility to Formations, this will allow to share data products within all services belonging to SAP BDC&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_1-1760366486982.png" style="width: 760px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326841iF0AE1E3872079DC9/image-dimensions/760x669?v=v2" width="760" height="669" role="button" title="daniele_cortopassi_1-1760366486982.png" alt="daniele_cortopassi_1-1760366486982.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once a valid Data provider profile has been set up, is possible to create the data product from My Data product (&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/e4059f908d16406492956e5dbcf142dc/bbcbf42b0cb541529e63628d95f394c8.html" target="_blank" rel="noopener noreferrer"&gt;link&lt;/A&gt;)&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_2-1760366486985.png" style="width: 781px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326842i7FAA1F8A1D0FA03C/image-dimensions/781x274?v=v2" width="781" height="274" role="button" title="daniele_cortopassi_2-1760366486985.png" alt="daniele_cortopassi_2-1760366486985.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Provide a Business name and a Technical name to the Data Product:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_3-1760366486985.png" style="width: 508px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326846i5049630A24F59C51/image-dimensions/508x178?v=v2" width="508" height="178" role="button" title="daniele_cortopassi_3-1760366486985.png" alt="daniele_cortopassi_3-1760366486985.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Assign a meaningful description:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_4-1760366486986.png" style="width: 691px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326844i9CC46CD96F490C82/image-dimensions/691x178?v=v2" width="691" height="178" role="button" title="daniele_cortopassi_4-1760366486986.png" alt="daniele_cortopassi_4-1760366486986.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;And product details:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_5-1760366486991.png" style="width: 880px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326843iD652F44CFBDC523A/image-dimensions/880x245?v=v2" width="880" height="245" role="button" title="daniele_cortopassi_5-1760366486991.png" alt="daniele_cortopassi_5-1760366486991.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In section Product artifacts is necessary to select the Datasphere Space where BW targets the generation of artifacts via DPG and then with Add artifacts button insert the Local Table(file) we created&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_6-1760366486993.png" style="width: 902px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326847i66943CEBA7FD9250/image-dimensions/902x226?v=v2" width="902" height="226" role="button" title="daniele_cortopassi_6-1760366486993.png" alt="daniele_cortopassi_6-1760366486993.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;At the end just save the changes&lt;/P&gt;&lt;P&gt;Once the Product is saved is necessary to switch the status to List:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_7-1760366486993.png" style="width: 895px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326848iA61284F766C9647C/image-dimensions/895x75?v=v2" width="895" height="75" role="button" title="daniele_cortopassi_7-1760366486993.png" alt="daniele_cortopassi_7-1760366486993.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;We can now see the data product in the Datasphere Catalog:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_8-1760366840482.png" style="width: 899px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326851iD604455C9A34EAAD/image-dimensions/899x337?v=v2" width="899" height="337" role="button" title="daniele_cortopassi_8-1760366840482.png" alt="daniele_cortopassi_8-1760366840482.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The same data product is also obviously visible within SAP BDC Cockpit&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="daniele_cortopassi_9-1760366840484.png" style="width: 902px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/326852iBFF543DE25E1380B/image-dimensions/902x338?v=v2" width="902" height="338" role="button" title="daniele_cortopassi_9-1760366840484.png" alt="daniele_cortopassi_9-1760366840484.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Stay tuned for the next chapter of this series, where we’ll share the newly created Data Product with SAP Databricks and enhance it using machine learning capabilities.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-bdc-enhance-a-bw-data-product-with-sap-databricks/ba-p/14242606"/>
    <published>2025-10-15T09:14:54.994000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/sac-seamless-planning-model-design-principles-compared-to-sap-bw/ba-p/14242687</id>
    <title>SAC seamless planning: Model design principles - compared to SAP BW</title>
    <updated>2025-10-15T10:16:53.034000+02:00</updated>
    <author>
      <name>Tano_B</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1661359</uri>
    </author>
    <content>&lt;P&gt;&lt;FONT color="#000000"&gt;After years of developing planning solutions with SAP BW Integrated Planning and BPC, I recently completed a SAC Planning project with seamless planning. Coming from a BW IP/BPC background, I initially tried to replicate familiar structures in SAC. But I quickly realized that SAC’s flexibility requires a different mindset, starting with model design and granularity.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;In this first blog post, I’ll share model design decisions, and practical tips for BW developers moving to SAC Planning. This blog post shall also help developers without BW background by highlighting the restrictions of certain functionalities in SAC. Finally, I also want to show you the potential additional value of seamless planning for your planning project.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;1. SAC vs. SAP BW modelling: general background information&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;In SAC, the new model is a mixture of InfoCube-like and a direct-update planning ADSO in BW. All characteristics are keys (InfoCube-like), but there is only an active table (direct-update). Furthermore, measures in SAC models cannot be of a text/characteristic type. So,&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;there are no requests, no chance to roll back&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;no inherited delta mechanism&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;no characteristic as key figure.&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;But SAC models come with a Standard data audit functionality, that works out of the box (except for import jobs). Because of the missing requests in SAC, planning functions should be kept simple.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="5" color="#000000"&gt;&lt;STRONG&gt;2. Model Design: SAC is not BW&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="3" color="#000000"&gt;When designing planning solutions in SAC, I recommend you to break down planning requirements across multiple models. In SAP BW, developers were required to create composite providers and aggregation levels (and input enabled queries) on top of ADSOs to structure planning logic. SAC does not have those intermediate layers, which can accelerate development. But this simplicity also introduces challenges when trying to consolidate everything into a single model.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;&lt;STRONG&gt;Here are a few examples:&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;Any data entry creates an edit version. If multiple planning scenarios share one model, SAC shows the “Publish Data” banner across all stories when you edit plan data in one story.&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;The SAC Excel Add-In allows end users to plan on ad-hoc created tables, which can be convenient for flexibility. However, this becomes significantly more critical when SAC models are large and complex. In such cases, ad-hoc planning can bypass frontend validations (for instance, javascript logic in stories), leading to inconsistencies and governance challenges (check comments here&amp;nbsp;&lt;A href="https://influence.sap.com/sap/ino/#/idea/296876/?section=sectionDetails" target="_self" rel="noopener noreferrer"&gt;Ability to disable planning option in SAC Cloud excel add-in centrally by admin&lt;/A&gt;).&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;Upload jobs in SAC cannot derive master data automatically. In huge models, this often leads to wide files with many columns.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;Data validations are less robust than characteristic relationships in BW. They must be handled manually in Data Actions and carefully considered during story design, since SAC still allows "unassigned" values even when validations are defined.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;Data point comments are more fragile. Because they depend on the full navigation state, they can be lost more easily in huge models.&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;These limitations highlight the need to rethink model design. Instead of treating an SAC planning model like a BW ADSO, it’s more accurate to compare it to an aggregation level or even an input enabled query. It's a layer tailored to specific planning logic.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;3. How does seamless planning help?&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;Seamless planning let's you expose your fact and dimension tables to Datasphere. Hence, you can bring together the data of your different models more easily for reporting purposes instead of having a lot of cross model copies in native SAC.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;You can also&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;add SQLscript logic,&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;enrich your plan data with&amp;nbsp;Datasphere tables for configuration/customizing (multiple keys and characteristics as non-key fields),&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;or leveraging public dimensions exposed from SAC (single key).&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;The results can be consumed&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;FONT size="3" color="#000000"&gt;via real-time reporting (Datasphere Analytic Models)&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;or via import jobs to SAC models.&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;4. What's next?&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="3" color="#000000"&gt;With the Q4/2025 update, seamless planning shall become bidirectional, meaning that the View data in Datasphere can be added to SAC models as read-only version. This update will make Datasphere data better accessible.&amp;nbsp;It&lt;SPAN&gt;&amp;nbsp;will support direct consumption of Datasphere fact data in planning models, which will let you have a single planning enabled table with real-time reference data from other planning models.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="5" color="#000000"&gt;&lt;STRONG&gt;Summary&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;&lt;STRONG&gt;Model design matters&lt;/STRONG&gt;: Avoid putting all planning scenarios into one model. SAC lacks BW’s aggregation layer, so splitting models improves performance and governance.&amp;nbsp;&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;&lt;STRONG&gt;Seamless Planning&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;currently focuses on exposing SAC fact and dimension tables to SAP Datasphere, enabling integrated reporting and SQLScript-based logic. It will help you implementing a federated planning landscape in SAC.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;&lt;STRONG&gt;Always keep the Roadmap in mind&lt;/STRONG&gt;: By Q4/2025, SAC will support direct consumption of Datasphere fact data in planning models, reducing reliance on import jobs and enabling real-time integration in planning enabled crosstabs.&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/sac-seamless-planning-model-design-principles-compared-to-sap-bw/ba-p/14242687"/>
    <published>2025-10-15T10:16:53.034000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/sap-datasphere-news-in-september/ba-p/14235999</id>
    <title>SAP Datasphere News in September</title>
    <updated>2025-10-16T06:00:00.038000+02:00</updated>
    <author>
      <name>kpsauer</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14110</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;SAP Datasphere News in September&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Another month with two nice new release deliveries &lt;span class="lia-unicode-emoji" title=":sparkles:"&gt;✨&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Learn more in my short top features video in September 2025 on YouTube &lt;span class="lia-unicode-emoji" title=":television:"&gt;📺&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In addition, explore the latest updates in our community news blogs and more.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Slide9.PNG" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/323393iAC5024206C279836/image-size/large?v=v2&amp;amp;px=999" role="button" title="Slide9.PNG" alt="Slide9.PNG" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt; &lt;/P&gt;&lt;H2 id="toc-hId-1761912904"&gt;My top features in September&lt;/H2&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1694482118"&gt;Input Parameters in Task Chains and Transformation Flows&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;You can now define input parameters on the task level of task chains and also for transformation flows. &lt;/SPAN&gt;A scheduled transformation flow uses the default value of the input parameter. Input parameters defined in transformation flows can be used in operators within the transformation flow, except for the Python operation in Apache Spark runtime.&lt;/P&gt;&lt;P&gt;A transformation flow executed as part of a task chain receives input parameters from the task chain. &lt;SPAN&gt;This will allow for more flexible usage of task chains and even nested task chains.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;A href="https://help.sap.com/docs/PRODUCTS/d4185d7d9a634d06a5459c214792c67e/f7161e6c20204672ac4a6d90c81762e4.html?version=cloud&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;Creating a Transformation Flow&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;A href="https://help.sap.com/docs/PRODUCTS/d4185d7d9a634d06a5459c214792c67e/c9906ec515f04fbd9589c59339b03c6c.html?version=cloud&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;Creating Input Parameters in Task Chains&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1497968613"&gt;Email notification in Replication Flows&lt;/H3&gt;&lt;P&gt;You can setup email notifications to stay informed when individual replication objects fail in a running replication flow. From both the Replication Flow editor or the Flows monitor, you can setup an email notification for failures of an individual object in a replication flow.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;A href="https://help.sap.com/docs/PRODUCTS/d4185d7d9a634d06a5459c214792c67e/5dc4db23d3894b10aca6ade3c666554d.html?version=cloud&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;Configure Email Notification for Replication Flow Failure at Object Level&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;A href="https://help.sap.com/docs/PRODUCTS/d4185d7d9a634d06a5459c214792c67e/da62e1ee746448e8bc043e1be4377cbe.html?version=cloud&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;Working With Existing Replication Flow Runs&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1301455108"&gt;Fiscal Time Dimension&lt;/H3&gt;&lt;P&gt;When creating a time dimension view, you now have the option for dimension type &lt;EM&gt;Standard&lt;/EM&gt; and &lt;EM&gt;Fiscal Time&lt;/EM&gt;. You use the new Fiscal Time dimension type to model your fiscal time periods and the columns that define their starts and ends. When you add a fiscal time dimension to an analytic model, a Fiscal Variant variable is created for this dimension. The variable can then be handled like any other variable. Its data type is derived from the fiscal variance column from the fiscal time dimension.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&lt;/SPAN&gt;&amp;nbsp;&amp;nbsp;&lt;A href="https://help.sap.com/docs/PRODUCTS/d4185d7d9a634d06a5459c214792c67e/5aae0e95361a4a4c964e69c52eada87d.html?version=cloud&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;More information&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1104941603"&gt;Structure Support for Analytic Models&lt;/H3&gt;&lt;P&gt;In order to create restrictions and calculations across all measures of an analytic model, you can create structures. Structures help you to save time and ensure consistency in your calculations, as you don’t need to create a formula/calculation for each measure. &lt;SPAN&gt;In the data preview, the structure members are displayed in their own section. When you use a structure member in the drill-down of a preview, the restriction and calculations defined in the structure member will be applied to each measure. Structures can also be used and enhanced&amp;nbsp;in&amp;nbsp;SAP Analytics Cloud. When the analytic model has measures&amp;nbsp;and at least one&amp;nbsp;structure you&amp;nbsp;need to&amp;nbsp;define how the calculations should be prioritized. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&amp;nbsp;&lt;A href="https://help.sap.com/docs/PRODUCTS/d4185d7d9a634d06a5459c214792c67e/de1ed4742dec44088236131e239df8b9.html?version=cloud&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;More information&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;div class="video-embed-center video-embed"&gt;&lt;iframe class="embedly-embed" src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FkvIhMO5u3Jc&amp;amp;display_name=YouTube&amp;amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DkvIhMO5u3Jc&amp;amp;image=http%3A%2F%2Fi.ytimg.com%2Fvi%2FkvIhMO5u3Jc%2Fhqdefault.jpg&amp;amp;type=text%2Fhtml&amp;amp;schema=youtube" width="400" height="225" scrolling="no" title="YouTube embed" frameborder="0" allow="autoplay; fullscreen; encrypted-media; picture-in-picture;" allowfullscreen="true"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-779345379"&gt;&lt;SPAN&gt;SAP Business Data Cloud Getting Started Series&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="kpsauer_0-1759765981803.jpeg" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/323394i3A793FAD592A45FD/image-size/large?v=v2&amp;amp;px=999" role="button" title="kpsauer_0-1759765981803.jpeg" alt="kpsauer_0-1759765981803.jpeg" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Starting September 10, the Getting Started Series kicks off with four modules &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Module 1: Build an Intelligent Application Grounded in Data Products (Sep 10, 2025)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Module 2: Fuel AI Innovation with SAP Databricks in Business Data Cloud (Sep 24, 2025)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Module 3: Create and Enrich an Analytical Model with SAP Datasphere (Oct 8, 2025)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Module 4: From Ingredients to Impact: How Döhler built a data fabric for data and AI (Oct 22, 2025)&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":backhand_index_pointing_right:"&gt;👉&lt;/span&gt;&lt;SPAN&gt;Sign up today on the &lt;A href="https://event.on24.com/wcc/r/5049141/155E33D499506054AF6FD5A553C2BD38/6298861" target="_blank" rel="noopener nofollow noreferrer"&gt;registration page&lt;/A&gt;. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;Check out the&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/step-by-step-guide-getting-started-with-the-sap-business-data-cloud-basic/ba-p/14172806" target="_blank"&gt;Step-By-Step Guide: Getting started with the SAP Business Data Cloud Basic Trial&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-582831874"&gt;More blogs about SAP BDC and Datasphere to check out &lt;span class="lia-unicode-emoji" title=":backhand_index_pointing_down:"&gt;👇&lt;/span&gt;&lt;/H2&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/enterprise-architecture-blog-posts/integrating-sap-datasphere-with-s-4hana-in-ecs/ba-p/14214268" target="_blank"&gt;Integrating SAP Datasphere with S/4HANA in ECS&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/enterprise-architecture-blog-posts/highlights-enterprise-architects-guide-on-sap-bw-modernization/ba-p/14226193" target="_blank"&gt;Highlights: Enterprise Architects Guide on SAP BW Modernization &lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/from-rest-to-datasphere-a-cap-based-integration-approach/ba-p/14218922" target="_blank"&gt;From REST to Datasphere: A CAP-based Integration Approach&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/choosing-the-right-sap-analytics-tool-features-benefits-and-strategy/ba-p/14230016" target="_blank"&gt;Choosing the Right SAP Analytics Tool: Features, Benefits, and Strategy&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/archive-sac-change-docs-into-datasphere/ba-p/14229415" target="_blank"&gt;Archive SAC Change Docs into Datasphere&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/unsupported-features-with-sap-datasphere-live-connections-in-sap-analytics/ba-p/14228053" target="_blank"&gt;Unsupported Features with SAP Datasphere Live Connections in SAP Analytics Cloud&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/human-capital-management-blog-posts-by-members/seeing-skills-before-they-matter-people-intelligence-in-sap-successfactors/ba-p/14226130" target="_blank"&gt;Seeing Skills Before They Matter: People Intelligence in SAP SuccessFactors&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/community-corner-blog-posts/unleashing-creativity-with-cloud-based-ai-apps-2025-premium-hub-coe-high/ba-p/14195307" target="_blank"&gt;Unleashing Creativity with Cloud-Based AI Apps: 2025 Premium Hub CoE High School Summer Orientation&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/building-custom-llm-agent-in-databricks-an-example-generating-ai-responses/ba-p/14223274" target="_blank"&gt;Building Custom LLM Agent in Databricks: An Example Generating AI Responses from Customer Review&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/fortaleza-blog-posts/o-que-%C3%A9-o-sap-datasphere/ba-p/14227147" target="_blank"&gt;O que é o SAP Datasphere?&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-datasphere-integration-with-sap-s-4hana-sap-cloud-connector-setup-guide/ba-p/14224459" target="_blank"&gt;SAP Datasphere Integration with SAP S/4HANA: SAP Cloud Connector Setup Guide&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/planning-amp-analytics-p-amp-a-is-an-essential-part-of-sap-business-data/ba-p/14223762" target="_blank"&gt;Planning &amp;amp; Analytics (P&amp;amp;A) is an essential part of SAP Business Data Cloud (SAP BDC)&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/shanghai-blog-posts-%E5%8D%9A%E5%AE%A2/sap-business-data-cloud%E4%B8%AD%E6%96%87%E5%85%A5%E9%97%A8%E5%90%AF%E5%8A%A8%E4%B9%8B%E6%97%85-%E8%A7%86%E9%A2%91%E8%AE%B2%E8%A7%A3/ba-p/14225129" target="_blank"&gt;SAP Business Data Cloud中文入门启动之旅 视频讲解&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-business-data-cloud-from-provisioning-to-intelligent-applications/ba-p/14224669" target="_blank"&gt;SAP Business Data Cloud - From Provisioning to Intelligent Applications&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sapinsider-emea-2025-in-three-easy-steps/ba-p/14224371" target="_blank"&gt;SAPinsider EMEA 2025 in Three Easy Steps&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/build-a-data-driven-enterprise-with-sap-s-data-amp-analytics-advisory/ba-p/14224035" target="_blank"&gt;Build a Data-Driven Enterprise with SAP’s Data &amp;amp; Analytics Advisory Methodology&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/building-enterprise-ready-data-products-with-sap-business-data-cloud/ba-p/14223082" target="_blank"&gt;Building Enterprise Ready Data Products with SAP Business Data Cloud&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-blog-posts/e-learning-sap-datasphere-security-amp-data-access-controls/ba-p/14213412" target="_blank"&gt;E-Learning: SAP Datasphere Security &amp;amp; Data Access Controls&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/sap-for-utilities-blogs/unlocking-a-cleaner-and-greener-energy-future-with-ai/ba-p/14220956" target="_blank"&gt;Unlocking a Cleaner and Greener Energy Future with AI&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-blog-posts/e-learning-hybrid-integration-between-sap-analytics-cloud-and-sap/ba-p/14211207" target="_blank"&gt;E-Learning: Hybrid integration between SAP Analytics Cloud and SAP BusinessObjects BI&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-technical-user-in-sap-datasphere-consumption-apis-client-credentials/ba-p/14218919" target="_blank"&gt;Using Technical User in SAP Datasphere Consumption APIs (Client Credentials)&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/enterprise-architecture-blog-posts/session-1-recap-amp-highlight-sap-bdc-the-future-of-intelligent-data/ba-p/14218631" target="_blank"&gt;Session 1 Recap &amp;amp; Highlight - SAP BDC The Future of Intelligent Data Architectures&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/how-to-add-bw-last-data-update-field-to-sap-analytics-cloud-datasphere-sap/ba-p/14220846" target="_blank"&gt;How to add BW Last Data Update field to SAP Analytics Cloud + Datasphere (SAP Note 2706430)&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-blog-posts/erp-centric-planning-with-sap-analytics-cloud-and-sap-s-4hana/ba-p/14214876" target="_blank"&gt;ERP-Centric Planning with SAP Analytics Cloud and SAP S/4HANA&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/ai-assisted-data-quality-screening-in-sap-business-data-cloud/ba-p/14218695" target="_blank"&gt;AI Assisted Data Quality Screening in SAP Business Data Cloud&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-blog-posts/e-learning-series-sap-datasphere-connectivity/ba-p/14211076" target="_blank"&gt;E-Learning series: SAP Datasphere Connectivity&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-blog-posts/enabling-the-business-data-fabric-of-sap/ba-p/14212271" target="_blank"&gt;Enabling the Business Data Fabric of SAP&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-blog-posts/sap-business-data-cloud-overview-and-guide-to-further-learning-and/ba-p/14211212" target="_blank"&gt;SAP Business Data Cloud – Overview and Guide to Further Learning and Resources&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-btp-weekly-seguridad-reforzada-ia-aplicada-y-nuevas-alianzas/ba-p/14217615" target="_blank"&gt;SAP BTP Weekly: seguridad reforzada, IA aplicada y nuevas alianzas estratégicas&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/crm-and-cx-blog-posts-by-sap/implementing-sap-emarsys-loyalty-management-part-1/ba-p/14216345" target="_blank"&gt;Implementing SAP Emarsys Loyalty Management - Part 1&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/easier-integration-of-sap-cis-with-bdc-sac-dsp-bdcc-with-a-new-identity/ba-p/14165026" target="_blank"&gt;Easier Integration of SAP CIS with BDC (SAC, DSP, BDCC) with a new Identity Provider Administration&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/enterprise-architecture-blog-posts/architecting-your-sap-business-data-cloud-journey-from-data-to-intelligence/ba-p/14211958" target="_blank"&gt;Architecting Your SAP Business Data Cloud Journey – From Data to Intelligence!&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-blog-posts/practical-guide-how-to-build-sap-analytics-cloud-stories-using-sap/ba-p/14213710" target="_blank"&gt;Practical Guide: How to build SAP Analytics Cloud stories using SAP Datasphere&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/application-development-and-automation-blog-posts/sap-developer-news-september-11th-2025/ba-p/14215007" target="_blank"&gt;SAP Developer News September 11th, 2025&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/master-data-management-via-business-data-cloud-datasphere-amp-seamless/ba-p/14197189" target="_blank"&gt;Master Data Management via Business Data Cloud: Datasphere &amp;amp; Seamless Planning in combination&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/join-the-sap-enterprise-architecture-amp-business-data-cloud-apac-event/ba-p/14213981" target="_blank"&gt;Join the SAP Enterprise Architecture &amp;amp; Business Data Cloud APAC Event!&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/the-magic-of-attributes-in-sap-ias-default-vs-enrich-assertion/ba-p/14202929" target="_blank"&gt;The Magic of Attributes in SAP IAS: Default vs Enrich Assertion&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-blog-posts/e-learning-sap-datasphere-lifecycle-management/ba-p/14213493" target="_blank"&gt;E-Learning: SAP Datasphere Lifecycle Management&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/tokyo-blog-posts/hotter-than-july-sap-bdc-databricks-jsug-ngb-%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88%E5%8F%82%E5%8A%A0%E3%83%AC%E3%83%9D%E3%83%BC%E3%83%88/ba-p/14213309" target="_blank"&gt;Hotter Than July: SAP BDC × Databricks × JSUG NGB イベント参加レポート&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/partner-learning-managers-blog-posts/win-more-cloud-business-amp-enhance-your-services-with-sap-complementary/ba-p/14208572" target="_blank"&gt;Win more cloud business &amp;amp; enhance your services with SAP® complementary services built for partners&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-business-data-cloud-series-part-3-customer-managed-data-products/ba-p/14195545" target="_blank"&gt;SAP Business Data Cloud Series – Part 3: Customer-Managed Data Products&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/modernize-with-sap-business-data-cloud-using-the-sap-business-data-cloud/ba-p/14212128" target="_blank"&gt;Modernize with SAP Business Data Cloud using the SAP Business Data Cloud Modernization Assessment&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-btp-weekly-practical-ai-enhanced-analytics-and-a-vision-for-the-future/ba-p/14211112" target="_blank"&gt;SAP BTP Weekly: Practical AI, Enhanced Analytics, and a Vision for the Future&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/same-code-different-results-obsolete-version-in-dsp-cache/ba-p/14209466" target="_blank"&gt;Same code, different results. Obsolete Version in DSP cache?&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/portuguese-sap-business-data-cloud-sess%C3%B5es-de-expert-guided-implementation/ba-p/14208758" target="_blank"&gt;[Portuguese] SAP Business Data Cloud: Sessões de Expert-Guided Implementation&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-partners-fast-track-your-sap-business-technology-platform-certification/ba-p/14194751" target="_blank"&gt;SAP Partners - Fast Track your SAP Business Technology Platform Certification Path&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/demystifying-sap-business-data-cloud-a-simplified-take/ba-p/14181755" target="_blank"&gt;Demystifying SAP Business Data Cloud, A Simplified Take&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-in-sap-business-data-cloud-a-typical-machine-learning/ba-p/14206612" target="_blank"&gt;SAP Databricks in SAP Business Data Cloud – a Typical Machine Learning Workflow&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/restrict-access-of-oauth2-0-clients-with-the-technical-user-purpose/ba-p/14195095" target="_blank"&gt;Restrict Access of OAuth2.0 Clients with the Technical User purpose&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-architecture-and-lessons-learned/ba-p/14189930" target="_blank"&gt;SAP Datasphere - Architecture and Lessons-Learned&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="kpsauer_0-1759766213581.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/323395iC98529A585B85DFE/image-size/large?v=v2&amp;amp;px=999" role="button" title="kpsauer_0-1759766213581.png" alt="kpsauer_0-1759766213581.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Find more information and related blog posts on the&amp;nbsp;&lt;SPAN&gt;&lt;A href="https://pages.community.sap.com/topics/datasphere" target="_blank" rel="noopener noreferrer"&gt;topic page for SAP Datasphere&lt;/A&gt;&lt;/SPAN&gt;. You will find further product information on our Community with various subpages about &lt;SPAN&gt;&lt;A href="https://pages.community.sap.com/topics/datasphere/business-content" target="_blank" rel="noopener noreferrer"&gt;Business Content&lt;/A&gt;&lt;/SPAN&gt;, the&amp;nbsp;&lt;SPAN&gt;&lt;A href="https://pages.community.sap.com/topics/datasphere/bw-bridge" target="_blank" rel="noopener noreferrer"&gt;SAP BW Bridge&lt;/A&gt;&lt;/SPAN&gt; as well as content for&amp;nbsp;&lt;SPAN&gt;&lt;A href="https://pages.community.sap.com/topics/datasphere/best-practices-troubleshooting" target="_blank" rel="noopener noreferrer"&gt;Best Practices &amp;amp; Troubleshooting&lt;/A&gt;&lt;/SPAN&gt;. Also check out the new &lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/SUPPORT_CONTENT/datasphere/4181116697.html?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;support content for SAP Datasphere&lt;/A&gt;&lt;/SPAN&gt; on SAP Help for troubleshooting and analysis guides, how-to guides, technical details, and more.&lt;/P&gt;&lt;P&gt;Find out how to unleash the power of your business data with SAP’s free learning content on &lt;SPAN&gt;&lt;A href="https://learning.sap.com/learning-journey/explore-sap-datasphere?source=social-meta-prdteng-ExploreSAPDatasphere" target="_blank" rel="noopener noreferrer"&gt;SAP Datasphere&lt;/A&gt;&lt;/SPAN&gt;. It’s designed to help you enrich your data projects, simplify the data landscape, and make the most out of your investment. Check out even more role-based learning resources and opportunities to get certified in one place on &lt;SPAN&gt;&lt;A href="https://learning.sap.com/?url_id=text-sapcommunity-prdteng" target="_blank" rel="noopener noreferrer"&gt;&amp;nbsp;SAP Learning site.&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-datasphere-news-in-september/ba-p/14235999"/>
    <published>2025-10-16T06:00:00.038000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/parameterized-task-chains-what-you-can-and-can-t-do/ba-p/14245534</id>
    <title>Parameterized Task Chains: What You Can and Can’t Do</title>
    <updated>2025-10-16T10:21:24.040000+02:00</updated>
    <author>
      <name>XaviPolo</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/129732</uri>
    </author>
    <content>&lt;P&gt;Recently, the ability to use parameters in Task Chains was added ... a long-awaited feature for many of us. But what exactly can we do with parameters in Task Chains, and what are the limitations?&lt;/P&gt;&lt;H3 id="toc-hId-1891915109"&gt;&lt;STRONG&gt;&lt;span class="lia-unicode-emoji" title=":information:"&gt;ℹ️&lt;/span&gt;Allowed Actions in Task Chains&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Task Chains let us execute tasks in a controlled way, whether in parallel, sequentially, or a mix of both. The actions we can perform include:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Executing a Task Chain&lt;/LI&gt;&lt;LI&gt;Executing a Data Flow&lt;/LI&gt;&lt;LI&gt;Executing a Transformation Flow&lt;/LI&gt;&lt;LI&gt;Creating/Deleting persistence of a View&lt;/LI&gt;&lt;LI&gt;API Task: calling HTTP service (POST, PUT)&lt;/LI&gt;&lt;LI&gt;Notification Task (to send email)&lt;/LI&gt;&lt;LI&gt;Call BW Process Chain&lt;/LI&gt;&lt;LI&gt;Call SQL Script Procedures&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;However, &lt;STRONG&gt;only some of these actions support parameter usage within a Task Chain&lt;/STRONG&gt;:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;span class="lia-unicode-emoji" title=":heavy_check_mark:"&gt;✔️&lt;/span&gt;&amp;nbsp;Executing a Task Chain&lt;/LI&gt;&lt;LI&gt;&lt;span class="lia-unicode-emoji" title=":heavy_check_mark:"&gt;✔️&lt;/span&gt;&amp;nbsp;Executing a Transformation Flow&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1695401604"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId-1498888099"&gt;&lt;STRONG&gt;&lt;span class="lia-unicode-emoji" title=":information:"&gt;ℹ️&lt;/span&gt;&amp;nbsp;Restrictions when using parameters in Task Chains&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;These objects can be defined with parameters, but&amp;nbsp;&lt;STRONG&gt;we cannot pass parameters from the Task Chain to these objects directly:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;span class="lia-unicode-emoji" title=":cross_mark:"&gt;❌&lt;/span&gt;Executing a Data Flow&lt;/LI&gt;&lt;LI&gt;&lt;span class="lia-unicode-emoji" title=":cross_mark:"&gt;❌&lt;/span&gt;&amp;nbsp;Creating/Deleting persistence of a View&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;If we add these parameterized objects to a Task Chain, they will only work &lt;STRONG&gt;if their parameters have default values set&lt;/STRONG&gt;. We won’t be able to change them dynamically, but at least we can execute them from within a Task Chain.&lt;BR /&gt;If the default parameter is not set, we’ll see an error when adding them to the Task Chain&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="XaviPolo_0-1760601413754.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328229i53536592181F69D2/image-size/medium?v=v2&amp;amp;px=400" role="button" title="XaviPolo_0-1760601413754.png" alt="XaviPolo_0-1760601413754.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;That said, &lt;STRONG&gt;we can pass parameters to a view if it’s used inside a Transformation Flow&lt;/STRONG&gt;. The parameter is first passed to the Transformation Flow, which then passes it to the view.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="toc-hId-1302374594"&gt;&lt;span class="lia-unicode-emoji" title=":magnifying_glass_tilted_left:"&gt;🔍&lt;/span&gt;&lt;STRONG&gt;How Does It Work?&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;It’s actually quite simple. In the Task Chain, you define the necessary input parameters (you can have multiple inputs if needed) and assign them a value or leave them blank, which will be treated as an empty string.&lt;/P&gt;&lt;P&gt;There’s no data type enforcement, no length restrictions, and no functions involved ...&amp;nbsp;&lt;STRONG&gt;all parameters are treated as String value&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="XaviPolo_1-1760601957224.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328232iE5317070031C669E/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="XaviPolo_1-1760601957224.png" alt="XaviPolo_1-1760601957224.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now we add our tasks to the Task Chain. If those tasks support parameters under this new functionality, you’ll see an option to assign values to them.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="XaviPolo_2-1760602462574.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328235iDE06F042B5B03C7C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="XaviPolo_2-1760602462574.png" alt="XaviPolo_2-1760602462574.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;You can either set a fixed value or &lt;STRONG&gt;map the Task Chain’s input parameter&lt;/STRONG&gt; to pass the value dynamically.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="XaviPolo_3-1760602488951.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328236iE483A775CA1CA568/image-size/medium?v=v2&amp;amp;px=400" role="button" title="XaviPolo_3-1760602488951.png" alt="XaviPolo_3-1760602488951.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;If the parameter isn’t supported, you won’t see any option to assign a value or link the parameter. Here’s an example of a Data Flow defined with a parameter (with a default value), but without the option to map the Task Chain Input Parameter or assign a value.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="XaviPolo_4-1760602551504.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328238i4B7445F766FEA906/image-size/medium?v=v2&amp;amp;px=400" role="button" title="XaviPolo_4-1760602551504.png" alt="XaviPolo_4-1760602551504.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;And that’s it ! ... once you run the Task Chain, it will use the values defined in the Input Parameters. If you need to run it with different values, just update them and execute.&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="toc-hId-1105861089"&gt;&lt;span class="lia-unicode-emoji" title=":rocket:"&gt;🚀&lt;/span&gt;&amp;nbsp;&lt;STRONG&gt;Why This Matters&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;This new functionality is a major step forward in building smarter and more advanced flows. Hopefully, we’ll soon see features like a &lt;STRONG&gt;global variable repository&lt;/STRONG&gt;, the ability to pass those values into parameters, use functions, or derive values from views ... all of which would make the system even more powerful.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/parameterized-task-chains-what-you-can-and-can-t-do/ba-p/14245534"/>
    <published>2025-10-16T10:21:24.040000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/sap-business-data-cloud-%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%A0%E3%83%87%E3%83%BC%E3%82%BF%E3%83%97%E3%83%AD%E3%83%80%E3%82%AF%E3%83%88%E3%81%AE%E4%BD%9C%E6%88%90/ba-p/14235138</id>
    <title>SAP Business Data Cloud: カスタムデータプロダクトの作成</title>
    <updated>2025-10-17T07:32:47.646000+02:00</updated>
    <author>
      <name>akaney</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/852758</uri>
    </author>
    <content>&lt;H2 id="toc-hId-1761905029"&gt;&lt;STRONG&gt;はじめに&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;SAP Business Data Cloud&lt;SPAN&gt;ではSAP&lt;SPAN&gt;のビジネスアプリケーション間のデータを共通のデータモデルとしてデータセットおよびセマンティック（項目名の用語や意味合い）を整え、SAP &lt;SPAN&gt;データプロダクトとして提供します。これによりSAPが管理の下でSAPのアプリケーションのデータは自動的にコピーされ、メタデータも併せてメンテナンスを行っていきます&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&lt;SPAN&gt;&lt;SPAN&gt;が、&lt;SPAN&gt;S/4HANAのアドオンテーブルやカスタムCDS view、SAP以外のデータソースなどお客様独自の要件データソースに対してはカスタムデータプロダクトを作成することで、同様のフレームワークに組み込むことが可能です。&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;これによってSAP&lt;SPAN&gt;アプリケーションのデータだけでなく、SAP&lt;SPAN&gt;以外のデータも整備しAI&lt;SPAN&gt;エージェントに必要なデータとして提供できるため、ダッシュボードでデータを可視化するだけではなく、Joule&lt;SPAN&gt;を使いながら対話形式でさらなるデータ分析の深堀やインサイトを得るなどデータ活用の幅を広げることができます。&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1565391524"&gt;&lt;STRONG&gt;概要&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;本ブログではS/4HANA on-premise&lt;SPAN&gt;から連携したCDS view&lt;SPAN&gt;をベースとするカスタムデータプロダクトの作成を想定し解説いたします。SAP&lt;SPAN&gt;以外のデータソースが対象となる場合でも同様の手順でカスタムデータプロダクトの作成が可能です。&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;大まかなカスタムデータプロダクトの作成手順は以下の通りです。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="00_全体.png" style="width: 716px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/327386i5DCDD6748F831188/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="00_全体.png" alt="00_全体.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;オブジェクトストアへのデータ連携&lt;/LI&gt;&lt;LI&gt;データ変換処理&lt;/LI&gt;&lt;LI&gt;カスタムデータプロダクトの定義&lt;/LI&gt;&lt;/OL&gt;&lt;H2 id="toc-hId-1368878019" id="toc-hId-1368878019"&gt;オブジェクトストアへのデータ連携&lt;/H2&gt;&lt;P&gt;こちらでは以下の手順でオブジェクトストア内のローカルテーブルにソースシステムからデータ連携をします。&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;複製フローの作成・実行&lt;/LI&gt;&lt;LI&gt;マージタスクの実行&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;SAP Datasphere&lt;SPAN&gt;オブジェクトストア内にデータを連携するため、データビルダより複製フローの作成を行います。複製フローは選択したソースシステムから選択したターゲットシステムへのデータ複製を行うことが出来る機能です。データビルダに統合されたユーザインタフェースを使用してシンプルな射影とフィルタを使用した1:1の複製を作成でき、&lt;/SPAN&gt;簡単な設定でソースシステムからターゲット システムへ大量データ複製を実現します。&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;オブジェクトストアの概要に関しては&amp;nbsp;こちらのブログ（&lt;A href="https://community.sap.com/t5/blogs/blogarticleprintpage/blog-id/technology-blog-sap/article-id/183048" target="_blank"&gt;SAP Business Data Cloud: オブジェクトストア 入門編&lt;/A&gt;）&lt;SPAN&gt;をご確認ください。&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;複製フローの概要に関してはこちらのブログ（&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/%E8%A4%87%E8%A3%BD%E3%83%95%E3%83%AD%E3%83%BCpart%EF%BC%91-%E8%A4%87%E8%A3%BD%E3%83%95%E3%83%AD%E3%83%BC%E6%A6%82%E8%A6%81/ba-p/13575795" target="_blank"&gt;複製フローPart１: 複製フロー概要&lt;/A&gt;）&lt;/SPAN&gt;&lt;SPAN&gt;をご確認ください。&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1301447233" id="toc-hId-1301447233"&gt;複製フローの作成・実行&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;オブジェクトストアスペース内で「データビルダ」より「新規複製フロー」を選択します。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="01.01_複製フロー選択.png" style="width: 856px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328941i6BCECF106D9AD43C/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="01.01_複製フロー選択.png" alt="01.01_複製フロー選択.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;データソースを選択します。本ブログではS/4HANA on-premise&lt;SPAN&gt;への作成済みの接続を介して複製フローを作成します。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="01.02_複製フロー接続選択.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328942iF97F1D7012EAD165/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="01.02_複製フロー接続選択.png" alt="01.02_複製フロー接続選択.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;S/4HANAからの連携方法として、CDS viewを選択します。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="01.03_cds view選択.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328943i44BA0C5122740DE6/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="01.03_cds view選択.png" alt="01.03_cds view選択.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;以下のように１つの複製フローではソースシステムからターゲットシステムに対して並列処理で複数のオブジェクトを複製することが可能です。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="01.04_cds view決める.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328944i52DF816FD8990771/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="01.04_cds view決める.png" alt="01.04_cds view決める.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;今回はターゲットにオブジェクトストアのスペースを選択することで、ターゲットオブジェクトとして新規のローカルテーブルがオブジェクトストア内に作成されます。&lt;/P&gt;&lt;P&gt;また、複製フローでは&lt;SPAN&gt;シンプルな射影やフィルタの追加や、&lt;/SPAN&gt;初期ロードやデルタロードなどのロードタイプを選択することが可能です。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="01.0_複製フローンお作成.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328945i43CC94583A645F11/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="01.0_複製フローンお作成.png" alt="01.0_複製フローンお作成.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;複製フローにビジネス名と技術名を付けて&lt;/SPAN&gt;デプロイ・実行することで、オブジェクトストア内にローカルテーブルが作成されます。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="01.0_複製フローンデプロイ実行.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328946i8F338C4EBECD3E7D/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="01.0_複製フローンデプロイ実行.png" alt="01.0_複製フローンデプロイ実行.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1104933728" id="toc-hId-1104933728"&gt;マージタスクの実行&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;その後「マージタスク」という処理を通じてテーブルにそのデータを反映させます。&lt;BR /&gt;複製フローの実行によりソースシステムからオブジェクトストア内に作成された受信バッファにデータが書き込まれますが、ここからマージタスクを実行することでオブジェクトストア内のデルタテーブル（ローカルテーブル）にデータが挿入されます。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;このマージタスクは、「データ統合モニタ」からそれぞれのテーブル毎に実行することもできますが、タスクチェーンの中に複数のテーブルに対するマージタスクを組み込むことで、複製フロー&lt;/SPAN&gt;&lt;SPAN&gt;/&lt;/SPAN&gt;&lt;SPAN&gt;変換フロー実行後にマージするなどのジョブ実行のスケジュールを組むことも可能です。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;本ブログではタスクチェーンを作成し、５つのローカルテーブルに対してマージタスクを並列実行させるように構成します。&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;タスクチェーンに関して詳細はこちらのSAP Helpページ（&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/c8a54ee704e94e15926551293243fd1d/d1afbc2b9ee84d44a00b0b777ac243e1.html?locale=ja-JP" target="_self" rel="noopener noreferrer"&gt;タスクチェーンの作成&lt;/A&gt;）をご確認ください。&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;「データビルダ」より「新規タスクチェーン」を選択します。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="02_タスクチェーンの作成.png" style="width: 852px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328947i893443467CB07896/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="02_タスクチェーンの作成.png" alt="02_タスクチェーンの作成.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;左側のリポジトリより「オブジェクトストアへのデータ連携」で作成したローカルテーブルをドラッグ＆ドロップでタスクチェーンに追加します。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="03_ソース選択.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328948iAA537C341B85CF26/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="03_ソース選択.png" alt="03_ソース選択.png" /&gt;&lt;/span&gt;&amp;nbsp;&lt;/SPAN&gt;その他ローカルテーブルや複製フロー/変換フローなどのオブジェクトをタスクチェーンの中に新規タスクあるいは並列タスクとして追加することが可能です。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="04_新規タスク.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328949iF491617B45763741/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="04_新規タスク.png" alt="04_新規タスク.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;アクティビティに「マージ」が選択されていることを確認し、タスクチェーンの作成・実行をします。&lt;BR /&gt;また、タスクチェーンの実行後に電子メールによる通知を設定することもできます。&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="05_タスク.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328958i84AE24BE7E4964C0/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="05_タスク.png" alt="05_タスク.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;タスクチェーンの実行状況はデータ統合モニタよりタスクチェーンの&lt;SPAN&gt;ステータスや進捗を確認することができ、タスクチェーンのプロパティから直接移動することが可能です。&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="06_保存.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328952iAD2D7EBD505733F9/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="06_保存.png" alt="06_保存.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;詳細画面では実行に関するステータスやメトリクス、実行ログなどを確認できます。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="07_モニタ.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328953i3C22BC6B91342947/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="07_モニタ.png" alt="07_モニタ.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;また、「ローカルテーブル（ファイル）」メニュー画面よりローカルテーブルごとの詳細を確認することができ、受信バッファからそれぞれのローカルテーブルにデータが書き込まれレコードが挿入されたことが確認できます。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="08_モニタ２.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328954iBC242E2A61D85F04/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="08_モニタ２.png" alt="08_モニタ２.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;「データビルダ」より複製フローで作成したターゲットテーブルを選択し、プレビューをするとデータが挿入されたことが確認できます。以上で、データソースからオブジェクトストア内にデータ連携が完了します。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="01.05_プレビュー.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328956i900C169D26B9C9A6/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="01.05_プレビュー.png" alt="01.05_プレビュー.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;このような形で複製フローを用いてデータ連携をすることで、オブジェクトストアを大量のデータを安価に保持するデータレイク領域として利用することができます。ローカルテーブルとして作成されたオブジェクトはスペースへと共有することで、ビューや分析モデルなど分析の用途のデータモデルとして活用することが出来ます。&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-582823999" id="toc-hId-779337504"&gt;データ変換処理&lt;/H2&gt;&lt;P&gt;複製フローでローデータをオブジェクトストアにデータ抽出をした後には、データ変換や集計、計算列の追加などの処理を変換フローにて実現することも可能です。変換フローの中ではSQLやSQLスクリプト、Pythonによるデータ変換などを組み込むことが出来ます。&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;変換フローの概要に関してはこちらのブログ（&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/%E8%A4%87%E8%A3%BD%E3%83%95%E3%83%AD%E3%83%BCpart2-%E3%83%87%E3%83%AB%E3%82%BF%E3%82%AD%E3%83%A3%E3%83%97%E3%83%81%E3%83%A3%E3%81%A8%E5%A4%89%E6%8F%9B%E3%83%95%E3%83%AD%E3%83%BC/ba-p/13581517" target="_blank"&gt;複製フローPart2 : デルタキャプチャと変換フロー&lt;/A&gt;）&lt;/SPAN&gt;&lt;SPAN&gt;をご確認ください。&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;「データビルダ」より「新規変換フロー」を選択します。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="09_変換フロー.png" style="width: 888px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328957iDB310FCCF704A7D9/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="09_変換フロー.png" alt="09_変換フロー.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;変換フローでは&lt;SPAN&gt;中間ビューとしてグラフィックビューあるいはSQLビューを作成し、ソースからデータをロードしデータを変換します。今回はグラフィックビューによるデータ変換をおこなうため、「グラフィックビュー変換」を選択します。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="10_ぐらふぃく.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328959i8CFF2303BD3D26CA/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="10_ぐらふぃく.png" alt="10_ぐらふぃく.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;画面左側のリポジトリよりオブジェクトをドラッグ＆ドロップでグラフィックビューエディタに追加をします。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="11_テーブルの追加.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328960iE492C6CA3A710546/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="11_テーブルの追加.png" alt="11_テーブルの追加.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;結合などの&lt;/SPAN&gt;データ変換や集計、計算列の追加などを定義します。&lt;BR /&gt;グラフィックエディタから左上の「＞（戻る）」を選択することで変換フローエディタへ遷移することが出来ます。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="12_変換処理.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328961iA0478FB7AC2ED3CC/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="12_変換処理.png" alt="12_変換処理.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;変換処理がされたデータが書き込まれるターゲットテーブルを新規に作成するため、&lt;/SPAN&gt;&lt;SPAN&gt;「新規ターゲットテーブルの作成」を選択します。リポジトリより既存のテーブルをターゲットテーブルとして追加することも可能です。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="13_ターゲットテーブルの作成.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328962i199DA67AE1653620/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="13_ターゲットテーブルの作成.png" alt="13_ターゲットテーブルの作成.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;変換フローおよびターゲットテーブルにビジネス名と技術名を付けて&lt;/SPAN&gt;デプロイ・実行することで、変換処理されたデータがターゲットテーブルに挿入されます。&lt;SPAN&gt;変換フロー&lt;/SPAN&gt;の実行状況はデータ統合モニタよりタスクチェーンの&lt;SPAN&gt;ステータスや進捗を確認することができ、変換フローのプロパティから直接移動することが可能です。&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="14_変換フロー実装.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328963i0AE266BDA077FD2F/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="14_変換フロー実装.png" alt="14_変換フロー実装.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;このように複製フローを用いてオブジェクトストアを大量のデータを安価に保持するデータレイク領域としてデータ抽出・保持ができるだけでなく、&lt;/SPAN&gt;不要な列の削除や計算列の追加などクレンジングの変換処理を加え、分析用途で使える状態にした中間データもオブジェクトストアで保持することができます。&lt;/P&gt;&lt;P&gt;これらのデータソースから抽出したデータや、変換処理後のデータはメタデータと併せてカタログに情報が自動で登録され、管理されますが、カスタムデータプロダクトとしてカタログに公開することで対象のシステムに対してゼロコピーでデルタシェアによるデータの共有が可能です。&lt;/P&gt;&lt;H2 id="toc-hId-582823999"&gt;カスタムデータプロダクトの定義&lt;/H2&gt;&lt;P&gt;カスタムデータプロダクトの定義は「データ共有コックピット」を利用して行います。&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;データ共有コックピットに関して詳細はこちらのSAP Helpページ（&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/e4059f908d16406492956e5dbcf142dc/b07e95d07a1e4569b87d9bb57b732bcf.html?locale=ja-JP" target="_self" rel="noreferrer noopener"&gt;カスタムデルタ共有データプロダクトの作成&lt;/A&gt;）をご確認ください。&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;「データ共有コックピット」＞「データプロバイダプロファイル」よりデータプロバイダーを作成します。この際に、「データプロバイダ/データプロダクトの表示/非表示」で「フォーメーション」を選択し、その他必要な情報を入力のうえ作成します。&lt;/P&gt;&lt;H2 id="toc-hId-386310494" id="toc-hId-386310494"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="16_プロファイルの作成.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328915iE77F9C4FC347C8C2/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="16_プロファイルの作成.png" alt="16_プロファイルの作成.png" /&gt;&lt;/span&gt;&lt;/H2&gt;&lt;H2 id="toc-hId-189796989"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="17_プロバイダーの家訓ん.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328934i17B625CF065A6D0A/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="17_プロバイダーの家訓ん.png" alt="17_プロバイダーの家訓ん.png" /&gt;&lt;/span&gt;&lt;/H2&gt;&lt;P&gt;データプロバイダの作成後、「データ共有コックピット」＞「データプロダクト」よりデータプロダクトの作成をおこないます。&lt;/P&gt;&lt;H2 id="toc-hId--6716516"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="18_データプロダクトの定義.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328914i7BFC9C990ED3DD26/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="18_データプロダクトの定義.png" alt="18_データプロダクトの定義.png" /&gt;&lt;/span&gt;&lt;/H2&gt;&lt;P&gt;「アーティファクトスペース」を選択します。アーティファクトスペースでは通常のHANA Cloudスペースではなく、オブジェクトストアの領域より選択が可能です。&lt;/P&gt;&lt;P&gt;その他ビジネス名や技術名などを入力します。&lt;/P&gt;&lt;H2 id="toc-hId-144024336"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="19_定位１.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328916i076B225B691D9765/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="19_定位１.png" alt="19_定位１.png" /&gt;&lt;/span&gt;&lt;/H2&gt;&lt;P&gt;「プロダクトアーティファクト」よりソースとなるオブジェクトをオブジェクトストアより選択し「変更を保存」することで、カスタムデータプロダクトを作成することが出来ます。&lt;/P&gt;&lt;H2 id="toc-hId--52489169"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="20_オブジェクトの選択２.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328917iC546B598647F2C0E/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="20_オブジェクトの選択２.png" alt="20_オブジェクトの選択２.png" /&gt;&lt;/span&gt;&lt;/H2&gt;&lt;P&gt;カスタムデータプロダクトをカタログに公開するために、ライフサイクルステータスを「ドラフト」より「一覧表示済み」にステータスの切り替えを行います。これにより、作成したカスタムデータプロダクトがカタログ上に公開され、利用できるようになります。&lt;/P&gt;&lt;H2 id="toc-hId--249002674"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="21_リスティング.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328918iF3C7B62761C4D729/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="21_リスティング.png" alt="21_リスティング.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="22_リスティング.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328919i44E46A6E0DDC14F5/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="22_リスティング.png" alt="22_リスティング.png" /&gt;&lt;/span&gt;&lt;/H2&gt;&lt;P&gt;SAP Business Data Cloud Cockpitの「カタログおよびマーケットプレイス」よりアクセスすると、先ほど作成したカスタムデータプロダクトを検索・利用することができることを確認できます。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="23_カタログ.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/329348iAF35EDA2AC81BB1D/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="23_カタログ.png" alt="23_カタログ.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;データ共有コックピットで定義したカタログ情報などが確認できますが、「共有」を開始することで、対象システムとデータプロダクトをゼロコピーで利用することが出来るようになります。&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;対象システムへのデルタシェアに関してはこちらのSAP Helpページ（&lt;A href="https://help.sap.com/docs/business-data-cloud/governing-and-publishing-data-in-catalog/sharing-data-products-to-sap-databricks?locale=ja-JP" target="_self" rel="noreferrer noopener"&gt;他の SAP システムへのデータ製品の共有&lt;/A&gt;）をご確認ください。&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="24_カタログ確認.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/329349iF002739A93920E9A/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="24_カタログ確認.png" alt="24_カタログ確認.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;今回はSAP Databircksを共有先のターゲットシステムとして選択し、共有名などを入力します。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="25_デルタシェア.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/329350iAA121C1438C4F99A/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="25_デルタシェア.png" alt="25_デルタシェア.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;共有が完了すると、カスタムデータプロダクトはSAP DatabircksのカタログであるUnity Catalogに登録され、ゼロコピーで利用することが出来るようになります。&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="26_デルタシェエア.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328939i2D6BBDBAC6741C70/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="26_デルタシェエア.png" alt="26_デルタシェエア.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId--445516179"&gt;さいごに&lt;/H2&gt;&lt;P&gt;最後までご覧いただきありがとうございました！&lt;BR /&gt;本ブログではS/4HANA on-premiseのCDS viewをベースにオブジェクトストアへのデータ連携および変換、またカスタムデータプロダクトとして定義のうえカタログに公開することでSAP Databricksにおいて高度な機械学習シナリオで活用できるようになりました。&lt;/P&gt;&lt;P&gt;その他関連する情報をまとめておりますので、併せてご確認ください。&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/c8a54ee704e94e15926551293243fd1d/2a6bc3f6d79b4c39a01b6d58d043fbaf.html?locale=ja-JP&amp;amp;version=DEV&amp;amp;state=DRAFT#loio2a6bc3f6d79b4c39a01b6d58d043fbaf__section_create_file_space" target="_self" rel="noopener noreferrer"&gt;オブジェクトストアでのデータの取得および準備&lt;/A&gt;&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://me.sap.com/notes/3538038" target="_self" rel="noopener noreferrer"&gt;3538038 - SAP Datasphere オブジェクトストアの重要な考慮事項&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A class="" title="https://help.sap.com/docs/sap_datasphere/c8a54ee704e94e15926551293243fd1d/f7161e6c20204672ac4a6d90c81762e4.html?locale=ja-jp" href="https://help.sap.com/docs/SAP_DATASPHERE/c8a54ee704e94e15926551293243fd1d/f7161e6c20204672ac4a6d90c81762e4.html?locale=ja-JP" target="_blank" rel="noreferrer noopener"&gt;変換フローの作成&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/e4059f908d16406492956e5dbcf142dc/b07e95d07a1e4569b87d9bb57b732bcf.html?locale=ja-JP" target="_self" rel="noopener noreferrer"&gt;カスタムデルタ共有データプロダクトの作成&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/business-data-cloud/governing-and-publishing-data-in-catalog/sharing-data-products-to-sap-databricks?locale=ja-JP" target="_self" rel="noreferrer noopener"&gt;他の SAP システムへのデータ製品の共有&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-business-data-cloud-%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%A0%E3%83%87%E3%83%BC%E3%82%BF%E3%83%97%E3%83%AD%E3%83%80%E3%82%AF%E3%83%88%E3%81%AE%E4%BD%9C%E6%88%90/ba-p/14235138"/>
    <published>2025-10-17T07:32:47.646000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/sap-teched-berlin-2025-sap-business-data-cloud-data-products-master-data/ba-p/14246937</id>
    <title>SAP TechEd Berlin 2025: SAP Business Data Cloud: Data products, master data, governance</title>
    <updated>2025-10-17T16:32:04.802000+02:00</updated>
    <author>
      <name>AndreasSeifried</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/45581</uri>
    </author>
    <content>&lt;P&gt;Dear Data-Enthusiasts!&lt;/P&gt;&lt;P&gt;Are you still unsure how your data management approach can benefit of SAP Business Data Cloud, what data products are, and which advantages SAP-managed data products bring?&lt;/P&gt;&lt;P&gt;Then you might want to attend our session &lt;A href="https://www.sap.com/events/teched/berlin/flow/sap/te25/catalog-inperson/page/catalog/session/1749041296911001MzGE" target="_blank" rel="noopener noreferrer"&gt;SAP Business Data Cloud: Data products, master data, and governance (DA100)&lt;/A&gt; at SAP TechEd in Berlin on &lt;STRONG&gt;Tuesday, Nov 4&lt;/STRONG&gt; at &lt;STRONG&gt;9:30&lt;/STRONG&gt; AM.&lt;/P&gt;&lt;P&gt;Besides the questions above, we will also discuss the role of SAP Master Data Governance and how to use it for improved data quality, analytics, and AI.&lt;/P&gt;&lt;P&gt;We are Florian Neukirch&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/5959"&gt;@FlorianN&lt;/a&gt;&amp;nbsp;and Andreas Seifried&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/45581"&gt;@AndreasSeifried&lt;/a&gt;, looking forward meeting you during and after our lecture!&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="AndreasSeifried_0-1760694900503.jpeg" style="width: 200px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328990i23C9D672F3B0CA74/image-size/small/is-moderation-mode/true?v=v2&amp;amp;px=200" role="button" title="AndreasSeifried_0-1760694900503.jpeg" alt="AndreasSeifried_0-1760694900503.jpeg" /&gt;&lt;/span&gt;Florian is a Senior Product Management Specialist for SAP BDC&amp;amp;I. His focus is on Data Products, Catalog, Marketplace and Data Product Governance. Florian started his career at SAP in Solution Management and has taken over several roles in the SAP BDC&amp;amp;I organization since then.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="AndreasSeifried_0-1760693992111.jpeg" style="width: 200px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/328977i0AEDE65187D1FAB9/image-size/small/is-moderation-mode/true?v=v2&amp;amp;px=200" role="button" title="AndreasSeifried_0-1760693992111.jpeg" alt="AndreasSeifried_0-1760693992111.jpeg" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Andreas is a product manager for SAP Master Data Governance and is engaged in shaping SAP’s portfolio for data management since he joined the development organization in 2004. Andreas started at SAP as a technology consultant in 2001, when he helped organizations all over the world to solve their data and process integration challenges.&lt;/P&gt;&lt;P&gt;We will introduce you to the concept of data products and explore how SAP-managed data products can enhance your data architecture. We'll delve into the significance of master data for analytics, processes, and AI, and discuss upcoming features like the data product studio.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Other related sessions that we recommend:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://www.sap.com/events/teched/berlin/flow/sap/te25/catalog-inperson/page/catalog/session/1753910209205001V1Vm" target="_self" rel="noopener noreferrer"&gt;DA203&lt;/A&gt; | SAP Business Data Cloud: The path forward for SAP Business Warehouse by&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/14110"&gt;@kpsauer&lt;/a&gt;&amp;nbsp;and &lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/41772"&gt;@kurzdo93&lt;/a&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://www.sap.com/events/teched/berlin/flow/sap/te25/catalog-inperson/page/catalog/session/1754081071909001LQxU" target="_self" rel="noopener noreferrer"&gt;DA266&lt;/A&gt; | Operationalizing AI with SAP Databricks in SAP Business Data Cloud by&amp;nbsp;&lt;/SPAN&gt;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/434167"&gt;@san_tran&lt;/a&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Related community topic pages:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://pages.community.sap.com/topics/master-data-governance" target="_blank" rel="noopener noreferrer"&gt;SAP Master Data Governance | SAP Community&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://pages.community.sap.com/topics/business-data-cloud" target="_blank" rel="noopener noreferrer"&gt;SAP Business Data Cloud | SAP Community&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://pages.community.sap.com/topics/datasphere" target="_blank" rel="noopener noreferrer"&gt;SAP Datasphere | SAP Community&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Looking forward to seeing you in Berlin!&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;Florian and Andreas&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Now let’s hear from you:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;What are your experiences with SAP Business Data Cloud and SAP Master Data Governance?&lt;/LI&gt;&lt;LI&gt;Is it valid to have distinct views on (generic) data management and master data management? What are the reasons?&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Please add your thoughts as comments to this blog. Thanks!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-teched-berlin-2025-sap-business-data-cloud-data-products-master-data/ba-p/14246937"/>
    <published>2025-10-17T16:32:04.802000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/crm-and-cx-blog-posts-by-sap/implementing-sap-emarsys-loyalty-management-part-2-technical-deep-dive/ba-p/14247872</id>
    <title>Implementing SAP Emarsys Loyalty Management – Part 2 (Technical Deep Dive)</title>
    <updated>2025-10-20T06:02:50.534000+02:00</updated>
    <author>
      <name>vijaysb15</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/44279</uri>
    </author>
    <content>&lt;P&gt;In &lt;A href="https://community.sap.com/t5/crm-and-cx-blog-posts-by-sap/implementing-sap-emarsys-loyalty-management-part-1/ba-p/14216345" target="_blank"&gt;&lt;STRONG&gt;Part 1&lt;/STRONG&gt;&lt;/A&gt;, of this series, we explored how SAP Emarsys Loyalty Management addresses modern‐loyalty demands by going far beyond traditional point-schemes. We reviewed how loyalty programs are evolving into personalised, omnichannel experiences—and how Emarsys enables brands to design tiers, define actions and rewards, unify customer profiles across touchpoints, and engage members through highly relevant communications.&lt;/P&gt;&lt;P&gt;With that foundational business and functional outlook established, this article now moves into the &lt;STRONG&gt;technical implementation journey&lt;/STRONG&gt;, explaining how the architecture, integrations and processes come together to make these business capabilities operational.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1891977696"&gt;&lt;STRONG&gt;Prerequisites&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;To successfully implement SAP Emarsys Loyalty Management, ensure the following components and configurations are in place across the connected SAP landscape.&lt;/P&gt;&lt;H4 id="toc-hId-1824546910"&gt;&lt;STRONG&gt;&amp;nbsp; SAP Emarsys and Loyalty&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;Unique Identifier for contacts&lt;/LI&gt;&lt;LI&gt;Smart Insight setup&lt;/LI&gt;&lt;LI&gt;Automation program to create and assign &lt;STRONG&gt;Loyalty HashID&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Loyalty plan configuration (tiers, actions, and benefits)&lt;/LI&gt;&lt;LI&gt;Voucher setup (optional)&lt;/LI&gt;&lt;LI&gt;Loyalty Wallet (standard SDK-based or custom via Loyalty APIs)&lt;/LI&gt;&lt;LI&gt;Automation program to trigger &lt;STRONG&gt;Webhook&lt;/STRONG&gt; on loyalty point confirmation events&lt;/LI&gt;&lt;/UL&gt;&lt;H4 id="toc-hId-1628033405"&gt;&lt;STRONG&gt;&amp;nbsp; &amp;nbsp;&lt;/STRONG&gt;&lt;STRONG&gt;SAP S/4HANA&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;Sales data posting integration&lt;/LI&gt;&lt;LI&gt;GL accounts and controlling objects&lt;/LI&gt;&lt;LI&gt;Settlement and clearing logic&lt;/LI&gt;&lt;LI&gt;REST APIs for financial posting for the accruals and redemption scenario&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1302437181"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId-1105923676"&gt;&lt;STRONG&gt;Technical Architecture&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="vijaysb15_0-1760848383434.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/329564i33B2C2C0C1AEFA2B/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="vijaysb15_0-1760848383434.png" alt="vijaysb15_0-1760848383434.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-909410171"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId-712896666"&gt;&lt;STRONG&gt;Customer Registration and Loyalty Onboarding&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Customer registration and loyalty onboarding begin when users join the program to enjoy rewards from their purchases and activities.&lt;BR /&gt;New customers can &lt;STRONG&gt;enrol during registration&lt;/STRONG&gt;, while existing customers can &lt;STRONG&gt;join the program anytime&lt;/STRONG&gt;. For both scenarios, a &lt;STRONG&gt;unique HashID&lt;/STRONG&gt; must be generated and assigned to their record before enrolment.&lt;/P&gt;&lt;P&gt;The onboarding process can be initiated across &lt;STRONG&gt;mobile apps&lt;/STRONG&gt;, &lt;STRONG&gt;websites&lt;/STRONG&gt;, or &lt;STRONG&gt;POS systems&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;Typically, SAP Sales Cloud or SAP S/4HANA act as the primary sources of customer data, which are then replicated to SAP Emarsys via SAP CPI.&lt;/P&gt;&lt;P&gt;When a new contact is registered, the record is first created in Sales Cloud or S/4HANA and then replicated to Emarsys. Once created, an automation program generates a HashID and stores it in a custom field at the contact level. Afterward, a Join API call is triggered to add the contact to the relevant Loyalty Plan.&lt;/P&gt;&lt;P&gt;For existing customers who join the loyalty program later, ensure that their &lt;STRONG&gt;HashID&lt;/STRONG&gt; is already generated before executing the Join API call.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="vijaysb15_0-1760848663195.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/329566i871807C1277BABD8/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="vijaysb15_0-1760848663195.png" alt="vijaysb15_0-1760848663195.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-516383161"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId-319869656"&gt;&lt;STRONG&gt;Points Accrual&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;The &lt;STRONG&gt;points accrual&lt;/STRONG&gt; process enables customers to earn loyalty points and benefits based on their purchases and other qualifying activities. For purchase-based accruals, sales data flows from SAP S/4HANA (or ERP) to Smart Insight and then to Emarsys Loyalty, where points and benefits are automatically calculated according to the customer’s plan and tier.&lt;/P&gt;&lt;P&gt;Once points are confirmed, they are sent back to SAP S/4HANA for financial posting, ensuring accounting accuracy.&lt;/P&gt;&lt;P&gt;S/4HANA periodically sends sales transaction data to Emarsys through a tenant-specific Sales Data Load URL found under &lt;STRONG&gt;Predict → Data Sources → Sales Data&lt;/STRONG&gt; in Emarsys. Once Emarsys receives the data, it calculates points based on the predefined logic.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="vijaysb15_1-1760848693559.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/329567i6D2AD11617CE6ACB/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="vijaysb15_1-1760848693559.png" alt="vijaysb15_1-1760848693559.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;An automation program triggers a webhook on the &lt;STRONG&gt;loyalty_points_from_purchase_confirmed&lt;/STRONG&gt; event, which calls a CPI endpoint. This endpoint posts accrual entries in SAP S/4HANA, crediting customer accounts and updating liability GLs as per company-specific financial configurations.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="vijaysb15_2-1760848747475.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/329568i4CF873696D73DC08/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="vijaysb15_2-1760848747475.png" alt="vijaysb15_2-1760848747475.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-123356151"&gt;&lt;STRONG&gt;Points Redemption&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;At checkout, customers can redeem their earned loyalty points either by paying directly with points or by using a voucher. Redemption can be initiated via mobile apps or websites during a purchase.&lt;/P&gt;&lt;P&gt;If the customer chooses to pay directly with points, the &lt;STRONG&gt;Remove Points API&lt;/STRONG&gt; is called to deduct the required amount from their balance. A “Points Removed” activity is automatically recorded in their Emarsys profile.&lt;/P&gt;&lt;P&gt;Alternatively, customers can claim a voucher using the &lt;STRONG&gt;Claim Voucher API&lt;/STRONG&gt;. Once the voucher code is generated, it can be applied at checkout. When a voucher is redeemed, the equivalent points are deducted, and a “Points Redeemed” activity is logged in Emarsys.&lt;/P&gt;&lt;P&gt;The financial postings for redemptions are handled by the respective sales channel (web, mobile, or POS) and then pushed to SAP S/4HANA via CPI to ensure accurate accounting entries.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="vijaysb15_0-1760848849628.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/329569i7CDAD629F0C61303/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="vijaysb15_0-1760848849628.png" alt="vijaysb15_0-1760848849628.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--148388723"&gt;&lt;STRONG&gt;Loyalty Segmentation, Personalization, and Campaigns&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Effective segmentation and personalization are key to increasing engagement and retention. SAP Emarsys enables marketers to create segments using &lt;STRONG&gt;relational data templates&lt;/STRONG&gt;, combining loyalty attributes (tier, points, activity type, or benefits) with contact and behavioral data.&lt;/P&gt;&lt;P&gt;The relational data connection can be setup easily by referring the help link “ &lt;A href="https://help.sap.com/docs/SAP_EMARSYS/f8e2fafeea804018a954a8857d9dfff3/fdf13fc574c110148813e9861f7fecda.html?locale=en-US&amp;amp;state=PRODUCTION&amp;amp;version=CLOUD" target="_blank" rel="noopener noreferrer"&gt;Setting up Loyalty RDS connection&lt;/A&gt;” and templates can be setup as mentioned in the link&amp;nbsp; “ &lt;A href="https://help.sap.com/docs/SAP_EMARSYS/f8e2fafeea804018a954a8857d9dfff3/fdf146fe74c11014a46091ef8e59f041.html?q=Loyalty+Segement+templates&amp;amp;locale=en-US&amp;amp;version=LATEST" target="_blank" rel="noopener noreferrer"&gt;Setting up Loyalty segment templates&lt;/A&gt;”&lt;/P&gt;&lt;P&gt;These segments can be used across multiple campaign channels, including email, SMS, push, and web. Personalization tokens dynamically adapt campaign messages to show details such as the customer’s name, tier, available points, or next reward milestone.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="vijaysb15_4-1760849096026.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/329573iDCD2D647A7F5AA56/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="vijaysb15_4-1760849096026.png" alt="vijaysb15_4-1760849096026.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H4 id="toc-hId--638305235"&gt;&lt;STRONG&gt;&amp;nbsp; Personalization and Campaign Execution&lt;/STRONG&gt;&lt;/H4&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&amp;nbsp;&lt;/STRONG&gt;Once segments are built, they can be used across multiple channels — &lt;STRONG&gt;email, SMS, push notifications, or web campaigns&lt;/STRONG&gt;.&lt;BR /&gt;&amp;nbsp; Using &lt;STRONG&gt;personalization tokens&lt;/STRONG&gt;, each campaign message can dynamically adapt to display the customer’s &lt;STRONG&gt;name&lt;/STRONG&gt;, &lt;STRONG&gt;tier&lt;/STRONG&gt;, &lt;STRONG&gt;available points&lt;/STRONG&gt;, or &lt;STRONG&gt;next reward milestone&lt;/STRONG&gt;, delivering a truly personalized experience.&lt;/P&gt;&lt;P&gt;&amp;nbsp; SAP Emarsys offers prebuilt email template blocks designed for loyalty-related communications. Upon activation of a loyalty plan, the system automatically generates the relevant loyalty tokens. Furthermore, whenever a new Action or voucher is created, corresponding personalization tokens are generated by default.&lt;/P&gt;&lt;P&gt;&amp;nbsp; By blending loyalty data with Emarsys campaign automation, businesses can drive:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Higher engagement through relevant messaging&lt;/LI&gt;&lt;LI&gt;Increased redemption and repeat purchase rates&lt;/LI&gt;&lt;LI&gt;Stronger customer retention and satisfaction&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="vijaysb15_3-1760849064233.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/329572iBA1DF9C01C9ED064/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="vijaysb15_3-1760849064233.png" alt="vijaysb15_3-1760849064233.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId--541415733"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId--737929238"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId--934442743"&gt;&lt;STRONG&gt;Loyalty Reports and Dashboards&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Analytics play a critical role in measuring loyalty program performance. SAP Emarsys publishes loyalty data to Google Cloud Platform through &lt;STRONG&gt;Open Data Views&lt;/STRONG&gt;. These can be connected to &lt;STRONG&gt;SAP Datasphere&lt;/STRONG&gt; using the Remote Table option for near real-time data access.&lt;/P&gt;&lt;P&gt;Within SAP Datasphere, organizations can model data, define KPIs (such as Total Points Accrued vs. Redeemed or Active Members by Tier), and then visualize insights using &lt;STRONG&gt;SAP Analytics Cloud (SAC)&lt;/STRONG&gt; dashboards.&lt;/P&gt;&lt;P&gt;This seamless data flow — from Emarsys to GCP, Datasphere, and SAC — provides real-time visibility into loyalty KPIs, helping businesses make data-driven decisions and optimize customer engagement strategies.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--1130956248"&gt;&lt;STRONG&gt;References:&lt;/STRONG&gt;&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_EMARSYS/8bf21e3e3ad3475bb9e25de1e0ac3d86/fdf6b8c874c11014ab07d03045e4962a.html" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;List of All Public API Endpoints&lt;/STRONG&gt;&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_EMARSYS/f8e2fafeea804018a954a8857d9dfff3/fde868ae74c110148a62b53930abbd3a.html" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Smart Insight Settings&lt;/STRONG&gt;&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_EMARSYS/f8e2fafeea804018a954a8857d9dfff3/45d03e6a8c9d4e6fb48daff2d581b422.html" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Loyalty Implementation &amp;amp; Activation&lt;/STRONG&gt;&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_EMARSYS/f8e2fafeea804018a954a8857d9dfff3/57b315024f7a40ad9975fa1dab2cb36d.html" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Loyalty Tactics&lt;/STRONG&gt;&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_EMARSYS/f8e2fafeea804018a954a8857d9dfff3/fdf6e2a274c11014a5528187e2f772da.html" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Relational Data&lt;/STRONG&gt;&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_EMARSYS/f8e2fafeea804018a954a8857d9dfff3/52f427591f86482c9c5838a88ff7ebfe.html?q=segments" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Creating Segments&lt;/STRONG&gt;&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_EMARSYS/f8e2fafeea804018a954a8857d9dfff3/275ffe318bcb411ebf2eb9eced0d6101.html" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Personalization&lt;/STRONG&gt;&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_EMARSYS/f8e2fafeea804018a954a8857d9dfff3/8e7330ec1eb34779a3042304478a700e.html" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Automation Programs&lt;/STRONG&gt;&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--1327469753"&gt;&lt;STRONG&gt;Summary&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;In &lt;STRONG&gt;Part 2&lt;/STRONG&gt;, we explored the &lt;STRONG&gt;technical implementation journey&lt;/STRONG&gt; of SAP Emarsys Loyalty Management — covering end-to-end integration, automation flows, financial postings, customer service enablement, campaign personalization, and analytical insights through SAP Datasphere and SAP Analytics Cloud.&lt;/P&gt;&lt;P&gt;Stay tuned for &lt;STRONG&gt;Part 3&lt;/STRONG&gt;, where we will focus on &lt;STRONG&gt;Customer Service and Support Scenarios&lt;/STRONG&gt; in greater detail.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Co-Authors:&amp;nbsp;&amp;nbsp;&lt;/STRONG&gt;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/363791"&gt;@sandeepmkh&lt;/a&gt;(Sandeep Kulkarni) and&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/316584"&gt;@lokeshla&lt;/a&gt;&amp;nbsp;(&lt;SPAN&gt;Lokesh Lakhondae)&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/crm-and-cx-blog-posts-by-sap/implementing-sap-emarsys-loyalty-management-part-2-technical-deep-dive/ba-p/14247872"/>
    <published>2025-10-20T06:02:50.534000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/join-the-data-and-analytics-value-map-on-sap-community/ba-p/14249416</id>
    <title>Join the Data and Analytics Value Map on SAP Community</title>
    <updated>2025-10-22T12:55:34.476000+02:00</updated>
    <author>
      <name>Caroline-S</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/105086</uri>
    </author>
    <content>&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Blog Post Banner (4).png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/330252i4A5E0C9B16BC5B38/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Blog Post Banner (4).png" alt="Blog Post Banner (4).png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;SAP Enterprise Support Value Maps have moved to SAP Community. &lt;STRONG&gt;Join us now in the SAP Community Groups&lt;/STRONG&gt; to stay up to date and informed on the &lt;STRONG&gt;SAP Enterprise Support portfolio for Data and Analytics&lt;/STRONG&gt;, ranging from Expert-guided implementation (EGI) sessions, Continuous Quality Check (CQC) services, E-learnings, SAP Enterprise Support Advisory Council pilot programs and more.&lt;/P&gt;&lt;P&gt;The Data and Analytics Value Map provides guidance for solutions including SAP Business Data Cloud, SAP Analytics Cloud, SAP Datasphere, SAP Business Warehouse, SAP HANA Cloud, SAP Databricks, as well as SAP BusinessObjects. To see our new look in the SAP Community, watch the short SAP video (1 min, 30): &lt;A href="https://sapvideo.cfapps.eu10-004.hana.ondemand.com/?entry_id=1_n9gri9t0" target="_blank" rel="noopener nofollow noreferrer"&gt;SAP Enterprise Support Value Maps on SAP Community&lt;/A&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1892033252"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId-1695519747"&gt;&lt;STRONG&gt;How to Access&lt;/STRONG&gt;&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;To access the SAP Enterprise Support Value Maps Group, you must login to SAP Community with an S-user ID or a Universal ID&lt;/LI&gt;&lt;LI&gt;Navigate to us via the tab “Groups”, then “Customer Only Groups” or via our dedicated page: &lt;A href="https://pages.community.sap.com/resources/enterprise-support-value-maps" target="_blank" rel="noopener noreferrer"&gt;SAP Enterprise Support Value Maps&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="SAPCommunityGroupsList.png" style="width: 784px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/330261i1F3C3335E74B81F4/image-dimensions/784x490/is-moderation-mode/true?v=v2" width="784" height="490" role="button" title="SAPCommunityGroupsList.png" alt="SAPCommunityGroupsList.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Once in the SAP Enterprise Support Value Maps Group, select the Data and Analytics Value Map and click “Join Group”&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;Expand the “Options” button and click “Subscribe” to get email notifications of activity within the group&lt;/LI&gt;&lt;LI&gt;Why join and subscribe? To set customization preferences, get notifications, participate in the group and have a better user experience&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="JoinGroup_Subscribe.png" style="width: 782px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/330262i07D8EC551AE7E6EB/image-dimensions/782x643/is-moderation-mode/true?v=v2" width="782" height="643" role="button" title="JoinGroup_Subscribe.png" alt="JoinGroup_Subscribe.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1499006242"&gt;&lt;STRONG&gt;Blog Posts&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;We will continue to post blogs to let you know about availability of new and updated content in the SAP Enterprise Support portfolio, such as new E-Learnings, events taking place, best practices, and other relevant information for the Data and Analytics topic.&lt;/P&gt;&lt;H3 id="toc-hId-1302492737"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId-1105979232"&gt;&lt;STRONG&gt;Knowledge Base&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Our Knowledge Base is a collection of documents, which provide both foundational information and in-depth guidance for SAP Data and Analytics topics including SAP Business Data Cloud. These focused documents organize the Expert-guided implementation (EGI) sessions, Continuous Quality Check (CQC) services, E-learnings, best practices, and more by topic. Making it easier for you to see in one place the SAP Enterprise Support offerings by topic and/or solution area. Here are three Knowledge Base directories to bookmark within the Data and Analytics Value Map:&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-knowledge-base/sap-business-data-cloud-directory/ta-p/14220062" target="_blank"&gt;SAP Business Data Cloud Directory&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-knowledge-base/sap-data-warehousing-directory/ta-p/14220319" target="_blank"&gt;SAP Data Warehousing Directory&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-knowledge-base/sap-businessobjects-bi-2025-directory/ta-p/14205030" target="_blank"&gt;SAP BusinessObjects BI 2025 Directory&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-909465727"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId-712952222"&gt;&lt;STRONG&gt;Q&amp;amp;A&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Use the Q&amp;amp;A section to ask us questions or find questions that have already been answered.&amp;nbsp;For example, maybe you need guidance on how to find best practices and make use of the SAP Enterprise Support offerings for your project such as a BW modernization in SAP Business Data Cloud. The following could be relevant for you:&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;EGI for SAP BW Modernization with SAP Business Data Cloud&lt;/LI&gt;&lt;LI&gt;CQC for Private Cloud Go-Live&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;CQC for Implementation&lt;/LI&gt;&lt;LI&gt;CQC Technical Performance Optimization (TPO)&lt;/LI&gt;&lt;LI&gt;CQC Business Process Performance Optimization (BPPO)&lt;/LI&gt;&lt;LI&gt;CQC for Security Optimization&lt;/LI&gt;&lt;LI&gt;CQC for Data Volume Management&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Full details are in the Knowledge Base &lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-knowledge-base/sap-bw-modernization-with-foundational-support/ta-p/14206374" target="_blank"&gt;SAP BW Modernization with Foundational Support&lt;/A&gt;&lt;/P&gt;&lt;H3 id="toc-hId-516438717"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId-319925212"&gt;&lt;STRONG&gt;Events&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;The monthly EGI schedule will be populated here giving details of the planned EGI topics, dates, time, regions and languages.&lt;/P&gt;&lt;H3 id="toc-hId-123411707"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId--148333167"&gt;&lt;STRONG&gt;Request a Call&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Request a call with one of our topic experts to connect with the right content and resources.&lt;/P&gt;&lt;H5 id="toc-hId--931652686"&gt;&amp;nbsp;&lt;/H5&gt;&lt;H3 id="toc-hId--541360177"&gt;&lt;STRONG&gt;LIVE SESSIONS on SAP Enterprise Support value maps – Our Move to SAP Community&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Join this live session on&amp;nbsp;October 22, 2025, to learn more, where we will demo SAP Enterprise Support value maps on SAP Community.&amp;nbsp;&lt;span class="lia-unicode-emoji" title=":link:"&gt;🔗&lt;/span&gt;&amp;nbsp;&lt;A href="https://www.youtube.com/live/1nTUW1L8biA" target="_blank" rel="noopener nofollow noreferrer"&gt;Link to join / Watch Replay&lt;/A&gt;&lt;/P&gt;&lt;H5 id="toc-hId--1324679696"&gt;&amp;nbsp;&lt;/H5&gt;&lt;H5 id="toc-hId--1521193201"&gt;Enhance Your SAP Experience with Value Maps&amp;nbsp;&lt;/H5&gt;&lt;P&gt;SAP Enterprise Support offers additional resources to help you drive innovation. SAP Enterprise Support value maps provide expert-led resources, tailored recommendations, and advisory services - all included in your SAP cloud subscription. Get started today:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;One-time sign up for SAP Learning Hub, edition for SAP Enterprise Support, using a valid S-User ID (please allow up to 2 hours for processing)&lt;/LI&gt;&lt;LI&gt;Access SAP Enterprise Support value maps for personalized guidance&lt;/LI&gt;&lt;LI&gt;Request a call with our solution area experts for tailored advice&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Value Maps are part of SAP Enterprise Support commitment to your success. Visit the SAP Enterprise Support value maps&amp;nbsp;&lt;A href="https://pages.community.sap.com/resources/enterprise-support-value-maps" target="_blank" rel="noopener noreferrer"&gt;landing page&lt;/A&gt;&amp;nbsp;to explore our range of topics and start engaging with us today.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;About the author:&amp;nbsp;&lt;/STRONG&gt;&lt;BR /&gt;&lt;STRONG&gt;Caroline Sheridan&lt;/STRONG&gt; is a Topic Expert for SAP Enterprise Support value maps, specializing in SAP Data and Analytics. With a tenure of 12 years at SAP, Caroline’s expertise lies in assisting and guiding customers to succeed through SAP Enterprise Support offerings.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":light_bulb:"&gt;💡&lt;/span&gt;&lt;STRONG&gt;Have&amp;nbsp;questions&lt;/STRONG&gt;&amp;nbsp;or&amp;nbsp;&lt;STRONG&gt;feedback&lt;/STRONG&gt;&amp;nbsp;on this content? Feel free to leave a comment below or submit them in the&amp;nbsp;&lt;A href="https://community.sap.com/t5/data-and-analytics-value-map-q-a/qa-p/es-data-analyticsqanda-board" target="_blank"&gt;Q&amp;amp;A&lt;/A&gt;&amp;nbsp;section.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/join-the-data-and-analytics-value-map-on-sap-community/ba-p/14249416"/>
    <published>2025-10-22T12:55:34.476000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/launch-your-data-science-platform-with-sap-business-data-cloud/ba-p/14250546</id>
    <title>Launch your Data Science Platform with SAP Business Data Cloud</title>
    <updated>2025-10-23T06:39:09.372000+02:00</updated>
    <author>
      <name>JoelleS</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1431336</uri>
    </author>
    <content>&lt;P&gt;Let's set the architecture.&lt;/P&gt;&lt;P&gt;Within SAP Business Data Cloud we will use SAP Datasphere and SAP Business Data Cloud. Note that SAP Databricks runs on its own Object Store. This is not the same object store that could be activated in SAP Datasphere. We will not activate an Object Store (BDC Object Store) for this case.&amp;nbsp; You can do that. This means, that you will benefit from Data Products (SAP and Customer managed). But as of today you will lose semantics. Therefore we will go for another approach this time. Make sure to check which approach might be best for you.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;1. Step: Activate SAP Datasphere and SAP Databricks. If you already have a Datasphere (activated before 2025) and you want it to be in your BDC formation, please make sure to contact your BDC account executive.&lt;/LI&gt;&lt;LI&gt;2. Step: Within SAP Datasphere create a space (HANA Cloud not Hana Data Lake Files)&lt;/LI&gt;&lt;LI&gt;3. Step: Within this space, create a view which is exposed for consumption. Note that you have to create a view. Tables (also remote tables) cannot be exposed&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="JoelleS_0-1761132218459.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/330926i775B4027A902F2A6/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="JoelleS_0-1761132218459.png" alt="JoelleS_0-1761132218459.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;4. Step: Create a database user&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="JoelleS_1-1761132380078.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/330927i692B85EA63780CC0/image-size/medium?v=v2&amp;amp;px=400" role="button" title="JoelleS_1-1761132380078.png" alt="JoelleS_1-1761132380078.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;5. Step Open SAP Databricks&lt;/LI&gt;&lt;LI&gt;6. Step Open a Workbook and connect it to a running Cluster&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;7. Step Insert the following to find your Clusters IP Address&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;%pip install fedml-databricks --no-cache-dir --upgrade --force-reinstall from fedml_databricks import DbConnection,predict 
import numpy as np 
import pandas as pd 
import json 
import socket 

hostname = socket.gethostname() ip_address = socket.gethostbyname(hostname) display({"Cluster Hostname": hostname, "Cluster IP Address": ip_address})​&lt;/code&gt;&lt;/pre&gt;&lt;UL&gt;&lt;LI&gt;8. Step: In SAP Datasphere whitelist the IP Address&lt;/LI&gt;&lt;LI&gt;9. Step: Create personal token in SAP Databricks&lt;/LI&gt;&lt;LI&gt;10. Step: Create Scope&lt;/LI&gt;&lt;LI&gt;11. Step: Create Secret (enter Credentials from SAP Datasphere Database User)&lt;/LI&gt;&lt;LI&gt;12. Step: Establish Connection with Secret&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;pip install hana-ml
from hana_ml.dataframe import ConnectionContext
conn = dataframe.ConnectionContext(address='',
                                   port=443, 
                                   user='', 
                                   password='' 
                                  )
conn.connection.isconnected()&lt;/code&gt;&lt;/pre&gt;&lt;UL&gt;&lt;LI&gt;13. Step: Connect to view&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;df_remote = hana_conn.table('&amp;lt;yourexposedview&amp;gt;', schema='&amp;lt;yourspaceschema&amp;gt;')​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Congrats! You now can perform predictions based on your data in SAP Datashere. You can return the data to SAP Datasphere as HANA Table.&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/launch-your-data-science-platform-with-sap-business-data-cloud/ba-p/14250546"/>
    <published>2025-10-23T06:39:09.372000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/sap-teched-sessions-in-berlin-and-sydney-2025-by-kp-sauer/ba-p/14251763</id>
    <title>SAP TechEd Sessions in Berlin and Sydney 2025 by KP Sauer</title>
    <updated>2025-10-27T17:35:29.715000+01:00</updated>
    <author>
      <name>kpsauer</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14110</uri>
    </author>
    <content>&lt;H2 id="toc-hId-1763638761"&gt;SAP TechEd 2025&lt;/H2&gt;&lt;P&gt;One more week to #SAPTechEd 2025.&lt;BR /&gt;&lt;SPAN&gt;I am super excited &lt;span class="lia-unicode-emoji" title=":sparkles:"&gt;✨&lt;/span&gt; to speak at this year’s SAP TechEd in Berlin, and also in Sydney for SAP TechEd on Tour.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;🤩 Looking forward to meet and talk to all you data and analytics experts in Berlin or Sydney.&lt;/P&gt;&lt;P&gt;Join me for a variety of sessions this year and gain a comprehensive understanding of our strategic direction and priorities with SAP Business Data Cloud.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1567125256"&gt;SAP TechEd in Berlin&lt;/H2&gt;&lt;H4 id="toc-hId-1628777189"&gt;Deep Dive Sessions&lt;/H4&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;STRONG&gt;DA204 | The impact of SAP Business Data Cloud on SAP Datasphere users&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This session is for all users of SAP Datasphere to better understand the impact with SAP Business Data Cloud and the new options you get within such a new landscape. Rithivika Acharya will give you a demo and we will have some time for Q&amp;amp;A at the end&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;🔗&lt;/span&gt;&amp;nbsp; &lt;A href="https://www.sap.com/events/teched/berlin/flow/sap/te25/catalog-inperson/page/catalog/session/1753913915410001RQyH" target="_blank" rel="noopener noreferrer"&gt;https://www.sap.com/events/teched/berlin/flow/sap/te25/catalog-inperson/page/catalog/session/1753913915410001RQyH&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="DA204.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/331601iCEA9ABE801466DB8/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="DA204.png" alt="DA204.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;STRONG&gt;DA203 | SAP Business Data Cloud: The path forward for SAP Business Warehouse&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This session is for all users of SAP BW or BW/4HANA to better understand the impact with SAP Business Data Cloud and exploring the best practices for modernizing with such a new landscape. Domink Kurz will mainly talk here and we will have some time for Q&amp;amp;A at the end.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;🔗&lt;/span&gt;&amp;nbsp; &lt;A href="https://www.sap.com/events/teched/berlin/flow/sap/te25/catalog-inperson/page/catalog/session/1753910209205001V1Vm" target="_blank" rel="noopener noreferrer"&gt;https://www.sap.com/events/teched/berlin/flow/sap/te25/catalog-inperson/page/catalog/session/1753910209205001V1Vm&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="kpsauer_0-1761224561237.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/331602i4055646C57CAFD1F/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="kpsauer_0-1761224561237.png" alt="kpsauer_0-1761224561237.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H4 id="toc-hId-1432263684"&gt;Hands-on Workshop&lt;/H4&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&amp;nbsp;&amp;nbsp;&lt;STRONG&gt;DA264 | SAP Business Data Cloud: Explore the analytical components end to end&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This beginner hands-on workshop takes you through the analytical components of the SAP Business Data Cloud solution. Use the SAP Datasphere and SAP Analytics Cloud solutions to design and build custom scenarios from beginning to end. This session is ideal for technical users seeking to transform data into meaningful business insights. I will be hosting this together with Hannes Keil, Daniel Ingenhaag and Florian Neukirch.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;🔗&lt;/span&gt;&amp;nbsp; &lt;A href="https://www.sap.com/events/teched/berlin/flow/sap/te25/catalog-inperson/page/catalog/session/1754056240863001fO9w" target="_blank" rel="noopener noreferrer"&gt;https://www.sap.com/events/teched/berlin/flow/sap/te25/catalog-inperson/page/catalog/session/1754056240863001fO9w&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="kpsauer_1-1761224580227.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/331603i908E9B49B0383441/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="kpsauer_1-1761224580227.png" alt="kpsauer_1-1761224580227.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Are you ready? &lt;span class="lia-unicode-emoji" title=":backhand_index_pointing_right:"&gt;👉&lt;/span&gt; Register now: &lt;A href="https://www.sap.com/events/teched.html" target="_blank" rel="noopener noreferrer"&gt;https://www.sap.com/events/teched.html&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-977584741"&gt;SAP TechEd on Tour in Sydney&lt;/H2&gt;&lt;P&gt;In Sydney I will be talking live about &lt;span class="lia-unicode-emoji" title=":rocket:"&gt;🚀&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&amp;nbsp; &lt;STRONG&gt;DA806 | SAP Business Data Cloud Solution Road Map&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Join me and gain a comprehensive understanding of our strategic direction and priorities with SAP Business Data Cloud. Find out about the product road map and ongoing development in key areas. Learn about our plans to continue to deliver innovation to aid in your data strategy.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="DA806.jpg" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/331611iE0B2C1D3ABDBC63C/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="DA806.jpg" alt="DA806.jpg" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":right_arrow:"&gt;➡️&lt;/span&gt;&amp;nbsp; &lt;STRONG&gt;DA100 | An Introduction to SAP Business Data Cloud&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Join us for an insightful overview of SAP Business Data Cloud. Discover the key capabilities including seamless integration of SAP and non-SAP data sources, the data product concept, and analytics-ready data across your organization. Learn how SAP Business Data Cloud supports agile decision-making, simplifies complex data challenges, and drives digital transformation.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="DA100.jpg" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/331613iAA8C010F4A4BB191/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="DA100.jpg" alt="DA100.jpg" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Other than these sessions I will be around the show floor and support hands-on sessions too.&lt;BR /&gt;So please be welcome to talk to me as I’m happy to share my SAP experience during the three days &lt;span class="lia-unicode-emoji" title=":loudspeaker:"&gt;📢&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Passes to Mastering SAP Collaborate, an SAP TechEd on Tour event, are available online now – join me in Sydney on 12 – 14 November!&lt;/P&gt;&lt;P&gt;Program and passes at &lt;A href="http://sapteched.sydney/" target="_blank" rel="noopener nofollow noreferrer"&gt;&lt;STRONG&gt;http://sapteched.sydney&lt;/STRONG&gt;&lt;/A&gt; and best of all you can use code SPEAKER5OFF to save 5% on a pass.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":spiral_calendar:"&gt;🗓&lt;/span&gt;&amp;nbsp; When: 12 - 14 November 2025&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":round_pushpin:"&gt;📍&lt;/span&gt;&amp;nbsp; Where: International Convention Centre, ICC, Darling Harbour, Sydney&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;STRONG&gt;Related community &lt;/STRONG&gt;&lt;/SPAN&gt;&lt;STRONG&gt;topic pages&lt;SPAN&gt;:&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://pages.community.sap.com/topics/business-data-cloud" target="_blank" rel="noopener noreferrer"&gt;SAP Business Data Cloud | SAP Community&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://pages.community.sap.com/topics/datasphere" target="_blank" rel="noopener noreferrer"&gt;SAP Datasphere | SAP Community&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/topics/cloud-analytics" target="_blank"&gt;SAP Analytics Cloud | SAP Community&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;STRONG&gt;Looking forward to seeing you in Berlin and Sydney!&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;STRONG&gt;Now let’s hear from you&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;What is your favorite feature in SAP Datasphere?&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Do you already have any plans for SAP Business Data Cloud or are you waiting to adopt?&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;Please add your thoughts as comments to this blog. Thanks!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-teched-sessions-in-berlin-and-sydney-2025-by-kp-sauer/ba-p/14251763"/>
    <published>2025-10-27T17:35:29.715000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/building-bridges-between-sap-and-databricks-a-dream-team-for-your-data-and/ba-p/14255167</id>
    <title>Building Bridges Between SAP and Databricks: A Dream Team for Your Data and AI-Powered Analytics</title>
    <updated>2025-10-28T13:25:22.036000+01:00</updated>
    <author>
      <name>marcel_scherbinek</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/185392</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;The Interplay of SAP &amp;amp; Databricks: Why Now?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The combination of SAP and Databricks is more than just a technical integration; it is a &lt;STRONG&gt;strategic course-setting&lt;/STRONG&gt;. It brings together the best of two worlds:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;SAP as a Stable Foundation:&lt;/STRONG&gt; Your SAP systems contain the most important business data—from financial key figures to master data. This data is not only comprehensive but also semantic and contextual, making it an ideal basis for training AI models.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Databricks as an Innovation Engine:&lt;/STRONG&gt; Databricks offers a scalable platform for Data, Analytics, and AI. It is a powerful engine for machine learning and complex analyses, enabling companies to gain valuable insights from large amounts of data.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This &lt;STRONG&gt;Dream Team&lt;/STRONG&gt; transforms corporate management. Instead of merely answering questions like "What happened?", Business AI enables a look into the future: "&lt;STRONG&gt;Why&lt;/STRONG&gt; did it happen?" and, most importantly, "&lt;STRONG&gt;What&lt;/STRONG&gt; will happen and what should we do?".&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="marcel_scherbinek_0-1761653862390.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333399iDAA688BD72468DAF/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="marcel_scherbinek_0-1761653862390.png" alt="marcel_scherbinek_0-1761653862390.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;Figure 1: Interplay of SAP &amp;amp; Databricks&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;The Benefits of Integration at a Glance&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The partnership between SAP and Databricks offers tangible benefits that are evident at the strategic, technical, and operational levels.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Strategic Advantages&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The integration ensures &lt;STRONG&gt;open data management and analytics&lt;/STRONG&gt; for SAP and non-SAP data. Complete alignment with the SAP Business Data Cloud with strong &lt;STRONG&gt;governance&lt;/STRONG&gt; creates a future-proof architecture. The simplified pricing model in general &lt;STRONG&gt;Capacity Units&lt;/STRONG&gt; also makes the start easier to plan.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Technical Advantages&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The platform is designed to allow extended use via interfaces and can &lt;STRONG&gt;scale&lt;/STRONG&gt; with growing demands and data volumes. The &lt;STRONG&gt;seamless integration&lt;/STRONG&gt; of the SAP Business Warehouse and SAP S/4HANA with data products enables an end-to-end process. An important difference when deciding for or against an SAP Databricks: The &lt;STRONG&gt;SAP Databricks is fully managed by SAP&lt;/STRONG&gt;. This means it is technically operational immediately.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Operational Advantages&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Companies benefit from a &lt;STRONG&gt;Hyperscaler infrastructure&lt;/STRONG&gt;, which ensures &lt;STRONG&gt;resilience&lt;/STRONG&gt; and a reduction in &lt;STRONG&gt;Total Cost of Ownership (TCO)&lt;/STRONG&gt;. Technical operation is supported by &lt;STRONG&gt;Managed Services from SAP&lt;/STRONG&gt;, which reduces complexity in day-to-day business and allows for the installation of upgrades on demand.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;How the Dream Team Works in Practice&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Databricks offers a number of key elements to enable integration and analysis:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Unity Catalog:&lt;/STRONG&gt; The &lt;STRONG&gt;Unity Catalog&lt;/STRONG&gt; serves as a central landing zone for &lt;STRONG&gt;governance and data products&lt;/STRONG&gt;. Metadata is managed here and the data is stored in &lt;STRONG&gt;Delta Tables&lt;/STRONG&gt;, ensuring a consistent view of your information and secure access.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="marcel_scherbinek_1-1761653862405.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333401i6FEF07CA63950021/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="marcel_scherbinek_1-1761653862405.png" alt="marcel_scherbinek_1-1761653862405.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;Figure 2: Databricks Unity Catalog: The landing zone for governance and data products.&lt;/EM&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Databricks Workspace:&lt;/STRONG&gt; &lt;STRONG&gt;Modeling and development&lt;/STRONG&gt; take place in the &lt;STRONG&gt;Databricks Workspace&lt;/STRONG&gt;. Users work here with &lt;STRONG&gt;interactive notebooks&lt;/STRONG&gt;, which offer an encapsulated programming interface for agile and flexible work. SQL, Python, R, and Scala are supported as languages.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="marcel_scherbinek_2-1761653862428.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333400i3E41990489FFB01F/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="marcel_scherbinek_2-1761653862428.png" alt="marcel_scherbinek_2-1761653862428.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;Figure 3: Databricks Workspace: Modeling takes place in Databricks within the Workspace, using "Notebooks" among other tools.&lt;/EM&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Databricks Machine Learning:&lt;/STRONG&gt; The integration of &lt;STRONG&gt;MLflow&lt;/STRONG&gt; enables the &lt;STRONG&gt;training, versioning, and deployment of models&lt;/STRONG&gt;. The clear management of training runs and the linking of datasets significantly simplifies the establishment of professional AI in the company. Important to know: The operation of Machine Learning models should strategically take place in &lt;STRONG&gt;SAP AI Core&lt;/STRONG&gt;, although Databricks also supports this functionality depending on the use case.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="marcel_scherbinek_3-1761653862449.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333402iB7B7B85E47379C7B/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="marcel_scherbinek_3-1761653862449.png" alt="marcel_scherbinek_3-1761653862449.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;Figure 4: Databricks Machine Learning. Model training (experiments), model versioning, or the deployment of models on one platform.&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Conclusion: From Dataset to Smart Decision&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The combination of SAP and Databricks elevates data analysis to a new level. Your financial key figures and master data serve as a reliable source for intelligent analyses. The integration with Databricks makes it possible to automatically &lt;STRONG&gt;recognize patterns and correlations&lt;/STRONG&gt; from this data. The platform's flexibility and scalability allow complex AI models to be applied and the resulting &lt;STRONG&gt;cluster information seamlessly fed back into your SAP world&lt;/STRONG&gt; to enable users to make well-founded decisions. The deep and exclusive technical integration of both worlds guarantees a secure and fast exchange of data products.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Key Takeaways for Your Company&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Data and AI are moving closer together:&lt;/STRONG&gt; The separation between data storage (SAP) and data analysis (Databricks) is a thing of the past. The seamless integration allows your most valuable business data to be used directly for modern AI applications. This creates a unified information base and eliminates fragmented data silos.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;High Potential through Synergies:&lt;/STRONG&gt; The combination of SAP’s standardized data storage and proven processes with Databricks’ innovative AI technology opens up completely new possibilities. You can not only see what happened but also why it happened and what will happen next. This empowers you to act proactively and identify risks early on.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Professional AI Establishment:&lt;/STRONG&gt; The Databricks platform offers a mature environment for professionally establishing AI applications in the company. Thanks to functions like &lt;STRONG&gt;Unity Catalog&lt;/STRONG&gt; for data governance and &lt;STRONG&gt;Databricks Machine Learning&lt;/STRONG&gt; for model training, you can ensure that your AI initiatives are scalable, secure, and sustainable.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;How You Can Get Started Now: Our Practical Advice&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Many companies hesitate to take the first step because the topic seems complex. However, getting started doesn't have to be overwhelming. We recommend starting with a &lt;STRONG&gt;Proof-of-Concept (PoC)&lt;/STRONG&gt;.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Define a Clear Use Case:&lt;/STRONG&gt; Choose an area in your company where data analysis can bring real added value. This could be optimizing inventory management, predicting customer behavior, or automating financial forecasts.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Utilize Your Existing Potential:&lt;/STRONG&gt; A PoC helps you assess how you can tap into your unused data potential. This provides concrete results and allows you to prove the business case for a broader implementation.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Start Small to Grow Big:&lt;/STRONG&gt; Begin with a manageable project to achieve quick successes and build confidence in the new technology. The scalability of the platform allows you to easily add more use cases later.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The partnership between SAP and Databricks is not a futuristic concept but a &lt;STRONG&gt;practice-oriented solution&lt;/STRONG&gt; that helps you make data-driven decisions and future-proof your company. The time to awaken your SAP data from its slumber is now.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Now it’s your turn:&lt;/STRONG&gt; What experiences have you already had with using SAP data for intelligent analyses? What challenges do you see on the path to Business AI? We look forward to your perspectives and to shaping the future of data analysis together.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/building-bridges-between-sap-and-databricks-a-dream-team-for-your-data-and/ba-p/14255167"/>
    <published>2025-10-28T13:25:22.036000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/converting-fsv-financial-statement-version-into-a-flattened-structure-using/ba-p/14253164</id>
    <title>Converting FSV (Financial Statement Version) into a Flattened Structure using Python</title>
    <updated>2025-10-29T12:02:14.807000+01:00</updated>
    <author>
      <name>LaxminarayanGupta</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1949744</uri>
    </author>
    <content>&lt;P&gt;&lt;FONT size="6"&gt;&lt;STRONG&gt;Introduction&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;The Financial Statement Version (FSV) is one of the most critical structures in SAP for representing how financial data rolls up across accounts and reporting nodes. This article walks through how to use &lt;STRONG&gt;Python within Datasphere Dataflows&lt;/STRONG&gt; to flatten the hierarchical FSV structure into a simple, analysis-ready table.&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;P&gt;Use case A: Often flattened structures are required by a downstream system (e.g. Onestream, Snowflake or Azure) from SAP Datasphere.&lt;/P&gt;&lt;P&gt;Use case B: Reporting requirements on flattened structure in SAC (SAP Analytics Cloud) stories.&amp;nbsp; &amp;nbsp;&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="LaxminarayanGupta_0-1761387188585.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/332345i875F2228BC6DCF71/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="LaxminarayanGupta_0-1761387188585.png" alt="LaxminarayanGupta_0-1761387188585.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;*Figure : Example of a Financial Statement Version hierarchy with multiple reporting levels.*&amp;nbsp;&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT size="6"&gt;Python Transform&lt;/FONT&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/STRONG&gt;The FSV in SAP stores hierarchical information - each node represents a reporting group, which may have sub-nodes or leaf nodes pointing to G/L accounts.&lt;/P&gt;&lt;P&gt;Source Data:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="LaxminarayanGupta_2-1761387480550.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/332348iAF920E150328F4E9/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="LaxminarayanGupta_2-1761387480550.png" alt="LaxminarayanGupta_2-1761387480550.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Using a &lt;STRONG&gt;Python Transform&lt;/STRONG&gt; node inside a Datasphere Dataflow, we can achieve this through a recursive traversal. The logic builds two key lookup dictionaries:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;One mapping each &lt;STRONG&gt;parent node&lt;/STRONG&gt; to its &lt;STRONG&gt;children&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Another mapping each &lt;STRONG&gt;node ID&lt;/STRONG&gt; to its &lt;STRONG&gt;node name&lt;/STRONG&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Then, a recursive build_paths() function walks through the hierarchy using &lt;STRONG&gt;Depth-First Search (DFS)&lt;/STRONG&gt; - visiting each node, building its full path (e.g., Financial Statement Version &amp;gt;&amp;nbsp;&lt;EM&gt;Assets &amp;gt; Current Assets&lt;/EM&gt;), and recording its level details (LEVEL1, LEVEL2, etc.).&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# Ensure no missing values in parent IDs
    data["PARENT_ID"] = data["PARENT_ID"].fillna("ROOT")

    # Build lookup dictionary: parent → children
    children_map = data.groupby("PARENT_ID")["NODE_ID"].apply(list).to_dict()
    names_map = data.set_index("NODE_ID")["NODE_NAME"].to_dict()

    # Recursive function to build paths
    def build_paths(node, path):
        name = names_map.get(node, "")
        current_path = path + [name] if name else path
        results = [{"NODE_ID": node,
                    "NODE_NAME": name,
                    "FULL_PATH": " &amp;gt; ".join(current_path),
                    "LEVEL1": current_path[0] if len(current_path) &amp;gt; 0 else None,
                    "LEVEL2": current_path[1] if len(current_path) &amp;gt; 1 else None,
                    "LEVEL3": current_path[2] if len(current_path) &amp;gt; 2 else None,
                    "LEVEL4": current_path[3] if len(current_path) &amp;gt; 3 else None,
                    "LEVEL5": current_path[4] if len(current_path) &amp;gt; 4 else None,
                    "LEVEL6": current_path[5] if len(current_path) &amp;gt; 5 else None,
                    "LEVEL7": current_path[6] if len(current_path) &amp;gt; 6 else None,
                    "LEVEL8": current_path[7] if len(current_path) &amp;gt; 7 else None}]
        for child in children_map.get(node, []):
            results.extend(build_paths(child, current_path))
        return results

    # Start from ROOT (or null parent)
    flattened = []
    for root in children_map.get("ROOT", []):
        flattened.extend(build_paths(root, []))

    # Convert back to DataFrame
    data = pd.DataFrame(flattened)

    return data&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;BR /&gt;The final output is a &lt;STRONG&gt;flat table&lt;/STRONG&gt; showing node ID, name, full path, and level columns - ready for SAC visualizations or direct joins with GL balances.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="LaxminarayanGupta_5-1761387609566.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/332351i2FF4A237E880430D/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="LaxminarayanGupta_5-1761387609566.png" alt="LaxminarayanGupta_5-1761387609566.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT size="6"&gt;&lt;STRONG&gt;Conclusion&amp;nbsp;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;This approach ensures that the FSV - a cornerstone of SAP Financials remains a powerful, adaptable asset for unified financial reporting and planning.&amp;nbsp; This method simplifies downstream modelling and Python gives developers precise control over custom FSV structures or hybrid hierarchies that span SAP and non-SAP sources.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;(To know more about FSV- refer the SAP learning &lt;A href="https://learning.sap.com/learning-journeys/designing-the-record-to-report-process-in-sap-s-4hana/configuring-a-new-financial-statement-version_fca3de26-5c46-4cfd-8a21-8c38be6e298e" target="_self" rel="noopener noreferrer"&gt;journey&lt;/A&gt;)&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/converting-fsv-financial-statement-version-into-a-flattened-structure-using/ba-p/14253164"/>
    <published>2025-10-29T12:02:14.807000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/from-sap-datasphere-to-a-local-llm-llama-3-1-hands-on-tutorial/ba-p/14253357</id>
    <title>From SAP Datasphere to a Local LLM (Llama 3.1)  — Hands-On Tutorial</title>
    <updated>2025-10-29T12:05:30.405000+01:00</updated>
    <author>
      <name>SethiR</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1792324</uri>
    </author>
    <content>&lt;P&gt;&lt;FONT size="6"&gt;&lt;BR /&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Introduction&amp;nbsp;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This post documents a small, reproducible pattern for bringing SAP Datasphere data to a local large language model (LLM) for lightweight analysis. The goal is simple: keep modeling and governance in Datasphere, pull a view into a Jupyter notebook with pandas, and let a local LLM produce machine-readable JSON that you can filter, join, or visualize. The prototype runs on a CPU-only laptop so anyone can follow along without special hardware.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;What this is&lt;/STRONG&gt;:&lt;BR /&gt;-&amp;nbsp;A step-by-step walkthrough that uses hdbcli to query a Datasphere view and Transformers to run Meta Llama 3.1 locally.&lt;BR /&gt;-&amp;nbsp;A row-by-row prompt pattern that returns compact JSON (total, average, flags) you can plug back into your DataFrame. A row-by-row prompt pattern that returns compact JSON (total, average, flags) you can plug back into your DataFrame.&lt;BR /&gt;-&amp;nbsp;A row-by-row prompt pattern that returns compact JSON (total, average, flags) you can plug back into your DataFrame.&lt;BR /&gt;&lt;BR /&gt;&lt;STRONG&gt;What this is not:&lt;/STRONG&gt;&lt;BR /&gt;-&amp;nbsp;A benchmarking or performance guide. CPU runs are slow but convenient for learning.&lt;BR /&gt;-&amp;nbsp;A recommendation to hard-code credentials. The POC mirrors the original notebook for clarity; use environment variables or a vault in real projects.A recommendation to hard-code credentials. The POC mirrors the original notebook for clarity; use environment variables or a vault in real projects.&lt;BR /&gt;-&amp;nbsp;A pattern for sending sensitive data to external endpoints. Use test or masked data if you move past local inference. A pattern for sending sensitive data to external endpoints. Use test or masked data if you move past local inference.&lt;BR /&gt;&lt;BR /&gt;&lt;STRONG&gt;What you will build:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;A compact flow: SAP Datasphere View -&amp;gt; Python/Jupyter (hdbcli + pandas) -&amp;gt; row-level prompt -&amp;gt; Local LLM (Transformers) -&amp;gt; JSON back to DataFrame. The same prompts can be pointed to managed inference later for production.&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1763694472"&gt;Prerequisites&lt;/H2&gt;&lt;P&gt;1.&amp;nbsp;SAP Datasphere space with permission to create a Database User and a SQL View&lt;BR /&gt;2.&amp;nbsp;Python 3.10+ with Jupyter&lt;BR /&gt;3.&amp;nbsp;Libraries: pandas, hdbcli, transformers, torch, accelerate, ipython&lt;BR /&gt;4.&amp;nbsp;Hugging Face account + access token (accept access for the Llama 3.1 model)&lt;BR /&gt;&lt;BR /&gt;Security note: The POC code below uses inline credentials to mirror the original run. In real work, put secrets in environment variables or a vault and keep TLS validation enabled.&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Part A — SAP Datasphere&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;A1. Enable database access for the space&lt;/P&gt;&lt;P&gt;1.&amp;nbsp;Open SAP Datasphere -&amp;gt; Spaces -&amp;gt; select your space.&lt;BR /&gt;2.&amp;nbsp;Go to Database Access and confirm SQL access is enabled for the space&amp;nbsp;&lt;/P&gt;&lt;P&gt;A2. Create a Database User&lt;/P&gt;&lt;P&gt;1.&amp;nbsp;Database Access -&amp;gt; Database Users -&amp;gt; Create.Database Access -&amp;gt; Database Users -&amp;gt; Create.&lt;BR /&gt;2.&amp;nbsp;Grant only read privileges/necessary privileges to the schema/view you will query.&lt;BR /&gt;3.&amp;nbsp;Copy the SQL Endpoint (host) and port 443 for Python connectivity. Make sure you copy password and host details and store it in a safe place.&amp;nbsp;&lt;BR /&gt;&lt;BR /&gt;A3. Create a demo view with a few rows&lt;/P&gt;&lt;P&gt;Create a SQL View (or graphical view). Here we have taken&amp;nbsp; "ACN_DWC"."DemoView_SETHIR_PY" with columns:&lt;BR /&gt;Stud_ID, Stud_Fname, Stud_Lname, Stud_DOB, Maths, Physics, Chemistry, Total, Stud_Addr, Stud_Faname for the demo.&lt;BR /&gt;Make sure the view is exposed for Consumption.&lt;BR /&gt;Optional seed SQL you can adapt:&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;SELECT * FROM (
  SELECT 101 AS Stud_ID, 'Arjun'     AS Stud_Fname, 'Singh'    AS Stud_Lname, DATE'2012-04-06' AS Stud_DOB,
         80 AS Maths, 75 AS Physics, 80 AS Chemistry, 235 AS Total, 'Chandigarh' AS Stud_Addr, 'Sukhdev' AS Stud_Faname
  UNION ALL
  SELECT 102, 'Harpreet', 'Kaur',  DATE'2010-09-08', 85, 78, 85, 248, 'Ludhiana',  'Gurinder'
  UNION ALL
  SELECT 103, 'Gursimran','Gill',  DATE'2011-07-09', 95, 85, 90, 270, 'Amritsar',  'Balwinder'
  UNION ALL
  SELECT 104, 'Manpreet', 'Sidhu', DATE'2014-01-01', 90, 85, 95, 270, 'Patiala',   'Harjit'
  UNION ALL
  SELECT 105, 'Jasleen',  'Dhillon',DATE'2012-03-02', 89, 90, 75, 254, 'Jalandhar', 'Paramjit'
) AS t;
SELECT * FROM (
  SELECT 101 AS Stud_ID, 'Arjun'     AS Stud_Fname, 'Singh'    AS Stud_Lname, DATE'2012-04-06' AS Stud_DOB,
         80 AS Maths, 75 AS Physics, 80 AS Chemistry, 235 AS Total, 'Chandigarh' AS Stud_Addr, 'Sukhdev' AS Stud_Faname
  UNION ALL
  SELECT 102, 'Harpreet', 'Kaur',  DATE'2010-09-08', 85, 78, 85, 248, 'Ludhiana',  'Gurinder'
  UNION ALL
  SELECT 103, 'Gursimran','Gill',  DATE'2011-07-09', 95, 85, 90, 270, 'Amritsar',  'Balwinder'
  UNION ALL
  SELECT 104, 'Manpreet', 'Sidhu', DATE'2014-01-01', 90, 85, 95, 270, 'Patiala',   'Harjit'
  UNION ALL
  SELECT 105, 'Jasleen',  'Dhillon',DATE'2012-03-02', 89, 90, 75, 254, 'Jalandhar', 'Paramjit'
) AS t;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;SAP Datasphere DB user :&amp;nbsp;&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="SAP Datasphere DB user screen" style="width: 521px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/332993i05D97A6906259C90/image-dimensions/521x754/is-moderation-mode/true?v=v2" width="521" height="754" role="button" title="Screenshot 2025-10-27 170111.png" alt="SAP Datasphere DB user screen" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;SAP Datasphere DB user screen&lt;/span&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Demo View :&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="SethiR_0-1761564892069.png" style="width: 709px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/332994i6C5415EEA2B13F92/image-dimensions/709x443/is-moderation-mode/true?v=v2" width="709" height="443" role="button" title="SethiR_0-1761564892069.png" alt="SethiR_0-1761564892069.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Part B — Local environment (quick path)&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="3"&gt;1. Create a project folder and venvCreate a project folder and venv&lt;BR /&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;mkdir datasphere-local-llm &amp;amp;&amp;amp; cd datasphere-local-llm
python -m venv .venv
# Windows: .venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;2.&amp;nbsp;Install requirements&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;pip install hdbcli
pip install sqlalchemy
pip install sqlalchemy-hana
pip install pandas
pip install hdbcli
pip install transformers torch accelerate
pip install ipython&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;3.&amp;nbsp;Launch Jupyter&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;jupyter notebook&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Part C — Original POC notebook&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="3"&gt;1. Open a new notebook and write the code.&lt;BR /&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# --- Imports and setup (original)
import pandas as pd
from hdbcli import dbapi
import warnings
from transformers import pipeline
from IPython.display import display
warnings.filterwarnings('ignore')

# --- Inline credentials (POC-style; replace with environment variables for real use)
db_user = 'ACN_DWC#SETHIR_DB'
db_password = 'secret'
db_host = 'secret'
db_port = 443
db_schema = 'ACN_DWC'


connection = dbapi.connect(
    address = db_host,
    port = db_port,
    user = db_user,
    password = db_password,
    encrypt = True,
    sslValidCertificate = False   # POC-only convenience; prefer True in real use
)
print("Connected to SAP Datasphere - confirmation")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;2. If you see the output - "Connected to SAP Datasphere - confirmation" -- this implies you are on right track.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# --- Query the view
view_name = 'DemoView_SETHIR_PY'
sql_query = f'SELECT * FROM "{db_schema}"."{view_name}"'
print(f"Executing query: {sql_query}")

cursor = connection.cursor()
cursor.execute(sql_query)
rows = cursor.fetchall()
columns = [desc[0] for desc in cursor.description]

df = pd.DataFrame(rows, columns=columns)
display(df.head())&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;3. At this point, you should see the outcome of the view that you have. The last statement is used for displaying the data in the form of pandas dataFrame.&lt;BR /&gt;&lt;BR /&gt;4. Now we need to prepare our data , so that the LLM can process it. This can be done by converting our data in the form of string format.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# ==============================================================================
#Prepare Data and Interact with OpenLLM
# ==============================================================================

# Convert DataFrame to a string
data_as_string = df.to_string(index=False)
print("\n--- Data Prepared for LLM ---")
print("The DataFrame has been converted to the following string format:")
print(data_as_string[:300] + "\n...")  # snippet preview&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;5. Prepare data pipeline :&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# --- LLM imports
import os
import torch
import json
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline

# --- LLM Configuration
MODEL_ID = "meta-llama/Meta-Llama-3.1-8B-Instruct"

def load_llama_pipeline():
    """
    Loads the quantized Llama 3 model, tokenizer, and the text-generation pipeline.
    """
    print("\n--- Loading Llama 3 Model ---")
    hf_token = "secret"  # replace with your HF token; accept model access first

    quantization_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.bfloat16
    )

    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=hf_token)
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_ID,
        token=hf_token,
        quantization_config=quantization_config,
        torch_dtype=torch.bfloat16,
        device_map="auto",
    )

    print("Model loaded. Creating text generation pipeline...")
    return pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
    )&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;6. Build the prompt for the LLM model :&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# --- Prompt builder 
def build_student_analysis_prompt(tokenizer, student_data: pd.Series) -&amp;gt; str:
    """
    Builds a structured prompt for Llama 3 to analyze student marks.
    """
    input_text = (
        f"Student {student_data['Stud_Fname']} {student_data['Stud_Lname']} "
        f"(ID: {student_data['Stud_ID']}) scored {student_data['Maths']} in Maths, "
        f"{student_data['Physics']} in Physics, and {student_data['Chemistry']} in Chemistry."
    )

    messages = [
        {
            "role": "system",
            "content": (
                "You analyze one student's marks and return ONLY a valid JSON object. "
                "Output must start with '{' and end with '}'. No commentary, no markdown, no backticks.\n\n"
                "Schema (keys and types MUST match exactly):\n"
                "{\n"
                '  "total_marks": &amp;lt;int&amp;gt;,\n'
                '  "average_percentage": &amp;lt;float&amp;gt;,\n'
                '  "is_top_performer": &amp;lt;boolean&amp;gt;\n'
                "}\n\n"
                "Rules:\n"
                "1) total_marks = Maths + Physics + Chemistry (each out of 100).\n"
                "2) average_percentage = total_marks / 3.\n"
                "3) Round average_percentage to TWO decimals.\n"
                "4) is_top_performer = true if average_percentage &amp;gt; 80.0; else false.\n"
                "5) Use lowercase true/false for booleans.\n"
                "6) Do not include extra keys. Do not include trailing commas.\n"
                "7) Return JSON only."
            )
        },
        {
            "role": "user",
            "content": input_text
        }
    ]
    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;7. Do the analysis :&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# --- Row-by-row analysis
def analyze_student_data(df, text_pipeline):
    """
    Analyzes the student DataFrame row by row using the LLM pipeline.
    """
    print("\n--- Starting Student Performance Analysis with Llama 3 ---")
    results = []
    for index, row in df.iterrows():
        print(f"\nAnalyzing student ID: {row['Stud_ID']}...")

        prompt = build_student_analysis_prompt(text_pipeline.tokenizer, row)

        raw_output = text_pipeline(
            prompt,
            max_new_tokens=128,
            do_sample=False,  # deterministic
            temperature=None,
            top_p=None,
        )[0]['generated_text']

        json_response_str = raw_output[len(prompt):].strip()
        try:
            analysis_result = json.loads(json_response_str)
            results.append(analysis_result)
            print("Analysis successful.")
        except json.JSONDecodeError:
            print(f"  &amp;gt; Failed to decode JSON from model output.")
            print(f"  &amp;gt; Raw model output: {json_response_str}")
            results.append({"error": "Invalid JSON output", "raw_output": json_response_str})

    print("\n--- Analysis Complete ---")
    return pd.DataFrame(results)

# --- Main
if __name__ == "__main__":
    if df is not None and not df.empty:
        try:
            llm_pipeline = load_llama_pipeline()
            analysis_df = analyze_student_data(df, llm_pipeline)

            if analysis_df is not None:
                final_df = pd.concat([df.reset_index(drop=True), analysis_df.reset_index(drop=True)], axis=1)

                print("\n--- Full Data with LLM Analysis ---")
                display(final_df)

                print("\n--- Top Performing Students (Average &amp;gt; 80%) ---")
                top_performers = final_df[final_df['is_top_performer'] == True]

                if not top_performers.empty:
                    display(top_performers[['Stud_ID', 'Stud_Fname', 'Stud_Lname', 'total_marks', 'average_percentage']])
                else:
                    print("No students found with an average greater than 80%.")

        except Exception as e:
            print(f"\nAn unexpected error occurred during the analysis process: {e}")
    else:
        print("\nDataFrame is empty. Cannot proceed with analysis.")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;8.&amp;nbsp;Example output (simulated for the final cell)&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-markup"&gt;&lt;code&gt;Full Data with LLM Analysis (excerpt)

Stud_ID  Stud_Fname  Stud_Lname  Maths  Physics  Chemistry  total_marks  average_percentage  is_top_performer
101      Arjun       Singh       80     75       80         235          78.33               false
102      Harpreet    Kaur        85     78       85         248          82.67               true
103      Gursimran   Gill        95     85       90         270          90.00               true
104      Manpreet    Sidhu       90     85       95         270          90.00               true
105      Jasleen     Dhillon     89     90       75         254          84.67               true

Top Performing Students (Average &amp;gt; 80%)

Stud_ID  Stud_Fname  Stud_Lname  total_marks  average_percentage
102      Harpreet    Kaur        248          82.67
103      Gursimran   Gill        270          90.00
104      Manpreet    Sidhu       270          90.00
105      Jasleen     Dhillon     254          84.67&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Part D —&amp;nbsp;Production path (same pattern, managed inference)&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="3"&gt;When performance or scale matters, swap the local pipeline for a hosted endpoint and keep the Datasphere extraction and prompts identical. When performance or scale matters, swap the local pipeline for a hosted endpoint and keep the Datasphere extraction and prompts identical.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="3"&gt;1.&amp;nbsp;Databricks Model Serving / Foundation Model Endpoints (REST).&lt;BR /&gt;2.&amp;nbsp;Hugging Face Inference Endpoints (private endpoints; REST with your HF token)&lt;BR /&gt;3.&amp;nbsp;SAP AI Core (containerized model hosting; REST)SAP AI Core (containerized model hosting; REST)&lt;BR /&gt;&lt;BR /&gt;Minimal REST skeleton --&lt;BR /&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import requests, os, json
endpoint = os.getenv("INFERENCE_URL")
token = os.getenv("INFERENCE_TOKEN")
r = requests.post(endpoint, headers={"Authorization": f"Bearer {token}"},
                  json={"inputs": "your_prompt_here", "parameters": {"max_new_tokens": 128, "temperature": 0.0}})
print(r.json())&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;FONT size="3"&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;FONT size="5"&gt;Conclusion ---&lt;BR /&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;This walkthrough demonstrated how to extract data from SAP Datasphere, process it in pandas, and apply a local LLM for row-level analysis that returns clean, machine-readable JSON. The pattern is intentionally small and portable: you can keep iterating locally to refine prompts and outputs, then swap the model call for a managed endpoint (Databricks, Hugging Face, or SAP AI Core) when performance, cost control, or governance call for it. From here, natural next steps include batching larger datasets, persisting results back to a database table, wiring the outputs to SAP Analytics Cloud dashboards, and adding guardrails around data privacy and prompt consistency.&lt;/P&gt;&lt;P&gt;I would be excited to hear how you adapt this to your solutions. Feel free to reach out to me or comment.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/from-sap-datasphere-to-a-local-llm-llama-3-1-hands-on-tutorial/ba-p/14253357"/>
    <published>2025-10-29T12:05:30.405000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/how-to-monitor-consumption-for-sap-business-data-cloud-bdc-and-its/ba-p/14257413</id>
    <title>How to monitor consumption for SAP Business Data Cloud (BDC) and its components?</title>
    <updated>2025-10-30T18:37:48.747000+01:00</updated>
    <author>
      <name>FernandaFroelich</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1410810</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;Symptom&lt;/STRONG&gt;: You don't know how to check&amp;nbsp;SAP Business Data Cloud (BDC) usage.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Requirements&lt;/STRONG&gt;: You need to have an S-user and the role of Super Administrator assigned in SAP for Me.&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;If you don't have an S-User, please check&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://support.sap.com/en/my-support/users/welcome.html" target="_blank" rel="noopener noreferrer"&gt;this page&lt;/A&gt;.&lt;/LI&gt;&lt;LI&gt;If you are unsure which role you have, please check&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://me.sap.com/notes/1282821" target="_blank" rel="noopener noreferrer"&gt;this note&lt;/A&gt;.&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Resolution&lt;/STRONG&gt;:&lt;/P&gt;&lt;P&gt;1) Open&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://me.sap.com/" target="_blank" rel="noopener noreferrer"&gt;SAP for Me&lt;/A&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;and log in.&lt;/P&gt;&lt;P&gt;2) Navigate to the "&lt;EM&gt;Dashboards&lt;/EM&gt;" section and click "&lt;EM&gt;Finance &amp;amp; Legal&lt;/EM&gt;".&lt;/P&gt;&lt;P&gt;3) Select "&lt;EM&gt;Consumption&lt;/EM&gt;".&lt;/P&gt;&lt;P&gt;4) Filter for "&lt;EM&gt;Business Data Cloud&lt;/EM&gt;".&lt;/P&gt;&lt;P&gt;5) Click on the measured number to open a card; it explains the consumption by each metric.&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;STRONG&gt;Image 01&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="FernandaFroelich_0-1761845531617.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334479iD0F371C3EF721D18/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="FernandaFroelich_0-1761845531617.png" alt="FernandaFroelich_0-1761845531617.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;STRONG&gt;Image 2&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="FernandaFroelich_0-1761848037864.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334512i78FBDF2E31558FC7/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="FernandaFroelich_0-1761848037864.png" alt="FernandaFroelich_0-1761848037864.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-align-left" style="text-align : left;"&gt;&lt;STRONG&gt;Important reminder:&amp;nbsp;&lt;/STRONG&gt;SAP Databricks and SAP Datasphere usage is based on actual consumption instead of what is in the quota assignment. For SAP Analytics Cloud, on the other hand, it is considered the number of users assigned for each SAC license according to the quota assignment. For more information on the components usage (SAP Analytics Cloud, SAP Datasphere), please refer to this &lt;A href="https://support.sap.com/content/dam/support/en_us/library/ssp/my-support/systems-installations/system-measurement/cloud-saas-application-usage/sap-business-data-cloud.pdf" target="_blank" rel="noopener noreferrer"&gt;documentation&lt;/A&gt;. If you want to know more about how the metric itself works, check this &lt;A href="https://www.sap.com/about/trust-center/agreements/cloud/cloud-services.html?search=Business%20Data%20Cloud&amp;amp;sort=latest_desc&amp;amp;pdf-asset=aaa18b5a-267f-0010-bca6-c68f7e60039b&amp;amp;page=4" target="_blank" rel="noopener noreferrer"&gt;pdf&lt;/A&gt;.&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/how-to-monitor-consumption-for-sap-business-data-cloud-bdc-and-its/ba-p/14257413"/>
    <published>2025-10-30T18:37:48.747000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/bw-data-product-generator-to-databricks-enterprise-capability/ba-p/14251192</id>
    <title>BW Data Product Generator to Databricks Enterprise Capability</title>
    <updated>2025-10-31T03:51:37.796000+01:00</updated>
    <author>
      <name>JonGooding</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/202972</uri>
    </author>
    <content>&lt;P&gt;In this blog, I will cover getting BW Business Content data into Databricks using the following 4 steps:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Enable the BW Data Product Generator in the SAP BW (7.5 or BW/4HANA) instance.&lt;/LI&gt;&lt;LI&gt;Run the BW Data Product Generator on the BW Content&lt;/LI&gt;&lt;LI&gt;Create the Data Product based on the BW Data &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/LI&gt;&lt;LI&gt;Delta Share the Data Product to Enterprise Databricks.&amp;nbsp;&lt;/LI&gt;&lt;/OL&gt;&lt;H3 id="toc-hId-1892715806"&gt;&lt;STRONG&gt;Step 1 -&amp;nbsp;Enable the BW Data Product Generator in the SAP BW (7.5 or BW/4HANA) instance.&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Installation documentation is via the note at:&amp;nbsp;&lt;A href="https://me.sap.com/notes/3590400/E" target="_blank" rel="noopener noreferrer"&gt;https://me.sap.com/notes/3590400/E&amp;nbsp;&lt;/A&gt;&lt;/P&gt;&lt;P&gt;To install the BW Data Product Generator the current condition applies (speak to your SAP team for potential options to this):&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;You have an SAP Business Warehouse, private cloud edition system (in SAP Business Data Cloud) in place and the object store in SAP Datasphere is enabled. Now, you want to connect to your SAP BW system to your existing&amp;nbsp;SAP Business Data Cloud tenant and the connection is not configured.&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;In addition to the installation guide, making sure the&amp;nbsp;&lt;STRONG&gt;Note Analyzer for Data Product Generator&amp;nbsp;&lt;/STRONG&gt;is run successfully.&amp;nbsp;&lt;/P&gt;&lt;P&gt;The good news in running the SAP_BW_BDC_CONFIGURATION task, is it is now re-runnable and you can reuse the same target space (BWDPG) in my case.&amp;nbsp; I won't go through the details of running the installation - but it relatively straight forward using the documentation - making sure you have the certificates corrected assigned in the BWPCE STRUST.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Once successfully installing the BW DPG, you can access the Data Subscriptions Tile (in BW/4HANA) :&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.06.39 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334543iD74023C6792FC8AC/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.06.39 am.png" alt="Screenshot 2025-10-31 at 11.06.39 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Associated Details :&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.05.51 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334542iB5C220D7CB0E593F/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.05.51 am.png" alt="Screenshot 2025-10-31 at 11.05.51 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;Also available via the SAP GUI, for use in BW 7.5 :&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.04.23 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334541i2CD0479A0AA53268/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.04.23 am.png" alt="Screenshot 2025-10-31 at 11.04.23 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1696202301"&gt;&lt;STRONG&gt;Step 2 - Run the BW Data Product Generator on the BW Content&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;In the next steps, I will use the BW Cockpit version (It is similiar using the GUI)&lt;/P&gt;&lt;P&gt;Initially creating and selecting a source:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.08.24 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334544i1EC806BE2B544380/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.08.24 am.png" alt="Screenshot 2025-10-31 at 11.08.24 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;SPAN&gt;The following BW InfoProviders can be used in a subscription for the BW DPG:&lt;/SPAN&gt;&lt;/P&gt;&lt;UL class="lia-align-justify" style="text-align : justify;"&gt;&lt;LI&gt;&lt;SPAN&gt;Base Providers: InfoCubes, Datastore Objects (Classic and Advanced), InfoObjects (Masterdata)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Composite Provider, MultiProvider&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Queries: Query-as-InfoProvider&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.09.27 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334545iFEE3FDDE6E7B149C/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.09.27 am.png" alt="Screenshot 2025-10-31 at 11.09.27 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;And selecting the BW Content that is activated.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Once saved, it still needs to be activated as per message below:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.11.25 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334547i38FB94E863AB83E1/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.11.25 am.png" alt="Screenshot 2025-10-31 at 11.11.25 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Also, as part of the Data Subscription,&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Settings : Allows Full or Delta execution mode, apply filters to the data extraction and add Process Chain Variants to the subscription.&lt;/LI&gt;&lt;LI&gt;Projections : Able to simpify the output columns&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.13.06 am.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334548iC66C4251785EB5D7/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="Screenshot 2025-10-31 at 11.13.06 am.png" alt="Screenshot 2025-10-31 at 11.13.06 am.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.13.17 am.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334549i1F21E2CB9AB1F7DD/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="Screenshot 2025-10-31 at 11.13.17 am.png" alt="Screenshot 2025-10-31 at 11.13.17 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once you have configured any settings, you can activate the Data Subscription:&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.15.32 am.png" style="width: 823px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334550iA9DEA127AF947991/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.15.32 am.png" alt="Screenshot 2025-10-31 at 11.15.32 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Activating the Subscription will also create the Datasphere Local Table in the BWDPG space (accessible from the link in the BW DPG or via Datasphere: :&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.21.35 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334551iD1322F8F488D600C/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.21.35 am.png" alt="Screenshot 2025-10-31 at 11.21.35 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now the Target table exists on the Object store, which can also be seen in the BWDPG.&lt;/P&gt;&lt;P&gt;Side Note:&amp;nbsp;I originally deployed the BW DPG using an earlier release, and the target objects where the Semantics Usage Type was : Local Table (Relational Dataset). Now after applying some recent notes it is now&amp;nbsp; : Local Table (Fact)&lt;/P&gt;&lt;P&gt;As the Data Subscription is now ready, it can be run directly from the Subscription screen:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.25.01 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334555iDF785CFC514FB765/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.25.01 am.png" alt="Screenshot 2025-10-31 at 11.25.01 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Viewing the executions:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.28.16 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334557iFBE52007ABA12560/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.28.16 am.png" alt="Screenshot 2025-10-31 at 11.28.16 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now the data from BW exists in Datasphere Object store and if selected, can be delta updated as required&amp;nbsp;&lt;/P&gt;&lt;P&gt;I have shown the BW/4HANA Cockpit for the above, but it's also fully available for the GUI as well:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.33.29 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334561i09B6C4C6983CBB00/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.33.29 am.png" alt="Screenshot 2025-10-31 at 11.33.29 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Viewing the BW Data from Datasphere:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.38.22 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334563i87C69EBF64288A23/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.38.22 am.png" alt="Screenshot 2025-10-31 at 11.38.22 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 3 -&amp;nbsp;Create the Data Product based on the BW Data&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;I won't cover every step in this process, as there are other blogs that do this, but essentially&lt;/P&gt;&lt;P&gt;The new Data Product, will use the BWDPG space:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.43.08 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334565iDD43B6F8A5855334/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.43.08 am.png" alt="Screenshot 2025-10-31 at 11.43.08 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Then add the 2 Data Products - Purchase Order Header and Line Items BW generated objects:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.45.39 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334566i2C34870824B96494/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.45.39 am.png" alt="Screenshot 2025-10-31 at 11.45.39 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Then change the status of the Data Product to Listed. Once the Data Product is Listed, then it can be Delta Shared in the BDC Cockpit.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.49.03 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334567iAC38144349F353D8/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.49.03 am.png" alt="Screenshot 2025-10-31 at 11.49.03 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 4 -&amp;nbsp;Delta Share the Data Product to Enterprise Databricks.&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Within the Business Data Cloud Cockpit, the new BW Data Product is available:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.56.39 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334568i7DB7AA14A369DB8D/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.56.39 am.png" alt="Screenshot 2025-10-31 at 11.56.39 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Sharing the Data Product to Enterprise Databricks is via the share button. I have already added the BDC Partner Connector for the DataBricks instance (seperate to this doco)&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 11.59.41 am.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334569iCAD451C5CBE0C111/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 11.59.41 am.png" alt="Screenshot 2025-10-31 at 11.59.41 am.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The sharing to Enterprise Databricks is quick and easy (no effort around ETL):&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 12.01.55 pm.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334570iB4F38B2B2E3A82C6/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="Screenshot 2025-10-31 at 12.01.55 pm.png" alt="Screenshot 2025-10-31 at 12.01.55 pm.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 12.02.24 pm.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334571i63C1BA6C1B7187F3/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="Screenshot 2025-10-31 at 12.02.24 pm.png" alt="Screenshot 2025-10-31 at 12.02.24 pm.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Within the Databricks environment, accessing the Catalog Explorer and the BDC Connect provider:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 12.42.51 pm.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334572i4E86B9C9706186D5/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 12.42.51 pm.png" alt="Screenshot 2025-10-31 at 12.42.51 pm.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The difference with Delta Sharing from BDC to Enterprise Databricks (as compared to SAP Databricks) is the requirement to select the mount point for the Delta share:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 12.45.21 pm.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334573i329BBBAC7CF6A733/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 12.45.21 pm.png" alt="Screenshot 2025-10-31 at 12.45.21 pm.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once mounted, the SAP Data Product can be accessed directly in the Catalog:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-10-31 at 3.24.45 pm.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/334574iF9F93ED822DEE815/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-10-31 at 3.24.45 pm.png" alt="Screenshot 2025-10-31 at 3.24.45 pm.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;From here, users can perform all the advanced features of Databricks on the SAP BW data.&amp;nbsp;&lt;/P&gt;&lt;P&gt;This has been a basic end to end showcase - hopefully will have time to add in tips and tricks as we build out more customer Use Cases.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Please post any questions and I can try to answer them.&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/bw-data-product-generator-to-databricks-enterprise-capability/ba-p/14251192"/>
    <published>2025-10-31T03:51:37.796000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/integration-between-sap-cpi-and-sap-datasphere-jdbc-connection/ba-p/14256236</id>
    <title>Integration Between SAP CPI and SAP DataSphere (JDBC Connection)</title>
    <updated>2025-10-31T08:17:01.679000+01:00</updated>
    <author>
      <name>MUGILAN_KANAGARAJ</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2190179</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;Integration Between SAP CPI and SAP DataSphere (JDBC Connection)&lt;/STRONG&gt; &lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;JDBC – JAVA DATABASE CONNECTIVITY&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;Why Recommendation for JDBC Over OData API :&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;JDBC is recommended over OData when consuming large-scale records (e.g., 100,000+) because JDBC streams data directly from the database with better performance and less overhead, while OData is optimized for lightweight, paginated, service-based access.&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;Problem statement: &lt;SPAN&gt;&lt;A href="https://userapps.support.sap.com/sap/support/knowledge/en/3337495" target="_blank" rel="noopener noreferrer"&gt;3337495 - OData API returns less records than expected due paging&lt;BR /&gt;&lt;/A&gt;&lt;/SPAN&gt;Pagination limits in OData and Ariba APIs can be handled in SAP CPI using a looping process call. I’ll cover this with a clear explanation in an upcoming post.&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;G&lt;STRONG&gt;oal:&lt;/STRONG&gt; Connect CPI to a database used by DataSphere (JDBC) and run a simple read data from the (Analytical Model / Table /View). &lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;For the Write / Delete / Update method, the attached SAP Help Portal Link has syntax in the reference section.&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;STRONG&gt;Prerequisites:&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;SAP DataSphere&lt;/STRONG&gt; – Subscribed account (⚠ Trial has limited features, JDBC not supported)&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;SAP Integration Suite&lt;/STRONG&gt; – Subscribed or Trial (JDBC actions supported)&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;SAP DataSphere Step by Step Guide :&lt;/STRONG&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Step&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Action / Notes&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;1. Create a Space&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;DataSphere → Space Management → &lt;EM&gt;New Space&lt;/EM&gt; → Name it → Create.&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;2. Create Table / Analytical Model&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;Data Builder → In your Space → &lt;EM&gt;New&lt;/EM&gt; → Table or Analytical Model → define fields &amp;amp; data types → Save &amp;amp; Publish.&lt;BR /&gt;*Verify Table/Model Deployed Successfully. *&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;3. Prepare / Load Data&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;Load data manually for testing cases. Otherwise load CSV/import to table via Data Builder/Data Integration.&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;4. Note Schema &amp;amp; Object Names&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;Record schema name, table name, and view names for JDBC SQL use.&lt;BR /&gt;* Created space name is the SCHEMA name and Collect Table / Model name *&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;5. Decide Where to Create DB User&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;If HANA Cloud → use HANA Cockpit/DB Explorer. If on-prem DB → use DB admin tools or contact DB Admin.&lt;BR /&gt;* We are using the HANA cloud system for practical session*&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;6. Create JDBC DB User&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;DB admin tool → Security/Users → &lt;EM&gt;New User&lt;/EM&gt; → set username &amp;amp; strong password → Save.&lt;BR /&gt;*Check Active status of User*&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;7. Grant Privileges for the DB user&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;Assign only required privileges (e.g., &lt;STRONG&gt;SELECT&lt;/STRONG&gt; for read; add &lt;STRONG&gt;INSERT/UPDATE/DELETE&lt;/STRONG&gt; for CRUD). Best practice: create role &lt;/SPAN&gt;JDBC_ROLE&lt;SPAN&gt; and assign.&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;8. Prepare JDBC Connection Details&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="301"&gt;&lt;P&gt;&lt;SPAN&gt;Gather JDBC URL (e.g. &amp;nbsp;sample URL from datasphere: z*********-abc.hana.prod-eu10.hanacloud.ondemand.com&lt;BR /&gt;Format for CPI JDBC Material:&lt;BR /&gt;&lt;/SPAN&gt;jdbc:sap://&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/?encrypt=true&amp;amp;validateCertificate=true&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;STRONG&gt;SAP Integration Suite Step by Step Guide :&lt;/STRONG&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;STRONG&gt;Create a Package &amp;amp; Artifact&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;In CPI → &lt;EM&gt;Design&lt;/EM&gt; → Create a new package → Add an integration flow artifact.&lt;/LI&gt;&lt;LI&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;✅&lt;/span&gt; Make sure your CPI user has the required roles to create and access design-time artifacts.&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Go to Monitoring → JDBC Material&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;In CPI → &lt;EM&gt;Monitor&lt;/EM&gt; → Integrations and APIs → Manage Security → JDBC Material&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_9-1761743104479.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333936i6D0241B617F00B77/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_9-1761743104479.png" alt="MUGILAN_KANAGARAJ_9-1761743104479.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;→ Add &lt;EM&gt;JDBC Data Source. &lt;/EM&gt;→ Select HANA cloud &lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_10-1761743104489.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333937iE85BFA171AC5354A/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_10-1761743104489.png" alt="MUGILAN_KANAGARAJ_10-1761743104489.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Provide JDBC URL in the correct format (e.g., jdbc:sap://&amp;lt;hana-host&amp;gt;:443/?encrypt=true&amp;amp;validateCertificate=true).&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_11-1761743104501.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333938i78679B85543ED506/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_11-1761743104501.png" alt="MUGILAN_KANAGARAJ_11-1761743104501.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Enter DB username and password (use the dedicated JDBC user created earlier in DataSphere).&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_12-1761743104508.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333940iFF24BD979E951623/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_12-1761743104508.png" alt="MUGILAN_KANAGARAJ_12-1761743104508.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Save and deploy the JDBC material.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Apply JDBC Material in iFlow&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;In your integration flow, configure the JDBC receiver adapter → select the JDBC data source created.&lt;/LI&gt;&lt;LI&gt;Use SQL queries (SELECT) in the &lt;EM&gt;Processing tab&lt;/EM&gt; or provide XML query body. &lt;SPAN&gt;Here, I’m using SQL &lt;/SPAN&gt;SELECT * to&lt;SPAN&gt; fetch all records from the table.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_13-1761743104513.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333939i0C4A23EA2DD7435A/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_13-1761743104513.png" alt="MUGILAN_KANAGARAJ_13-1761743104513.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;STRONG&gt;Step 1: Timer Start &lt;/STRONG&gt;&lt;BR /&gt;&amp;nbsp;In this iFlow, the Start Timer is configured with a Simple Schedule → None → On Deployment, which means the integration flow automatically triggers immediately after deployment.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_14-1761743104520.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333941iB3F7F36AA2A7DE16/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_14-1761743104520.png" alt="MUGILAN_KANAGARAJ_14-1761743104520.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;STRONG&gt;Step 2: Content Modifier&lt;/STRONG&gt;&lt;BR /&gt;Use this SQL query to fetch all records with the body operation.&lt;BR /&gt;&amp;nbsp;SELECT * FROM "&amp;lt;Schema&amp;gt;"."&amp;lt;Model/TableName&amp;gt;"&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_15-1761743104527.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333943i58EEBA8EA1D3F197/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_15-1761743104527.png" alt="MUGILAN_KANAGARAJ_15-1761743104527.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;STRONG&gt;Step 3: Request Reply &amp;amp; JDBC Receiver Adapter&lt;/STRONG&gt;&lt;BR /&gt;&amp;nbsp;→ Use the deployed JDBC Data Source alias in the JDBC Material in the previous step and set Max records count based on your requirement.&lt;BR /&gt;→ JDBC Maximum Records per call:&amp;nbsp; 2,147,483,647&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_16-1761743104534.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333944i6290D296884CAE5A/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_16-1761743104534.png" alt="MUGILAN_KANAGARAJ_16-1761743104534.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;Sample data Response from JDBC Connection:&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_17-1761743104538.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333942iC7431EDC092521C8/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_17-1761743104538.png" alt="MUGILAN_KANAGARAJ_17-1761743104538.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;References :&lt;SPAN&gt;&lt;BR /&gt;same blog by me for clear picture quality:&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-q-a/integration-of-sap-cpi-and-sap-datasphere-using-jdbc/qaq-p/14256172" target="_blank"&gt;Integration of SAP CPI and SAP DataSphere using JD... - SAP Community&lt;/A&gt;&lt;BR /&gt;&lt;/SPAN&gt;CPI JDBC – XML Query in Body for CRUD Operations (Syntax Guide)&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&amp;nbsp;link:&lt;SPAN&gt;&lt;BR /&gt;&lt;A href="https://help.sap.com/docs/cloud-integration/sap-cloud-integration/payload-and-operation" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/cloud-integration/sap-cloud-integration/payload-and-operation&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/integration-between-sap-cpi-and-sap-datasphere-jdbc-connection/ba-p/14256236"/>
    <published>2025-10-31T08:17:01.679000+01:00</published>
  </entry>
</feed>
