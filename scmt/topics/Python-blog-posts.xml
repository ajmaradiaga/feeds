<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/Python-blog-posts.xml</id>
  <title>SAP Community - Python</title>
  <updated>2025-10-12T11:11:32.121453+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/Python/pd-p/f220d74d-56e2-487e-8e6c-a8cb3def2378" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>Python blog posts in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-and-ai-features-in-sap-hana-cloud-2025-q2/ba-p/14136079</id>
    <title>New Machine Learning and AI features in SAP HANA Cloud 2025 Q2</title>
    <updated>2025-06-24T21:40:03.946000+02:00</updated>
    <author>
      <name>ChristophMorgen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14106</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;With the &lt;STRONG&gt;SAP HANA Cloud 2025 Q2 release&lt;/STRONG&gt;, several &lt;STRONG&gt;new embedded Machine Learning / AI functions&lt;/STRONG&gt;&amp;nbsp;have been released with the SAP HANA Cloud Predictive Analysis Library (PAL) and the Automated Predictive Library (APL). &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Key new capabilities to be highlighted include &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;A &lt;STRONG&gt;new text embedding model version&lt;/STRONG&gt;, covering more languages and short-text embedding scenarios,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;more &lt;STRONG&gt;tabular AI functions&lt;/STRONG&gt; enhanced to support&amp;nbsp;&lt;STRONG&gt;vector data processing&lt;/STRONG&gt; like &lt;STRONG&gt;AutoML&lt;/STRONG&gt;, &lt;STRONG&gt;k-nearest neighbors&lt;/STRONG&gt; (k-NN),&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;outlier detection using &lt;STRONG&gt;isolation forest&lt;/STRONG&gt; supporting &lt;STRONG&gt;outlier explainability &lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;machine learning &lt;STRONG&gt;experiment tracking&lt;/STRONG&gt; and &lt;STRONG&gt;task scheduling&lt;/STRONG&gt; capabilities&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;STRONG&gt;data drift analysis&lt;/STRONG&gt; using the &lt;STRONG&gt;Automated Predictive Library&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;An enhancement summary is available in the What’s new document for &lt;A href="https://help.sap.com/whats-new/2495b34492334456a49084831c2bea4e?Category=Predictive+Analysis+Library&amp;amp;Valid_as_Of=2025-06-01:2025-06-30&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP HANA Cloud database 2025.14 (QRC 2/2025)&lt;/A&gt;.&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1733304833"&gt;&lt;SPAN&gt;Text processing, text embedding and vector processing using ML functions&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text tokenization&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-tokenize" target="_blank" rel="noopener noreferrer"&gt;text tokenization &lt;/A&gt;function has been released, allowing to &lt;STRONG&gt;split text into tokens&lt;/STRONG&gt;, a fundamental preparation step in natural language processing (NLP) like text analysis, and many other downstream text processing tasks like text embedding or vector similarity search. The new function support key tokenization capabilities like&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;removal of common stopwords (e.g., "the", "and", "is").&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;filtering out purely numeric and alphanumeric tokens&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;specifications of characters or symbols that should always be kept or removed &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;controls for stemming, language detection.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_0-1750792982539.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/278450iC65F3B44B14FB758/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_0-1750792982539.png" alt="ChristophMorgen_0-1750792982539.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text embedding &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new &lt;STRONG&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/no-content-for-file-textembedding-md?" target="_blank" rel="noopener noreferrer"&gt;text embedding&lt;/A&gt;&lt;/STRONG&gt; model version (&lt;/SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-embedding-model?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP_GXY.20250407&lt;/A&gt;&lt;SPAN&gt;) is made available, which has been fine-tuned based on a roberta-base-encoder model and more training data for improved retrieval accuracy, short text scenarios and extend multi-lingual &amp;amp; cross-lingual retrieval scenarios. New additional languages supported include Chinese (CH), Japanese (JP) and Italian (IT). The default token length for embedding functions has been increase to 512.&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Extended embedding vector processing by Machine Learning functions&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Unlocking the semantic understanding of your text data stored in SAP HANA Cloud, for use cases like similarity search, however moreover for machine learning scenarios like &amp;nbsp;document/text- classification and –clustering, and more has now been extended to even more PAL Machine Learning functions&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;K-nearest neighbor models (&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/knn-knn-f2440c6" target="_blank" rel="noopener noreferrer"&gt;K-NN&lt;/A&gt;) for classification/regression/similarity search&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/random-decision-trees-random-decision-trees-9ad576a" target="_blank" rel="noopener noreferrer"&gt;Random Decision Trees&lt;/A&gt;&lt;/SPAN&gt; &lt;SPAN&gt;for classification/regression models &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/automl-automl?" target="_blank" rel="noopener noreferrer"&gt;AutoML&lt;/A&gt; &lt;/SPAN&gt;scenarios for classification, regression and times series&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;including the fit, prediction, scoring, and pipeline procedures&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;support with all pipeline operators (algorithms), except for the Imputer and&lt;BR /&gt;&amp;nbsp;ImputeTS-operators&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_1-1750792982549.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/278449iA91EDCE14A4D9CEF/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_1-1750792982549.png" alt="ChristophMorgen_1-1750792982549.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1536791328"&gt;&lt;SPAN&gt;Machine Learning function enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Outlier detection enhancements using Isolation Forests&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The &lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/isolation-forest-isolation-forest-11345d9" target="_blank" rel="noopener noreferrer"&gt;Isolation Forest &lt;/A&gt;&amp;nbsp;function for &lt;STRONG&gt;outlier detection&lt;/STRONG&gt; has been enhanced with &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;support categorial columns as features in outlier models&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;a new massive outlier detection function for parallel analysis of multiple data subsets&lt;BR /&gt;(PAL_MASSIVE_ISOLATION_FOREST)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;a new outlier explanation method based on Shapley values (PAL_ISOLATION_FOREST_EXPLAIN)&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;providing local explanations for the predicted outlier classification,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;describing the contribution of each feature to the predicted classification,&lt;BR /&gt;based on a Tree-SHAP explainer model,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;options to configure the explanation function by setting contamination level (proportion of outliers), scope (explanations for outliers only or all predictions), top K contributions (set k number of features in explanations)&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&lt;EM&gt;Isolation Forest&lt;/EM&gt; is a strong and &lt;EM&gt;trending function for outlier detection&lt;/EM&gt;, which can be applied on any data for outlier analysis inside the database, hence especially suitable also for use cases where data shall not leave the system or is too big to be copied out for analysis like use cases for &lt;STRONG&gt;detecting outliers on your financial accounting&lt;/STRONG&gt;, like the &lt;STRONG&gt;universal journal data&lt;/STRONG&gt; (ACDOCA).&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_2-1750792982556.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/278448i1C259DFB5755E343/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_2-1750792982556.png" alt="ChristophMorgen_2-1750792982556.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Constraint Clustering&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/constrained-clustering" target="_blank" rel="noopener noreferrer"&gt;constraint clustering &lt;/A&gt;function is introduced, an advanced form of clustering that &lt;STRONG&gt;incorporates domain-specific constraints or prior information&lt;/STRONG&gt; to &lt;EM&gt;guide the clustering process&lt;/EM&gt;, ensuring more accurate and meaningful results tailored to specific analytical needs. Traditional clustering methods are mostly limited and cannot include prior knowledge about the data, often leading to challenges in achieving meaningful or contextually relevant groupings. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Prior contexts can be included in the clustering process as &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Pairwise constraints: Must-link / Must-Not-link constraints of data points to be / not in the same cluster&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Triplet Constraints: With an anchor instance (a), a positive instance (p), and a negative instance (n), the constraint shows that instance a is more similar to p than to n.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;A detailed introduction to the new function is given in the following blog post &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/clustering-text-documents-using-constrained-clustering/ba-p/14134157" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/clustering-text-documents-using-constrained-clustering/ba-p/14134157&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Further enhanced machine learning algorithms for Tabular AI scenarios&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The recently implemented &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/multi-task-multilayer-perceptron?" target="_blank" rel="noopener noreferrer"&gt;Multi-task MLP&lt;/A&gt; (&lt;STRONG&gt;multi-layer perceptron&lt;/STRONG&gt;) &lt;STRONG&gt;neural network&lt;/STRONG&gt; function, unlocking predictions for &lt;STRONG&gt;multiple targets / labels using a single model&lt;/STRONG&gt;, has now been enhanced with an improved built-in &lt;STRONG&gt;model evaluation and parameter search&lt;/STRONG&gt; interface, providing faster approach and productivity to achieve even better prediction outcomes.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The new optimization can be leveraged by calling the function directly or via its use within the Unified Classification/Regression functions and supports to search and select the following optimal neural network model parameter values&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;LEARNING_RATE, EMBEDDED_NUM, RESIDUAL_NUM, DROPOUT_PROB, HIDDEN_LAYER_SIZE, HIDDEN_LAYER_ACTIVE_FUNC, OPTIMIZER&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;In the domain of &lt;STRONG&gt;time series analysis and forecasting,&lt;/STRONG&gt; the &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/arima-arima-dbd52a1" target="_blank" rel="noopener noreferrer"&gt;ARIMA&lt;/A&gt; forecasting function now supports to keep context of the time horizon index and interval&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Trained ARIMA model keeps track of the final time index value and the determined index interval&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Subsequently,&amp;nbsp;ARIMA_PREDICT&amp;nbsp;will use this information to output forecast values with a continuous index&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1340277823"&gt;&lt;SPAN&gt;Machine Learning experiment tracking and task scheduling&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Experiment tracking and monitoring for PAL ML models&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Machine learning &lt;STRONG&gt;experimentation&lt;/STRONG&gt; requires robust &lt;STRONG&gt;tracking capabilities&lt;/STRONG&gt; to ensure reproducibility, comparison, and auditability of models. SAP HANA Cloud's new &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/pal-track?q=PAL_REMOVE_MLTRACK_LOG&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;ML tracking&lt;/A&gt; feature provides seamless integration with Predictive Analysis Library (PAL) procedures, enabling &lt;STRONG&gt;automatic logging of critical experiment artifacts&lt;/STRONG&gt;. This end-to-end tracking solution captures &lt;EM&gt;parameters, datasets, models, metrics, and visualizations&lt;/EM&gt; in a structured way, transforming how data scientists manage ML workflows.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The new execution &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/pal-track?q=PAL_REMOVE_MLTRACK_LOG&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;tracking of PAL &lt;/A&gt;procedure supports&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;use with al Unified Regression/Classification-, Pipeline-fit/score procedures&amp;nbsp;(with new interfaces suffix&amp;nbsp; “_TRACK” suffix)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;tracking of content including: Parameters, Dataset Metadata, Model Signature, Metrics(including Variable Importance), Figures(discrete and continuous), etc.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;management of tracking data in a built-in schema PAL_ML_TRACK and tables for metadata, log and header information&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;procedure parameters activate the tracking like LOG_ML_TRACK, TRACK_ID, etc.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;A more detailed introduction is provided in the following blog post &lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Task scheduling for PAL procedures&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new PAL &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/calling-pal-with-schedule?q=PAL_REMOVE_MLTRACK_LOG&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;task scheduling&lt;/A&gt; &lt;/SPAN&gt;allows you to run SQLScript procedures (calling PAL procedures) by the SAP HANA Cloud schedular asynchronously (&lt;SPAN&gt;cron-based).&lt;/SPAN&gt; The targeted SQLScript (PAL) procedure calls get mapped to a define task with task ID, task descriptions, owner, etc. A task can be scheduled to executed, a job is the instance of scheduled task.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;The built-in schema PAL_SCHEDULED_EXECUTION provides tables for storage of task definition/metadata, relationships, procedures parameters, TASK_SCHEDULE_JOB, task (operation) log&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;The actual job execution information is provided within the System views SCHEDULE_JOBS, M_SCHEDULE_JOBS&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;New PAL procedures are provided for task creation (AFLPAL_CREATE_TASK_PROC)&lt;BR /&gt;and removal, scheduled job creation for a task (AFLPAL_CREATE_TASK_SCHEDULE_PROC), altering, pausing, resuming and removing task jobs&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The python ML client adds additional interfaces and methods to leverage the new capabilities easily by experts developing HANA ML scenarios.&lt;/P&gt;&lt;H2 id="toc-hId-1143764318"&gt;&lt;SPAN&gt;Data Drift detector with the Automated Predictive Library (APL)&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;The new data drift detector in the APL helps you spot changes or deviations between a given dataset and a reference. Reference data could be a version in the past, or a particular segment of customers or employees, or an expected distribution (e.g. Benford). Use cases of data comparison are:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;This year employee survey results versus last year results by country&lt;/LI&gt;&lt;LI&gt;Machine learning inference dataset versus training dataset&lt;/LI&gt;&lt;LI&gt;Male staff versus female staff&lt;/LI&gt;&lt;LI&gt;Payment amounts by legal entity versus the Benford’s law to find potential fraud&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This feature from APL (Automated Predictive Library) is available for both Python and SQL. For more details see blog post on the&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/hana-ml-data-drift-detector/ba-p/14148518" target="_blank"&gt;HANA ML Data Drift Detector&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_0-1752234591748.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285456i75A1F6A79758D3C3/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_0-1752234591748.png" alt="ChristophMorgen_0-1752234591748.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-947250813"&gt;&lt;SPAN&gt;Python ML client (hana-ml) enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;EM&gt;The full list of new methods and enhancements with hana_ml 2.25&amp;nbsp; is summarized in the &lt;/EM&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/doc/cd94b08fe2e041c2ba778374572ddba9/2025_2_QRC/en-US/change_log.html" target="_blank" rel="noopener noreferrer"&gt;&lt;EM&gt;changelog for hana-ml 2.25&lt;/EM&gt;&lt;/A&gt; &lt;/SPAN&gt;&lt;EM&gt;as part of the documentation. The key enhancements in this release include&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text and vector processing enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;New embedding model version SAP_GXY.20250407&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Classification / regression function enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Use of Multi-task MLP with UnifiedClassification | Regression&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;Benefit from unified interface capabilities like score-function, resampling/parameter search and optimization, model-report, …&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;HGBT regressor with Linear Tree trend extrapolation&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;AutoML and pipeline modeling improvements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Faster random search with hyperband optimization support&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Progress monitor enhancements for fine-tuning and random search &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;HANA ML experiment tracking and task schedule execution&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Experiment tracking and experiment monitor UI (&lt;/SPAN&gt;detailed introduction is provided in the referenced &lt;A title="comprehensive-guide-to-mltrack-in-sap-hana-cloud" href="https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217" target="_self"&gt;blog post&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Enhanced PAL task schedule and job schedule execution UI&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;You can find an examples notebook illustrating the highlighted feature enhancements &lt;SPAN&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/pal/notebooks/25QRC02_2.25.ipynb" target="_blank" rel="noopener nofollow noreferrer"&gt;here 25QRC02_2.25.ipynb&lt;/A&gt;.&amp;nbsp; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-and-ai-features-in-sap-hana-cloud-2025-q2/ba-p/14136079"/>
    <published>2025-06-24T21:40:03.946000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/microsoft-autogen-v0-6-1-with-sap-ai-core/ba-p/14136999</id>
    <title>Microsoft AutoGen v0.6.1 with SAP AI Core</title>
    <updated>2025-06-25T19:45:24.629000+02:00</updated>
    <author>
      <name>Shivang11</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1616935</uri>
    </author>
    <content>&lt;H3 id="toc-hId-1862396263"&gt;Introduction&lt;/H3&gt;&lt;P data-unlink="true"&gt;As a part of&amp;nbsp;&lt;A href="https://help.sap.com/docs/SAP_INTELLIGENT_PRODUCT_RECOMMENDATION?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;Intelligent Product Recommendation&lt;/A&gt; team we are trying to use Autogen for agentic usecases.&amp;nbsp;I initially came across a helpful post&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/autogen-with-sap-ai-core/ba-p/13662908" target="_blank"&gt;AutoGen with SAP AI Core&lt;/A&gt; by&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/407116"&gt;@lars_gregori&lt;/a&gt;&amp;nbsp;, which explores the integration of autogen using &lt;STRONG&gt;pyautogen&lt;/STRONG&gt; and &lt;STRONG&gt;llm_config&lt;/STRONG&gt;. However, use of &lt;STRONG&gt;llm_config&lt;/STRONG&gt;&amp;nbsp;is deprecated in v0.6.1 of&amp;nbsp;&lt;A href="https://microsoft.github.io/autogen/stable//user-guide/agentchat-user-guide/quickstart.html" target="_self" rel="nofollow noopener noreferrer"&gt;AutoGen.&lt;/A&gt;&amp;nbsp; This blog will guide you how to integrate&amp;nbsp;AutoGen&amp;nbsp; with&amp;nbsp;SAP AI Core with the help of&amp;nbsp;&amp;nbsp;&lt;STRONG&gt;AzureOpenAIChatCompletionClient&lt;/STRONG&gt;&amp;nbsp;.&lt;/P&gt;&lt;H3 id="toc-hId-1665882758"&gt;Background&lt;/H3&gt;&lt;P data-unlink="true"&gt;Currently, IPR product is already using python&amp;nbsp;&lt;STRONG&gt;generative-ai-hub-sdk&amp;nbsp;&lt;/STRONG&gt;to call the LLM which takes in the 'AI-Resource-Group' as the required &lt;STRONG&gt;&lt;EM&gt;header&lt;/EM&gt;&lt;/STRONG&gt; and the &lt;STRONG&gt;&lt;EM&gt;model name&lt;/EM&gt;&lt;/STRONG&gt;. Now we have came accross a critical business usecase that requires the use of&amp;nbsp;Autogen&amp;nbsp;to implement the reflection pattern, which led me to explore&amp;nbsp;&lt;STRONG&gt;OpenAIChatCompletionClient &lt;/STRONG&gt;class&amp;nbsp;of Autogen library.&lt;/P&gt;&lt;P data-unlink="true"&gt;I tried using&amp;nbsp;&lt;STRONG&gt;OpenAIChatCompletionClient&amp;nbsp;&lt;/STRONG&gt;by passing&amp;nbsp;&lt;STRONG&gt;base_url&lt;/STRONG&gt; and &lt;STRONG&gt;token&lt;/STRONG&gt;&amp;nbsp;which returned&amp;nbsp;&lt;STRONG&gt;404 resource not found,&lt;/STRONG&gt; since all SAP AI Core requests redirect to Azure OpenAI platform that requires&amp;nbsp;&lt;STRONG&gt;api_version&lt;/STRONG&gt; as&amp;nbsp; a mandatory query parameter. But OpenAIChatCompletionClient class doesn't provides api_version to the LLM while calling it. After further deep dive I figured out&amp;nbsp;&lt;STRONG&gt;AzureOpenAIChatCompletionClient,&lt;/STRONG&gt;&amp;nbsp;which allows requests to be redirected successfully via SAP AI Core to Azure OpenAI by passing the api_version.&lt;/P&gt;&lt;H3 id="toc-hId-1469369253"&gt;Reason to use&amp;nbsp;&lt;STRONG&gt;AzureOpenAIChatCompletionClient&lt;/STRONG&gt;&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;OpenAIChatCompletionClient cannot be used directly.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Instead, we need:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;base_url&lt;/STRONG&gt;: The model deployment URL from SAP AI Core.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;api_key&lt;/STRONG&gt;: A bearer token from GenAI Hub (via SAP AI Core).&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;api_version&lt;/STRONG&gt;: Required by Azure for all chat completions.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Additional headers like AI-Resource-Group.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1272855748"&gt;Code Sample&lt;/H3&gt;&lt;P&gt;Below code sample shows how we can get deployment url and auth token using&amp;nbsp;&lt;SPAN&gt;generative-ai-hub-sdk, that can be passed to AzueOpenAIChatCompletionClient along with api_version.&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import AzureOpenAIChatCompletionClient
from autogen_core.models import ModelFamily
from gen_ai_hub.proxy import GenAIHubProxyClient
from ai_core_sdk.ai_core_v2_client import AICoreV2Client
from autogen_agentchat.ui import Console
import asyncio

# Fetch deployment URL from SAP AI Core
def get_deployment_url():
    try:
        ai_core_client = AICoreV2Client.from_env()
        resources = ai_core_client.deployment.query(resource_group="default", scenario_id="foundation-models").resources
        return resources[0].deployment_url if resources else None
    except Exception:
        return None

# Fetch token and prepare model client
base_url = get_deployment_url()
gen_ai_hub_proxy_client = GenAIHubProxyClient(resource_group='default')
token = gen_ai_hub_proxy_client.get_ai_core_token().replace("Bearer ", "")

model_client = AzureOpenAIChatCompletionClient(
    model="gpt-4.1",
    base_url=base_url,
    api_key=token,
    default_headers={'AI-Resource-Group': 'default'},
    model_info={
        "family": ModelFamily.GPT_41,
        "vision": False,
        "function_calling": True,
        "json_output": False
    },
    api_version="2023-05-15" // api_version as per SAP AI Core documentation
)

# Tool example
async def get_weather(city: str) -&amp;gt; str:
    return f"The weather in {city} is 73 degrees and Sunny."

# Define the agent
agent = AssistantAgent(
    name="weather_agent",
    model_client=model_client,
    tools=[get_weather],
    system_message="You are a weather assistant. Give complete details about the weather in the city requested by the user."
)

# Run the agent
async def main() -&amp;gt; None:
    await Console(agent.run_stream(task="What is the weather in New York?"))
    await model_client.close()

asyncio.run(main())&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-1076342243"&gt;Conclusion&lt;/H3&gt;&lt;P&gt;Above example is referred from&amp;nbsp;&lt;A href="https://microsoft.github.io/autogen/stable//user-guide/agentchat-user-guide/quickstart.html" target="_blank" rel="noopener nofollow noreferrer"&gt;Autogen&lt;/A&gt;&amp;nbsp;documentation. For api_version, ChatCompletionClient can be referred from&amp;nbsp;&lt;A href="https://help.sap.com/docs/AI_CORE/2d6c5984063c40a59eda62f4a9135bee/bf0373b1cf2a4680a7044e1a562d3853.html?locale=en-US&amp;amp;state=PRODUCTION&amp;amp;version=CLOUD&amp;amp;q=2023-05-15" target="_blank" rel="noopener noreferrer"&gt;SAP AI Core&lt;/A&gt; documentation.&amp;nbsp; Output from above code:&lt;/P&gt;&lt;P class="lia-indent-padding-left-60px" style="padding-left : 60px;"&gt;&lt;FONT face="courier new,courier" size="2"&gt;---------- TextMessage (user) ----------&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;What is the weather in New York?&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;---------- ToolCallRequestEvent (weather_agent) ----------&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;[FunctionCall(id='call_WJfl63g7skHT3dWnxMCwNtCr', arguments='{"city":"New York"}', name='get_weather')]&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;---------- ToolCallExecutionEvent (weather_agent) ----------&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;[FunctionExecutionResult(content='The weather in New York is 73 degrees and Sunny.', name='get_weather', call_id='call_WJfl63g7skHT3dWnxMCwNtCr', is_error=False)]&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;---------- ToolCallSummaryMessage (weather_agent) ----------&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;The weather in New York is 73 degrees and Sunny.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;I hope this post helps other teams building solutions on SAP AI Core to successfully integrate newer versions of AutoGen to call the LLM and build multiple AI agents.&lt;/P&gt;&lt;P&gt;Elevate with AI !!&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/microsoft-autogen-v0-6-1-with-sap-ai-core/ba-p/14136999"/>
    <published>2025-06-25T19:45:24.629000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/application-development-and-automation-blog-posts/cloning-and-setting-up-private-github-repositories-on-macos-with-terminal/ba-p/14142843</id>
    <title>Cloning and setting up Private GitHub Repositories on macOS (with Terminal &amp; VS Code)</title>
    <updated>2025-07-04T16:22:39.618000+02:00</updated>
    <author>
      <name>SugandhaSachdeva</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1485764</uri>
    </author>
    <content>&lt;P&gt;Working in a corporate environment often means using private repositories hosted on GitHub Enterprise. If you're on a Mac and prefer the Terminal, here’s a simple step-by-step guide to clone the repo and get started with VS Code.&lt;/P&gt;&lt;H2 id="toc-hId-1734116779"&gt;Prerequisites&lt;/H2&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Homebrew&lt;/STRONG&gt;:&amp;nbsp; Install&amp;nbsp;&lt;A href="https://brew.sh/" target="_blank" rel="noopener nofollow noreferrer"&gt;Homebrew&lt;/A&gt;&amp;nbsp;if its not already available.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Git&lt;/STRONG&gt;: Check if git is installed by running&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;which git
git --version​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;If not installed, install it using:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;brew install git​&lt;/code&gt;&lt;/pre&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Visual Studio Code&lt;/STRONG&gt;: If not installed download it from &lt;A href="https://code.visualstudio.com/" target="_blank" rel="noopener nofollow noreferrer"&gt;Visual Studio Code&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Access to your company’s GitHub Enterprise&lt;/STRONG&gt; (e.g., GitHub Enterprise or another corporate Git)&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;STRONG&gt;Personal Access Token (PAT):&amp;nbsp;&lt;/STRONG&gt;&lt;/STRONG&gt;GitHub no longer supports password-based authentication for Git over HTTPS. Instead, it requires a &lt;STRONG&gt;Personal Access Token (PAT)&lt;/STRONG&gt; -&lt;SPAN&gt;&amp;nbsp;safer, more flexible way to authenticate.&lt;/SPAN&gt;&lt;P&gt;GitHub currently supports two types of PATs:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Classic&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Fine-Grained&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;I used the Classic Token because it is recommended when you're working with GitHub Enterprise Server and the fine-grained token is still in the beta phase.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;You can generate PATs at &lt;A class="" href="https://github.com/settings/tokens" target="_new" rel="noopener nofollow noreferrer"&gt;GitHub → Settings → Developer Settings → Personal Access Tokens&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="SugandhaSachdeva_1-1751625219727.png" style="width: 889px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/282696i278C25D79AEB5BA5/image-dimensions/889x351?v=v2" width="889" height="351" role="button" title="SugandhaSachdeva_1-1751625219727.png" alt="SugandhaSachdeva_1-1751625219727.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;UV (optional)&lt;/STRONG&gt;: A modern Python dependency manager&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;brew install uv​&lt;/code&gt;&lt;/pre&gt;&lt;H2 id="toc-hId-1537603274"&gt;Steps&lt;/H2&gt;&lt;H3 id="toc-hId-1470172488"&gt;&lt;STRONG&gt;1.&amp;nbsp;Verify Git is Installed&lt;/STRONG&gt;&lt;/H3&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;which git
git --version​&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-1273658983"&gt;&lt;STRONG&gt;2. Install GitHub Repositories Extension in VS Code&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;In VS Code:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Press Cmd + Shift + X (or click Extensions)&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Search and install &lt;STRONG&gt;GitHub Repositories&lt;/STRONG&gt; by GitHub&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1077145478"&gt;&lt;STRONG&gt;3. Clone the Repository via Terminal&lt;/STRONG&gt;&lt;/H3&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;git clone https://github.company.com/your-team/your-repo.git​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;BR /&gt;When prompted,&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;enter your GitHub username&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;your &lt;STRONG&gt;Personal Access Token&lt;/STRONG&gt; instead of a password.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;I initially tried using VS Code directly to clone the repository, but it proved not be too straight forward for GitHub Enterprise with custom domains. Using the terminal proved to be much easier and quicker for me.&lt;/P&gt;&lt;H3 id="toc-hId-880631973"&gt;&lt;STRONG&gt;4. Navigate into the Cloned Repository&lt;/STRONG&gt;&lt;/H3&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;cd your-repo​&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-684118468"&gt;5.&amp;nbsp;&lt;STRONG&gt;Open the Project in VS Code&lt;/STRONG&gt;&lt;/H3&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;code .&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;If code is not recognized:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Open VS Code&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Press Cmd + Shift + P&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Run: Shell Command: Install 'code' command in PATH&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-487604963"&gt;&lt;STRONG&gt;6. Install Python Extensions in VS Code&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;If you're working on a Python project, consider installing the following VS Code extensions:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Python&lt;/LI&gt;&lt;LI&gt;Jupyter&lt;/LI&gt;&lt;LI&gt;Black Formatter&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-291091458"&gt;&lt;STRONG&gt;7. Install Python Project Dependencies with uv (Optional)&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;If your project includes a pyproject.toml, you can install dependencies using uv:&lt;/P&gt;&lt;H3 id="toc-hId-94577953"&gt;In the VS Code terminal:&lt;/H3&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;uv sync&lt;/code&gt;&lt;/pre&gt;&lt;H2 id="toc-hId-116236086"&gt;&lt;STRONG&gt;Summary:&amp;nbsp;&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;Cloning a private repository from GitHub Enterprise on a Mac can be smooth and efficient with the right setup. By using the Terminal alongside VS Code, you avoid the complexities that sometimes arise with GitHub Enterprise's custom domains in the GUI. This guide walks you through the essentials—setting up Git, generating a Personal Access Token (especially using the Classic token for GitHub Enterprise), and configuring your environment with useful tools like uv and Python extensions. Once everything is in place, working on your codebase in VS Code becomes fast and seamless.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/application-development-and-automation-blog-posts/cloning-and-setting-up-private-github-repositories-on-macos-with-terminal/ba-p/14142843"/>
    <published>2025-07-04T16:22:39.618000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/hana-ml-data-drift-detector/ba-p/14148518</id>
    <title>HANA ML Data Drift Detector</title>
    <updated>2025-07-10T17:08:13.870000+02:00</updated>
    <author>
      <name>marc_daniau</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/187920</uri>
    </author>
    <content>&lt;P&gt;The release of HANA ML 2.23 includes a new function called: APL data drift detector. This drift detector helps you spot changes or deviations between a given dataset and a reference. Reference data could be a version in the past, or a particular segment of customers or employees, or an expected distribution (e.g. Benford). Use cases of data comparison are:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;This year employee survey results versus last year results by country&lt;/LI&gt;&lt;LI&gt;Machine learning inference dataset versus training dataset&lt;/LI&gt;&lt;LI&gt;Male staff versus female staff&lt;/LI&gt;&lt;LI&gt;Payment amounts by legal entity versus the Benford’s law to find potential fraud&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This feature from APL (Automated Predictive Library) is available for both Python and SQL.&lt;/P&gt;&lt;P&gt;The rest of this blog will walk you through a scenario with code snippets in Python as well as SQL that you can reuse and adapt to your own case.&lt;/P&gt;&lt;P&gt;We chose to work with Olympics athletes and results data. The dataset contains summer and winter games since 1896. We want to make a comparison over time.&lt;/P&gt;&lt;P&gt;First, we connect to the SAP HANA database using a Python notebook.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;DB_Host='host'  
DB_Port='port_number'
DB_User='user_name'
DB_Password='user_password'

from hana_ml import dataframe as hd
conn = hd.ConnectionContext(address = DB_Host, port = DB_Port, 
                            user = DB_User, password = DB_Password, 
                            encrypt = 'true', sslValidateCertificate = 'false' )
conn.connection.isconnected()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The reference dataframe comprises the Olympic games before 1970 …&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport" 
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;lt;= 1970  
order by "Id"
"""
hdf_ref= hd.DataFrame(conn, sql_cmd)
hdf_ref.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_Ref.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284591i95E55218053F1DBE/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_Ref.png" alt="Data_Ref.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-left" style="text-align : left;"&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;… and the comparison dataframe, after 1970:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport"
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;gt; 1970 
order by "Id"
"""
hdf_new= hd.DataFrame(conn, sql_cmd)
hdf_new.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_New.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284593i5A0C2A7E6A164C02/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_New.png" alt="Data_New.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The code to run the comparison is the following:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from hana_ml.algorithms.apl.drift_detector import DriftDetector
apl_model = DriftDetector()
results = apl_model.fit_detect(hdf_ref, hdf_new, build_report=True)
print(results.collect())&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Deviation_Over_time.png" style="width: 200px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284595iD85393F245D82537/image-size/small?v=v2&amp;amp;px=200" role="button" title="Deviation_Over_time.png" alt="Deviation_Over_time.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;All the variables appearing here have a deviation indicator over 0.95. This threshold can be changed with the syntax below:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;results = apl_model.fit_detect(hdf_ref, hdf_new, threshold=0.80)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Here is a report putting the two datasets side by side with their counts (aka weight) by category; the most changing categories (top 10 here) appear first:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;df = apl_model.get_debrief_report('Deviation_CategoryFrequencies').head(10).deselect(['Oid','Category Order']).collect()
format_dict = {
    'Ref Weight': '{:,.0f}', 'New Weight': '{:,.0f}', 'Change': '{:,.0f}', 
    'Ref % Weight': '{:.1f}', 'New % Weight': '{:.1f}', '% Change': '{:.1f}', 'Abs % Change': '{:.1f}'
}
df.style.format(format_dict).hide(axis='index')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Top_Changing.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284599iAD21273F45BCE584/image-size/large?v=v2&amp;amp;px=999" role="button" title="Top_Changing.png" alt="Top_Changing.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;KxMissing is a special category created by APL when finding empty or null values. With far less missing values on athletes’ height and weight, we see that data quality is getting better overtime.&lt;/P&gt;&lt;P&gt;More women are participating to the Olympic games after 1970. The male % change value mirrors the female % change value. The same remark applies to summer and winter seasons.&lt;/P&gt;&lt;P&gt;The following code brings the data drift results as charts:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;apl_model.generate_notebook_iframe_report()
# apl_model.generate_html_report('drift_olympics')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="HTML_Report.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284610i88BD0F5CB087BFE5/image-size/large?v=v2&amp;amp;px=999" role="button" title="HTML_Report.png" alt="HTML_Report.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;After comparing athletes across all types of sports, let’s compare them by sport. For that we must provide the drift detector with two dataframes sorted by Sport:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;## Reference Dataset
sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport" 
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;lt;= 1970  
order by "Sport", "Id"
"""
hdf_ref= hd.DataFrame(conn, sql_cmd)
hdf_ref.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_Ref-By_Sport.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284614i904817BDECD46EDB/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_Ref-By_Sport.png" alt="Data_Ref-By_Sport.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;## Dataset for comparison
sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport" 
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;gt; 1970  
order by "Sport", "Id"
"""
hdf_new= hd.DataFrame(conn, sql_cmd)
hdf_new.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_New-By_Sport.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284615iA1B4FC007FBA9463/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_New-By_Sport.png" alt="Data_New-By_Sport.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;You specify the segment for drift detection the same way as for segmented forecasting, regression or classification scenarios:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;col_segment= 'Sport'    
from hana_ml.algorithms.apl.drift_detector import DriftDetector
apl_model = DriftDetector(segment_column_name= col_segment, max_tasks= 4)
results = apl_model.fit_detect(hdf_ref, hdf_new, threshold=0.95)
print(results.sort(["Segment","Variable"]).collect())&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The deviating variables appear for each sport:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Deviation_Over_time-By_Sport.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284619iEDD5AE5373CE1C3B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Deviation_Over_time-By_Sport.png" alt="Deviation_Over_time-By_Sport.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;We check if there are segments with status ‘Failed’:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;my_filter = "KEY in ('AplTaskStatus') and VALUE ='Failed'"
df = apl_model.get_summary().filter(my_filter).select('OID').collect()
failed_segments = df['OID'].tolist()
print('Preview of failed segments')
print(failed_segments[:5])&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Failed_Segments.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284621iAC4A5C8B2A51FC6B/image-size/large?v=v2&amp;amp;px=999" role="button" title="Failed_Segments.png" alt="Failed_Segments.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The log contains the cause of failure:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;df = apl_model.get_fit_operation_log().filter("LEVEL = 0").select('OID','ORIGIN','MESSAGE').head(5).collect()
df.columns = [col_segment, 'Cause', 'Error']
df.style.hide(axis='index')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Cause_Of_Failure.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284622iAC753A3C7B57F4AE/image-size/large?v=v2&amp;amp;px=999" role="button" title="Cause_Of_Failure.png" alt="Cause_Of_Failure.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;These sports were introduced after 1970. Thus, there is no reference data to compare against.&lt;/P&gt;&lt;P&gt;To obtain the Data Drift report, you must provide a segment value as in the example below:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;seg_value = "Swimming"
apl_model.build_report(segment_name=seg_value)
apl_model.generate_notebook_iframe_report()
#apl_model.generate_html_report('Sport_Report')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;We are nearing the end of this post, and you have not yet seen how to run a comparison with the SQL interface. Here is the syntax for calling the new APL function COMPARE_DATA from a SQL script:&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;drop view DATASET_1;
create view DATASET_1 as (
 select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport"
 from "APL_SAMPLES"."OLYMPICS" 
 where "Year" &amp;lt;= 1970  
 order by "Sport", "Id"
);

drop view DATASET_2;
create view DATASET_2 as (
 select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport"
 from "APL_SAMPLES"."OLYMPICS" 
 where "Year" &amp;gt; 1970  
 order by "Sport", "Id"
);

DO BEGIN
    declare header "SAP_PA_APL"."sap.pa.apl.base::BASE.T.FUNCTION_HEADER";
    declare config "SAP_PA_APL"."sap.pa.apl.base::BASE.T.OPERATION_CONFIG_EXTENDED";   
    declare var_desc "SAP_PA_APL"."sap.pa.apl.base::BASE.T.VARIABLE_DESC_OID";      
    declare var_role "SAP_PA_APL"."sap.pa.apl.base::BASE.T.VARIABLE_ROLES_WITH_COMPOSITES_OID";      
    declare out_log   "SAP_PA_APL"."sap.pa.apl.base::BASE.T.OPERATION_LOG";             
    declare out_summary  "SAP_PA_APL"."sap.pa.apl.base::BASE.T.SUMMARY";   
    declare out_metric   "SAP_PA_APL"."sap.pa.apl.base::BASE.T.DEBRIEF_METRIC_OID";      
    declare out_property "SAP_PA_APL"."sap.pa.apl.base::BASE.T.DEBRIEF_PROPERTY_OID";
 
    :header.insert(('Oid', 'Before-After 1970'));

    :config.insert(('APL/SegmentColumnName', 'Sport',null)); 

	:var_desc.insert((0,'Height','number','continuous',0,0,null,null,null,null));
	:var_desc.insert((1,'Weight','number','continuous',0,0,null,null,null,null));
	:var_desc.insert((2,'Age','integer','continuous',0,0,null,null,null,null));
    :var_desc.insert((3,'Medal','string','nominal',0,0,null,null,null,null));
	:var_desc.insert((4,'Gender','string','nominal',0,0,null,null,null,null));
	:var_desc.insert((5,'Season','string','nominal',0,0,null,null,null,null));
	:var_desc.insert((6,'Country','string','nominal',0,0,null,null,null,null));
	
	"SAP_PA_APL"."sap.pa.apl.base::COMPARE_DATA" (
	:header, :config, :var_desc, :var_role,'USER_APL','DATASET_1', 'USER_APL','DATASET_2', 
	out_log, out_summary, out_metric, out_property );
 
 	select value as "Status", count(*) as "Nb of Segments" from :out_summary where key = 'AplTaskStatus' group by value;
	select OID as "Sport", message as "Error" from :out_log where level=0;
	 	
    select * from SAP_PA_APL."sap.pa.apl.debrief.report::Deviation_ByVariable"(:out_property,:out_metric, Deviation_Threshold =&amp;gt; 0.9);
    select * from SAP_PA_APL."sap.pa.apl.debrief.report::Deviation_ByCategory"(:out_property,:out_metric, Deviation_Threshold =&amp;gt; 0.9); 
    select * from SAP_PA_APL."sap.pa.apl.debrief.report::Deviation_CategoryFrequencies"(:out_property,:out_metric) order by "Abs % Change" desc;
END;

-- Cases where a comparison is not possible
select "Sport" from "DATASET_1" minus select "Sport" from "DATASET_2"; -- Sports that have been removed 
select "Sport" from "DATASET_2" minus select "Sport" from "DATASET_1"; -- New Sports&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The APL drift detector supports also a 2-step approach to address the cases where you have a changing dataset that needs to be compared on a regular basis (e.g. every week or every month) to a fixed reference. The samples below illustrate how it works with Python:&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/apl/notebooks/63a_Data_Drift-Learn_and_Report.ipynb" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 1 notebook&lt;/A&gt;&amp;nbsp; &amp;nbsp;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/apl/notebooks/63b_Data_Drift-Detect_and_Report.ipynb" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 2 notebook&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;and with SQL:&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/APL-SQL/63a_Data_Drift-Learn_and_Report.sql" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 1 script&lt;/A&gt;&amp;nbsp; &amp;nbsp;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/APL-SQL/63b_Data_Drift-Detect_and_Report.sql" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 2 script&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Happy data drift detection with APL.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/viewer/p/apl" target="_self" rel="noopener noreferrer"&gt;To know more about APL&lt;/A&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/hana-ml-data-drift-detector/ba-p/14148518"/>
    <published>2025-07-10T17:08:13.870000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/exploring-sap-generative-ai-sdk-python-javascript-and-java-libraries/ba-p/14150705</id>
    <title>Exploring SAP Generative AI SDK: Python, JavaScript, and Java Libraries 🎁</title>
    <updated>2025-07-11T20:59:21.243000+02:00</updated>
    <author>
      <name>Yogananda</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/75</uri>
    </author>
    <content>&lt;P&gt;&lt;A href="https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/libraries-and-sdks" target="_self" rel="noopener noreferrer"&gt;SAP's Generative AI SDK&lt;/A&gt; offers powerful tools for integrating AI capabilities into your business applications.&lt;/P&gt;&lt;P&gt;This blog will guide you through the libraries available for &lt;FONT color="#0000FF"&gt;Python, JavaScript, and Java&lt;/FONT&gt;, and how to use them effectively.&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-07-11_20-51-00.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285646iE39F1A18CFDFB822/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-07-11_20-51-00.png" alt="2025-07-11_20-51-00.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-1993145073"&gt;1.&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":blue_circle:"&gt;🔵&lt;/span&gt;&amp;nbsp;&lt;/SPAN&gt;SAP Generative AI SDK for Python&lt;/H4&gt;&lt;P&gt;The SAP Generative AI SDK for Python allows developers to leverage generative models from the SAP AI Core. This SDK supports models from providers like OpenAI, Amazon, and Google, and integrates with LangChain for enhanced functionality.&lt;/P&gt;&lt;P&gt;Documentation and Examples :&amp;nbsp;&lt;A href="https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/index.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/index.html&lt;/A&gt;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Yogananda_1-1752259770526.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285644i13469DC27D9AC732/image-size/large?v=v2&amp;amp;px=999" role="button" title="Yogananda_1-1752259770526.png" alt="Yogananda_1-1752259770526.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Installation:&amp;nbsp;To install the SDK, use the following command:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;pip install sap-ai-sdk-gen[all]&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;SPAN&gt;You can also install specific model providers:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;pip install "sap-ai-sdk-gen[google, amazon]"&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Configuration:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Set up your environment variables or configuration file to authenticate and connect to SAP AI Core:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;export AICORE_CLIENT_ID="your_client_id"
export AICORE_CLIENT_SECRET="your_client_secret"
export AICORE_AUTH_URL="your_auth_url"
export AICORE_BASE_URL="your_base_url"&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Usage:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Here's a simple example to generate text using the OpenAI model:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from sap_ai_sdk_gen import OpenAI

client = OpenAI()
response = client.generate_text(prompt="Hello, world!")
print(response)&lt;/code&gt;&lt;/pre&gt;&lt;H4 id="toc-hId-1796631568"&gt;2.&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":blue_circle:"&gt;🔵&lt;/span&gt;&amp;nbsp;&lt;/SPAN&gt;SAP Generative AI SDK for JavaScript&lt;/H4&gt;&lt;P&gt;The JavaScript SDK enables Node.js applications to interact with SAP AI Core, providing seamless integration with generative models.&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP/ai-sdk-js" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/SAP/ai-sdk-js&lt;/A&gt;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Yogananda_0-1752259610583.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285643iBB7D6B6568C71C17/image-size/large?v=v2&amp;amp;px=999" role="button" title="Yogananda_0-1752259610583.png" alt="Yogananda_0-1752259610583.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Installation:&amp;nbsp;Install the SDK via npm:&lt;/P&gt;&lt;pre class="lia-code-sample language-javascript"&gt;&lt;code&gt;npm install -ai-sdk/ai-api&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Configuration:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Ensure your environment variables are set up correctly:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-javascript"&gt;&lt;code&gt;export AICORE_CLIENT_ID="your_client_id"
export AICORE_CLIENT_SECRET="your_client_secret"
export AICORE_AUTH_URL="your_auth_url"
export AICORE_BASE_URL="your_base_url"&lt;/code&gt;&lt;/pre&gt;&lt;H4 id="toc-hId-1600118063"&gt;&lt;STRONG&gt;Usage:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Here's a basic example to generate text:&lt;/SPAN&gt;&lt;/H4&gt;&lt;pre class="lia-code-sample language-javascript"&gt;&lt;code&gt;import { OpenAI } from '@sap-ai-sdk/ai-api';

const client = new OpenAI();
client.generateText('Hello, world!').then(response =&amp;gt; {
  console.log(response);
});&lt;/code&gt;&lt;/pre&gt;&lt;H4 id="toc-hId-1403604558"&gt;3.&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":blue_circle:"&gt;🔵&lt;/span&gt;&amp;nbsp;&lt;/SPAN&gt;SAP Generative AI SDK for Java&lt;/H4&gt;&lt;P&gt;The Java SDK integrates AI capabilities into Java-based applications, leveraging the SAP AI Core's generative models.&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP/ai-sdk-java" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/SAP/ai-sdk-java&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Installation:&amp;nbsp;Add the SDK to your Maven project:&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-java"&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;com.sap.ai&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;sap-ai-sdk&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;5.6.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Configuration:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Configure your application properties:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-java"&gt;&lt;code&gt;aicore.client.id=your_client_id
aicore.client.secret=your_client_secret
aicore.auth.url=your_auth_url
aicore.base.url=your_base_url&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Usage:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Here's an example to generate text:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-java"&gt;&lt;code&gt;import com.sap.ai.sdk.OpenAI;

public class Main {
    public static void main(String[] args) {
        OpenAI client = new OpenAI();
        String response = client.generateText("Hello, world!");
        System.out.println(response);
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-1078008334"&gt;Conclusion&lt;/H3&gt;&lt;P&gt;SAP's Generative AI SDKs for Python, JavaScript, and Java provide robust tools for integrating AI into your applications. By following the installation, configuration, and usage examples provided, you can start leveraging the power of generative AI in your projects.&lt;/P&gt;&lt;P&gt;Feel free to reach out if you have any questions or need further assistance! Happy coding!&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/exploring-sap-generative-ai-sdk-python-javascript-and-java-libraries/ba-p/14150705"/>
    <published>2025-07-11T20:59:21.243000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/using-python-in-sap-business-application-studio-my-notes/ba-p/14155516</id>
    <title>Using Python in SAP Business Application Studio – my notes</title>
    <updated>2025-07-18T13:55:15.744000+02:00</updated>
    <author>
      <name>Vitaliy-R</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/183</uri>
    </author>
    <content>&lt;P&gt;The &lt;STRONG&gt;Python Tools extension&lt;/STRONG&gt;, which enhances the Python coding experience, was introduced in SAP Business Application Studio (referred to as "BAS" below) exactly two years ago. Here are my notes from using it.&lt;/P&gt;&lt;P&gt;This post is not a tutorial or a comprehensive guide to best practices. It’s a collection of personal notes, which I hope you find helpful when working with Python in BAS. The &lt;STRONG&gt;focus here is on&lt;/STRONG&gt; &lt;STRONG&gt;running Python code in BAS&lt;/STRONG&gt;, not on deploying to SAP BTP runtimes like Cloud Foundry (CF) or Kyma. This is when you are usually working on &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/quot-getting-started-with-machine-learning-using-sap-hana-quot-as-a-new-sap/ba-p/13574098" target="_self"&gt;Machine Learning&lt;/A&gt; or AI projects in BAS,&amp;nbsp;like during SAP CodeJams.&lt;/P&gt;&lt;P&gt;I assume you're not an absolute beginner with SAP Business Application Studio—or at least you're familiar with Visual Studio Code.&lt;/P&gt;&lt;P&gt;For the examples in this post, I’ll be using the SAP Business Application Studio available in the SAP BTP Trial environment.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1606043981"&gt;Python runtime&lt;/H1&gt;&lt;P&gt;In SAP Business Application Studio, the dev space includes a system-level Python 3 binary at &lt;FONT face="terminal,monaco" color="#000080"&gt;/bin/python3&lt;/FONT&gt;, which is primarily intended for OS-level scripts and tooling. This version is tied to the base container image and is only updated when the image itself is refreshed.&lt;/P&gt;&lt;H3 id="toc-hId-1667695914"&gt;Managing Python versions&lt;/H3&gt;&lt;P&gt;For application development, developers typically use user-managed Python runtimes. Since &lt;A href="https://help.sap.com/docs/bas/sap-business-application-studio/2024-what-s-new-for-sap-business-application-studio?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;January 2024&lt;/A&gt;, you can select the Python version with which you want to work.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752787857188.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288194i63734250F432B502/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1752787857188.png" alt="VitaliyR_0-1752787857188.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;SAP Business Application Studio uses &lt;A href="https://asdf-vm.com/guide/introduction.html" target="_self" rel="nofollow noopener noreferrer"&gt;asdf&lt;/A&gt; to allow you to select which runtime versions to install and use for developing your application. You can check this in the BAS terminal with &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf current python&lt;/FONT&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752826029935.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288476i3AA3E4CCAB7C035F/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1752826029935.png" alt="VitaliyR_0-1752826029935.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;By default, SAP Business Application Studio provides only one officially supported Python version.&lt;/P&gt;&lt;P&gt;If you need another version of Python, you can install it with&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;FONT face="terminal,monaco" color="#000080"&gt;asdf install python &amp;lt;version&amp;gt;&lt;/FONT&gt;. If you want the latest minor version, then use&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;FONT face="terminal,monaco" color="#000080"&gt;latest:&lt;/FONT&gt;, like&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;FONT face="terminal,monaco" color="#000080"&gt;asdf install python latest:3.12&lt;/FONT&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;in the case of the 3.12 version of Python.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1752826587342.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288479i3F1AFA339D0457AC/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_1-1752826587342.png" alt="VitaliyR_1-1752826587342.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;At the time of writing this post, the &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf&lt;/FONT&gt;&amp;nbsp;version used in BAS is 0.12.0. This version uses the &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf global&lt;/FONT&gt;&amp;nbsp;and &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf local&lt;/FONT&gt;&amp;nbsp;commands to set the actual runtime version. If you refer to the &lt;A href="https://asdf-vm.com/manage/commands.html" target="_self" rel="nofollow noopener noreferrer"&gt;asdf documentation&lt;/A&gt;, these commands have been replaced with &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf set&lt;/FONT&gt;, so don't get confused.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_4-1752832090379.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288513i2594100CA73554EA/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_4-1752832090379.png" alt="VitaliyR_4-1752832090379.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1471182409"&gt;Runtime management from the command palette&lt;/H3&gt;&lt;P&gt;You can also install different versions from the command palette. Select &lt;STRONG&gt;&amp;gt; Runtime: Install&lt;/STRONG&gt;,&amp;nbsp;then Python, and the version you want to install. To set the default version of Python for execution, use the command &lt;STRONG&gt;&amp;gt; Runtime: Set Default&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_3-1752831488109.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288507iF7D44FFABFDAC454/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_3-1752831488109.png" alt="VitaliyR_3-1752831488109.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://help.sap.com/docs/bas/sap-business-application-studio/runtime-version-management" target="_blank" rel="noopener noreferrer"&gt;These commands&lt;/A&gt; are provided by the built-in &lt;STRONG&gt;BAS Framework&lt;/STRONG&gt; extension.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_2-1752831268028.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288505i52FE94C88EEC6711/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_2-1752831268028.png" alt="VitaliyR_2-1752831268028.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1274668904"&gt;You can now run your Python programs in BAS...&lt;/H3&gt;&lt;P&gt;...using a version of Python accordingly to your requirements.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752833019314.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288533iF1F4C8ABA0F83A9D/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_0-1752833019314.png" alt="VitaliyR_0-1752833019314.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-819989961"&gt;Design-time&lt;/H1&gt;&lt;P&gt;Being a &lt;STRONG&gt;fork of Visual Studio Code - Open Source ("&lt;A href="https://github.com/microsoft/vscode" target="_self" rel="nofollow noopener noreferrer"&gt;Code - OSS&lt;/A&gt;")&lt;/STRONG&gt;—SAP Business Application Studio provides basic support for Python files and Jupyter notebooks out of the box.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752835179123.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288559i5DC7A0BAB2529980/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_0-1752835179123.png" alt="VitaliyR_0-1752835179123.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-881641894"&gt;BAS additional extension "&lt;SPAN&gt;Python Tools&lt;/SPAN&gt;"&lt;/H3&gt;&lt;P&gt;To improve your Python coding experience, SAP Business Application Studio provides an additional extension called "&lt;SPAN&gt;Python Tools&lt;/SPAN&gt;". This extension includes IntelliSense, formatting, linting, and debugging support for Python files and Jupyter notebooks.&lt;/P&gt;&lt;P&gt;To add "Python Tools" to your BAS dev space, go to the configuration of a stopped or a newly created dev space, and select &lt;STRONG&gt;Python Tools&lt;/STRONG&gt; from&amp;nbsp;&lt;STRONG&gt;Additional SAP Extensions&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1752833807354.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288542i4B3C4AE1B211B686/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1752833807354.png" alt="VitaliyR_1-1752833807354.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Upon activation, you should see additional extensions listed now as built-in in BAS.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1752835746649.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288580i881221FC5560023D/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1752835746649.png" alt="VitaliyR_1-1752835746649.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Note&lt;SPAN&gt;&amp;nbsp;that BAS installs its extensions from &lt;A href="https://open-vsx.org/" target="_self" rel="nofollow noopener noreferrer"&gt;Open VSX&lt;/A&gt;, an open-source registry for VS Code extensions.&amp;nbsp;&lt;A href="https://github.com/Microsoft/vscode-python" target="_blank" rel="noopener nofollow noreferrer"&gt;VS Code's Python extension&lt;/A&gt;&amp;nbsp;is available&lt;/SPAN&gt;&amp;nbsp;at:&amp;nbsp;&lt;A href="https://open-vsx.org/extension/ms-python/python" target="_blank" rel="noopener nofollow noreferrer"&gt;https://open-vsx.org/extension/ms-python/python&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;You can see Python extensions in the file system:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;ls -lad /extbin/local/openvscode-server/extensions/ms-py*&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_2-1752837415019.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288590iAD09D0AB5EF7209B/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_2-1752837415019.png" alt="VitaliyR_2-1752837415019.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;These are extensions selected and integrated by the BAS product team at SAP.&lt;/P&gt;&lt;H3 id="toc-hId-685128389"&gt;Additional notes:&lt;/H3&gt;&lt;P&gt;You can install other versions of the same extensions directly from&amp;nbsp;&lt;A href="https://open-vsx.org/," target="_blank" rel="noopener nofollow noreferrer"&gt;https://open-vsx.org/,&lt;/A&gt;&amp;nbsp;but there is no guarantee that they have been tested and will properly work with BAS. First of all, the extension version installed directly from the marketplace should be compatible with the version of SAP Business Application Studio (or the "Code—OSS" to be more precise).&lt;/P&gt;&lt;P&gt;For example, at the time of writing this post, the version of the Python extension at the VSX marketplace is 2025.04...&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752844419611.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288649i9D1EA9993790B188/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1752844419611.png" alt="VitaliyR_0-1752844419611.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;which is compatible with version&amp;nbsp;1.94.0 of Code-OSS and therefore BAS:&amp;nbsp;&lt;A href="https://github.com/microsoft/vscode-python/blob/v2025.4.0/package.json#L50" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/microsoft/vscode-python/blob/v2025.4.0/package.json#L50&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_1-1752844619669.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288650i4AACB703E4B1AB99/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_1-1752844619669.png" alt="VitaliyR_1-1752844619669.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-488614884"&gt;Usage of the Python extension in BAS&lt;/H3&gt;&lt;P&gt;Upon installation of the Python extension in BAS, you can:&lt;/P&gt;&lt;P&gt;1/ Execute Python extension's commands from the palette:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_3-1752839390743.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288612iE7D273E2ECA1213B/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_3-1752839390743.png" alt="VitaliyR_3-1752839390743.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;2/ Trigger an execution of a program from the editor:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_4-1752839526904.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288613i6971D9697275CE7D/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_4-1752839526904.png" alt="VitaliyR_4-1752839526904.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;...which you can configure by editing the&amp;nbsp;&lt;FONT face="terminal,monaco" color="#000080"&gt;python.terminal&lt;/FONT&gt;&amp;nbsp;settings:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1753218387860.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/290009i4BCA41DCB5E93013/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1753218387860.png" alt="VitaliyR_0-1753218387860.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;3/ modify its &lt;FONT face="terminal,monaco" color="#000080"&gt;@ext:ms-python.python&lt;/FONT&gt;&amp;nbsp;settings:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_5-1752839680256.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288616i88C848EA078DDAA6/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_5-1752839680256.png" alt="VitaliyR_5-1752839680256.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-33935941"&gt;Python virtual environments&lt;/H1&gt;&lt;P&gt;To run your code, you usually need additional Python packages, such as the&amp;nbsp;&lt;A href="https://pypi.org/project/hana-ml/" target="_blank" rel="noopener nofollow noreferrer"&gt;Python machine learning client for SAP HANA (hana-ml)&lt;/A&gt;&amp;nbsp;or &lt;A href="https://pypi.org/project/sap-ai-sdk-gen/" target="_self" rel="nofollow noopener noreferrer"&gt;SAP Cloud SDK for AI (Python)&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;If you have experience with Python, then you already know all the advantages of using virtual environments. Although you can think of BAS devspace as an isolated project development environment, there is a good reason to use Python virtual environments there, as I already explained in&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/persisting-python-environment-when-using-jupyter-notebooks-in-sap-business/ba-p/13549863" target="_self"&gt;Persisting Python environment in SAP Business Application Studio&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;An additional reason to use a virtual environment is if you plan to test or run your project using different versions of Python managed by &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf&lt;/FONT&gt;. Each of the installed versions of Python will use their own location to store packages:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1753198029018.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/289900iDF172F958DDDAA5B/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1753198029018.png" alt="VitaliyR_1-1753198029018.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-1208218584" id="toc-hId-224670593"&gt;You should be ready to work with Python in SAP Business Application Studio now!&amp;nbsp;&lt;/H4&gt;&lt;P&gt;Please share your tips in the comments!&lt;/P&gt;&lt;H4 id="toc-hId--469560007"&gt;In my other blog posts, I focused on:&lt;BR /&gt;🪐&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-jupyter-in-sap-business-application-studio-my-notes/ba-p/14167294" target="_blank"&gt;Using Jupyter in SAP Business Application Studio&lt;/A&gt;, and&lt;BR /&gt;&lt;span class="lia-unicode-emoji" title=":hammer:"&gt;🔨&lt;/span&gt;&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-conda-forge-in-sap-business-application-studio-my-notes/ba-p/14169956" target="_blank"&gt;Using conda-forge in SAP Business Application Studio&lt;/A&gt;.&lt;/H4&gt;&lt;P&gt;------&lt;/P&gt;&lt;P&gt;-Vitaliy, aka&amp;nbsp;&lt;A href="https://bsky.app/profile/sygyzmundovych.bsky.social" target="_self" rel="nofollow noopener noreferrer"&gt;@Sygyzmundovych&lt;/A&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-python-in-sap-business-application-studio-my-notes/ba-p/14155516"/>
    <published>2025-07-18T13:55:15.744000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/exposing-sap-s4-onprem-data-to-external-system-odata-service-btp/ba-p/14151915</id>
    <title>Exposing SAP S4 Onprem data to external System || Odata Service || BTP || Destination-Connectivity</title>
    <updated>2025-07-24T09:09:11.979000+02:00</updated>
    <author>
      <name>Ace_D</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1501366</uri>
    </author>
    <content>&lt;H2 id="toc-hId-1735011379"&gt;&lt;STRONG&gt;Prerequisites from BTP Side&lt;/STRONG&gt;&lt;/H2&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;SAP BTP Account&lt;/STRONG&gt;&lt;UL&gt;&lt;LI&gt;Access to SAP Business Technology Platform (BTP) with appropriate entitlements.&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;SAP Cloud Connector Setup&lt;/STRONG&gt;&lt;UL&gt;&lt;LI&gt;SAP Cloud Connector installed and configured to connect your on-premise S/4HANA system to SAP BTP.&lt;/LI&gt;&lt;LI&gt;Destination configured in BTP cockpit pointing to your on-premise system.&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Connectivity Service and Destination Service&lt;/STRONG&gt;&lt;UL&gt;&lt;LI&gt;SAP BTP Connectivity service and destination service instance on the BTP account.&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Cloud Foundry Environment&lt;/STRONG&gt;&lt;UL&gt;&lt;LI&gt;Cloud Foundry space set up in your BTP subaccount to deploy the application.&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;Use Case:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Lets take a simple use case for creating a RAP service on S4, which is a wrapper API call on the reprocess IDOC function module.&lt;/P&gt;&lt;P&gt;For this we will create a RAP service on the S4 box, than activate the service with the &lt;STRONG&gt;/IWFND/MAINT_SERVICE&amp;nbsp;&lt;/STRONG&gt;and activate the &lt;STRONG&gt;ICF Node as well.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Note: In this blog we will not go through the steps of setting cloud connector and destination on the BTP account. We will assume that destination with cloud connector setup is already available on the BTP.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 1: Create and activate the RAP service on the S4 Box.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;We will create a unmanaged rap scenario with custom entity and than we will create a service definition and top of service definition we will create service binding.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_0-1752479114889.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286063i6147300A58FD94EB/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_0-1752479114889.png" alt="Ace_D_0-1752479114889.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Lets create the class for the query implementation.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_1-1752479219667.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286066i8FE4DD17F2125A3B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_1-1752479219667.png" alt="Ace_D_1-1752479219667.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_3-1752479284513.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286068i7DF33D859E64B0B5/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_3-1752479284513.png" alt="Ace_D_3-1752479284513.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_4-1752479314425.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286069i1ADC607EAFF20853/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_4-1752479314425.png" alt="Ace_D_4-1752479314425.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;We are calling the FM to reprocess the idoc and checking the relevant table to get the latest reprocessed idoc status for the same.&lt;/P&gt;&lt;P&gt;Now we will create a service definition and service binding for the custom entity created.&lt;/P&gt;&lt;P&gt;Service Definition&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_8-1752479854976.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286073i72B0728E2CDB8D9C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_8-1752479854976.png" alt="Ace_D_8-1752479854976.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;And overall project will look something like this.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_5-1752479511558.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286070iB8D8CB8704C75416/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_5-1752479511558.png" alt="Ace_D_5-1752479511558.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Here i have created two types of service bindings v2 and v4 but we will be using only v2 for this.&lt;/P&gt;&lt;P&gt;So overall we created below 4 artifacts.&lt;/P&gt;&lt;P&gt;1. Custom entity&lt;/P&gt;&lt;P&gt;2. Class&lt;/P&gt;&lt;P&gt;3. Service definition&lt;/P&gt;&lt;P&gt;4. Service binding&lt;/P&gt;&lt;P&gt;Now to test the service we will publish the service first and than call the generated url&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_7-1752479816432.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286072iDC562CE467DBAAA5/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_7-1752479816432.png" alt="Ace_D_7-1752479816432.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;if you see the image, i have published the service and after publish we also got the custom entity that we have created, click on the &lt;STRONG&gt;service url&lt;/STRONG&gt; and it will open in browser asking for authentication of S4 user id and password.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_9-1752480025822.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286074iD29880ABB4A5E44A/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_9-1752480025822.png" alt="Ace_D_9-1752480025822.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once the authentication is successful you should be able to see this.&lt;/P&gt;&lt;P&gt;Now lets open the SAP GUI so that i can show you the ICF node activation, which is generally taken care by basis team.&lt;/P&gt;&lt;P&gt;Open the Tcode:&amp;nbsp;&lt;STRONG&gt;/IWFND/MAINT_SERVICE&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_10-1752480290098.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286075i2C11D72626448B10/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_10-1752480290098.png" alt="Ace_D_10-1752480290098.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Here you can find your activated service binding and make sure all components of the service looks as it is in the image.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Assuming cloud connector and destination is setup on BTP.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;With this we completed the S4 box setup, now its ready to communicate with other external systems.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 2: Creating the Destination service and Connectivity service on the BTP Account.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Login in to BTP account and lets create 2 service instances with service keys.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_11-1752483153170.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286097iDCC3A3321CE1ECB0/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_11-1752483153170.png" alt="Ace_D_11-1752483153170.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;1.&amp;nbsp;&lt;STRONG&gt;Destination service&lt;/STRONG&gt;, this will help us to get the destination details, Destination service gets all the registered destinations on the BTP, from which we can filter out the destination that is up for our S4 onprem box.&lt;/P&gt;&lt;P&gt;Destination service will give us all the relevant things like user id passwd, location and etc. for that destination.&lt;/P&gt;&lt;P&gt;Service key for the destination service&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_12-1752483270245.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286098iBE180D64FD0F615E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_12-1752483270245.png" alt="Ace_D_12-1752483270245.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_13-1752483330309.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286099i127A1F287FB75995/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_13-1752483330309.png" alt="Ace_D_13-1752483330309.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;2. &lt;STRONG&gt;Connectivity Service,&amp;nbsp;&lt;/STRONG&gt;Since we are trying to get the data out of onprem system we will have to use connectivity service from btp, which will provide us proxies, this proxies will be use to call the onprem odata url.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_14-1752483491742.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286106i3806395799EEF5CB/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_14-1752483491742.png" alt="Ace_D_14-1752483491742.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_15-1752483598535.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286107iCD11D07C5A492C3E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_15-1752483598535.png" alt="Ace_D_15-1752483598535.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;It is important to paste here the service keys for better understanding since we will be using many things from the service key into our application&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 3: Lets create a python application to call the onprem service.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Important things to consider here.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;By using destination and connectivity service we cannot test the application on local system, we will have to deploy our app on CF to test the same.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;We will use the flask requests and certain other libraries for the python programming&lt;/P&gt;&lt;P&gt;file: .env file to store all the secrets this secrets are from the service keys only.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_2-1752492372749.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286202iF6300349E7896528/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_2-1752492372749.png" alt="Ace_D_2-1752492372749.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;File: Requirements.txt&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_0-1752492015085.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286200i27F53BD3C09B09AE/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_0-1752492015085.png" alt="Ace_D_0-1752492015085.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;File: Runtime.txt&lt;/P&gt;&lt;P&gt;python-3.11.*&lt;/P&gt;&lt;P&gt;file: manifest.yaml&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_1-1752492157202.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286201iA56CB734CFA3967C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_1-1752492157202.png" alt="Ace_D_1-1752492157202.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;file:idocapis.py (should be same as mentioned in Manifest.yml file&lt;/P&gt;&lt;P&gt;Load all the required libraries.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_3-1752492555784.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286203iEB454EAAAAA7E66C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_3-1752492555784.png" alt="Ace_D_3-1752492555784.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;define the function to get the token&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_4-1752493129840.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286204i152BA582C8BA1F8B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_4-1752493129840.png" alt="Ace_D_4-1752493129840.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Define function to get the list of all destinations on the BTP&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_5-1752493241781.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286205iA640B84C01B00E5E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_5-1752493241781.png" alt="Ace_D_5-1752493241781.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Define the function to construct the URL for the odata call&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_6-1752493319173.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286206i83806D03EC8AE6C7/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_6-1752493319173.png" alt="Ace_D_6-1752493319173.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Define function to get token for the connectivity service&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_7-1752493411094.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286213i4C439E0B0047EB4E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_7-1752493411094.png" alt="Ace_D_7-1752493411094.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Define function to call the odata service with connectivity things&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_8-1752493551879.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286242iDE3AED9EE0D95C35/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_8-1752493551879.png" alt="Ace_D_8-1752493551879.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_9-1752493573946.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286243i670226B5E2674B07/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_9-1752493573946.png" alt="Ace_D_9-1752493573946.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now lets define the final route in flask to call this service&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_13-1752494450583.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286281i0C7C7F657EECF5CA/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_13-1752494450583.png" alt="Ace_D_13-1752494450583.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;One thing to note here the&amp;nbsp;&lt;STRONG&gt;RESOURCE variable will depend on the destination url of the onprem that is setup on BTP.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_11-1752494105816.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286279i7A1D0EA83E29C50A/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_11-1752494105816.png" alt="Ace_D_11-1752494105816.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_12-1752494133009.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286280iBAC4EB399CB3AEFD/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_12-1752494133009.png" alt="Ace_D_12-1752494133009.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;STEP 4: Deployment&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Lets deploy the app on the CF by pushing the app to the cloud foundry from the BAS&lt;/P&gt;&lt;P&gt;Use command &lt;STRONG&gt;cf push&lt;/STRONG&gt; after successful authentication for your cloud foundry space.&lt;/P&gt;&lt;P&gt;After the deployment on the cloud we can get the url that is generated on the cloud.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_14-1752495094785.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286283iF188D4ACAB2AC66A/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_14-1752495094785.png" alt="Ace_D_14-1752495094785.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Testing the application:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Lets create a small python program to call this API in local now to test it.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ace_D_15-1752495325813.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286284iA1C1678704489B7A/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Ace_D_15-1752495325813.png" alt="Ace_D_15-1752495325813.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;You should get response coming from your S4 onPrem system.&lt;/P&gt;&lt;P&gt;Thanks for staying till the end!!!&lt;span class="lia-unicode-emoji" title=":smiling_face_with_smiling_eyes:"&gt;😊&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/exposing-sap-s4-onprem-data-to-external-system-odata-service-btp/ba-p/14151915"/>
    <published>2025-07-24T09:09:11.979000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-2/ba-p/14167025</id>
    <title>SAP Databricks: Building an Intelligent Enterprise with AI Unleashed – Part 2</title>
    <updated>2025-07-30T15:18:04.435000+02:00</updated>
    <author>
      <name>jing_wen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1923466</uri>
    </author>
    <content>&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-1/ba-p/14166813" target="_self"&gt;&lt;SPAN&gt;Part 1 – SQL analytics with SAP Data Products&lt;BR /&gt;&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-2/ba-p/14167025" target="_self"&gt;Part 2 – Build and deploy Mosaic AI and Agent Tools&lt;/A&gt;&lt;BR /&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-how-to-use-automl-to-forecast-sales-data-part-3/ba-p/14174354" target="_self"&gt;Part 3 – How to use AutoML to forecast sales data&lt;/A&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-3/ba-p/14174201" target="_self"&gt;&lt;SPAN&gt;Part 4 – Connect SAP Data Products with non-SAP data from AWS S3&lt;BR /&gt;&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-4/ba-p/14178056" target="_self"&gt;Part 5 – End-to-end integration: SAP Databricks, SAP Datasphere, and SAP Analytics Cloud&lt;/A&gt;&lt;BR /&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-create-inferences-for-application-integration-with-sap-build/ba-p/14186662" target="_self"&gt;Part 6 – Create inferences and endpoints for application integration with SAP Build&lt;/A&gt;&lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-create-inferences-for-application-integration-with-sap-build/ba-p/14186662" target="_self"&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/A&gt;&lt;BR /&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-in-sap-business-data-cloud-a-typical-machine-learning/ba-p/14206612" target="_self"&gt;Part 7&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;–&amp;nbsp;SAP Databricks in SAP Business Data Cloud - A Typical Machine Learning Workflow&lt;/SPAN&gt;&lt;/A&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1865165611" id="toc-hId-1865187747"&gt;SAP Databricks in SAP Business Data Cloud&amp;nbsp;&lt;/H3&gt;&lt;P&gt;In part 2 of this series, we move beyond SQL analytics and explore how to harness the full power of &lt;STRONG&gt;Mosaic AI&lt;/STRONG&gt; and &lt;STRONG&gt;Agent &lt;/STRONG&gt;&lt;STRONG&gt;T&lt;/STRONG&gt;&lt;STRONG&gt;ools&lt;/STRONG&gt; within SAP Databricks. These capabilities enable developers and data scientists to rapidly prototype and deploy custom AI agent functions that interact with SAP Data Products—unlocking new levels of automation, personalization, and decision intelligence across the enterprise.&lt;/P&gt;&lt;H3 id="toc-hId-1865165611" id="toc-hId-1668674242"&gt;The Value of AI Powered by SAP Data Products&lt;/H3&gt;&lt;P&gt;Many companies envision AI as a simple linear path:&lt;/P&gt;&lt;H2 id="toc-hId-1343078018"&gt;&lt;STRONG&gt;Data &lt;/STRONG&gt;&lt;STRONG&gt;→&lt;/STRONG&gt;&lt;STRONG&gt; AI &lt;/STRONG&gt;&lt;STRONG&gt;→&lt;/STRONG&gt;&lt;STRONG&gt; Value&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;In reality, achieving business value from AI is far more complex. It starts with &lt;STRONG&gt;data selection, sourcing, and synthesis&lt;/STRONG&gt;, followed by rigorous &lt;STRONG&gt;data engineering&lt;/STRONG&gt; tasks such as cleaning, normalization, model training, evaluation, and hyperparameter tuning. The real challenge—and where many initiatives stall—is in &lt;STRONG&gt;operationalizing&lt;/STRONG&gt; these models: deploying them in production, monitoring performance, and continuously retraining to maintain accuracy.&lt;/P&gt;&lt;P&gt;This is where &lt;STRONG&gt;SAP Databricks and SAP Data Products&lt;/STRONG&gt; play a critical role. By combining SAP’s semantically rich, governed data with Databricks’ powerful analytics and machine learning platform, organizations can bridge the gap between experimentation and enterprise-scale value—making AI not just possible, but sustainable and impactful.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="What AI actually is.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293977iDAC814AF09AD0C3D/image-size/large?v=v2&amp;amp;px=999" role="button" title="What AI actually is.png" alt="What AI actually is.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Let’s explore several key features of SAP Databricks and dive into two practical use cases:&lt;BR /&gt;Analyzing a&amp;nbsp;&lt;STRONG&gt;Customer Data Product &lt;/STRONG&gt;with&lt;STRONG&gt; LLM&lt;/STRONG&gt;, and integrating &lt;STRONG&gt;SAP BTP Document AI&lt;/STRONG&gt; with the &lt;STRONG&gt;SAP Databricks Playground&lt;/STRONG&gt;.&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1275647232"&gt;AI/ML Features in SAP Databricks&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#ai-playground" target="_blank" rel="noopener nofollow noreferrer"&gt;AI Playground&lt;/A&gt;&amp;nbsp;for testing generative AI models from your Databricks workspace. You can prompt, compare and adjust settings such as system prompt and inference parameters.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#ai-functions" target="_blank" rel="noopener nofollow noreferrer"&gt;AI Functions&lt;/A&gt;&amp;nbsp;that you can use to apply AI, like text translation or sentiment analysis, on your data that is stored on Databricks.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#ai-gateway" target="_blank" rel="noopener nofollow noreferrer"&gt;Mosaic AI Gateway&lt;/A&gt;&amp;nbsp;for governing and monitoring access to supported generative AI models and their associated model serving endpoints.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#model-serving" target="_blank" rel="noopener nofollow noreferrer"&gt;Mosaic AI Model Serving&lt;/A&gt;&amp;nbsp;for deploying LLMs.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#vector-serach" target="_blank" rel="noopener nofollow noreferrer"&gt;Mosaic AI Vector Search&lt;/A&gt;&amp;nbsp;provides a queryable vector database that stores embedding vectors and can be configured to automatically sync to your knowledge base.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#lakehouse-monitoring" target="_blank" rel="noopener nofollow noreferrer"&gt;Lakehouse Monitoring&lt;/A&gt;&amp;nbsp;for data monitoring and tracking model prediction quality and drift using automatic payload logging with inference tables.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#mlflow" target="_blank" rel="noopener nofollow noreferrer"&gt;Managed MLflow&lt;/A&gt;&amp;nbsp;for AI agent and ML model lifecycle.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#agent-framework" target="_blank" rel="noopener nofollow noreferrer"&gt;Mosaic AI Agent Framework&lt;/A&gt;&amp;nbsp;for building and deploying production-quality agents like Retrieval Augmented Generation (RAG) applications.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#agent-eval" target="_blank" rel="noopener nofollow noreferrer"&gt;Mosaic AI Agent Evaluation&lt;/A&gt;&amp;nbsp;for evaluating the quality, cost, and latency of generative AI applications, including RAG applications and chains.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#automl" target="_blank" rel="noopener nofollow noreferrer"&gt;AutoML&lt;/A&gt;&amp;nbsp;to simplify the process of applying machine learning to your datasets.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#finetuning" target="_blank" rel="noopener nofollow noreferrer"&gt;Foundation Model Fine-tuning&lt;/A&gt;&amp;nbsp;for customizing a foundation model using your own data to optimize its performance for your specific application.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/machine-learning#unity-catalog" target="_blank" rel="noopener nofollow noreferrer"&gt;Unity Catalog&lt;/A&gt;&amp;nbsp;for managing AI assets, including models and experiments.&lt;BR /&gt;&lt;BR /&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H4 id="toc-hId-1208216446"&gt;SAP Databricks Model Serving&lt;/H4&gt;&lt;P&gt;Model Serving provides a unified interface to deploy, govern, and query AI models for real-time and batch inference. Each model you serve is available as a REST API that you can integrate into your web or client application. Deploy custom models (including scikit-learn, XGBoost, PyTorch, Hugging Face transformer models) and foundational models hosted outside of Databricks.&lt;BR /&gt;&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="SAP Databricks Model Serving.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293982iB770BBA479D06C23/image-size/large?v=v2&amp;amp;px=999" role="button" title="SAP Databricks Model Serving.png" alt="SAP Databricks Model Serving.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-1011702941"&gt;&lt;SPAN&gt;SAP Databricks Vector Search&lt;/SPAN&gt;&lt;/H4&gt;&lt;P&gt;Specifically designed for RAG applications, Vector Search delivers similarity search results, enriching LLM queries with context and domain knowledge, and improving accuracy and quality of results.&lt;/P&gt;&lt;P&gt;Create a Vector Search Index using the &lt;STRONG&gt;&lt;A href="https://api-docs.databricks.com/python/vector-search/databricks.vector_search.html" target="_blank" rel="noopener nofollow noreferrer"&gt;Python SDK&lt;/A&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Vector Search.png" style="width: 454px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293984i8DE956AF1C13DCA4/image-size/large?v=v2&amp;amp;px=999" role="button" title="Vector Search.png" alt="Vector Search.png" /&gt;&lt;/span&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;H3 id="toc-hId-686106717"&gt;&lt;STRONG&gt;SAP Databricks Playground&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Databricks Playground provides a built-in integration with your functions.&lt;BR /&gt;It’ll analyze which functions are available, and call them to properly answer your question&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Open the Playground&lt;/LI&gt;&lt;LI&gt;Select a &lt;STRONG&gt;model&lt;/STRONG&gt; (like Llama)&lt;/LI&gt;&lt;LI&gt;Add the &lt;STRONG&gt;tools/functions&lt;/STRONG&gt; you want your model to leverage&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Ask a question, and the playground will do the magic for you!&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="SAP Databricks Playground.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293985iD3B18B397C90A44B/image-size/large?v=v2&amp;amp;px=999" role="button" title="SAP Databricks Playground.png" alt="SAP Databricks Playground.png" /&gt;&lt;/span&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;H4 id="toc-hId-618675931"&gt;SAP Databricks AI Gateway&lt;/H4&gt;&lt;P&gt;Mosaic AI Gateway offers unified access to AI/ML models through a single standard query interface. This eliminates the need to maintain separate systems to manage AI traffic. Enterprises can effortlessly switch between foundation and custom models.&lt;/P&gt;&lt;P&gt;AI Gateway includes &lt;STRONG&gt;usage tracking &lt;/STRONG&gt;and &lt;STRONG&gt;guardrail activation&lt;/STRONG&gt; for secure storage, sharing, and management.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="SAP Databricks AI Gateway.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293986i23C2418E43142EF1/image-size/large?v=v2&amp;amp;px=999" role="button" title="SAP Databricks AI Gateway.png" alt="SAP Databricks AI Gateway.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-422162426"&gt;Use Case #1: Analyze Customer Data Product with LLM&lt;/H4&gt;&lt;P&gt;Using generative AI, you can seamlessly analyze customer records from the Customer Data Product. The LLM output, consisting of business insights, is added as a new column. The enriched data is saved as a Delta table and published to the BDC Catalog.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;AI prompt is built using key fields like Customer Name, Country, Industry, Tax Number, City, Postal Code, and business flags&lt;/LI&gt;&lt;LI&gt;The&amp;nbsp;&lt;STRONG&gt;databricks-meta-llama-3-3-70b-instruct&lt;/STRONG&gt;&amp;nbsp;LLM generates concise business analyses per record,&lt;BR /&gt;identifying potential issues or opportunities&lt;/LI&gt;&lt;LI&gt;Responses are evaluated using&amp;nbsp;&lt;STRONG&gt;MLflow Databricks Agent&lt;/STRONG&gt;, ensuring clarity (e.g., checking the presence of customer names).&lt;/LI&gt;&lt;LI&gt;Enriched data is saved as a Delta Table:&amp;nbsp;&lt;STRONG&gt;default.customerllm&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;The Delta Table is published as a Data Product to the BDC Catalog using the&amp;nbsp;&lt;A href="https://pypi.org/project/sap-bdc-connect-sdk/" target="_self" rel="nofollow noopener noreferrer"&gt;&lt;STRONG&gt;sap-bdc-connect-sdk&lt;/STRONG&gt;&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="1-Analyze Customer Data Product with LLM.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293988iA0E034BF16401B79/image-size/large?v=v2&amp;amp;px=999" role="button" title="1-Analyze Customer Data Product with LLM.png" alt="1-Analyze Customer Data Product with LLM.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2-Analyze Customer Data Product with LLM.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/294555iF3DDA153FF40A0E3/image-size/large?v=v2&amp;amp;px=999" role="button" title="2-Analyze Customer Data Product with LLM.png" alt="2-Analyze Customer Data Product with LLM.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="3-Analyze Customer Data Product with LLM.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293990i6C112D23E775BC2E/image-size/large?v=v2&amp;amp;px=999" role="button" title="3-Analyze Customer Data Product with LLM.png" alt="3-Analyze Customer Data Product with LLM.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="4-Analyze Customer Data Product with LLM.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293991i7D6DE20DD5F37B9E/image-size/large?v=v2&amp;amp;px=999" role="button" title="4-Analyze Customer Data Product with LLM.png" alt="4-Analyze Customer Data Product with LLM.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="5-Agent Evaluation.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293992i2DA12E7EF54C845D/image-size/large?v=v2&amp;amp;px=999" role="button" title="5-Agent Evaluation.png" alt="5-Agent Evaluation.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-225648921"&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;Use Case #2:&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;SAP Document AI &amp;amp; AI-Powered Validation in SAP Databricks&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/H4&gt;&lt;P&gt;You can build an end-to-end pipeline for processing documents – with ingestion, validation, and audit review using&amp;nbsp;&lt;STRONG&gt;SAP Document AI, SAP Databricks&lt;/STRONG&gt;,&amp;nbsp;&lt;STRONG&gt;MLflow&lt;/STRONG&gt;, and&amp;nbsp;&lt;STRONG&gt;Claude AI&lt;/STRONG&gt;.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Integration with BTP Document AI via API&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Combine the result.json files within SAP Databricks Experiments and convert them into a parquet file. Upload as a delta table into the Unity Catalog.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Use of MLflow and Claude-3-7-sonnet model&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Connectivity to SAP Databricks Playground with Tools/Functions&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This allows business users to reduce manual review time through automation, improve data quality and compliance with AI-driven checks, and create summaries for finance teams.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Tool Status Checker.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293994i7D44745CBEE9C943/image-size/large?v=v2&amp;amp;px=999" role="button" title="Tool Status Checker.png" alt="Tool Status Checker.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Tool AI Validation.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/294556i5072E6DD597E9A3B/image-size/large?v=v2&amp;amp;px=999" role="button" title="Tool AI Validation.png" alt="Tool AI Validation.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Agent Tools.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293997iB681D6445205AC0E/image-size/large?v=v2&amp;amp;px=999" role="button" title="Agent Tools.png" alt="Agent Tools.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Playground Output.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/293998i834F955A838D2313/image-size/large?v=v2&amp;amp;px=999" role="button" title="Playground Output.png" alt="Playground Output.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In part 2 of this series, we've gone beyond SQL analytics to explore how &lt;STRONG&gt;Mosaic AI&lt;/STRONG&gt;&lt;STRONG&gt;&amp;nbsp;tools&amp;nbsp;&lt;/STRONG&gt;within &lt;STRONG&gt;SAP Databricks&lt;/STRONG&gt; empower teams to build production-grade, enterprise-ready AI solutions. By combining the semantic richness of &lt;STRONG&gt;SAP Data Products&lt;/STRONG&gt; with Databricks' unified data and AI platform, organizations can move from isolated experiments to &lt;STRONG&gt;operationalized AI&lt;/STRONG&gt; that drives real business value.&lt;/P&gt;&lt;P&gt;As you continue building with &lt;STRONG&gt;SAP Business Data Cloud and SAP Databricks&lt;/STRONG&gt;, the focus shifts from experimentation to &lt;STRONG&gt;governance, reusability, and scale&lt;/STRONG&gt;. This is the foundation of the intelligent enterprise—where &lt;STRONG&gt;trusted SAP data fuels impactful AI&lt;/STRONG&gt;, delivered seamlessly and responsibly.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-2/ba-p/14167025"/>
    <published>2025-07-30T15:18:04.435000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/using-jupyter-in-sap-business-application-studio-my-notes/ba-p/14167294</id>
    <title>Using Jupyter in SAP Business Application Studio – my notes</title>
    <updated>2025-08-01T17:29:38.575000+02:00</updated>
    <author>
      <name>Vitaliy-R</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/183</uri>
    </author>
    <content>&lt;P&gt;In my previous blog post&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-python-in-sap-business-application-studio-my-notes/ba-p/14155516" target="_blank"&gt;Using Python in SAP Business Application Studio – my notes&lt;/A&gt;, I focused on Python.&lt;/P&gt;&lt;P&gt;This blog post focuses on running Jupyter notebooks in SAP Business Application Studio&amp;nbsp;&lt;SPAN&gt;(referred to as "BAS" below)&lt;/SPAN&gt;.&amp;nbsp;I assume you're not an absolute beginner with SAP Business Application Studio—or at least you're familiar with Visual Studio Code. If you need a general introduction to navigating, coding, and executing code in notebooks using the Jupyter extension, then check:&amp;nbsp;&lt;A href="https://code.visualstudio.com/docs/datascience/jupyter-notebooks#_create-or-open-a-jupyter-notebook" target="_blank" rel="nofollow noopener noreferrer"&gt;https://code.visualstudio.com/docs/datascience/jupyter-notebooks#_create-or-open-a-jupyter-notebook&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;For the examples in this post, I’ll be using the SAP Business Application Studio, which is available in the SAP BTP Trial environment.&lt;/P&gt;&lt;H2 id="toc-hId-1736107166"&gt;Creating a virtual environment with the Python extension&lt;/H2&gt;&lt;P&gt;As already discussed in&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/persisting-python-environment-when-using-jupyter-notebooks-in-sap-business/ba-p/13549863" target="_blank"&gt;Persisting Python environment when using Jupyter notebooks in SAP Business Application Studio&lt;/A&gt;, one of the first things you might want to do, when working with the Python code in BAS, is to create a virtual environment. There, we discussed how to use the `&lt;FONT face="terminal,monaco" color="#000080"&gt;python -m venv&lt;/FONT&gt;` command to create it. Now, let's use the extension commands.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;&lt;span class="lia-unicode-emoji" title=":nerd_face:"&gt;🤓&lt;/span&gt;&amp;nbsp;Pro tip:&lt;/STRONG&gt; if you want to understand what is happening when extension commands are executed, then:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Open the Output panel (eg, &lt;STRONG&gt;View -&amp;gt; Output&lt;/STRONG&gt; from the menu).&lt;/LI&gt;&lt;LI&gt;Choose the output for the &lt;STRONG&gt;Python&lt;/STRONG&gt; extension, and then in &lt;STRONG&gt;Settings&lt;/STRONG&gt;, set the level to &lt;STRONG&gt;Info&lt;/STRONG&gt; and&amp;nbsp;&lt;STRONG&gt;Set As Default&lt;/STRONG&gt;:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_0-1753987148253.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/294808iA00DF79EEB2DED50/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_0-1753987148253.png" alt="VitaliyR_0-1753987148253.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Alternatively, if the Python extension has not yet been loaded, then open the command palette and run the command &lt;FONT face="terminal,monaco" color="#000080"&gt;&amp;gt;Python:&amp;nbsp;Show Output&lt;/FONT&gt;:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_1-1753988104700.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/294816i1A41D1412BCD4050/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1753988104700.png" alt="VitaliyR_1-1753988104700.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Go to the command palette and run the command `Python: Create Environment...`...&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_2-1753988411673.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/294818iA62DBE8BF3AA3AD7/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_2-1753988411673.png" alt="VitaliyR_2-1753988411673.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;..and select the &lt;STRONG&gt;Venv&lt;/STRONG&gt; option to create a virtual environment `.venv` (the name cannot be modified, at least in the current version of the Python extension):&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_3-1753988600004.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/294819i8339A533DC5C36F0/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_3-1753988600004.png" alt="VitaliyR_3-1753988600004.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;...selecting the required base Python run-time installation (like &lt;FONT face="terminal,monaco" color="#000080"&gt;~/.asdf-inst/shims/python&lt;/FONT&gt;&lt;span class="lia-unicode-emoji" title=":disappointed_face:"&gt;😞&lt;/span&gt;&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_5-1753989146997.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/294824iB54EFA8DE6BA8E9E/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_5-1753989146997.png" alt="VitaliyR_5-1753989146997.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;If you have set output on the Info level for the Python extension, then you should see (interesting) details on how the environment was created:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_6-1753990222424.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/294829iFFA2B57EB06A3F49/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_6-1753990222424.png" alt="VitaliyR_6-1753990222424.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;One additional note:&lt;/STRONG&gt; the &lt;FONT face="terminal,monaco" color="#000080"&gt;.gitignore&lt;/FONT&gt;&amp;nbsp;file has been automatically created for the virtual environment:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_7-1753990886473.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/294835iB005A7F1F2F0BC57/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_7-1753990886473.png" alt="VitaliyR_7-1753990886473.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1539593661"&gt;Select the Jupyter kernel&lt;/H2&gt;&lt;P&gt;To execute code in your Jupyter notebook, you need to select a &lt;A href="https://docs.jupyter.org/en/latest/glossary.html#term-kernel" target="_self" rel="nofollow noopener noreferrer"&gt;Jupyter kernel&lt;/A&gt;&amp;nbsp;that will be used to execute the code.&lt;/P&gt;&lt;P&gt;Click &lt;STRONG&gt;Select Kernel&lt;/STRONG&gt; and then on &lt;STRONG&gt;Python Environments...&lt;/STRONG&gt; category:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_1-1754052597730.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295259i23FB8803DB7F5A0E/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1754052597730.png" alt="VitaliyR_1-1754052597730.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;...which will show you the list of Python environments that the Python extension found in your BAS dev space. Click on your virtual environment created for your project, like &lt;STRONG&gt;&lt;FONT face="terminal,monaco" color="#333399"&gt;.venv&lt;/FONT&gt;&lt;/STRONG&gt;:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_2-1754052967744.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295262iB31F805BAEF302B6/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_2-1754052967744.png" alt="VitaliyR_2-1754052967744.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1343080156"&gt;Execute code in a Jupyter notebook&lt;/H2&gt;&lt;P&gt;During the first execution of your code, Jupyter will check if the &lt;A href="https://ipython.readthedocs.io/en/stable/install/kernel_install.html#installing-the-ipython-kernel" target="_self" rel="nofollow noopener noreferrer"&gt;IPython Kernel&lt;/A&gt; executable (the Python package &lt;FONT face="terminal,monaco" color="#333399"&gt;ipykernel&lt;/FONT&gt;) is installed in the selected Python environment. If not, it will automatically install it, as can be seen in the Jupyter extension's output, and then start it:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_3-1754056502781.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295283i783E48892ACD6FDB/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_3-1754056502781.png" alt="VitaliyR_3-1754056502781.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once started, the Kernel exposes 5 ports for communication with your notebook, which can be seen in the run-time specification in a file &lt;FONT face="terminal,monaco" color="#333399"&gt;~/.local/share/jupyter/runtime/kernel-*.json&lt;/FONT&gt;. While this information should not be required in most of the basic scenarios, you might find it overwhelming that BAS displays pop-up messages for each port every time the kernel runtime starts:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_4-1754057368976.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295297i85CDC3874404AD19/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_4-1754057368976.png" alt="VitaliyR_4-1754057368976.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;While information about open ports is relevant when developing front-end applications using SAP Business Application Studio, it might be useless and overwhelming when working with Jupyter notebooks. So, click on the settings icon and turn off notifications from the "Exposing router ports" extension&lt;SPAN&gt;&amp;nbsp;or disable this extension completely:&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_5-1754057622486.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295325i29F6A95A91A5DBDC/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_5-1754057622486.png" alt="VitaliyR_5-1754057622486.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1146566651"&gt;Limiting listed Python environments&lt;/H2&gt;&lt;P&gt;You might also find it quite overwhelming to deal with the list of all the global Python locations when setting the kernel for a notebook. To reduce this list, select the command &lt;STRONG&gt;Jupyter: Filter Kernels&lt;/STRONG&gt; from the command palette:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_0-1754060969070.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295350i759F9877C1C4BB3D/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_0-1754060969070.png" alt="VitaliyR_0-1754060969070.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;...which opens the setting &lt;STRONG&gt;&lt;FONT face="terminal,monaco" color="#333399"&gt;jupyter.kernels.excludePythonEnvironments&lt;/FONT&gt;&lt;/STRONG&gt;. Switch to the &lt;STRONG&gt;Workspace&lt;/STRONG&gt; tab and click &lt;STRONG&gt;Add Item&lt;/STRONG&gt; to specify which Python environments to exclude from the list. You might want to add the following items to the list:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;/bin/python3
/usr/bin/python3
~/.asdf-inst/shims/python3.13
~/.asdf-inst/shims/python3
~/.asdf-inst/shims/python&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_1-1754061618539.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295359i09FFA8A1E47B3F08/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1754061618539.png" alt="VitaliyR_1-1754061618539.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;&lt;span class="lia-unicode-emoji" title=":nerd_face:"&gt;🤓&lt;/span&gt;Pro tip:&lt;/STRONG&gt; these values can also be edited in the project's file &lt;FONT face="terminal,monaco" color="#000080"&gt;.vscode/settings.json&lt;/FONT&gt;.&lt;/P&gt;&lt;pre class="lia-code-sample language-javascript"&gt;&lt;code&gt;{
    "jupyter.kernels.excludePythonEnvironments": [
        "/bin/python3",
        "/usr/bin/python3",
        "~/.asdf-inst/shims/python3.13",
        "~/.asdf-inst/shims/python3",
        "~/.asdf-inst/shims/python"
    ]
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Next time you need to pick the kernel for a Jupyter notebook, you should see only your project's virtual Python environment:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_2-1754062063240.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295361iB582616218E20475/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_2-1754062063240.png" alt="VitaliyR_2-1754062063240.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-1208218584"&gt;You should be ready to work with your Jupyter notebooks in SAP Business Application Studio!&lt;/H4&gt;&lt;P&gt;Please share your tips in the comments!&lt;/P&gt;&lt;P&gt;------&lt;/P&gt;&lt;P&gt;-Vitaliy, aka&amp;nbsp;&lt;A href="https://bsky.app/profile/sygyzmundovych.bsky.social" target="_self" rel="nofollow noopener noreferrer"&gt;@Sygyzmundovych&lt;/A&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-jupyter-in-sap-business-application-studio-my-notes/ba-p/14167294"/>
    <published>2025-08-01T17:29:38.575000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/using-conda-forge-in-sap-business-application-studio-my-notes/ba-p/14169956</id>
    <title>Using conda-forge in SAP Business Application Studio – my notes</title>
    <updated>2025-08-01T23:07:46.509000+02:00</updated>
    <author>
      <name>Vitaliy-R</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/183</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;In my previous blog posts, I focused on&amp;nbsp;&lt;/SPAN&gt;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-python-in-sap-business-application-studio-my-notes/ba-p/14155516" target="_blank"&gt;Using Python in SAP Business Application Studio&lt;/A&gt;&lt;SPAN&gt;&amp;nbsp;and&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-jupyter-in-sap-business-application-studio-my-notes/ba-p/14167294" target="_blank"&gt;Using Jupyter in SAP Business Application Studio&lt;/A&gt;&amp;nbsp;with Python's virtual environments. But SAP Business Application Studio (referred to as "BAS" below) also allows you to work with the &lt;A href="https://en.wikipedia.org/wiki/Conda_(package_manager)" target="_self" rel="nofollow noopener noreferrer"&gt;Conda&lt;/A&gt; environments:&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_0-1754071912864.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295447i44DA5805AC4D52AD/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_0-1754071912864.png" alt="VitaliyR_0-1754071912864.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Usually, Conda is used when one needs binary package management, and installation with &lt;FONT face="terminal,monaco" color="#333399"&gt;pip&lt;/FONT&gt;&amp;nbsp;fails because of the build requirements that cannot be successfully completed with the tools and authorizations a developer has in their BAS dev space.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;span class="lia-unicode-emoji" title=":backhand_index_pointing_right:"&gt;👉&lt;/span&gt;&amp;nbsp;At the time of writing this post, using Conda might require additional commercial licenses from Anaconda, Inc. if downloading their tools and/or packages from their `&lt;FONT face="terminal,monaco"&gt;default&lt;/FONT&gt;` &lt;A href="https://en.wikipedia.org/wiki/Conda_(package_manager)#Channels" target="_self" rel="nofollow noopener noreferrer"&gt;channel&lt;/A&gt;. This might be a valid case for you, but this blog post covers only the use of the community-driven `conda-forge` channel and the minimum tools required to use it. To the best of my knowledge, I discuss only the technical setup here, but you might need to check any license implications for the dependencies of a project you are working on.&lt;/P&gt;&lt;H2 id="toc-hId-1736173353"&gt;Install miniforge&lt;/H2&gt;&lt;P&gt;Miniforge is a minimal installer for Conda and Mamba with the conda-forge channel set as the default (and only) channel.&lt;/P&gt;&lt;P&gt;Follow the installation steps, for example from&amp;nbsp;&lt;A href="https://github.com/conda-forge/miniforge?tab=readme-ov-file#unix-like-platforms-macos-linux--wsl" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/conda-forge/miniforge?tab=readme-ov-file#unix-like-platforms-macos-linux--wsl&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Download and run the installation script.&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;curl --location --remote-name --output-dir ~/tmp "https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh"

bash ~/tmp/Miniforge3-$(uname)-$(uname -m).sh -b&lt;/code&gt;&lt;/pre&gt;&lt;H2 id="toc-hId-1539659848"&gt;&amp;nbsp;Configure conda&lt;/H2&gt;&lt;P&gt;Activate conda and its &lt;FONT face="terminal,monaco" color="#333399"&gt;base&lt;/FONT&gt;&amp;nbsp;environment.&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;eval "$(/home/user/miniforge3/bin/conda shell.$(basename "${SHELL}") hook)"&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;Initialize conda (it will add the shell's integration).&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;conda init&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;To prevent the conda's &lt;FONT face="terminal,monaco" color="#333399"&gt;base&lt;/FONT&gt;&amp;nbsp;environment from being activated on startup (because it will be taken care of by the Python extension), run the following command:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;conda config --set auto_activate_base false&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;For changes to take effect, close and re-open your current shell.&lt;/P&gt;&lt;P&gt;Update conda's &lt;FONT face="terminal,monaco" color="#333399"&gt;base&lt;/FONT&gt; environment to the latest packages from the community-maintained &lt;FONT face="terminal,monaco" color="#333399"&gt;conda-forge&lt;/FONT&gt;&amp;nbsp;channel.&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;conda update -n base --all --yes&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;You can also use the faster &lt;FONT face="terminal,monaco" color="#333399"&gt;mamba&lt;/FONT&gt;&amp;nbsp;command instead of &lt;FONT face="terminal,monaco" color="#333399"&gt;conda&lt;/FONT&gt;. Both are parts of the Miniforge installation.&lt;/P&gt;&lt;H2 id="toc-hId-1343146343"&gt;Point Python extension to your Conda executable&lt;/H2&gt;&lt;P&gt;In &lt;STRONG&gt;Terminal&lt;/STRONG&gt;, check the location of the &lt;FONT face="terminal,monaco" color="#333399"&gt;conda&lt;/FONT&gt;&amp;nbsp;command, which should be something like &lt;FONT face="terminal,monaco" color="#333399"&gt;/home/user/miniforge3/condabin/conda&lt;/FONT&gt;:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;which conda&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;In &lt;STRONG&gt;Settings&lt;/STRONG&gt;, open &lt;FONT face="terminal,monaco" color="#333399"&gt;python.condaPath&lt;/FONT&gt;&amp;nbsp;and switch to the Remote tab. Input the value.&lt;/P&gt;&lt;H2 id="toc-hId-1146632838"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_1-1754077236838.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295487i523B13F658B4CF31/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1754077236838.png" alt="VitaliyR_1-1754077236838.png" /&gt;&lt;/span&gt;&lt;/H2&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;H2 id="toc-hId-950119333"&gt;Create a &lt;FONT face="terminal,monaco" color="#333399"&gt;.conda&lt;/FONT&gt;&amp;nbsp;environment in your project&lt;/H2&gt;&lt;P&gt;Open your project folder in BAS.&lt;/P&gt;&lt;P&gt;From the command palette, start the command&amp;nbsp;&lt;STRONG&gt;Python: Create Environment...&lt;/STRONG&gt;, then &lt;STRONG&gt;Conda&lt;/STRONG&gt;&amp;nbsp;environment type...&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_0-1754071912864.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295447i44DA5805AC4D52AD/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_0-1754071912864.png" alt="VitaliyR_0-1754071912864.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;...and select the required Python version from the list:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_2-1754078227143.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295497i93854803DCAD9C13/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_2-1754078227143.png" alt="VitaliyR_2-1754078227143.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;You should see the message that the environment is created and set as the active one for the project.&lt;/P&gt;&lt;P&gt;Open a new Terminal session, and you should see the &lt;FONT face="terminal,monaco" color="#333399"&gt;.conda&lt;/FONT&gt;&amp;nbsp;environment set.&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_3-1754078590314.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295499iD3EBC13944398F9A/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_3-1754078590314.png" alt="VitaliyR_3-1754078590314.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;You can check the list of environments with the command:&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;conda env list&lt;/code&gt;&lt;/pre&gt;&lt;H2 id="toc-hId-753605828"&gt;Install IPyKernel in your &lt;FONT face="terminal,monaco" color="#333399"&gt;.conda&lt;/FONT&gt; environment&lt;/H2&gt;&lt;P&gt;Unlike in a "venv" virtual environment, the Python extension might not automatically install IPyKernel in a conda environment. You need to install it manually.&lt;/P&gt;&lt;P&gt;In &lt;STRONG&gt;Terminal&lt;/STRONG&gt;, with the &lt;FONT face="terminal,monaco" color="#333399"&gt;.conda&lt;/FONT&gt;&amp;nbsp;environment set in the command line, run the command:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;conda install ipykernel --yes&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Check with the command&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;conda list ipykernel&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_4-1754079013971.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295500i6624BBBD3246EFC5/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_4-1754079013971.png" alt="VitaliyR_4-1754079013971.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-557092323"&gt;Select the &lt;FONT face="terminal,monaco" color="#333399"&gt;.conda&lt;/FONT&gt; env in your notebook&lt;/H2&gt;&lt;P&gt;Now, you can open your project's Jupyter notebook, select the &lt;FONT face="terminal,monaco" color="#333399"&gt;.conda&lt;/FONT&gt; environment, and execute the code &lt;span class="lia-unicode-emoji" title=":nerd_face:"&gt;🤓&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-360578818"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_5-1754079340647.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295501iFC432ED27A836EC4/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_5-1754079340647.png" alt="VitaliyR_5-1754079340647.png" /&gt;&lt;/span&gt;&lt;/H2&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;H4 id="toc-hId-1208218584" id="toc-hId-422230751"&gt;You should be ready to work with conda-forge in SAP Business Application Studio now!&amp;nbsp;&lt;/H4&gt;&lt;P&gt;Please share your tips in the comments!&lt;/P&gt;&lt;H4 id="toc-hId-1208218584" id="toc-hId-225717246"&gt;In my other blog posts, I focused on:&lt;BR /&gt;&lt;span class="lia-unicode-emoji" title=":snake:"&gt;🐍&lt;/span&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-python-in-sap-business-application-studio-my-notes/ba-p/14155516" target="_self"&gt;Using Python in SAP Business Application Studio&lt;/A&gt;, and&lt;BR /&gt;🪐&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-jupyter-in-sap-business-application-studio-my-notes/ba-p/14167294" target="_blank"&gt;Using Jupyter in SAP Business Application Studio&lt;/A&gt;.&lt;/H4&gt;&lt;P&gt;------&lt;/P&gt;&lt;P&gt;-Vitaliy, aka&amp;nbsp;&lt;A href="https://bsky.app/profile/sygyzmundovych.bsky.social" target="_self" rel="nofollow noopener noreferrer"&gt;@Sygyzmundovych&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-conda-forge-in-sap-business-application-studio-my-notes/ba-p/14169956"/>
    <published>2025-08-01T23:07:46.509000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/building-collaborative-microservices-in-python-with-fastapi-echo-amp/ba-p/14170025</id>
    <title>Building Collaborative Microservices in Python with FastAPI: Echo &amp; Reverse Agents (Beginner -Part1)</title>
    <updated>2025-08-02T10:18:39.981000+02:00</updated>
    <author>
      <name>Yogananda</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/75</uri>
    </author>
    <content>&lt;P&gt;Microservices encourage us to build distributed systems consisting of small, specialized components that communicate seamlessly. In this post, let’s explore a simple yet illustrative example:&amp;nbsp;Agent-A and Agent-B, two FastAPI-based Python microservices that interact in real-time.&lt;/P&gt;&lt;P&gt;We'll see how&amp;nbsp;Agent-A receives a request, calls Agent-B, and returns a transformed response—demonstrating the foundations of service-to-service HTTP communication.&lt;/P&gt;&lt;H2 id="toc-hId-1736820012"&gt;The Objective&lt;/H2&gt;&lt;P&gt;We want to create:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Agent-B&lt;/STRONG&gt;:&amp;nbsp;A service that reverses text.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Agent-A&lt;/STRONG&gt;:&amp;nbsp;A service that takes a string, sends it to Agent-B for reversal, and returns the reversed string as a response.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Both services are built with&amp;nbsp;&lt;A href="https://fastapi.tiangolo.com/" target="_blank" rel="noopener nofollow noreferrer"&gt;FastAPI&lt;/A&gt;&amp;nbsp;and use&amp;nbsp;&lt;A href="https://pydantic-docs.helpmanual.io/" target="_blank" rel="noopener nofollow noreferrer"&gt;Pydantic&lt;/A&gt;&amp;nbsp;for data validation.&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-08-02_10-23-41.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/295526i46C7EF2439E02129/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-08-02_10-23-41.png" alt="2025-08-02_10-23-41.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1540306507"&gt;Meet Agent-B: The Reverse Service&lt;/H2&gt;&lt;P&gt;&lt;SPAN&gt;Let's begin by looking at&amp;nbsp;&lt;/SPAN&gt;agent_b.py&lt;SPAN&gt;. It’s a minimal service that exposes one endpoint that takes a string and returns it reversed.&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from fastapi import FastAPI
from pydantic import BaseModel
import os

PORT = int(os.getenv("AGENT_B_PORT", 8001))
app = FastAPI(title="Agent-B")

class ReverseRequest(BaseModel):
    text: str

class ReverseResponse(BaseModel):
    source: str
    reversed: str

@app.post("/reverse", response_model=ReverseResponse)
def reverse(req: ReverseRequest):
    return ReverseResponse(source="Agent-B", reversed=req.text[::-1])&lt;/code&gt;&lt;/pre&gt;&lt;H2 id="toc-hId-1343793002"&gt;Meet Agent-A: The Forwarding Echo Service&lt;/H2&gt;&lt;P&gt;Now, let’s look at&amp;nbsp;&lt;STRONG&gt;agent_a.py&lt;/STRONG&gt;. While it’s called an "echo" service, it doesn’t simply echo back input. Instead, it&amp;nbsp;&lt;FONT color="#FF0000"&gt;&lt;STRONG&gt;forwards the input to Agent-B&lt;/STRONG&gt;&lt;/FONT&gt;, receives the reversed string, and returns that. This demonstrates microservice orchestration.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;agent_a.py&lt;/STRONG&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from fastapi import FastAPI
from pydantic import BaseModel
import httpx
import os

PORT = int(os.getenv("AGENT_A_PORT", 8000))
B_URL = os.getenv("AGENT_B_URL", "http://localhost:8001")
app = FastAPI(title="Agent-A")

class EchoRequest(BaseModel):
    text: str

class EchoResponse(BaseModel):
    source: str
    echoed: str

@app.post("/echo", response_model=EchoResponse)
async def echo(req: EchoRequest):
    # Forward the text to Agent-B
    async with httpx.AsyncClient() as client:
        r = await client.post(f"{B_URL}/reverse", json={"text": req.text})
        r.raise_for_status()
        reversed_text = r.json()["reversed"]
    # Respond with what Agent-B returned
    return EchoResponse(source="Agent-A", echoed=reversed_text)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;HR /&gt;&lt;H2 id="toc-hId-1147279497"&gt;Running Both Agents&lt;/H2&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;Start Agent-B:&lt;/P&gt;&lt;PRE&gt;uvicorn agent_b:app --port 8001&lt;/PRE&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Start Agent-A:&lt;/P&gt;&lt;PRE&gt;uvicorn agent_a:app --port 8000&lt;/PRE&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;H2 id="toc-hId-950765992"&gt;Testing the System&lt;/H2&gt;&lt;P&gt;Let’s see the microservices in action with&amp;nbsp;curl:&lt;/P&gt;&lt;PRE&gt;curl -X POST http://localhost:8000/echo \
     -H "Content-Type: application/json" \
     -d '{"text":"hello A2A"}'&lt;/PRE&gt;&lt;P&gt;Response:&lt;/P&gt;&lt;PRE&gt;{
  "source": "Agent-A",
  "echoed": "A2A olleh"
}&lt;/PRE&gt;&lt;P&gt;&lt;STRONG&gt;What happened?&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;The request hits Agent-A’s&amp;nbsp;/echo.&lt;/LI&gt;&lt;LI&gt;Agent-A calls Agent-B’s&amp;nbsp;/reverse&amp;nbsp;with the payload.&lt;/LI&gt;&lt;LI&gt;Agent-B reverses the string.&lt;/LI&gt;&lt;LI&gt;Agent-A returns Agent-B’s output* as its own&amp;nbsp;"echoed"&amp;nbsp;field.&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-754252487"&gt;How to Extend This Example&lt;/H2&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Add Logging/Tracing:&lt;/STRONG&gt;&amp;nbsp;See the flow end-to-end.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Synchronous vs Asynchronous calls:&lt;/STRONG&gt;&amp;nbsp;Both are possible; here&amp;nbsp;httpx&amp;nbsp;with&amp;nbsp;async&amp;nbsp;enables efficient concurrency.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Error Handling&lt;/STRONG&gt;:&amp;nbsp;Add more robust logic in production.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Authentication&lt;/STRONG&gt;:&amp;nbsp;Secure the endpoints as needed.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;More Agents:&lt;/STRONG&gt;&amp;nbsp;Build a family of collaborating services!&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-557738982"&gt;Conclusion&lt;/H2&gt;&lt;P&gt;With just a few lines of Python and FastAPI, we built two collaborating microservices with clear responsibilities and simple interaction via HTTP. This pattern underpins many real-world distributed architectures, making it a great learning foundation for building maintainable and scalable systems.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Try extending these agents on your own use case!&lt;/STRONG&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/building-collaborative-microservices-in-python-with-fastapi-echo-amp/ba-p/14170025"/>
    <published>2025-08-02T10:18:39.981000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/artificial-intelligence-blogs-posts/hands-on-tutorial-sap-databricks/ba-p/14156999</id>
    <title>Hands-on Tutorial: SAP Databricks</title>
    <updated>2025-08-04T09:17:31.648000+02:00</updated>
    <author>
      <name>AndreasForster</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14188</uri>
    </author>
    <content>&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="000 logos white.png" style="width: 584px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291532iF242B7265DB0E43A/image-size/large?v=v2&amp;amp;px=999" role="button" title="000 logos white.png" alt="000 logos white.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;With &lt;A href="https://www.sap.com/products/data-cloud/databricks.html" target="_blank" rel="noopener noreferrer"&gt;SAP Databricks&lt;/A&gt; we now have a dedicated environment for Data Scientists within the SAP Business Data Cloud. This blog gives a practical introduction to this bespoke Databricks edition by implementing a bare bones demand forecast.&amp;nbsp;SAP Databricks includes important functionality beyond what is explained in this entry-level tutorial., for example data sharing, experiment tracking or AutoML.&lt;BR /&gt;&lt;BR /&gt;The integration of SAP Databricks is adding a new option to the SAP Business Technology Platform (BTP), giving customers more choice when creating custom extensions or applications. Existing components on the BTP, which you might already be familiar with, remain very relevant and strategic, such as:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;A href="https://www.sap.com/suisse/products/artificial-intelligence/ai-core.html" target="_self" rel="noopener noreferrer"&gt;SAP AI Core&lt;/A&gt;, which provides for example access to a &lt;A href="https://me.sap.com/notes/3437766" target="_self" rel="noopener noreferrer"&gt;long list of Large Language Models&lt;/A&gt; through its &lt;A href="https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/generative-ai-hub-in-sap-ai-core-7db524ee75e74bf8b50c167951fe34a5" target="_self" rel="noopener noreferrer"&gt;Generative AI Hub.&lt;/A&gt;&amp;nbsp;Some of the models are even hosted on SAP's own physical infrastructure, giving increased security (currently Mistral and Aleph Alpha).&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://www.sap.com/products/artificial-intelligence/ai-foundation-os/document-ai.html" target="_self" rel="noopener noreferrer"&gt;SAP Document AI&lt;/A&gt;, which extracts information from documents such as PDFs, Excel, images, ...&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://www.sap.com/products/data-cloud/hana.html" target="_self" rel="noopener noreferrer"&gt;SAP HANA Cloud&lt;/A&gt; and &lt;A href="https://www.sap.com/products/data-cloud/datasphere.html" target="_self" rel="noopener noreferrer"&gt;SAP Datasphere&lt;/A&gt;, with their built-in multi-model capabilities, ie Machine Learning, embeddings generation for Text, Vector engine, Graph engine, Geospatial&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://www.sap.com/products/artificial-intelligence/joule-studio.html" target="_self" rel="noopener noreferrer"&gt;SAP Build, Joule Studio&lt;/A&gt; for adding new skills to our digital assistant Joule, and the ability to create new AI agents on the roadmap. This &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/how-sap-s-ai-agent-architecture-enables-unprecedented-automation-and/ba-p/14158296" target="_self"&gt;blog&lt;/A&gt;&amp;nbsp;(series) on SAP's AI Agent Architecture by our CTO and Chief AI Officer&amp;nbsp;Philipp Herzig&amp;nbsp;&lt;SPAN&gt;gives an excellent overview of the wider picture.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;SAP Databricks can also be used as development environment for the above components. &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/unlocking-sap-ai-foundation-capabilities-in-sap-databricks-a-technical-deep/ba-p/14162430" target="_self"&gt;This blog&lt;/A&gt; by &lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/434167"&gt;@san_tran&lt;/a&gt;&amp;nbsp;for instance shows a SAP Databricks project that integrates with Large Language Models on SAP AI Core.&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;And remember to check on the AI/ML functionality that has already been built into SAP standard applications, or what is in the pipeline to be released. Both released and planned functionality is shown in the &lt;A href="https://roadmaps.sap.com/board?FT=AI&amp;amp;FT=GEN_AI&amp;amp;range=FIRST-LAST" target="_self" rel="noopener noreferrer"&gt;Roadmap Explorer&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;&lt;FONT color="#FF0000"&gt;Note: All data, code and images that are used in this blog can be downloaded from this repository: &lt;A href="https://github.com/SAP-samples/mee-samples/tree/main/Hands-on%20Tutorial%20SAP%20Databricks" target="_self" rel="nofollow noopener noreferrer"&gt;Hands-on Tutorial SAP Databricks&lt;/A&gt;. In that repository you find the individual files but also the whole project exported as Databricks Archive.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;Before we get going, big thanks to Stojan Maleschlijski for all the great collaboration, including exploring the SAP Databricks capabilities together!&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/39047"&gt;@stojanm&lt;/a&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1606077867"&gt;Table of contents&lt;/H1&gt;&lt;UL&gt;&lt;LI&gt;&lt;A href="#background" target="_self" rel="nofollow noopener noreferrer"&gt;Use Case&amp;nbsp;&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="#architecture" target="_self" rel="nofollow noopener noreferrer"&gt;Architecture&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="#prerequisites" target="_self" rel="nofollow noopener noreferrer"&gt;Prerequisites&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="#uploaddata" target="_self" rel="nofollow noopener noreferrer"&gt;Upload data&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="#eda" target="_self" rel="nofollow noopener noreferrer"&gt;Explore the data&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="#forecast" target="_self" rel="nofollow noopener noreferrer"&gt;Create a forecast with SAP Databricks&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="#schedule" target="_self" rel="nofollow noopener noreferrer"&gt;Schedule a forecast with SAP Databricks&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="#goodtoknow" target="_self" rel="nofollow noopener noreferrer"&gt;Good to know&lt;/A&gt;&lt;UL&gt;&lt;LI&gt;Base file&lt;/LI&gt;&lt;LI&gt;Lineage &amp;amp; Table usage insights&lt;/LI&gt;&lt;LI&gt;Visuals&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="#summary" target="_self" rel="nofollow noopener noreferrer"&gt;Summary&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="background" id="toc-hId-1409564362"&gt;Use Case&lt;/H1&gt;&lt;P&gt;This blog aims to give a first introduction for carrying out a Machine Learning project on SAP Databricks. Trying to simulate a demand forecast, we will predict how many nights people spend in a hotel in Switzerland. We use some granular data that is kindly shared by the &lt;A href="https://opendata.swiss/de/dataset/hotellerie-ankunfte-und-logiernachte-der-geoffneten-betriebe-nach-jahr-monat-tourismusregion-un46/resource/dc676b65-69dc-437c-b0f0-4ef703be9ae2" target="_self" rel="nofollow noopener noreferrer"&gt;Swiss Statistics department&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;A Data Scientist (you) creates a monthly forecast and sets up a schedule for the forecast to be updated every month.&amp;nbsp; This data would then become part of a business process, maybe you want to provide the data to business users in a dashboard.&amp;nbsp;This tutorial however focusses solely on creating and scheduling the forecast in SAP Databricks.&lt;/P&gt;&lt;P&gt;It's a simple time-series forecasting example, but the concept is still extremely relevant for so many different business requirements. Instead of forecasting how many visitors are staying overnight, you might need to forecast your sales quantities, your cash flow or even for topics that don't come immediately to mind. One customer for instance is using time-series forecasting to improve the data quality of external data that is loaded into the system. If a new value is outside the predicted range, there might be a data quality issue and IT can follow up, whether the data is correct or whether indeed a data quality issue cropped up.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="architecture" id="toc-hId-1213050857"&gt;Architecture&lt;/H1&gt;&lt;P&gt;In a &lt;STRONG&gt;productive&lt;/STRONG&gt; system a typical architecture and data flow would look like this.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;A Data Product is pushed into the Business Data Cloud Object Store&lt;/LI&gt;&lt;LI&gt;This Data Product is shared with SAP Databricks&lt;/LI&gt;&lt;LI&gt;SAP Databricks creates and saves a forecast as DeltaTable into the Object Store&lt;/LI&gt;&lt;LI&gt;This table is registered as Custom Data Product in the Business Data Cloud&lt;/LI&gt;&lt;LI&gt;SAP Datasphere installs the Custom Data Product, making it accessible for further data modelling and visualisation in SAP Analytics Cloud&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="100 architecture prod.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291617iCD8EC574E5DB872A/image-size/large?v=v2&amp;amp;px=999" role="button" title="100 architecture prod.png" alt="100 architecture prod.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The architecture of this hands-on exercise is focused purely on getting some familiarity with SAP Databricks. The only interface we will be using is SAP Databricks. We use it to upload the data and to go through the steps of a Machine Learning project.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="114 hands-on architecture.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291641i1B8E5C353594A19C/image-size/large?v=v2&amp;amp;px=999" role="button" title="114 hands-on architecture.png" alt="114 hands-on architecture.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="prerequisites" id="toc-hId-1016537352"&gt;Prerequisites&lt;/H1&gt;&lt;P&gt;Getting started is pretty easy.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;You will just need to have access to an instance of SAP Databricks. This could be the &lt;A href="https://www.sap.com/products/data-cloud/trial.html" target="_self" rel="noopener noreferrer"&gt;SAP Business Data Cloud trial&lt;/A&gt;.&lt;/LI&gt;&lt;LI&gt;Some familiarity with SQL and especially Python would be very useful.&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;And maybe just some curiosity to try something new.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="uploaddata" id="toc-hId-820023847"&gt;Upload data&lt;/H1&gt;&lt;P&gt;Start by bringing the historic data, on which we want to train a model, into the system. Upload the dataset &lt;A href="https://github.com/SAP-samples/mee-samples/blob/main/Hands-on%20Tutorial%20SAP%20Databricks/OVERNIGHTSTAYS.csv" target="_self" rel="nofollow noopener noreferrer"&gt;OVERNIGHTSTAYS.csv&lt;/A&gt; with the Graphical User Interface of SAP Databricks. Follow the steps shown in this screencam. In case that you are working with the trial, then you need to change the Catalog drop-down as shown to "workspace".&lt;/P&gt;&lt;P&gt;&lt;EM&gt;HINT: In case the upload fails with the message "Table with same name already exists", then another user has already created the table in this shared environment. Due to access rights you won't be able to see that other user's table. Just change the table name&amp;nbsp; in your upload to something unique and remember to use this name when accessing the table further on.&lt;BR /&gt;&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="010 data upload.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291462i85AFDC42927C8AE0/image-size/large?v=v2&amp;amp;px=999" role="button" title="010 data upload.gif" alt="010 data upload.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The data is uploaded. it is showing in the Catalog as (Delta)Table. Physically it is stored in the Object Store. The table's Overview tab lists the column names and their data types:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="200 table.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291821i2442B47235562A8F/image-size/large?v=v2&amp;amp;px=999" role="button" title="200 table.png" alt="200 table.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Move to the table's "Sample Data" tab to see some of the uploaded rows.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="210 sample data.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291822i8812DF688B48DC5A/image-size/large?v=v2&amp;amp;px=999" role="button" title="210 sample data.png" alt="210 sample data.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The first lines shows that in January 2022 there were 392.805 nights spent by Swiss residents in the area of Graubünden. In case you are not that familiar with Swiss geography, Graubünden is the largest Canton in Switzerland, it's in the Alps and includes beautiful places like St. Moritz and Davos.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="eda" id="toc-hId-623510342"&gt;Explore the data&amp;nbsp;&lt;/H1&gt;&lt;P&gt;You have two options to explore the data in SAP Databricks.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Either query the DeltaTable directly with SQL&lt;/LI&gt;&lt;LI&gt;Or use a Notebook, in which you can use both SQL or Python&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-556079556"&gt;&lt;FONT color="#000000"&gt;Data exploration with the SQL Editor&lt;/FONT&gt;&lt;/H2&gt;&lt;P&gt;Let's look closer into the data. You can start with some SQL statements. You can go into the SQL Editor and type in your own syntax. The screencam shows two simple examples. We learn for instance that we have data from January 2022 to May 2025 to work with.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;SELECT * from overnightstays&lt;/LI&gt;&lt;LI&gt;SELECT min(MONTH), max(month) from overnightstays&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="1 SQL Editor.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291823i07AAB646DC970612/image-size/large?v=v2&amp;amp;px=999" role="button" title="1 SQL Editor.gif" alt="1 SQL Editor.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Or describe what you are looking for and have SAP Databrick's write the SQL for you! Click that small red-ish star icon to toggle on the &lt;A href="https://www.databricks.com/product/databricks-assistant" target="_self" rel="nofollow noopener noreferrer"&gt;Databricks Assistant&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="230 assistant toggle.png" style="width: 793px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291825i58D63393E550F4C2/image-size/large?v=v2&amp;amp;px=999" role="button" title="230 assistant toggle.png" alt="230 assistant toggle.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Just try out what you are interested in. I was wondering for example:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;which regions are in overnightstays?&lt;/LI&gt;&lt;LI&gt;use table overnightstays to determine how many overnight stays were they by region, sort the results&lt;/LI&gt;&lt;LI&gt;use table overnightstays to summarise overnightstays by countryofresidence&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2 sql assistant.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291827i03309ED58F155C9F/image-size/large?v=v2&amp;amp;px=999" role="button" title="2 sql assistant.gif" alt="2 sql assistant.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;It turns out that most overnight stays in Switzerland are by Swiss residents, followed by German residents. Maybe surprisingly residents from the United States are a close third.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="240 overnight by countryofresidence.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291828iAF52C2350418D6FE/image-size/large?v=v2&amp;amp;px=999" role="button" title="240 overnight by countryofresidence.png" alt="240 overnight by countryofresidence.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-359566051"&gt;&lt;FONT color="#000000"&gt;Data exploration with a Notebook&lt;/FONT&gt;&lt;/H2&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;Now continue the data exploration in a Notebook. &lt;A href="https://docs.databricks.com/aws/en/notebooks/" target="_self" rel="nofollow noopener noreferrer"&gt;Databricks Notebooks&lt;/A&gt; are quite special in that they can contain more than one scripting language. SAP Databricks supports both SQL as well as Python. The Notebook created in this section can also be downloaded from the &lt;A href="https://github.com/SAP-samples/mee-samples/tree/main/Hands-on%20Tutorial%20SAP%20Databricks" target="_self" rel="nofollow noopener noreferrer"&gt;repository&lt;/A&gt;.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;Begin by creating a folder in which we will save our Notebooks. Go into the "Workspace" section, which is where such files are kept together. Within your user's workspace create a folder called "Demand forecast".&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="250 create folder.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291832iC5DC43480B5680ED/image-size/large?v=v2&amp;amp;px=999" role="button" title="250 create folder.gif" alt="250 create folder.gif" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;In that new folder create a first Notebook as shown in the next screencam. Rename it to "010 Data exploration". And add a short header in Markdown at the top. Markdown is a common way to add comments and context to the code in a Notebook. Adding "#" character at the beginning of a line formats the text as top-level heading. Two&amp;nbsp;"#" characters make it a second-level heading, and so on. Without any&amp;nbsp;"#" character the following text is formatted just normally as plain text.&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;To add the Markdown, you need to change the cell's language selector to "Markdown" as shown in the screencam. Enter your text. When done, click outside the cell and the formatting kicks in.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="260 create notebook.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291833i095F807AD2D1B795/image-size/large?v=v2&amp;amp;px=999" role="button" title="260 create notebook.gif" alt="260 create notebook.gif" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Since the cells can also execute SQL code, add the most recent SQL statement from the SQL Editor.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;SELECT
  COUNTRYOFRESIDENCE,
  SUM(OVERNIGHTSTAYS) AS total_overnightstays
FROM
  workspace.default.overnightstays
GROUP BY
  COUNTRYOFRESIDENCE
ORDER BY
  total_overnightstays DESC&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;The screencam shows how a new cell can be added to the Notebook, by hovering with the mouse at the bottom of the cell above. Select "Code" as cell type. Change the cell's language selector to "SQL", paste the code and run it with the blue play button. You will see the same result as before in the "SQL Editor".&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="270 notebook with sql.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291834iD2FD9AF968D6F360/image-size/large?v=v2&amp;amp;px=999" role="button" title="270 notebook with sql.gif" alt="270 notebook with sql.gif" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Let's switch to Python for the data exploration so that you have tried all the options. Create a new Code cell, its language selector might already be on "Python" by default. Begin by loading the data into a PySpark DataFrame using the table's fully qualified path.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;overnightstays_sdf = spark.read.table("workspace.default.overnightstays") &lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Aggregate the data by month and look at the results. The display command initially shows the data as table, but it also comes with a Graphical User interface to quickly create a plot. Follow the steps in the screencam to create a line chart, to see how the numbers have evolved over time. There is a clear pattern, that especially in July and August the numbers are at their highest.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import pyspark.sql.functions as F
display(overnightstays_sdf.groupBy("month").agg(F.sum("overnightstays").alias("overnightstays")))&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="280 display chart.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292292iF1C7C59E9B75F071/image-size/large?v=v2&amp;amp;px=999" role="button" title="280 display chart.gif" alt="280 display chart.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Now explore, whether we can visually get a feel for an overall trend in the data, whether the numbers tend to go up or down over time. Have the Assistant do the work of writing the code with this request:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Create a new DataFrame that has the year in a new column. aggregate by year and show the result in a plotly chart&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Plotly is a very common Python charting library. And indeed, when looking at the yearly totals, the numbers are increasing for the years.&amp;nbsp; The year 2025 is not meaningful yet in this chart as the dataset only contains January to May for that year.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="290 yearly totals.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292297i05056079B6F0B3FE/image-size/large?v=v2&amp;amp;px=999" role="button" title="290 yearly totals.gif" alt="290 yearly totals.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="forecast" id="toc-hId-33969827"&gt;Create a forecast with SAP Databricks&lt;/H1&gt;&lt;P&gt;During the above data exploration we saw that the data has a trend (numbers are increasing over time) and some seasonality (ie numbers are largest in the summer). Let's train a Machine Learning that picks up on such patterns and can estimate future values.&amp;nbsp;&lt;FONT color="#000000"&gt;The Notebook created in this section can also be downloaded from the &lt;A href="https://github.com/SAP-samples/mee-samples/tree/main/Hands-on%20Tutorial%20SAP%20Databricks" target="_self" rel="nofollow noopener noreferrer"&gt;repository&lt;/A&gt;.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;In case you are unsure about how to implement the following 4 code blocks in a new notebook called "020 Demand forecast", then this screencam will guide you along. It shows in a quick scroll through what the output should look like.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="400 forecast prep.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292310iC793B83B80A6B323/image-size/large?v=v2&amp;amp;px=999" role="button" title="400 forecast prep.gif" alt="400 forecast prep.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Read the historic data again into a PySpark DataFrame.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;overnightstays_sdf = spark.read.table("workspace.default.overnightstays") &lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Since we want to create a monthly forecast on the total values, aggregate the history by month. Since we are working with the PySpark DataFrame, the built-in Spark engine is doing the work.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import pyspark.sql.functions as F
overnightstaysmonthly_sdf = overnightstays_sdf.groupBy("month").agg(F.sum("overnightstays").alias("overnightstays"))
display(overnightstaysmonthly_sdf)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The data needs to be prepared further, so that the Python package called Prophet can train a time-series model on it.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# Convert Spark DataFrame to Pandas DataFrame (the time series algorithm requires a Pandas DataFrame)
overnightstaysmonthly_df = overnightstaysmonthly_sdf.toPandas()

# Sort the DataFrame by date
overnightstaysmonthly_df = overnightstaysmonthly_df.sort_values('month')

# Rename the columns, as required by the time-series algoritm Prophet
overnightstaysmonthly_df = overnightstaysmonthly_df.rename(columns={'month': 'ds', 'overnightstays': 'y'})&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;We want to use the Prophet package for the forecast, which still needs to be installed. Here we install it directly from the Notebook. However, in the "Good to know" section below you see a more elegant way of using additional Python package, by creating your own customised Base environment.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;pip install prophet==1.1.7&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Everything is now in place to finally train the time-series model. The following block of code contains multiple steps. It is useful to run these steps together under the "with mlflow.start_run() section as this allows to log information about the training run in SAP Databricks.&amp;nbsp; The following code:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Trains the time series model&lt;/LI&gt;&lt;LI&gt;Creates a DataFrame with the future 12 months that are to be forecasted&lt;/LI&gt;&lt;LI&gt;Creates a forecast for the known past and the future 12 months&lt;/LI&gt;&lt;LI&gt;Calculates&amp;nbsp; and logs the model's accuracy on the known history&lt;/LI&gt;&lt;LI&gt;Plots and logs the known history against the predicted values&lt;/LI&gt;&lt;LI&gt;Logs the number of records that were used during training&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Yes, in a real project this code would be even more elaborate. For example you may want to try different model configurations to get even better forecast accuracy. And the accuracy should ideally be calculated on a hold-out sample. Currently the code uses the same data for training as well as for checking the model's accuracy. The accuracy should really be calculated on data the model has never seen before.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;HINT: In case the following code gives the error "MLflow not available", please check in the Environment settings on the right, that the "Environment version" is set to 2. These environments are explained a bit further down in the "Good to know" section further below. For some people it defaults to version 1 (which doesn't include the mlflow library), for others it defaults to the required version 2.&lt;/EM&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import pandas as pd
from prophet import Prophet
from sklearn.metrics import mean_absolute_percentage_error
import matplotlib.pyplot as plt
import mlflow, mlflow.tracking._model_registry.utils

mlflow.tracking._model_registry.utils._get_registry_uri_from_spark_session = lambda: "databricks-uc"

with mlflow.start_run():

    # Initialize the Prophet model
    model = Prophet()

    # Fit the model
    model.fit(overnightstaysmonthly_df)

    # Create a DataFrame that contains all dates for which a prediction is required, the future 12 months but also the known past for comparison
    datestopredict_df = model.make_future_dataframe(periods=12, freq='MS')

    # Forecast the future and known past
    forecast_df = model.predict(datestopredict_df)

    # Plot the predictions together with known past
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(forecast_df['ds'], forecast_df['yhat'], label='Forecast', color='red')
    ax.plot(overnightstaysmonthly_df['ds'], overnightstaysmonthly_df['y'], label='Historical Data')
    ax.fill_between(forecast_df['ds'], forecast_df['yhat_lower'], forecast_df['yhat_upper'], color='red', alpha=0.3)
    ax.set_title('Demand forecast')
    ax.set_xlabel('Month')
    ax.set_ylabel('Total Overnightstays')
    ax.legend()
    ax.grid(True)
    plt.show()

    # Calculate and log model accuracy, here MAPE on training data
    overnightstaysmonthly_df[["ds"]] = overnightstaysmonthly_df[["ds"]].apply(pd.to_datetime)
    anctualsandpredicted_df = overnightstaysmonthly_df[['ds', 'y']].merge(forecast_df[['ds', 'yhat']], on='ds', how='inner', suffixes=('_left', '_right'))
    prophet_mape = mean_absolute_percentage_error(anctualsandpredicted_df['y'], anctualsandpredicted_df['yhat'])
    mlflow.log_metric("mape", prophet_mape)

    # Log the chart in the Unity Catalog / Experiment
    mlflow.log_figure(fig, "Forecast.png") 

    # Log the size of the training dataset
    mlflow.log_metric("rowcount_training", overnightstaysmonthly_df.shape[0])&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Run the above code and we see our prediction!&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="410 forecast.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292311i9103A5F02A8E234B/image-size/large?v=v2&amp;amp;px=999" role="button" title="410 forecast.gif" alt="410 forecast.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;To persist the forecast, save it as DeltaTable. From here the data can be made available to SAP Datasphere and SAP Analytics Cloud. That part is outside the scope of this tutorial, please check the &lt;A href="https://help.sap.com/docs/SAP_BUSINESS_DATA_CLOUD/3708ee482fc441ef8bb91711b1629109/c4464c041dec43b58a32501c6a6dda3a.html?locale=en-US" target="_self" rel="noopener noreferrer"&gt;documentation&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;&lt;EM&gt;HINT: In case the saving fails with the message "PERMISSION_DENIED", then another user has already created that table and you are not allowed to overwrite it. Just change the name of the table you are creating to proceed.&amp;nbsp;&lt;/EM&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;forecast_sdf = spark.createDataFrame(forecast_df)
forecast_sdf.write.mode("overwrite").saveAsTable("workspace.default.overnightstays_forecast")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The forecast is saved as DeltaTable, that means you can see it in the Catalog!&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="420 forecast in catalog.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292312iF8375CFED009E0F8/image-size/large?v=v2&amp;amp;px=999" role="button" title="420 forecast in catalog.gif" alt="420 forecast in catalog.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The information that was logged during the training is now available in the Experiments section. The model's MAPE (Median Absolute Percentage Error) is at 1.4%, 41 records were used during training and we can see the chart that compares actuals to predictions. Especially when trying out different settings for the Machine Learning algorithm, this tracking becomes very useful, for instance to select which configuration to use for the prediction.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="430 catalog.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292313i0DFA2CC5C05A03F6/image-size/large?v=v2&amp;amp;px=999" role="button" title="430 catalog.gif" alt="430 catalog.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="schedule" id="toc-hId--162543678"&gt;Schedule&lt;/H1&gt;&lt;P&gt;Everything we need for our demand forecast is implemented and we can run it manually. That means we are also good to have it automated with a schedule. Straight from the notebook you can define the scheduling logic, ie the recurring interval and whether you want any notifications. The notebooks can also be triggered through APIs if you prefer.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="500 schedule.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292322i2DBBC49C66338C25/image-size/large?v=v2&amp;amp;px=999" role="button" title="500 schedule.gif" alt="500 schedule.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="goodtoknow" id="toc-hId-410682900"&gt;Good to know&lt;/H1&gt;&lt;P&gt;A few things that might be good to know.&lt;/P&gt;&lt;H2 id="toc-hId--79233612"&gt;&amp;nbsp;&lt;/H2&gt;&lt;H2 id="toc-hId--275747117"&gt;Base file&lt;/H2&gt;&lt;P&gt;In the above code the Python package Prophet is installed directly from within a Notebook. That's ok, but not ideal for ongoing use. If you were repeatedly re-running all cells from the Notebook, then Python will try to re-install the package every time. It's generally better to centrally specify the packages you know you will be using long term. This also ensures consistency across projects and developers. In SAP Databricks you can specify reusable / shareable lists of Python packages that are to be installed through Base environments.&lt;/P&gt;&lt;P&gt;Create a Base environment by creating a file called&amp;nbsp;base_env_prophet.yaml with this content:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;dependencies:
  - prophet==1.1.7&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="600 create base env file.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292444i2F3BB0DE70432780/image-size/large?v=v2&amp;amp;px=999" role="button" title="600 create base env file.gif" alt="600 create base env file.gif" /&gt;&lt;/span&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;With this base file in place, you can&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Step 1: Remove the pip install command from the "020 Demand forecast" Notebook&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="660 1 Delete cells.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292457iE2926E77E522CDA1/image-size/large?v=v2&amp;amp;px=999" role="button" title="660 1 Delete cells.gif" alt="660 1 Delete cells.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Step 2: Specify that the Notebook will use the base file instead, to determine which packages to install. Here you can also select the Environment version. These environment versions are documented&amp;nbsp;&lt;A href="https://docs.databricks.com/aws/en/release-notes/serverless/environment-version/" target="_self" rel="nofollow noopener noreferrer"&gt;here&lt;/A&gt;. After selecting a different base file or after changing the environment version you need hit "Apply" and confirm for the change to take effect.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="660 2 Apply base file.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292459i632B6A73035CB9CF/image-size/large?v=v2&amp;amp;px=999" role="button" title="660 2 Apply base file.gif" alt="660 2 Apply base file.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;To test out that the Package is correctly installed through the base file, clear the environment as shown in the screencam and run the Python code in the cells.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="620 run with base file.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292470i7C64B17F50E7A505/image-size/large?v=v2&amp;amp;px=999" role="button" title="620 run with base file.gif" alt="620 run with base file.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId--472260622"&gt;Lineage &amp;amp; Table usage insights&lt;/H2&gt;&lt;P&gt;Now that the table "overnightstays" has been used a few times, check out the lineage, which shows where the table is used and the statistics on how heavily that table is used.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="550 lineage and insights.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292347iEE1C9D6942221C23/image-size/large?v=v2&amp;amp;px=999" role="button" title="550 lineage and insights.gif" alt="550 lineage and insights.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId--668774127"&gt;Visuals&lt;/H2&gt;&lt;P&gt;From the distance most Notebooks look very much alike at first glance. I heard some great feedback that some visual / image on top of the notebook would help to differentiate. In the repository you find &lt;A href="https://github.com/SAP-samples/mee-samples/tree/main/Hands-on%20Tutorial%20SAP%20Databricks/Images" target="_self" rel="nofollow noopener noreferrer"&gt;a few examples&lt;/A&gt;, in case you would like to use those to distinguish between Data Exploration, AI/ML Sandboxing and AI/ML Deployment.&lt;/P&gt;&lt;P&gt;Upload any images that you want to use into the Workspace. To keep things tidy I am creating a separate folder for them.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="650 image upload.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292681i472440DD7D4505B1/image-size/large?v=v2&amp;amp;px=999" role="button" title="650 image upload.gif" alt="650 image upload.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;These images can then be shown in a Markup cell.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="660 image display.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292683i5E97FE69DBC59287/image-size/large?v=v2&amp;amp;px=999" role="button" title="660 image display.gif" alt="660 image display.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="summary" id="toc-hId--571884625"&gt;Summary&lt;/H1&gt;&lt;P&gt;SAP Databricks is adding a dedicated Data Science environment to the SAP landscape. After this hands-on experience you hopefully have a first feel for how a Data Scientist can enrich the data in SAP Business Data Cloud with Machine Learning.&lt;/P&gt;&lt;P&gt;For your own projects, you will want to check out the documentation:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/business-data-cloud/sap-databricks/introducing-sap-databricks" target="_self" rel="noopener noreferrer"&gt;SAP Databricks documentation by SAP&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://docs.databricks.com/sap/en/" target="_self" rel="nofollow noopener noreferrer"&gt;SAP Databricks documentation by Databricks&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;I hope you enjoyed getting hands-on with SAP Databricks!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/artificial-intelligence-blogs-posts/hands-on-tutorial-sap-databricks/ba-p/14156999"/>
    <published>2025-08-04T09:17:31.648000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-4/ba-p/14174201</id>
    <title>SAP Databricks: Building an Intelligent Enterprise with AI Unleashed – Part 4</title>
    <updated>2025-08-07T08:54:53.397000+02:00</updated>
    <author>
      <name>jing_wen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1923466</uri>
    </author>
    <content>&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-1/ba-p/14166813" target="_self"&gt;&lt;SPAN&gt;Part 1 – SQL analytics with SAP Data Products&lt;BR /&gt;&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-2/ba-p/14167025" target="_self"&gt;Part 2 – Build and deploy Mosaic AI and Agent Tools&lt;/A&gt;&lt;BR /&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-how-to-use-automl-to-forecast-sales-data-part-3/ba-p/14174354" target="_self"&gt;Part 3 – How to use AutoML to forecast sales data&lt;/A&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-3/ba-p/14174201" target="_self"&gt;&lt;SPAN&gt;Part 4 – Connect SAP Data Products with non-SAP data from AWS S3&lt;BR /&gt;&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-4/ba-p/14178056" target="_self"&gt;Part 5 – End-to-end integration: SAP Databricks, SAP Datasphere, and SAP Analytics Cloud&lt;/A&gt;&lt;BR /&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-create-inferences-for-application-integration-with-sap-build/ba-p/14186662" target="_self"&gt;Part 6 – Create inferences and endpoints for application integration with SAP Build&lt;/A&gt;&lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-create-inferences-for-application-integration-with-sap-build/ba-p/14186662" target="_self"&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/A&gt;&lt;BR /&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-in-sap-business-data-cloud-a-typical-machine-learning/ba-p/14206612" target="_self"&gt;Part 7&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;–&amp;nbsp;SAP Databricks in SAP Business Data Cloud - A Typical Machine Learning Workflow&lt;/SPAN&gt;&lt;/A&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1865165611" id="toc-hId-1866023751"&gt;SAP Databricks in SAP Business Data Cloud&amp;nbsp;&lt;/H3&gt;&lt;P&gt;In today's data-driven world, gaining a 360-degree view of your enterprise requires combining data from all corners of your business. SAP systems house governed business data. Meanwhile, Amazon S3 often contains unstructured or external data—everything from web logs and partner data to machine learning features and fraud detection inputs.&lt;/P&gt;&lt;H3 id="toc-hId-1669510246"&gt;&lt;STRONG&gt;Step-by-Step Playbook: Connecting AWS S3 to SAP Databricks&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;In this part of our blog series, we’ll walk you through &lt;STRONG&gt;connecting SAP Databricks to an Amazon S3 bucket&lt;/STRONG&gt; — empowering you to unify data from diverse sources and accelerate your analytics and AI workflows.&lt;/P&gt;&lt;P&gt;By the end of this guide, you’ll have:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;A &lt;STRONG&gt;Unity Catalog external location&lt;/STRONG&gt; pointing to your S3 bucket&lt;/LI&gt;&lt;LI&gt;A &lt;STRONG&gt;registered table&lt;/STRONG&gt; in Unity Catalog&lt;/LI&gt;&lt;LI&gt;A &lt;STRONG&gt;ready-to-run SAP Databricks notebook&lt;/STRONG&gt; to analyze your unified data&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;We will be covering the following steps in this guide:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Step 1 – Create the External Location (AWS Quickstart)&lt;/LI&gt;&lt;LI&gt;Step 2 – Generate a Personal Access Token (PAT) in SAP Databricks&lt;/LI&gt;&lt;LI&gt;Step 3 – Identify (or create) the target S3 bucket&lt;/LI&gt;&lt;LI&gt;Step 4 – Configure the AWS IAM Role &amp;amp; Policies&lt;/LI&gt;&lt;LI&gt;Step 5 – Launch the AWS Quickstart CloudFormation Stack&lt;/LI&gt;&lt;LI&gt;Step 6 – Provide the PAT to the CloudFormation Stack&lt;/LI&gt;&lt;LI&gt;Step 7 – Verify CloudFormation Completion&lt;/LI&gt;&lt;LI&gt;Step 8 – Test the External Location connection in SAP Databricks&lt;/LI&gt;&lt;LI&gt;Step 9– Create a Unity Catalog table from the S3 data&lt;/LI&gt;&lt;LI&gt;Step 10 – Work with SAP Data Products and non-SAP data from S3 within the SAP Databricks Notebook environment&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Let's dive in.&lt;/P&gt;&lt;H4 id="toc-hId-1602079460"&gt;&lt;STRONG&gt;Prerequisites&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;You must create the S3 bucket that you want to use as an external location before you create the external location object in&amp;nbsp;SAP Databricks. More details documented &lt;A href="https://docs.databricks.com/sap/en/external-locations" target="_blank" rel="noopener nofollow noreferrer"&gt;here&lt;/A&gt;:&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;UL&gt;&lt;LI&gt;The AWS CloudFormation template supports only S3 buckets.&lt;/LI&gt;&lt;LI&gt;The name of an S3 bucket that you want users to read from and write to cannot use dot notation (for example,&amp;nbsp;incorrect.bucket.name.notation). For more bucket naming guidance, see the&amp;nbsp;&lt;A href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html" target="_blank" rel="noopener nofollow noreferrer"&gt;AWS bucket naming rules&lt;/A&gt;.&lt;/LI&gt;&lt;LI&gt;Avoid using a path in S3 that is already defined as an external location in another&amp;nbsp;Unity Catalog&amp;nbsp;metastore. You can safely read data in a single external S3 location from more than one metastore, but concurrent writes to the same S3 location from multiple metastores can lead to consistency issues.&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;If you don't use the AWS CloudFormation template to create the external location, you must first create a storage credential in&amp;nbsp;SAP Databricks&amp;nbsp;that gives access to the cloud storage location path. See the following AWS doc:&amp;nbsp;&lt;A href="https://docs.databricks.com/aws/connect/unity-catalog/cloud-storage/storage-credentials" target="_blank" rel="noopener nofollow noreferrer"&gt;Create a storage credential&lt;/A&gt;.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;If you use the AWS CloudFormation flow, that storage credential is created for you.&lt;/P&gt;&lt;H4 id="toc-hId-1405565955"&gt;&lt;STRONG&gt;Permissions requirements&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;You must have the&amp;nbsp;&lt;STRONG&gt;CREATE EXTERNAL LOCATION&lt;/STRONG&gt;&amp;nbsp;privilege on both the metastore and the storage credential referenced in the external location. Metastore admins have&amp;nbsp;CREATE EXTERNAL LOCATION&amp;nbsp;on the metastore by default.&lt;/LI&gt;&lt;LI&gt;If you are using the AWS CloudFormation template, you must also have the&amp;nbsp;&lt;STRONG&gt;CREATE STORAGE CREDENTIAL&amp;nbsp;&lt;/STRONG&gt;privilege on the metastore. Metastore admins have&amp;nbsp;CREATE STORAGE CREDENTIAL&amp;nbsp;on the metastore by default.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This guide assumes you're using the &lt;STRONG&gt;SAP Databricks Quickstart on AWS&lt;/STRONG&gt;, which automates much of the setup. Advanced users may opt for a manual setup with your IAM role (ARN), including the encryption algorithm of SSE-S3 or SSE-KMS.&lt;/P&gt;&lt;H4 id="toc-hId-1209052450"&gt;&lt;STRONG&gt;Step 1 – Create the External Location&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;In&amp;nbsp;&lt;STRONG&gt;SAP Databricks Unity Catalog,&amp;nbsp;&lt;/STRONG&gt;navigate to "Create an external location".&lt;/LI&gt;&lt;LI&gt;Use the &lt;STRONG&gt;Quickstart&lt;/STRONG&gt; wizard to create your external location.&lt;/LI&gt;&lt;LI&gt;Alternatively, advanced users can manually configure an &lt;STRONG&gt;AWS IAM Role&lt;/STRONG&gt; and specify the &lt;STRONG&gt;S3 bucket path&lt;/STRONG&gt;.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="1.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297594i52AB164F42A7AC08/image-size/large?v=v2&amp;amp;px=999" role="button" title="1.png" alt="1.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297596i873B39FF94B3F71D/image-size/large?v=v2&amp;amp;px=999" role="button" title="2.png" alt="2.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-1012538945"&gt;&lt;STRONG&gt;Step 2 – Generate a Personal Access Token (PAT)&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;In SAP Databricks, generate a &lt;STRONG&gt;PAT&lt;/STRONG&gt; that will be used during the AWS CloudFormation setup.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="3 - AWS Quickstart.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297597i207587AA1288ACF2/image-size/large?v=v2&amp;amp;px=999" role="button" title="3 - AWS Quickstart.png" alt="3 - AWS Quickstart.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-816025440"&gt;&lt;STRONG&gt;Step 3 – Identify Your S3 Bucket&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;Meanwhile, choose or create the &lt;STRONG&gt;S3 bucket&lt;/STRONG&gt; that holds your non-SAP data.&lt;/LI&gt;&lt;LI&gt;Example: Fraud detection data (&lt;A href="https://github.com/aws-samples/aws-fraud-detector-samples/tree/master/data" target="_blank" rel="noopener nofollow noreferrer"&gt;AWS sample data&lt;/A&gt;).&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="4 - AWS S3 Bucket.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297598i925D069B74492B1E/image-size/large?v=v2&amp;amp;px=999" role="button" title="4 - AWS S3 Bucket.png" alt="4 - AWS S3 Bucket.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-619511935"&gt;&lt;STRONG&gt;Step 4 – Configure Your AWS IAM Role &amp;amp; Policies&lt;/STRONG&gt;&lt;/H4&gt;&lt;P&gt;Ensure the IAM role used by &lt;STRONG&gt;SAP Databricks&lt;/STRONG&gt; has the following permissions to enable secure and functional access to your AWS data environment:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;AmazonS3FullAccess&lt;/STRONG&gt;&lt;BR /&gt;Grants full access to all Amazon S3 buckets and objects within the account.&lt;BR /&gt;&lt;EM&gt;Used to read/write data from S3, list buckets, and manage objects.&lt;/EM&gt;&lt;EM&gt;&lt;BR /&gt;&lt;/EM&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;AmazonS3TablesFullAccess&lt;/STRONG&gt;&lt;BR /&gt;Grants access to AWS Glue tables and data lake metadata.&lt;BR /&gt;&lt;EM&gt;Supports Unity Catalog integration with external tables stored in S3.&lt;/EM&gt;&lt;EM&gt;&lt;BR /&gt;&lt;/EM&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;AmazonS3ObjectLambdaExecutionRolePolicy&lt;/STRONG&gt;&lt;BR /&gt;Enables the role to invoke AWS Lambda functions when accessing S3 objects.&lt;BR /&gt;&lt;EM&gt;Required only if using S3 Object Lambda to dynamically transform or filter data before it is consumed by Databricks.&lt;BR /&gt;&lt;/EM&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;IAMFullAccess&lt;/STRONG&gt;&lt;BR /&gt;Grants full access to manage IAM resources such as roles, policies, users, and groups.&lt;BR /&gt;&lt;EM&gt;Recommended only for administrative or automated setup environments (e.g., CloudFormation). For production, follow the principle of least privilege and only allow specific IAM actions such as &lt;/EM&gt;&lt;EM&gt;iam:PassRole&lt;/EM&gt;&lt;EM&gt; or &lt;/EM&gt;&lt;EM&gt;iam:AssumeRole&lt;/EM&gt;&lt;EM&gt;.&lt;BR /&gt;&lt;/EM&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;EM&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="4 - AmazonS3Access .png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297601iF40C9B86D2A955E1/image-size/large?v=v2&amp;amp;px=999" role="button" title="4 - AmazonS3Access .png" alt="4 - AmazonS3Access .png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="4 - IAMFullAccess.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297602iB42FDD37280BEBA9/image-size/large?v=v2&amp;amp;px=999" role="button" title="4 - IAMFullAccess.png" alt="4 - IAMFullAccess.png" /&gt;&lt;/span&gt;&lt;/EM&gt;&lt;/P&gt;&lt;H4 id="toc-hId-422998430"&gt;&lt;STRONG&gt;Step 5 – Launch the AWS Quickstart CloudFormation Stack&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;Launch the Quickstart template from within SAP Databricks, and it will direct you to the AWS Quickstart CloudFormation Stack.&lt;/LI&gt;&lt;LI&gt;Note the Personal Access Token (PAT) as you'll be prompted to input it in AWS.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="5 - Launch in Quickstart.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297608iE93B69E4AD46AAAB/image-size/large?v=v2&amp;amp;px=999" role="button" title="5 - Launch in Quickstart.png" alt="5 - Launch in Quickstart.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-226484925"&gt;&lt;STRONG&gt;Step 6 – Provide Your Personal Access Token to the Stack&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;Input the &lt;STRONG&gt;PAT&lt;/STRONG&gt; generated in the previous step to allow SAP Databricks access.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="5 - Quickstart.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297609i2CF23993EB954E0A/image-size/large?v=v2&amp;amp;px=999" role="button" title="5 - Quickstart.png" alt="5 - Quickstart.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId--467745675"&gt;&lt;STRONG&gt;Step 7 – Verify Stack Completion&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;Monitor the CloudFormation Stack – the status will change from &lt;STRONG&gt;CREATE_IN_PROGRESS&lt;/STRONG&gt; to &lt;STRONG&gt;CREATE_COMPLETE&lt;/STRONG&gt;.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="6 - Quickstart Successful Create_Complete.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297610i6971C5330C84E07B/image-size/large?v=v2&amp;amp;px=999" role="button" title="6 - Quickstart Successful Create_Complete.png" alt="6 - Quickstart Successful Create_Complete.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId--664259180"&gt;&lt;STRONG&gt;Step 8 – Test the External Location Connection&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;In SAP Databricks, return to your external location under Catalog Explorer and &lt;STRONG&gt;click “Test Connection”&lt;/STRONG&gt;.&lt;/LI&gt;&lt;LI&gt;Verify external location and credential permissions for &lt;STRONG&gt;Read&lt;/STRONG&gt;, &lt;STRONG&gt;Write&lt;/STRONG&gt;, and more.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="7 - SAP Databricks External Data.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297611iF09BB1A9C1062738/image-size/large?v=v2&amp;amp;px=999" role="button" title="7 - SAP Databricks External Data.png" alt="7 - SAP Databricks External Data.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="8 - S3 Files.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297612i5FE943658CF2A33D/image-size/large?v=v2&amp;amp;px=999" role="button" title="8 - S3 Files.png" alt="8 - S3 Files.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="9 - SAP Databricks Test Connection.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297613i87F80F84500A569B/image-size/large?v=v2&amp;amp;px=999" role="button" title="9 - SAP Databricks Test Connection.png" alt="9 - SAP Databricks Test Connection.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="10 - Validate Configuration.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297614iBE4F3B7D83C5AE50/image-size/large?v=v2&amp;amp;px=999" role="button" title="10 - Validate Configuration.png" alt="10 - Validate Configuration.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId--860772685"&gt;&lt;STRONG&gt;Step 9 –&amp;nbsp;&lt;/STRONG&gt;&lt;STRONG&gt;Create a Unity Catalog Table from S3 Data&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;Select a file in your S3 bucket and &lt;STRONG&gt;register it as a table&lt;/STRONG&gt; in Unity Catalog.&lt;/LI&gt;&lt;LI&gt;Navigate to Unity Catalog to confirm your new table appears and is accessible for querying&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="11 - Create Table.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297616i7A6F34A35E5E0B9B/image-size/large?v=v2&amp;amp;px=999" role="button" title="11 - Create Table.png" alt="11 - Create Table.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="12 - Select Table.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297618iFF0A10EA29EB96D9/image-size/large?v=v2&amp;amp;px=999" role="button" title="12 - Select Table.png" alt="12 - Select Table.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="13 - Preview &amp;amp; Create Table.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297619i46A13DCAFE21360F/image-size/large?v=v2&amp;amp;px=999" role="button" title="13 - Preview &amp;amp; Create Table.png" alt="13 - Preview &amp;amp; Create Table.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="14 - Table in UC.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297620i25D3A182C447310E/image-size/large?v=v2&amp;amp;px=999" role="button" title="14 - Table in UC.png" alt="14 - Table in UC.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId--1057286190"&gt;&lt;STRONG&gt;Step 10 – Work with SAP Data Products and non-SAP S3 Data within the Notebook environment&lt;/STRONG&gt;&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;Use the SAP Databricks notebook environment to run analyses on your newly unified data.&lt;/LI&gt;&lt;LI&gt;You can join SAP Data Products with external S3 data for richer insights, all within the same environment.&lt;/LI&gt;&lt;LI&gt;For basic visualizations, harness the power of the notebook environment. For comprehensive dashboarding, SAP Analytics Cloud—part of the SAP Business Data Cloud—offers pre-built templates, robust architecture, and seamless integration with enterprise data, enabling scalable and insightful analytics.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Notebook Dashboard.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/297622i085B94E22DC7BDB5/image-size/large?v=v2&amp;amp;px=999" role="button" title="Notebook Dashboard.png" alt="Notebook Dashboard.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;By connecting AWS S3 to SAP Databricks, you can seamlessly unify external and SAP business data for more powerful analytics and AI workflows. This integration enables easy access, management, and analysis of diverse datasets within SAP Business Data Cloud.&amp;nbsp;&lt;/P&gt;&lt;P&gt;In the &lt;STRONG&gt;next part&lt;/STRONG&gt;, we will explore &lt;STRONG&gt;end-to-end integration between SAP Databricks, SAP Datasphere, and SAP Analytics Cloud&lt;/STRONG&gt;, completing the unified analytics journey from data ingestion to actionable insights.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-4/ba-p/14174201"/>
    <published>2025-08-07T08:54:53.397000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/building-agents-for-a-simple-microservice-architecture-with-fastapi-part-2/ba-p/14176702</id>
    <title>🚀Building Agents  for a Simple Microservice Architecture with FastAPI (Part 2)</title>
    <updated>2025-08-10T09:01:21.368000+02:00</updated>
    <author>
      <name>Yogananda</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/75</uri>
    </author>
    <content>&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Previous Blog :&amp;nbsp;&amp;nbsp;&lt;/STRONG&gt;&lt;SPAN class=""&gt;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/building-collaborative-microservices-in-python-with-fastapi-echo-amp/ba-p/14170025" target="_blank"&gt;Building Collaborative Microservices in Python with FastAPI: Echo &amp;amp; Reverse Agents (Beginner -Part1)&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;Microservices are a powerful way to design scalable and maintainable applications. &lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;In this blog, we will explore a minimal yet effective microservice setup using&amp;nbsp;&lt;STRONG&gt;FastAPI&lt;/STRONG&gt;, perfect for learning and experimentation. This will help to you build better Microservices and deploy in SAP BTP - Kyma&lt;/EM&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1866088139"&gt;Sample Use Case&lt;/H3&gt;&lt;P&gt;A client sends a city name to the Weather Agent. The agent fetches enrichment data from the Data Enricher, generates fake weather data, and returns a combined report. This mimics real-world API composition and data aggregation.&lt;/P&gt;&lt;H3 id="toc-hId-1669574634"&gt;Overview&lt;/H3&gt;&lt;P&gt;It consists of two core services:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Fake Weather Agent&amp;nbsp;(&lt;FONT color="#FF6600"&gt;weather_agent.py&lt;/FONT&gt;)&lt;/LI&gt;&lt;LI&gt;Data Enricher&amp;nbsp;(&lt;FONT color="#FF6600"&gt;data_enricher.py&lt;/FONT&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;A shell script (&lt;FONT color="#FF6600"&gt;run.sh&lt;/FONT&gt;) is included to launch both services on separate ports, simulating a real-world microservice environment.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Yogananda_0-1754809227004.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/298973i1E5B429726C6F429/image-size/large?v=v2&amp;amp;px=999" role="button" title="Yogananda_0-1754809227004.png" alt="Yogananda_0-1754809227004.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1473061129"&gt;&lt;span class="lia-unicode-emoji" title=":sun_behind_rain_cloud:"&gt;🌦&lt;/span&gt;️ 1. Fake Weather Agent (&lt;FONT color="#FF6600"&gt;weather_agent.py&lt;/FONT&gt;)&lt;/H3&gt;&lt;P&gt;&lt;FONT color="#3366FF"&gt;Purpose&lt;/FONT&gt;:&amp;nbsp; &amp;nbsp;Generates a fake weather report for a given city.&lt;/P&gt;&lt;P&gt;&lt;FONT color="#3366FF"&gt;API Endpoint:&amp;nbsp;&amp;nbsp;&lt;/FONT&gt;&lt;FONT color="#FF6600"&gt;POST /weather&lt;/FONT&gt;&amp;nbsp;— Accepts a JSON payload with a city name.&lt;/P&gt;&lt;P&gt;&lt;FONT color="#3366FF"&gt;How It Works:&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Receives a city name from the client.&lt;/LI&gt;&lt;LI&gt;Optionally calls the&amp;nbsp;Data Enricher&amp;nbsp;service to fetch additional info (e.g., population, country).&lt;/LI&gt;&lt;LI&gt;Generates random weather data:&lt;UL&gt;&lt;LI&gt;Temperature&lt;/LI&gt;&lt;LI&gt;Condition (e.g., sunny, rainy)&lt;/LI&gt;&lt;LI&gt;Humidity&lt;/LI&gt;&lt;LI&gt;Wind speed&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;Returns a combined weather report, enriched with city metadata if available.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;FONT color="#3366FF"&gt;Tech Stack:&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;FastAPI for API development&lt;/LI&gt;&lt;LI&gt;Pydantic for data validation&lt;/LI&gt;&lt;LI&gt;httpx for asynchronous HTTP calls&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import httpx
import os
import random

PORT = int(os.getenv("PORT", 8002))
TARGET = os.getenv("TARGET_URL", "http://localhost:8003")   # downstream agent

app = FastAPI(title="Fake-Weather-Agent")

class Location(BaseModel):
    city: str

class WeatherReport(BaseModel):
    source: str
    city: str
    temperature: float   # °C
    condition: str
    humidity: int        # %
    wind_kmh: float

CONDITIONS = ["Sunny", "Cloudy", "Rain", "Snow", "Thunderstorm"]

@app.post("/weather", response_model=WeatherReport)
async def get_weather(loc: Location):
    """Generate a fake weather report for the given city."""
    # Optionally call another agent (e.g. a “data-enrichment” service)
    async with httpx.AsyncClient() as client:
        try:
            r = await client.post(
                f"{TARGET}/enrich",
                json={"city": loc.city}
            )
            r.raise_for_status()
            extra = r.json()
        except Exception:
            extra = {}

    return WeatherReport(
        source="Fake-Weather-Agent",
        city=loc.city,
        temperature=round(random.uniform(-10, 40), 1),
        condition=random.choice(CONDITIONS),
        humidity=random.randint(20, 95),
        wind_kmh=round(random.uniform(0, 40), 1),
        **extra
    )&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-1276547624"&gt;&lt;span class="lia-unicode-emoji" title=":cityscape:"&gt;🏙&lt;/span&gt;️ 2. Data Enricher (&lt;FONT color="#FF6600"&gt;data_enricher.py&lt;/FONT&gt;)&lt;/H3&gt;&lt;P&gt;&lt;FONT color="#3366FF"&gt;Purpose&lt;/FONT&gt;:&amp;nbsp;Provides additional metadata about a city.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;API Endpoint:&amp;nbsp;&lt;/STRONG&gt;&lt;FONT color="#FF6600"&gt;POST /enrich&lt;/FONT&gt;&amp;nbsp;— Accepts a JSON payload with a city name.&lt;/P&gt;&lt;P&gt;&lt;FONT color="#3366FF"&gt;How It Works:&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Looks up the city in a fake in-memory database.&lt;/LI&gt;&lt;LI&gt;Returns population and country if found.&lt;/LI&gt;&lt;LI&gt;If not found, returns default placeholder values.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;FONT color="#3366FF"&gt;Tech Stack:&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;FastAPI&lt;/LI&gt;&lt;LI&gt;Pydantic&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI(title="Data-Enricher")

class EnrichRequest(BaseModel):
    city: str

class EnrichResponse(BaseModel):
    population: int
    country: str

FAKE_DB = {
    "london": {"population": 9_000_000, "country": "UK"},
    "paris":  {"population": 2_100_000, "country": "France"},
    "tokyo":  {"population": 14_000_000, "country": "Japan"},
}

@app.post("/enrich", response_model=EnrichResponse)
def enrich(req: EnrichRequest):
    city = req.city.lower()
    if city not in FAKE_DB:
        return EnrichResponse(population=0, country="Unknown")
    return FAKE_DB[city]&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-1080034119"&gt;&lt;span class="lia-unicode-emoji" title=":desktop_computer:"&gt;🖥&lt;/span&gt;️ 3. Running the Services (&lt;FONT color="#FF6600"&gt;run.sh&lt;/FONT&gt;)&lt;/H3&gt;&lt;P&gt;&lt;FONT color="#3366FF"&gt;Purpose:&amp;nbsp;&lt;/FONT&gt;Starts both services using&amp;nbsp;uvicorn, FastAPI’s ASGI server.&lt;BR /&gt;A shell script (&lt;A title="" href="vscode-file://vscode-app/Applications/Visual%20Studio%20Code.app/Contents/Resources/app/out/vs/code/electron-browser/workbench/workbench.html" target="_blank" rel="noopener nofollow noreferrer"&gt;run.sh&lt;/A&gt;) is provided to run both services on different ports.&lt;/P&gt;&lt;P&gt;&lt;FONT color="#3366FF"&gt;How It Works&lt;/FONT&gt;:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Launches&amp;nbsp;Fake Weather Agent&amp;nbsp;on port&amp;nbsp;&lt;FONT color="#FF6600"&gt;8002&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;Launches&amp;nbsp;Data Enricher&amp;nbsp;on port&amp;nbsp;&lt;FONT color="#FF6600"&gt;8003&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;Each service runs in its own terminal window&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# Terminal 1
uvicorn fake_weather:app --port 8002 --reload

# Terminal 2
uvicorn data_enricher:app --port 8003 --reload&lt;/code&gt;&lt;/pre&gt;&lt;H2 id="toc-hId-754437895"&gt;Key Points :&amp;nbsp;&lt;/H2&gt;&lt;UL&gt;&lt;LI&gt;Microservice Communication:&lt;BR /&gt;The Weather Agent calls the Data Enricher via HTTP to demonstrate service-to-service communication.&lt;/LI&gt;&lt;LI&gt;Extensibility:&lt;BR /&gt;Easy to add more enrichment services or expand the fake database.&lt;/LI&gt;&lt;LI&gt;FastAPI Features:&lt;BR /&gt;Shows how to use Pydantic models, async endpoints, and response models.&lt;/LI&gt;&lt;LI&gt;Local Development:&amp;nbsp;&amp;nbsp;&lt;BR /&gt;Simple to run both services locally for testing and learning.&lt;/LI&gt;&lt;/UL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/building-agents-for-a-simple-microservice-architecture-with-fastapi-part-2/ba-p/14176702"/>
    <published>2025-08-10T09:01:21.368000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-members/easy-way-to-move-zeroes-in-sap-btp-abap-steampunk-js-amp-python/ba-p/14176847</id>
    <title>Easy way to move zeroes in SAP BTP ABAP(Steampunk), JS &amp; Python</title>
    <updated>2025-08-10T15:27:33.552000+02:00</updated>
    <author>
      <name>kallolathome</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14879</uri>
    </author>
    <content>&lt;H2 id="toc-hId-962976781" id="toc-hId-1737006510"&gt;Introduction&lt;/H2&gt;&lt;P&gt;&lt;SPAN&gt;This is part of the&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://blogs.sap.com/2022/12/20/easy-way-to-write-algorithms-in-abap-series-01/" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Easy way to write algorithms in ABAP: Series 01&lt;/STRONG&gt;&lt;/A&gt;&lt;SPAN&gt;. For more algorithms, please check the main blog-post.&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-766463276" id="toc-hId-1540493005"&gt;Problem&lt;/H2&gt;&lt;P&gt;Given an integer array&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;nums, move all&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;0's to the end of it while maintaining the relative order of the non-zero elements.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Note&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;that you must do this in-place without making a copy of the array.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Example 1:&lt;/STRONG&gt;&lt;/P&gt;&lt;PRE&gt;&lt;STRONG&gt;Input:&lt;/STRONG&gt; nums = [0,1,0,3,12]
&lt;STRONG&gt;Output:&lt;/STRONG&gt; [1,3,12,0,0]&lt;/PRE&gt;&lt;P&gt;&lt;STRONG&gt;Example 2:&lt;/STRONG&gt;&lt;/P&gt;&lt;PRE&gt;&lt;STRONG&gt;Input:&lt;/STRONG&gt; nums = [0]
&lt;STRONG&gt;Output:&lt;/STRONG&gt; [0]&lt;/PRE&gt;&lt;P&gt;&lt;STRONG&gt;Constraints:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;1 &amp;lt;= nums.length &amp;lt;= 104&lt;/LI&gt;&lt;LI&gt;-231 &amp;lt;= nums[i] &amp;lt;= 231 - 1&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Follow up:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Could you minimize the total number of operations done?&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-569949771" id="toc-hId-1343979500"&gt;Solution&lt;/H2&gt;&lt;P&gt;&lt;SPAN&gt;Time Complexity: &lt;STRONG&gt;O(n)&lt;/STRONG&gt;&lt;BR /&gt;Space Complexity: &lt;STRONG&gt;O(1)&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-502518985" id="toc-hId-1276548714"&gt;ABAP&lt;/H3&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;CLASS zmove_zeroes DEFINITION
  PUBLIC
  FINAL
  CREATE PUBLIC .

  PUBLIC SECTION.
    INTERFACES if_oo_adt_classrun.

  PROTECTED SECTION.
  PRIVATE SECTION.
    " Define a table type for integers
    TYPES ty_nums TYPE STANDARD TABLE OF i WITH EMPTY KEY.

    " Method to move zeroes in-place
    METHODS moveZeroes
      CHANGING lt_nums TYPE ty_nums.

ENDCLASS.

CLASS zmove_zeroes IMPLEMENTATION.

  METHOD if_oo_adt_classrun~main.
    " Initialize the number array with some zeroes and non-zeroes
    DATA(lt_nums) = VALUE ty_nums( ( 0 ) ( 1 ) ( 0 ) ( 3 ) ( 12 ) ).

    " Output the array before moving zeroes
    out-&amp;gt;write( |Array before moving zeroes: | ).
    LOOP AT lt_nums INTO DATA(lv_num).
      out-&amp;gt;write( lv_num ).
    ENDLOOP.

    " Call the method to move zeroes to the end
    moveZeroes( CHANGING lt_nums = lt_nums ).

    " Output the array after moving zeroes
    out-&amp;gt;write( |Array after moving zeroes: | ).
    LOOP AT lt_nums INTO lv_num.
      out-&amp;gt;write( lv_num ).
    ENDLOOP.

  ENDMETHOD.

  METHOD moveZeroes.

    DATA(lv_count) = 0. " Counter for non-zero elements

    " First pass: Move all non-zero elements to the front
    LOOP AT lt_nums ASSIGNING FIELD-SYMBOL(&amp;lt;lf_num&amp;gt;).
      IF &amp;lt;lf_num&amp;gt; &amp;lt;&amp;gt; 0.
        " Place the non-zero element at the next available position
        lt_nums[ lv_count + 1 ] = &amp;lt;lf_num&amp;gt;.
        lv_count += 1.
      ENDIF.
    ENDLOOP.

    " Second pass: Fill the rest of the array with zeroes
    WHILE lv_count &amp;lt; lines( lt_nums ).
      lt_nums[ lv_count + 1 ] = 0.
      lv_count += 1.
    ENDWHILE.

  ENDMETHOD.

ENDCLASS.&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-306005480" id="toc-hId-1080035209"&gt;JavaScript&lt;/H3&gt;&lt;pre class="lia-code-sample language-javascript"&gt;&lt;code&gt;function moveZeroes(nums) {
    let left = 0;
    for (let right = 0; right &amp;lt; nums.length; right++) {
        if (nums[right] !== 0) {
            // Swap nums[left] and nums[right]
            let temp = nums[left];
            nums[left] = nums[right];
            nums[right] = temp;
            left++;
        }
    }
    return nums;
}&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-883521704"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId-502518985" id="toc-hId-687008199"&gt;Python&lt;/H3&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;def moveZeroes(nums):
    left = 0
    for right in range(len(nums)):
        if nums[right] != 0:
            nums[left], nums[right] = nums[right], nums[left]
            left += 1
    return nums&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;N.B: For ABAP, I am using SAP BTP ABAP Environment 2309 Release.&lt;/SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;SPAN&gt;Happy Coding!&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN class="lia-unicode-emoji"&gt;&lt;span class="lia-unicode-emoji" title=":slightly_smiling_face:"&gt;🙂&lt;/span&gt;&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-members/easy-way-to-move-zeroes-in-sap-btp-abap-steampunk-js-amp-python/ba-p/14176847"/>
    <published>2025-08-10T15:27:33.552000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-automation-creating-database-user-in-sap-datasphere-using/ba-p/14176606</id>
    <title>SAP Datasphere Automation : Creating Database user in SAP Datasphere using Datasphere CLI &amp; Python</title>
    <updated>2025-08-12T08:06:51.294000+02:00</updated>
    <author>
      <name>shubham521</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/845865</uri>
    </author>
    <content>&lt;H3 id="toc-hId-1866087182"&gt;Introduction&lt;/H3&gt;&lt;P&gt;One way to access datasphere hana database is via database users. Each database user is linked to one space (except database analysis user). We can create database user vai GUI however, its a long process and prone to errors. In this blog, i will share my work on how i automated the process using SAP Datasphere CLI and Python without the need to login into datasphere GUI.&lt;/P&gt;&lt;H3 id="toc-hId-1669573677"&gt;Old Process:&lt;/H3&gt;&lt;P&gt;If you want to create a database user via GUI, you need to perform the below steps.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Login into the datasphere tenant. Make sure you have the required application roles to perform the task.&lt;/LI&gt;&lt;LI&gt;Go to Space management and select the space. Scroll down and click create in database user.&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;Provide the username and deploy the space. Save the password and share it with the user.&amp;nbsp;&lt;/LI&gt;&lt;/OL&gt;&lt;H3 id="toc-hId-1473060172"&gt;Automated Process&lt;/H3&gt;&lt;P&gt;To overcome the long process, i have divided the python script to perform all these task in sequential manner.&amp;nbsp;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Datasphere CLI Setup&lt;/STRONG&gt; : Set the CLI and login into datasphere&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Reading the metadata&lt;/STRONG&gt;: Read the space metadata using SAP Datasphere CLI &lt;STRONG&gt;space read&lt;/STRONG&gt; command&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Modifying JSON&lt;/STRONG&gt; : Enhance the output JSON with the new user details and deploy it using the &lt;STRONG&gt;space create&lt;/STRONG&gt; command&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Password Reset&lt;/STRONG&gt; : Reset the database user password and save it in a file for sharing.&lt;/LI&gt;&lt;/OL&gt;&lt;H3 id="toc-hId-1276546667"&gt;Set up SAP Datasphere CLI (First time only)&lt;/H3&gt;&lt;P&gt;To start working with Datasphere CLI, we need to perform few one time configuration like setting host, login in and setting cache. If you want to login via a different tenant, you need to change the CLIENT_ID and CLIENT_SECRETS as per the tenant.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;datasphere config set host {"host_url"}
datasphere login --client-id {"client_id"} --client-secret {"client_secret"}
datasphere config set cache --client-id {"client_id"} --client-secret {"client_secret"}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;Once you are done with the initial setup of CLI, we can start working on the main code which will create database users.&lt;/P&gt;&lt;H3 id="toc-hId-1080033162"&gt;Reading space metadata&lt;/H3&gt;&lt;P&gt;Since we do not have a direct command to create DB user, we extract the space metadata JSON using CLI. This command output the space metadata JSON into console. I have stored this into a variable that i will use later in modifying the JSON&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;space_Json = datasphere space read -space "{space"} --definations&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-883519657"&gt;Modifying the JSON and deploying it in datasphere&amp;nbsp;&lt;/H3&gt;&lt;P&gt;To create a new databased user in space, we need to add the new user details in the dbuser object of the JSON. We can store the space metadata JSON into our local machine and modify it or we can modify it on the go using tempfiles. I have used the later approach as it eliminates the need of JSON management&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;#Concatenating the space and username
new_db_user = f"{space}#{username}"

#Appending the new_db_user details into the space metadata JSON
space_JSON[space]["spaceDefinition"]["dbusers"][new_db_user] = {
"ingestion":{
        "auditing":{
          "dppRead":{
            "retentionPeriod":21
            "isAuditPolicyActive":True
          },
         
        }
      },
      "consumption":{
        "consumptionWithGrant":false,
        "spaceSchemaAccess":True,
        "scriptServerAccess":false,
        "localSchemaAccess":false,
        "hdiGrantorForCupsAccess":false
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Once the JSON is modified, write the new JSON into a temporary file. I have stored the file path into a variable called tmp_file_path. I will push this file path to datasphere tenant.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;#Pushing the modified JSON to datasphere tenant
datasphere space create --file-path "{tmp_file_path}" -- force-defination-deployment &lt;/code&gt;&lt;/pre&gt;&lt;P&gt;If you want to delete a database user, remove the entry from the JSON and run the same command and add&amp;nbsp;&lt;SPAN&gt;&lt;STRONG&gt;--enforce-database-user-deletion&lt;/STRONG&gt; in the end. If this command is not added, then the deletion will not work.&lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-687006152"&gt;Password Reset&lt;/H3&gt;&lt;P&gt;Once the database user is created, we need to reset the password to store it in a local file for sharing. Below is the command to perform that action&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;datasphere dbusers password reset --space{"space"} --databaseuser {"new_db_user"}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;(&lt;STRONG&gt;Tip: Add a 30 seconds wait time between creating the database user and resetting the password commands because the space deployment takes some time and we cannot reset the password before that&lt;/STRONG&gt;).&lt;/P&gt;&lt;P&gt;I have also added an automatic email creation in my workflow and inserting database user details into a local table for future analysis.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-08-09 at 20.56.29.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/298901iDFDFD74E03AF67EA/image-size/large?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-08-09 at 20.56.29.png" alt="Screenshot 2025-08-09 at 20.56.29.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-490492647"&gt;Conclusion:&lt;/H3&gt;&lt;P&gt;With this automation, we can create database users in datasphere tenant without even login into datasphere. This workflow provides a more robust way to handle creation and maintenance database users.&amp;nbsp;&lt;/P&gt;&lt;P&gt;I would love to know your thoughts on this workflow in the comments below. Lets explore more opportunities of automation using datasphere CLI.&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-automation-creating-database-user-in-sap-datasphere-using/ba-p/14176606"/>
    <published>2025-08-12T08:06:51.294000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/predictive-stock-transfer-amp-automatic-purchase-re-order-plant-to-plant/ba-p/14170063</id>
    <title>Predictive Stock Transfer &amp; Automatic Purchase Re-Order: Plant-to-Plant A2A Orchestration</title>
    <updated>2025-08-16T14:04:54.954000+02:00</updated>
    <author>
      <name>Yogananda</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/75</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;Use-case: Predictive Stock Transfer &amp;amp; Automatic Purchase Re-Order (Plant-to-Plant A2A scenario driven by real-time APIs)&lt;/STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Yogananda_0-1755345825205.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/301623i7ED9C4CC9FB704BB/image-size/large?v=v2&amp;amp;px=999" role="button" title="Yogananda_0-1755345825205.png" alt="Yogananda_0-1755345825205.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A fast-moving material in Plant A is kept in stock by an end-to-end, automated flow that &lt;/SPAN&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;SPAN&gt;checks forecast demand, &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;looks for internal surplus in nearby plants, and &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;automatically creates stock transfers or purchase requisitions as needed. &lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;Prerequisities and needed&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;SAP S/4HANA Cloud (Inventory &amp;amp; MRP) – On-hand stock, stock in transit, MRP items&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;SAP Integrated Business Planning (IBP) – Demand forecast for FG-100 at Plant A&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;SAP Extended Warehouse Management (EWM) – Real-time on-hand stock incl. quarantine&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;SAP Ariba – Supplier catalog and pricing for external options&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;External supplier catalog (Ariba-like) – External pricing and lead times&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;SAP Integration Suite / SAP Event Mesh – Orchestrates the end-to-end flow and publishes events&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Sequence – how the APIs interact end-to-end&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 0 – Trigger&lt;/STRONG&gt;&lt;BR /&gt;A nightly iFlow in SAP Integration Suite (or SAP Event Mesh) starts the orchestration.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 1 – Demand forecast&lt;/STRONG&gt;&lt;BR /&gt;GET /api/ibp/v1/demandplanning/forecast?material=FG-100&amp;amp;plant=A&amp;amp;weeks=4&lt;BR /&gt;→ Returns 1,200 pcs forecasted demand.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 2 – Current &amp;amp; projected stock in Plant A&lt;/STRONG&gt;&lt;BR /&gt;GET /sap/opu/odata/sap/API_MATERIAL_STOCK_SRV/MaterialStock?material=FG-100&amp;amp;plant=A&lt;BR /&gt;→ 180 pcs unrestricted, 40 pcs blocked.&lt;BR /&gt;GET /sap/opu/odata/sap/API_MRP_COCKPIT_SRV/MrpItems?material=FG-100&amp;amp;plant=A&lt;BR /&gt;&lt;SPAN&gt;Result: confirmed receipts 600 pcs&lt;/SPAN&gt;&lt;BR /&gt;→ Confirmed receipts 600 pcs, so net shortage = 1,200 – 180 – 600 = 420 pcs.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 3 – Locate surplus stock in the network&lt;/STRONG&gt;&lt;BR /&gt;Parallel calls (one per plant):&lt;BR /&gt;GET /sap/opu/odata/sap/API_MATERIAL_STOCK_SRV/MaterialStock?material=FG-100&amp;amp;plant=B&lt;BR /&gt;→ 300 pcs unrestricted.&lt;BR /&gt;GET /sap/opu/odata/sap/API_MATERIAL_STOCK_SRV/MaterialStock?material=FG-100&amp;amp;plant=C&lt;BR /&gt;→ 250 pcs unrestricted.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 4 – Check ATP (available-to-transfer) incl. transit time&lt;/STRONG&gt;&lt;BR /&gt;POST /sap/opu/odata/sap/API_ATP_CHECK_SRV/CheckAvailability&lt;BR /&gt;Body:&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;{ 
"material": "FG-100", 
"plant": "B", 
"demandQty": 300, 
"requiredDate": "2024-06-25" 
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;→ Confirms 300 pcs can be delivered by 2024-06-23.&lt;BR /&gt;Same for Plant C → 120 pcs available by 2024-06-24.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 5 – Decide cheapest internal option&lt;/STRONG&gt;&lt;BR /&gt;Cost service (custom REST on S/4):&lt;BR /&gt;POST /internal/transferCost&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;{ 
"fromPlants": ["B","C"], 
"toPlant": "A", 
"qty": [300,120] 
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;BR /&gt;→ Plant B has the lowest freight cost (€0.05/pc vs €0.07/pc).&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 6 – Create stock transport order (STO)&lt;/STRONG&gt;&lt;BR /&gt;POST /sap/opu/odata/sap/API_STOCK_TRANSPORT_ORDER_SRV/A_StockTransportOrder&lt;BR /&gt;Body:&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;{ 
"SupplyingPlant": "B", 
"ReceivingPlant": "A", 
"Material": "FG-100", 
"OrderQuantity": 300, 
"DeliveryDate": "2024-06-23" 
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;→ STO 4500012345 created.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 7 – Remaining uncovered quantity&lt;/STRONG&gt;&lt;BR /&gt;Shortage after internal transfer = 420 – 300 = 120 pcs.&lt;BR /&gt;Call Ariba to get best external price:&lt;BR /&gt;GET /v2/suppliers/catalog?material=FG-100&amp;amp;qty=120&amp;amp;currency=EUR&lt;BR /&gt;→ Supplier S-987 offers €2.30/pc, lead time 7 days.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 8 – Create purchase requisition in S/4&lt;/STRONG&gt;&lt;BR /&gt;POST /sap/opu/odata/sap/API_PURCHASEREQ_PROCESS_SRV/A_PurchaseRequisitionHeader&lt;BR /&gt;Body:&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;{ 
"Material": "FG-100", 
"Plant": "A", 
"Quantity": 120, 
"DeliveryDate": "2024-06-27", 
"SupplierHint": "S-987" 
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;→ PR 1000123456 created.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 9 – Notify planners&lt;/STRONG&gt;&lt;BR /&gt;Publish event to SAP Event Mesh topic /business/plantA/stockReplenished&lt;BR /&gt;Payload:&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;{ 
"material": "FG-100", 
"sto": "4500012345", 
"pr": "1000123456", 
"status": "covered" 
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Outcome&lt;/STRONG&gt;&lt;BR /&gt;Plant A will receive 300 pcs from Plant B via an automatically created STO and 120 pcs via a purchase requisition with the cheapest external supplier—no manual intervention, no stock-out, and minimal freight cost.&lt;/P&gt;&lt;P&gt;complete code&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;#!/usr/bin/env python3
"""
End-to-end A2A flow:
1. Read demand forecast (IBP)
2. Check stock &amp;amp; MRP in Plant A
3. Search surplus stock in Plants B/C
4. Run ATP check
5. Create STO (cheapest internal)
6. Create PR for remaining qty (Ariba best price)
"""

import os, json, math
from datetime import datetime, timedelta
from dotenv import load_dotenv
from requests import Session
from requests_oauthlib import OAuth2Session
from oauthlib.oauth2 import BackendApplicationClient

load_dotenv()

# ---------- CONFIG ----------
MATERIAL = "FG-100"
PLANT_A  = "A"
PLANTS_SURPLUS = ["B", "C"]
DEMAND_WEEKS   = 4
TRANSPORT_DAYS = 2
# ----------------------------

s = Session()

# ---------- 0.  OAUTH TOKEN for S/4 ----------
def s4_token():
    url = f"{os.getenv('S4_HOST')}/oauth/token"
    r = s.post(url,
               auth=(os.getenv('S4_USER'), os.getenv('S4_PASSWORD')),
               data={'grant_type':'client_credentials'})
    r.raise_for_status()
    return r.json()['access_token']

s.headers.update({'Authorization': f"Bearer {s4_token()}"})

# ---------- 1.  IBP – demand forecast ----------
def ibp_forecast():
    url = (f"{os.getenv('S4_HOST')}/sap/opu/odata/sap/"
           f"API_DEMAND_PLANNING_SRV/DemandForecast")
    params = {
        "$filter": f"Material eq '{MATERIAL}' and Plant eq '{PLANT_A}'",
        "$select": "DemandQuantity",
        "$format": "json"
    }
    r = s.get(url, params=params)
    r.raise_for_status()
    total = sum(item['DemandQuantity'] for item in r.json()['d']['results'])
    return total

demand_qty = ibp_forecast()
print("Demand forecast:", demand_qty)

# ---------- 2.  Stock &amp;amp; MRP ----------
def plant_stock(plant):
    url = (f"{os.getenv('S4_HOST')}/sap/opu/odata/sap/"
           f"API_MATERIAL_STOCK_SRV/MaterialStock")
    params = {
        "$filter": f"Material eq '{MATERIAL}' and Plant eq '{plant}' and "
                   f"StorageLocation ne ''",
        "$format": "json"
    }
    r = s.get(url, params=params)
    r.raise_for_status()
    return sum(item['UnrestrictedStockQuantity']
               for item in r.json()['d']['results'])

def plant_receipts(plant):
    url = (f"{os.getenv('S4_HOST')}/sap/opu/odata/sap/"
           f"API_MRP_COCKPIT_SRV/MrpItems")
    params = {
        "$filter": f"Material eq '{MATERIAL}' and Plant eq '{plant}' and "
                   f"MrpElementCategory eq 'AR'",
        "$format": "json"
    }
    r = s.get(url, params=params)
    r.raise_for_status()
    return sum(item['Quantity'] for item in r.json()['d']['results'])

stock_A = plant_stock(PLANT_A)
receipts_A = plant_receipts(PLANT_A)
shortage = max(0, demand_qty - stock_A - receipts_A)
print("Shortage:", shortage)
if shortage == 0:
    print("No action needed.")
    exit()

# ---------- 3.  Surplus stock ----------
surplus = {}
for p in PLANTS_SURPLUS:
    surplus[p] = plant_stock(p)
print("Surplus:", surplus)

# ---------- 4.  ATP check ----------
def atp_ok(plant, qty, req_date):
    url = (f"{os.getenv('S4_HOST')}/sap/opu/odata/sap/"
           f"API_ATP_CHECK_SRV/CheckAvailability")
    body = {
        "Material": MATERIAL,
        "Plant": plant,
        "DemandQuantity": str(qty),
        "RequiredDate": req_date.isoformat()
    }
    r = s.post(url, json=body)
    r.raise_for_status()
    return r.json()['d']['ConfirmedQuantity'] == str(qty)

best_internal = None
needed = shortage
for plant, qty in surplus.items():
    take = min(qty, needed)
    req = datetime.utcnow().date() + timedelta(days=TRANSPORT_DAYS)
    if atp_ok(plant, take, req):
        best_internal = (plant, take)
        break
if best_internal:
    plant, qty = best_internal
    print(f"Best internal: {qty} from {plant}")

    # ---------- 5.  Create STO ----------
    url = (f"{os.getenv('S4_HOST')}/sap/opu/odata/sap/"
           f"API_STOCK_TRANSPORT_ORDER_SRV/A_StockTransportOrder")
    body = {
        "SupplyingPlant": plant,
        "ReceivingPlant": PLANT_A,
        "Material": MATERIAL,
        "OrderQuantity": str(qty),
        "DeliveryDate": req.isoformat()
    }
    r = s.post(url, json=body)
    r.raise_for_status()
    sto = r.json()['d']['StockTransportOrder']
    print("STO created:", sto)
    shortage -= qty

# ---------- 6.  Ariba – best external price ----------
if shortage &amp;gt; 0:
    client = BackendApplicationClient(client_id=os.getenv('ARIBA_CLIENT_ID'))
    oauth = OAuth2Session(client=client)
    token = oauth.fetch_token(
        token_url=os.getenv('ARIBA_TOKEN_URL'),
        client_id=os.getenv('ARIBA_CLIENT_ID'),
        client_secret=os.getenv('ARIBA_CLIENT_SECRET')
    )
    url = "https://api.ariba.com/v2/suppliers/catalog"
    params = {
        "material": MATERIAL,
        "qty": shortage,
        "currency": "EUR"
    }
    r = oauth.get(url, params=params)
    r.raise_for_status()
    best = min(r.json()['offers'], key=lambda x: float(x['price']))
    print("Best supplier:", best['supplier'], best['price'])

    # ---------- 7.  Create PR ----------
    url = (f"{os.getenv('S4_HOST')}/sap/opu/odata/sap/"
           f"API_PURCHASEREQ_PROCESS_SRV/A_PurchaseRequisitionHeader")
    body = {
        "Material": MATERIAL,
        "Plant": PLANT_A,
        "Quantity": str(shortage),
        "DeliveryDate": (datetime.utcnow().date()
                         + timedelta(days=int(best['leadtime']))).isoformat(),
        "SupplierHint": best['supplier']
    }
    r = s.post(url, json=body)
    r.raise_for_status()
    pr = r.json()['d']['PurchaseRequisition']
    print("PR created:", pr)

print("Flow finished.")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/predictive-stock-transfer-amp-automatic-purchase-re-order-plant-to-plant/ba-p/14170063"/>
    <published>2025-08-16T14:04:54.954000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-amp-python-one-click-to-export-data-of-multiple-views-in/ba-p/14180664</id>
    <title>SAP Datasphere &amp; Python : One click to export data of multiple views in Excel/CSV</title>
    <updated>2025-08-19T08:22:39.531000+02:00</updated>
    <author>
      <name>vikasparmar88</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1528256</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Introduction&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Currently, SAP Datasphere only allows data export through Analytical Models. That means for every fact view, one has to create a separate Analytical Model just to download the data. It’s not ideal, especially when you have many views. Exporting them one by one becomes slow and repetitive.&lt;/P&gt;&lt;P&gt;To solve this,&amp;nbsp; Python script was developed that connects to SAP Datasphere, runs a query on each view from list, and saves the results as Excel files in a local drive path which is predefined. Now&amp;nbsp; just run the script, and it exports everything in one go—no manual effort needed.&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Requirements&amp;nbsp;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;Before running the script, install the following Python packages:&lt;/P&gt;&lt;P&gt;These packages enable secure connectivity to SAP Datasphere and support efficient data handling.&lt;/P&gt;&lt;PRE&gt;pip install hdbcli
pip install sqlalchemy
pip install sqlalchemy-hana&lt;/PRE&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Creating a Database User in SAP Datasphere&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;To enable Python connectivity, create a database user:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Navigate to&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Space Management&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;in SAP Datasphere&lt;/LI&gt;&lt;LI&gt;Select the relevant space&lt;/LI&gt;&lt;LI&gt;Click on&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Database Access&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Create a new user with read access&lt;/LI&gt;&lt;LI&gt;Copy the host, port, username, and password&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Helpful links :&amp;nbsp;&lt;A title="Create DB User in Datasphere Space" href="https://developers.sap.com/tutorials/data-warehouse-cloud-intro8-create-databaseuser..html" target="_blank" rel="noopener noreferrer"&gt;Create DB User in Datasphere Space&lt;/A&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Python&amp;nbsp;Script&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;PRE&gt;# &lt;span class="lia-unicode-emoji" title=":package:"&gt;📦&lt;/span&gt; Install required packages (run these in your terminal or notebook)
# pip install hdbcli              # SAP HANA database client
# pip install sqlalchemy          # SQL toolkit and ORM for Python
# pip install sqlalchemy-hana     # SAP HANA dialect for SQLAlchemy

# &lt;span class="lia-unicode-emoji" title=":books:"&gt;📚&lt;/span&gt; Import necessary libraries
import pandas as pd               # For data manipulation and Excel export
from hdbcli import dbapi          # SAP HANA DBAPI for direct connection
import warnings                   # To suppress unnecessary warnings
import os                         # For file path and directory handling

# &lt;span class="lia-unicode-emoji" title=":prohibited:"&gt;🚫&lt;/span&gt; Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# &lt;span class="lia-unicode-emoji" title=":locked_with_key:"&gt;🔐&lt;/span&gt; Define SAP Datasphere connection parameters
# &lt;span class="lia-unicode-emoji" title=":backhand_index_pointing_right:"&gt;👉&lt;/span&gt; Replace the placeholders below with your actual connection details
db_user = '&amp;lt;your_database_user&amp;gt;'           # User with access to target schema
db_password = '&amp;lt;your_secure_password&amp;gt;'     # Password (handle securely)
db_host = '&amp;lt;your_datasphere_host_url&amp;gt;'     # Host URL (e.g., xyz.hanacloud.ondemand.com)
db_port = 443                               # Default HTTPS port for SAP HANA Cloud
db_schema = '&amp;lt;your_schema_name&amp;gt;'           # Target schema containing views

# &lt;span class="lia-unicode-emoji" title=":file_folder:"&gt;📁&lt;/span&gt; Ensure output folder exists for Excel exports
output_folder = r'C:\Datasphere\Excel export'  # Update path as needed
os.makedirs(output_folder, exist_ok=True)

# &lt;span class="lia-unicode-emoji" title=":clipboard:"&gt;📋&lt;/span&gt; Define list of views to extract data from
# &lt;span class="lia-unicode-emoji" title=":backhand_index_pointing_right:"&gt;👉&lt;/span&gt; Add or modify view names based on your schema
view_list = ['VIEW_1', 'VIEW_2']  # Example views

try:
    # &lt;span class="lia-unicode-emoji" title=":globe_with_meridians:"&gt;🌐&lt;/span&gt; Establish secure connection to SAP Datasphere
    connection = dbapi.connect(
        address=db_host,
        port=db_port,
        user=db_user,
        password=db_password,
        encrypt=True,
        sslValidateCertificate=True
    )
    print("&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;✅&lt;/span&gt; Connected to SAP Datasphere")

    cursor = connection.cursor()

    # &lt;span class="lia-unicode-emoji" title=":repeat_button:"&gt;🔁&lt;/span&gt; Loop through each view and export its data
    for view_name in view_list:
        try:
            # &lt;span class="lia-unicode-emoji" title=":bar_chart:"&gt;📊&lt;/span&gt; Construct and execute SQL query
            sql_query = f'SELECT * FROM "{db_schema}"."{view_name}"'
            print(f"&lt;span class="lia-unicode-emoji" title=":bar_chart:"&gt;📊&lt;/span&gt; Executing query: {sql_query}")
            cursor.execute(sql_query)

            # &lt;span class="lia-unicode-emoji" title=":inbox_tray:"&gt;📥&lt;/span&gt; Fetch results and convert to DataFrame
            rows = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]
            df = pd.DataFrame(rows, columns=columns)

            # &lt;span class="lia-unicode-emoji" title=":outbox_tray:"&gt;📤&lt;/span&gt; Export DataFrame to Excel
            output_path = os.path.join(output_folder, f'{view_name}.xlsx')
            df.to_excel(output_path, index=False)
            print(f"&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;✅&lt;/span&gt; Data from '{view_name}' saved to: {output_path}")

        except dbapi.Error as view_err:
            print(f"&lt;span class="lia-unicode-emoji" title=":cross_mark:"&gt;❌&lt;/span&gt; Error querying '{view_name}': {view_err}")

except dbapi.Error as db_err:
    print(f"&lt;span class="lia-unicode-emoji" title=":cross_mark:"&gt;❌&lt;/span&gt; Database error: {db_err}")
except Exception as ex:
    print(f"&lt;span class="lia-unicode-emoji" title=":warning:"&gt;⚠️&lt;/span&gt; Unexpected error: {ex}")
finally:
    # &lt;span class="lia-unicode-emoji" title=":locked:"&gt;🔒&lt;/span&gt; Ensure connection is closed gracefully
    if 'connection' in locals():
        connection.close()
        print("&lt;span class="lia-unicode-emoji" title=":locked:"&gt;🔒&lt;/span&gt; Connection closed")&lt;/PRE&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Script Capabilities&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Establishes secure connection to SAP Datasphere&lt;/LI&gt;&lt;LI&gt;Executes queries on each listed view&lt;/LI&gt;&lt;LI&gt;Saves data from each view into a separate Excel file&lt;/LI&gt;&lt;LI&gt;Stores all files in a defined folder&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Only connection details and view names need to be updated. The script handles the rest.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;FONT size="5"&gt;&lt;STRONG&gt;One-Click Execution with a .bat File&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;To simplify execution, create a&amp;nbsp;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;RunExport.bat&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;file to run the Python script with a double-click.&lt;/P&gt;&lt;P&gt;Double-clicking the file will automatically export all views to Excel without opening a terminal&lt;/P&gt;&lt;PRE&gt; off
REM Activate Python and run the Export script

REM Change to the script directory
cd /d "C:\Datasphere\Excel export"

REM Run the Python script
python Export.py

REM Pause to keep the window open (optional)
pause&lt;/PRE&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Example&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT size="4"&gt;Before Execution&lt;/FONT&gt;&lt;/STRONG&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="11.jpeg" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/300844iD619132276E2474C/image-size/large?v=v2&amp;amp;px=999" role="button" title="11.jpeg" alt="11.jpeg" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Double Click on "RunExcel.bat" file&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2.jpeg" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/300845iCD8108A14F47A5B1/image-size/large?v=v2&amp;amp;px=999" role="button" title="2.jpeg" alt="2.jpeg" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Post Execution&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="3.jpg" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/300847iD739F0EA7A4E9615/image-size/large?v=v2&amp;amp;px=999" role="button" title="3.jpg" alt="3.jpg" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Conclusion&lt;/STRONG&gt;&lt;/FONT&gt;&lt;BR /&gt;This automation simplifies data exports from SAP Datasphere, especially when working with multiple views.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;It reduces manual effort&lt;/LI&gt;&lt;LI&gt;improves consistency and saves time.&lt;/LI&gt;&lt;LI&gt;ideal for recurring tasks or scheduled jobs.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;For setup support or customization, feel free to connect.&lt;/P&gt;&lt;P&gt;Thanks&lt;/P&gt;&lt;P&gt;Vikas Parmar&lt;/P&gt;&lt;P&gt;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Datasphere/pd-p/73555000100800002141" class="lia-product-mention" data-product="16-1"&gt;SAP Datasphere&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Business+Data+Cloud/pd-p/73554900100700003531" class="lia-product-mention" data-product="1249-1"&gt;SAP Business Data Cloud&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/Python/pd-p/f220d74d-56e2-487e-8e6c-a8cb3def2378" class="lia-product-mention" data-product="126-1"&gt;Python&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-amp-python-one-click-to-export-data-of-multiple-views-in/ba-p/14180664"/>
    <published>2025-08-19T08:22:39.531000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-in-sap-business-data-cloud-a-typical-machine-learning/ba-p/14206612</id>
    <title>SAP Databricks in SAP Business Data Cloud – a Typical Machine Learning Workflow</title>
    <updated>2025-09-04T04:16:17.227000+02:00</updated>
    <author>
      <name>js2</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/41060</uri>
    </author>
    <content>&lt;P&gt;With SAP Databricks you have access to an amazing set of capabilities to work with your BDC Data Products and other data.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_0-1756949550337.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308823i50F7383D319ECA1F/image-size/large?v=v2&amp;amp;px=999" role="button" title="js2_0-1756949550337.png" alt="js2_0-1756949550337.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;This blog post is part of a series exploring SAP Databricks in SAP Business Data Cloud:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-1/ba-p/14166813" target="_self"&gt;&lt;SPAN&gt;Part 1 – SQL analytics with SAP Data Products&lt;BR /&gt;&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-2/ba-p/14167025" target="_self"&gt;Part 2 – Build and deploy Mosaic AI and Agent Tools&lt;/A&gt;&lt;BR /&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-how-to-use-automl-to-forecast-sales-data-part-3/ba-p/14174354" target="_self"&gt;Part 3 – How to use AutoML to forecast sales data&lt;/A&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-3/ba-p/14174201" target="_self"&gt;&lt;SPAN&gt;Part 4 – Connect SAP Data Products with non-SAP data from AWS S3&lt;BR /&gt;&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-building-an-intelligent-enterprise-with-ai-unleashed-part-4/ba-p/14178056" target="_self"&gt;Part 5 – End-to-end integration: SAP Databricks, SAP Datasphere, and SAP Analytics Cloud&lt;/A&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-create-inferences-for-application-integration-with-sap-build/ba-p/14186662" target="_self"&gt;Part 6 – Create inferences for application integration with SAP Build&amp;nbsp;&lt;/A&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Part 7 -&amp;nbsp;SAP Databricks in SAP Business Data Cloud – a Typical Machine Learning Workflow&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;In this blog post we’ll look at the typical workflow you would undertake when trying to train a machine learning model.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Visualise and understand your data&lt;/LI&gt;&lt;LI&gt;Optimise for hyperparameters to tune your model&lt;/LI&gt;&lt;LI&gt;Explore hyperparameter sweep results with MLflow&lt;/LI&gt;&lt;LI&gt;Register the best performing model in MLflow&lt;/LI&gt;&lt;LI&gt;Apply the registered model with batch inference and Databricks Model Serving&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;We’ll use a classic machine learning dataset to predict whether a wine is of high quality or not (&lt;STRONG&gt;&lt;EM&gt;a data classification problem&lt;/EM&gt;&lt;/STRONG&gt;). Of course you have access to a range of SAP Data Products, but by using this dataset you don’t even need a connected S/4HANA system to follow along. The dataset also comes built-in with SAP Databricks.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1759168994"&gt;Wine Quality Classification&lt;/H2&gt;&lt;P&gt;We will train a binary classification model to predict the quality of Portuguese "Vinho Verde" wine based on the wine's physicochemical properties.&lt;/P&gt;&lt;P&gt;The dataset is from the UCI Machine Learning Repository, presented in Modelling wine preferences by data mining from physicochemical properties [Cortez et al., 2009]. And the good news is that this dataset comes preloaded with your Databricks system.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Let’s create a new notebook in our SAP Databricks system and in a new cell we will install some module dependencies.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;%pip install --upgrade -Uqqq mlflow&amp;gt;=3.0 xgboost hyperopt
%restart_python&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Installs:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;The latest &lt;STRONG&gt;&lt;A href="https://mlflow.org/" target="_blank" rel="nofollow noopener noreferrer"&gt;mlflow&lt;/A&gt;&lt;/STRONG&gt; for experiment tracking and general MLOps&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;A href="https://xgboost.readthedocs.io/en/stable/" target="_blank" rel="nofollow noopener noreferrer"&gt;xgboost&lt;/A&gt;&lt;/STRONG&gt; being a fantastic and very popular machine learning model architecture (it dominates many Kaggle competitions)&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;A href="https://hyperopt.github.io/hyperopt/" target="_blank" rel="nofollow noopener noreferrer"&gt;hyperopt&lt;/A&gt;&lt;/STRONG&gt; is a python library used for hyperparameter optimisation. It intelligently searches for the optimal hyperparameters to use when training a machine learning model.&lt;/LI&gt;&lt;LI&gt;The `&lt;STRONG&gt;%restart_python&lt;/STRONG&gt;` magic command it necessary in Databricks notebooks because they use long running Python processes and this ensures that the system path and any newly installed python packages are being used.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Next, we create a cell to connect MLFlow to the Databricks Unity Catalog (it would otherwise use an sqlite data store) and create a few constants that will be used later:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import mlflow
mlflow.set_registry_uri("databricks-uc")

CATALOG_NAME = "workspace"
SCHEMA_NAME = "default"
MODEL_NAME = "wine_quality_classifier"&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1562655489"&gt;Read and Understand the DATA&lt;/H2&gt;&lt;P&gt;Read the white wine quality and red wine quality CSV datasets and merge them into a single DataFrame. &lt;EM&gt;Note theses datasets come with your Databricks system&lt;/EM&gt;.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import pandas as pd

white_wine = pd.read_csv("/databricks-datasets/wine-quality/winequality-white.csv", sep=";")
red_wine = pd.read_csv("/databricks-datasets/wine-quality/winequality-red.csv", sep=";")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Merge the two DataFrames into a single dataset, with a new binary feature "is_red" that indicates whether the wine is red or white.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;red_wine['is_red'] = 1
white_wine['is_red'] = 0

data = pd.concat([red_wine, white_wine], axis=0)

# cast to float as a best practice (avoids dtype issues with NaN's later)
data["is_red"] = data["is_red"].astype("float32")

# Remove spaces from column names
data.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_1-1756949711124.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308824i39D3D0E1BF31443D/image-size/large?v=v2&amp;amp;px=999" role="button" title="js2_1-1756949711124.png" alt="js2_1-1756949711124.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now we have one dataset with a mix of white and red wines.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1495224703"&gt;Visualize data&lt;/H3&gt;&lt;P&gt;Before training a model, explore the dataset using popular charting libraries: Seaborn and Matplotlib.&lt;/P&gt;&lt;P&gt;Plot a histogram of the dependent variable, quality.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import seaborn as sns
sns.displot(data.quality, kde=False)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_2-1756949850129.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308825i87E79215C173B70F/image-size/large?v=v2&amp;amp;px=999" role="button" title="js2_2-1756949850129.png" alt="js2_2-1756949850129.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Looks like quality scores are normally distributed between 3 and 9. Define a wine as high quality if it has quality &amp;gt;= 7.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;high_quality = (data.quality &amp;gt;= 7)
data.quality = high_quality

# cast to float as a best practice (avoids dtype issues with NaN's later)
data["quality"] = data["quality"].astype("float32")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Box plots are useful for identifying correlations between features and a binary label. Create box plots for each feature to compare high-quality and low-quality wines. Significant differences in the box plots indicate good predictors of quality.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import matplotlib.pyplot as plt

dims = (3, 4)

f, axes = plt.subplots(dims[0], dims[1], figsize=(25, 15))
axis_i, axis_j = 0, 0
for col in data.columns:
  if col == 'is_red' or col == 'quality':
    continue # Box plots cannot be used on indicator variables
  sns.boxplot(x=high_quality, y=data[col], ax=axes[axis_i, axis_j])
  axis_j += 1
  if axis_j == dims[1]:
    axis_i += 1
    axis_j = 0&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_3-1756949850144.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308826iF8D13D55625B9536/image-size/large?v=v2&amp;amp;px=999" role="button" title="js2_3-1756949850144.png" alt="js2_3-1756949850144.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In the above box plots, a few variables stand out as good univariate predictors of quality.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;In the alcohol box plot, the median alcohol content of high-quality wines is greater than even the 75th quantile of low-quality wines. High alcohol content is correlated with quality.&lt;/LI&gt;&lt;LI&gt;In the density box plot, low quality wines have a greater density than high quality wines. Density is inversely correlated with quality.&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-1169628479"&gt;&amp;nbsp;&lt;/H2&gt;&lt;H2 id="toc-hId-973114974"&gt;Preprocess data&lt;/H2&gt;&lt;P&gt;Before training a model, check for missing values and split the data into training and validation sets.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;data.isna().any()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_4-1756950017285.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308827i2A0200F5FB07390B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="js2_4-1756950017285.png" alt="js2_4-1756950017285.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;There are no missing values.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-indent-padding-left-60px" style="padding-left : 60px;"&gt;&lt;EM&gt;Note: Often you will need to take advantage of &lt;STRONG&gt;feature engineering&lt;/STRONG&gt; at this step. This is where you can build new features as combinations of your existing data… for example multiplying two existing feature columns together to create a new column may enable the model to find better patterns in the data.&lt;/EM&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-60px" style="padding-left : 60px;"&gt;&lt;EM&gt;For time series data it can be very helpful to generate a new feature column called “Qtr” for example to show which qtr of the year that data point is in based on a date. You will need to experiment with this…&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-776601469"&gt;Prepare the dataset to train a baseline model&lt;/H2&gt;&lt;P&gt;Split the input data into 3 sets:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Train (60% of the dataset used to train the model)&lt;/LI&gt;&lt;LI&gt;Validation (20% of the dataset used to tune the hyperparameters)&lt;/LI&gt;&lt;LI&gt;Test (20% of the dataset used to report the true performance of the model on an unseen dataset)&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from sklearn.model_selection import train_test_split

X = data.drop(["quality"], axis=1)
y = data.quality

# Split out the training data
X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.6, random_state=123)

# Split the remaining data equally into validation and test
X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=123)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-580087964"&gt;Train a baseline model&lt;/H2&gt;&lt;P&gt;This task seems well suited to a &lt;STRONG&gt;random forest classifier&lt;/STRONG&gt;, since the output is binary and there may be interactions between multiple variables.&lt;/P&gt;&lt;P&gt;Build a simple classifier using scikit-learn and use MLflow to keep track of the model's accuracy and save the model for later use.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-indent-padding-left-60px" style="padding-left : 60px;"&gt;&lt;EM&gt;Note: When this cell is executed an MLFlow Experiment will be created by default (automatically) using the full path of this Notebook. In production experiments its best practice to set the Experiment name with&amp;nbsp;mlflow.set_experiment()&amp;nbsp;because you may work on the problem over multiple Notebooks and/or users.&lt;/EM&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import mlflow.pyfunc
import mlflow.sklearn
import numpy as np
import sklearn
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
from mlflow.models.signature import infer_signature
from mlflow.utils.environment import _mlflow_conda_env
import cloudpickle
import time

# The predict method of sklearn's RandomForestClassifier returns a binary classification (0 or 1). 
# The following code creates a wrapper function, SklearnModelWrapper, that uses 
# the predict_proba method to return the probability that the observation belongs to each class. 

class SklearnModelWrapper(mlflow.pyfunc.PythonModel):
  def __init__(self, model):
    self.model = model
    
  def predict(self, context, model_input):
    return self.model.predict_proba(model_input)[:,1]

# mlflow.start_run creates a new MLflow run to track the performance of this model. 
# Within the context, you call mlflow.log_param to keep track of the parameters used, and
# mlflow.log_metric to record metrics like accuracy.
with mlflow.start_run(run_name='rf_baseline_n10'):
  n_estimators = 10
  model = RandomForestClassifier(n_estimators=n_estimators, random_state=np.random.RandomState(123))
  model.fit(X_train, y_train)

  # predict_proba returns [prob_negative, prob_positive], so slice the output with [:, 1]
  predictions_test = model.predict_proba(X_test)[:,1]
  auc_score = roc_auc_score(y_test, predictions_test)
  mlflow.log_param('n_estimators', n_estimators)
  # Use the area under the ROC curve as a metric.
  mlflow.log_metric('auc', auc_score)
  wrappedModel = SklearnModelWrapper(model)
  
  # MLflow contains utilities to create a conda environment used to serve models.
  # The necessary dependencies are added to a conda.yaml file which is logged along with the model.
  conda_env = _mlflow_conda_env(
        additional_conda_deps=None,
        additional_pip_deps=["cloudpickle=={}".format(cloudpickle.__version__), "scikit-learn=={}".format(sklearn.__version__)],
        additional_conda_channels=None,
    )

  # Here we log the model and register it to Unity Catalog in one go.
  # MLflow automatically generates model signatures when you provide
  # an `input_example` during model logging. This works for all model 
  # flavors and is the recommended approach for most use cases.
  # By registering this model to Unity Catalog, you can easily reference
  # the model from anywhere within Databricks.
  # 
  sample_input = X_train.head(5)

  model_version = mlflow.pyfunc.log_model(
    name="rf_baseline",
    python_model=wrappedModel,
    conda_env=conda_env,
    input_example=sample_input,
    registered_model_name=MODEL_NAME,
  )&lt;/code&gt;&lt;/pre&gt;&lt;P class="lia-indent-padding-left-60px" style="padding-left : 60px;"&gt;&lt;EM&gt;Note how the trained model is registered when logging it to MLFlow. This can be done separately as we will see later. If you are running many experiments there is no need to register every model but only the best model.&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;Review the learned feature importances output by the model. As illustrated by the previous boxplots, alcohol and density are important in predicting quality.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;feature_importances = pd.DataFrame(model.feature_importances_, index=X_train.columns.tolist(), columns=['importance'])
feature_importances.sort_values('importance', ascending=False)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_5-1756950458175.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308828i525ABF330AAFB999/image-size/medium?v=v2&amp;amp;px=400" role="button" title="js2_5-1756950458175.png" alt="js2_5-1756950458175.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;You logged the Area Under the ROC Curve (AUC) to MLflow. Click the Experiment icon in the right sidebar to display the Experiment Runs sidebar. The model achieved an AUC of 0.854. A random classifier would have an AUC of 0.5, and higher AUC values are better.&lt;/P&gt;&lt;P&gt;The ROC AUC is a good evaluation metric for binary classification problems like we have here (is good quality / is not good quality).&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Next, assign this model the "Best" tag, and load it into this notebook from Unity Catalog.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from mlflow.tracking import MlflowClient

client = MlflowClient()
client.set_registered_model_alias(MODEL_NAME, "Best", model_version.registered_model_version)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;In Unity Catalog, the model version now has the tag "Best". You can now refer to the model using the path&amp;nbsp;&lt;FONT face="terminal,monaco"&gt;models:/{model_name}@Best&lt;/FONT&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_6-1756950552130.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308830iB8AEA9EA4051F02D/image-size/medium?v=v2&amp;amp;px=400" role="button" title="js2_6-1756950552130.png" alt="js2_6-1756950552130.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-383574459"&gt;Experiment with a new model&lt;/H2&gt;&lt;P&gt;The random forest model performed well even &lt;EM&gt;without&lt;/EM&gt; hyperparameter tuning.&lt;/P&gt;&lt;P&gt;Let's now try and do better and use the xgboost library to train a more accurate model. Run a hyperparameter sweep to train multiple models in parallel, using Hyperopt and Trials. As before, MLflow tracks the performance of each parameter configuration.&lt;/P&gt;&lt;P class="lia-indent-padding-left-60px" style="padding-left : 60px;"&gt;&lt;EM&gt;Note: We must use Trials and not SparkTrials in SAP Databricks, because SparkTrials tries to access the underlying JVM which is not supported on serverless compute.&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;We use the validation dataset here for hyperparameter search.&lt;/P&gt;&lt;P class="lia-indent-padding-left-60px" style="padding-left : 60px;"&gt;&lt;FONT color="#FF0000"&gt;&lt;EM&gt;Note this training cell takes over 20mins to complete!&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from hyperopt import fmin, tpe, hp, Trials, STATUS_OK
from hyperopt.pyll import scope
from math import exp
import mlflow.xgboost
import numpy as np
import xgboost as xgb

search_space = {
  'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),
  'learning_rate': hp.loguniform('learning_rate', -3, 0),
  'reg_alpha': hp.loguniform('reg_alpha', -5, -1),
  'reg_lambda': hp.loguniform('reg_lambda', -6, -1),
  'min_child_weight': hp.loguniform('min_child_weight', -1, 3),
  'objective': 'binary:logistic',
  'seed': 123, # Set a seed for deterministic training
}

def train_model(params):
  # With MLflow autologging, hyperparameters and the trained model are automatically logged to MLflow.
  mlflow.xgboost.autolog()
  with mlflow.start_run(nested=True):
    train = xgb.DMatrix(data=X_train, label=y_train)
    validation = xgb.DMatrix(data=X_val, label=y_val)
    # Pass in the validation set so xgb can track an evaluation metric. XGBoost terminates training when the evaluation metric
    # is no longer improving.
    booster = xgb.train(params=params, dtrain=train, num_boost_round=1000,
                        evals=[(validation, "validation")], early_stopping_rounds=50)
    validation_predictions = booster.predict(validation)
    auc_score = roc_auc_score(y_val, validation_predictions)
    mlflow.log_metric('auc', auc_score)

    # Don't register the model in one-step here - let the hyperparameter search find the best one first.
    #signature = infer_signature(X_train, booster.predict(train))
    #mlflow.xgboost.log_model(booster, name="xgboost", signature=signature)
    sample_input = X_train.head(5)
    mlflow.xgboost.log_model(booster, name="xgboost", input_example=sample_input)
    
    # Set the loss to -1*auc_score so fmin maximizes the auc_score
    return {'status': STATUS_OK, 'loss': -1*auc_score, 'booster': booster.attributes()}

# Use Trials instead of SparkTrials
trials = Trials()

# Run fmin within an MLflow run context so that each hyperparameter configuration is logged as a child run of a parent
# run called "xgboost_models" .
with mlflow.start_run(run_name='xgboost_models'):
  best_params = fmin(
    fn=train_model, 
    space=search_space, 
    algo=tpe.suggest, 
    max_evals=96,
    trials=trials,
  )&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-187060954"&gt;Use MLflow to view the results&lt;/H2&gt;&lt;P&gt;Open up the &lt;EM&gt;Experiments&lt;/EM&gt; sidebar to see the MLflow runs. Click on Date next to the down arrow to display a menu, and select 'auc' to display the runs sorted by the auc metric. The highest auc value is ~0.90.&amp;nbsp;&lt;STRONG&gt;Remember that this is against the validation data&lt;/STRONG&gt;.&lt;/P&gt;&lt;P class="lia-indent-padding-left-60px" style="padding-left : 60px;"&gt;&lt;EM&gt;Hyperparameter tuning (runs) score against the validation dataset!&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;MLflow tracks the parameters and performance metrics of each run. Click the External Link icon at the top of the Experiment Runs sidebar to navigate to the MLflow Runs Table.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId--9452551"&gt;Update the best version of the&amp;nbsp;&lt;FONT face="terminal,monaco"&gt;wine_quality_classifier&lt;/FONT&gt;&amp;nbsp;model&lt;/H2&gt;&lt;P&gt;Earlier, you saved the baseline model to Unity Catalog with the name&amp;nbsp;&lt;FONT face="terminal,monaco"&gt;wine_quality_classifier&lt;/FONT&gt;. Now you can update&amp;nbsp;&lt;FONT face="terminal,monaco"&gt;wine_quality_classifier&lt;/FONT&gt;&amp;nbsp;to a more accurate model from the hyperparameter sweep. Because you used MLflow to log the model produced by each hyperparameter configuration, you can use MLflow to identify the best performing run and save the model from that run to Unity Catalog.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;best_run = mlflow.search_runs(order_by=['metrics.auc DESC']).iloc[0]
print(f'AUC of Best Run: {best_run["metrics.auc"]}')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_7-1756950758865.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308831i3D6D3AA368E57F2C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="js2_7-1756950758865.png" alt="js2_7-1756950758865.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;new_model_version = mlflow.register_model(f"runs:/{best_run.run_id}/model", MODEL_NAME)

# Registering the model takes a few seconds, so add a small delay
import time
time.sleep(15)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Click&amp;nbsp;&lt;STRONG&gt;Models&lt;/STRONG&gt;&amp;nbsp;in the left sidebar to see that the&amp;nbsp;&lt;FONT face="terminal,monaco"&gt;wine_quality_classifier&lt;/FONT&gt;&amp;nbsp;model now has a new versions. Assign the "Best" alias to the new version.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from mlflow.tracking import MlflowClient

client = MlflowClient()
client.set_registered_model_alias(MODEL_NAME, "Best", new_model_version.version)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Clients that call&amp;nbsp;&lt;FONT face="terminal,monaco"&gt;load_model()&lt;/FONT&gt;&amp;nbsp;using the "Best" alias now get the new model.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&amp;gt;&amp;gt; &lt;/STRONG&gt;&lt;STRONG&gt;Let's get the AUC score against the Test data&lt;/STRONG&gt;&lt;STRONG&gt;:&lt;/STRONG&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;model = mlflow.pyfunc.load_model(f"models:/{MODEL_NAME}@Best")

from sklearn.metrics import roc_auc_score
print(f'AUC: {roc_auc_score(y_test, model.predict(X_test))}')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_8-1756950758865.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308832i435B28BDC047F3F0/image-size/medium?v=v2&amp;amp;px=400" role="button" title="js2_8-1756950758865.png" alt="js2_8-1756950758865.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The new version achieved a better score (AUC = 0.90) on the test set.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-141288301"&gt;Batch inference&lt;/H2&gt;&lt;P&gt;There are many scenarios where you might want to evaluate a model on a corpus of new data. For example, you may have a fresh batch of data or may need to compare the performance of two models on the same corpus of data.&lt;/P&gt;&lt;P&gt;Evaluate the model on data stored in a Delta table, using Spark to run the computation in parallel.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# To simulate a new corpus of data, save the existing X_train data to a Delta table. 
# In the real world, this would be a new batch of data.
spark_df = spark.createDataFrame(X_train)

table_name = f"{CATALOG_NAME}.{SCHEMA_NAME}.wine_data"

(spark_df
  .write
  .format("delta")
  .mode("overwrite")
  .option("overwriteSchema",True)
  .saveAsTable(table_name)
)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Load the model into a Spark UDF, so it can be applied to the Delta table.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;apply_model_udf = mlflow.pyfunc.spark_udf(spark, f"models:/{MODEL_NAME}@Best")&lt;/code&gt;&lt;/pre&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# Read the "new data" from the Unity Catalog table
new_data = spark.read.table(f"{CATALOG_NAME}.{SCHEMA_NAME}.wine_data")&lt;/code&gt;&lt;/pre&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from pyspark.sql.functions import struct

# Apply the model to the new data
udf_inputs = struct(*(X_train.columns.tolist()))

new_data = new_data.withColumn(
  "prediction",
  apply_model_udf(udf_inputs)
)

display(new_data)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_9-1756951022597.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308833iDD624907B34C7B23/image-size/large?v=v2&amp;amp;px=999" role="button" title="js2_9-1756951022597.png" alt="js2_9-1756951022597.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Each row now has an associated prediction. Note that the&amp;nbsp;&lt;STRONG&gt;xgboost&lt;/STRONG&gt;&amp;nbsp;function is using the objective "binary:logistic" so the predictions shown here are probabilities.&lt;/P&gt;&lt;P&gt;We also add a is_good_quality column:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from pyspark.sql.functions import col, when

new_data = new_data.withColumn("prediction", col("prediction")[0])

new_data = new_data.withColumn(
  "is_good_quality",
  when(col("prediction") &amp;gt; 0.5, True).otherwise(False)
)
display(new_data)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_10-1756951022605.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308834i46308B60261C3565/image-size/large?v=v2&amp;amp;px=999" role="button" title="js2_10-1756951022605.png" alt="js2_10-1756951022605.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Overwrite the table with the new columns:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;(new_data
  .write
  .format("delta")
  .mode("overwrite")
  .option("overwriteSchema", True)
  .saveAsTable(table_name)
)

# Enable Change Data Feed for the table
# Seems that we can only add this option via SQL!!
spark.sql(f"ALTER TABLE {table_name} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId--55225204"&gt;Serve the model&lt;/H2&gt;&lt;P&gt;To productionize the model for low latency predictions, use Mosaic AI Model Serving to deploy the model to an endpoint. The following cell shows how to use the MLflow Deployments SDK to create a model serving endpoint (which can also be done view the Serving menu on the left).&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;First of all, let’s just show the current model’s name and best version&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# Get the model vesion we tagged as &lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/1725027"&gt;@Best&lt;/a&gt;
from mlflow.tracking import MlflowClient
best_ver = MlflowClient().get_model_version_by_alias(MODEL_NAME, "Best").version
print(MODEL_NAME, best_ver)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_11-1756951367897.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308835i39C1C658C1D6029A/image-size/medium?v=v2&amp;amp;px=400" role="button" title="js2_11-1756951367897.png" alt="js2_11-1756951367897.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Check if any versions of this model are already being served and delete them&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from mlflow.deployments import get_deploy_client

client = get_deploy_client("databricks")
endpoints = client.list_endpoints()

deployed = False
deployed_versions = []
for ep in endpoints:
    ep_detail = client.get_endpoint(ep["name"])
    for entity in ep_detail.get("config", {}).get("served_models", []):
        if entity.get("model_name") == MODEL_NAME or entity.get("model_name").endswith(MODEL_NAME):
            deployed = True
            deployed_versions.append(str(entity.get("model_version")))
            # Delete the serving endpoint if the model is already deployed
            client.delete_endpoint(ep["name"])

if deployed_versions:
    deployed_versions_str = ", ".join(deployed_versions)
else:
    deployed_versions_str = ""

display(spark.createDataFrame([{"model_name": MODEL_NAME, "deployed": deployed, "deployed_versions": deployed_versions_str, "action": "deleting..."}]))&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_12-1756951367899.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308836iCF48545499B7C401/image-size/large?v=v2&amp;amp;px=999" role="button" title="js2_12-1756951367899.png" alt="js2_12-1756951367899.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;&lt;FONT color="#FF0000"&gt;Creating the endpoint can take 5+ minutes...&lt;/FONT&gt;&lt;/EM&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;# the "name" property can't include special chars so we drop the catalog and schema from the model_name

from mlflow.deployments import get_deploy_client

client = get_deploy_client("databricks")
endpoint = client.create_endpoint(
    name="wine-model-endpoint",
    config={
        "served_entities": [
            {
                "name": MODEL_NAME,
                "entity_name": f"{CATALOG_NAME}.{SCHEMA_NAME}.{MODEL_NAME}",
                "entity_version": best_ver,
                "workload_size": "Small",
                "scale_to_zero_enabled": True
            }
        ],
      }
)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId--251738709"&gt;Test the Model Serving Endpoint&lt;/H2&gt;&lt;P&gt;Navigate to User Settings -&amp;gt; Developer and create an Access Token for calling the serving endpoint.&lt;/P&gt;&lt;P&gt;Ensure the model is being served as this can take 5-10 mins.&lt;/P&gt;&lt;P&gt;In the below cells the notebook will:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Ask for your access token&lt;/LI&gt;&lt;LI&gt;Setup a payload (the required inputs for your model)&lt;/LI&gt;&lt;LI&gt;Call the model serving endpoint!&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from getpass import getpass
token = getpass("🔑  Paste your Databricks token: ")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Setup the api call request payload with sample wine quality data:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;payload = {
  "dataframe_split": {
    "columns": [
      "fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar",
      "chlorides", "free_sulfur_dioxide", "total_sulfur_dioxide",
      "density", "pH", "sulphates", "alcohol", "is_red"
    ],
    "data": [
      [7.3, 0.19, 0.27, 1.6, 0.027, 35, 136, 0.99248, 3.38, 0.54, 11, 0],
      [7.8, 0.88, 0.00, 2.6, 0.098, 25, 67, 0.9968, 3.20, 0.68, 9.8, 1]
    ]
  }&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Use the python requests package to make an api call to the SAP Databricks Model Serving Endpoint.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;FONT color="#FF0000"&gt;&lt;EM&gt;Make sure to update the endpoint uri below to match your current SAP Databricks system!&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import os, json, requests

url   = "https://&amp;lt;uri&amp;gt;.cloud.databricks.com/serving-endpoints/wine-model-endpoint/invocations"

resp = requests.post(
    url,
    headers={
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    },
    data=json.dumps(payload),
    timeout=60
)

if resp.status_code == 404:
    print("The endpoint is still deploying.")
else:
    print(resp.json())
    for i, score in enumerate(resp.json()["predictions"], start=1):
        is_good = score &amp;gt;= 0.5          # quality flag
        print(f"Row {i}: {score:.3f}  ➜  Good quality? {is_good}")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="js2_13-1756951569054.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/308837i0BC6D9EA17EBEA20/image-size/large?v=v2&amp;amp;px=999" role="button" title="js2_13-1756951569054.png" alt="js2_13-1756951569054.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;You can use this API endpoint to perform inference from your own applications – as is done with blog post : “&lt;STRONG&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-create-inferences-for-application-integration-with-sap-build/ba-p/14186662" target="_blank"&gt;Part 6 – Create inferences for application integration with SAP Build&amp;nbsp;&lt;/A&gt;&lt;/STRONG&gt;” in the series.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId--448252214"&gt;Conclusion&lt;/H2&gt;&lt;P&gt;We’ve seen in this notebook, if you have followed along, the typical pattern of training a machine learning model.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;It always starts with understanding the data available. Visualising the data with histograms and box plots as shown here can be a great help. Use tools like ChatGPT to assist in the best ways to flesh out information about your data&lt;/LI&gt;&lt;LI&gt;It can often be helpful to create a quick baseline model just to see that we can do better than random luck with the training data&lt;/LI&gt;&lt;LI&gt;Use a hyperparameter optimisation tool to help search for the ideal parameters to tune the best model. Be very careful with the split of training, validation and test data and ensure that there can never be any overlap. Research how to do this if using time-series data&lt;/LI&gt;&lt;LI&gt;Use MLFlow to log training experiments and their generated models. Assign tags to highlight specific or “best” models.&lt;/LI&gt;&lt;LI&gt;Look at Batch Inference or Model Serving.&lt;UL&gt;&lt;LI&gt;The former (batch) being ideal if you want to batch score a table of data and potentially share it back to BDC to be used in analytics models. Make use of scheduled notebooks to keep the data up to date and to train the model on new data&lt;/LI&gt;&lt;LI&gt;Use Model Serving to expose an endpoint for real-time applications to make predictions.&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-databricks-in-sap-business-data-cloud-a-typical-machine-learning/ba-p/14206612"/>
    <published>2025-09-04T04:16:17.227000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/hello-python-my-first-script-in-sap-bas-connecting-to-hana-cloud/ba-p/14228993</id>
    <title>Hello Python: My First Script in SAP BAS Connecting to HANA Cloud</title>
    <updated>2025-09-26T13:05:26.454000+02:00</updated>
    <author>
      <name>Sharathmg</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/174516</uri>
    </author>
    <content>&lt;P&gt;Credit:&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/183"&gt;@Vitaliy-R&lt;/a&gt;&amp;nbsp;Your startup blogs kindled my interest to explore working with Python in SAP ecosystem.&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-python-in-sap-business-application-studio-my-notes/ba-p/14155516" target="_self"&gt;Python in BAS&lt;/A&gt;&amp;nbsp;and&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-jupyter-in-sap-business-application-studio-my-notes/ba-p/14167294" target="_self"&gt;Jupyter in BAS&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;When I first started exploring SAP Business Application Studio (BAS), I was curious about how Python could fit into the SAP landscape. I’ve mostly associated BAS with HANA artefacts(SQLScript, hdbcalculationview, hdbreptask etc.) and CAP artefacts, so writing a Python script inside BAS felt like venturing into new territory. My goal was simple: write a basic script and connect it to SAP HANA Cloud. What I discovered along the way is that Python not only works smoothly in BAS but also makes it easy to interact with HANA Cloud, opening up opportunities for data exploration, automation, and integration in a way that feels both modern and approachable.&lt;/P&gt;&lt;P&gt;Before jumping into the Python script, I had to get my environment ready in SAP Business Application Studio (BAS). Here’s what I set up:&lt;/P&gt;&lt;P&gt;A BAS dev space with a full-stack cloud application space since it supports multiple runtimes, including Python. I had a space with HANA Native Application type. Since the Python tools extension&amp;nbsp;is not added by default, I edited the space to select the Python tools in the additional extension options.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="HANA Dev Space Python extension" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320334iFEC4E0932EFEAC15/image-size/large?v=v2&amp;amp;px=999" role="button" title="HANA_DevSpace_Setting.png" alt="HANA Dev Space Python extension" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;HANA Dev Space Python extension&lt;/span&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;Note: For initial steps to check the Python version, Jupyter notebook and set ups refer to the blogs listed at the start.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Use Case: I attempted to achieve the following:&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Establish a connection to HANA Cloud&lt;/LI&gt;&lt;LI&gt;Execute an SQL query on a table/view&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;Display the results&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;In the BAS, I created a project from Template: SAP HANA Database Project&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Project Template.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320351iEAE035C8FCA7C5B5/image-size/large?v=v2&amp;amp;px=999" role="button" title="Project Template.png" alt="Project Template.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Next step: Create a notebook file.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="notebook file.png" style="width: 339px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320356i8F1BB8DEF9D0E888/image-size/medium?v=v2&amp;amp;px=400" role="button" title="notebook file.png" alt="notebook file.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;My guide to connect to HANA Cloud:&amp;nbsp;&lt;A href="https://help.sap.com/docs/SAP_HANA_CLIENT/f1b440ded6144a54ada97ff95dac7adf/d12c86af7cb442d1b9f8520e2aba7758.html" target="_self" rel="noopener noreferrer"&gt;Connect to HANA Cloud&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;When I first tried importing hdbcli into my Jupyter Notebook within BAS, I ran into the same ModuleNotFoundError. Even though I had already installed hdbcli In the terminal, the notebook kernel wasn’t recognizing it. On some search and prompting with GPT( &lt;span class="lia-unicode-emoji" title=":beaming_face_with_smiling_eyes:"&gt;😁&lt;/span&gt;), I understood that it's a common issue because Jupyter can run in a different Python environment than the terminal. The fix was simple: I ran&lt;/P&gt;&lt;PRE&gt;import sys
!{sys.executable} -m pip install hdbcli&lt;/PRE&gt;&lt;P&gt;directly in a notebook cell. This ensures that the HANA client is installed in the same environment as the notebook kernel. After this step, I could successfully import dbapi and connect to HANA Cloud without any errors. It was a small but important lesson about Python environments in BAS, especially when using Jupyter.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="hdbcli Module Not found.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320378i62AF858DA44FE00C/image-size/large?v=v2&amp;amp;px=999" role="button" title="hdbcli Module Not found.png" alt="hdbcli Module Not found.png" /&gt;&lt;/span&gt;With the hdbcli package installed and working in my Jupyter Notebook, I was ready to write my first Python script to connect to SAP HANA Cloud.&lt;/P&gt;&lt;P&gt;In the next cell, I imported hdbcli in this notebook.&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import hdbcli
print(hdbcli.__file__)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="import hdbcli.png" style="width: 854px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320388iF426637D8D8CCB0F/image-size/large?v=v2&amp;amp;px=999" role="button" title="import hdbcli.png" alt="import hdbcli.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;The next step was to&amp;nbsp;gain access to the dbapi interface, which allows you to establish connections, execute SQL queries, and fetch results from your HANA Cloud instance. This simple import is the gateway to working with HANA directly from Python.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from hdbcli import dbapi&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The next step is to establish a connection to your HANA Cloud instance. This requires specifying the host, port, username, and password.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="hana cloud connection.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320408i84F10DA5613166DC/image-size/large?v=v2&amp;amp;px=999" role="button" title="hana cloud connection.png" alt="hana cloud connection.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;After connecting, you can create a cursor object to execute SQL statements. An SQL statement, preferably a Select Query to test the retrieval of data from HANA Cloud. In my case, I used a Select with count on the number of records in a view. Once the variables were ready, execute the connection cursor object.&lt;/P&gt;&lt;P&gt;Note: in the SQL variable, use single quotes and a semicolon at the end of the query. (beginner tip&amp;nbsp;&lt;span class="lia-unicode-emoji" title=":slightly_smiling_face:"&gt;🙂&lt;/span&gt; )&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Execution Cursor.png" style="width: 799px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320427iB0929785AAAB7257/image-size/large?v=v2&amp;amp;px=999" role="button" title="Execution Cursor.png" alt="Execution Cursor.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now is the time to test the data retrieval from the script and compare it with the Database Explorer.&lt;/P&gt;&lt;P&gt;Drum roll....&lt;span class="lia-unicode-emoji" title=":drum:"&gt;🥁&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data in DB explorer.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320447i3D6BB255F8FDBF13/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data in DB explorer.png" alt="Data in DB explorer.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-right" image-alt="Data in Script.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320448iDA977EF3358B8FF8/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data in Script.png" alt="Data in Script.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Hurray&amp;nbsp;&lt;span class="lia-unicode-emoji" title=":party_popper:"&gt;🎉&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Completing my first Python script in SAP Business Application Studio and connecting it to HANA Cloud was an exciting milestone. From the initial curiosity to the small hurdles like installing hdbcli in the notebook and finally seeing my script return results, every step felt like a mini victory.&lt;/P&gt;&lt;P&gt;That simple output from HANA Cloud made all the effort worthwhile and gave me a real sense of accomplishment.&lt;/P&gt;&lt;P&gt;This experience has sparked my curiosity to explore more complex queries, data analysis, and automation using Python in SAP.&lt;/P&gt;&lt;P&gt;I hope my journey inspires others to take that first step and discover how fun and powerful working with Python and HANA Cloud can be.&lt;/P&gt;&lt;P&gt;Chao.&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/hello-python-my-first-script-in-sap-bas-connecting-to-hana-cloud/ba-p/14228993"/>
    <published>2025-09-26T13:05:26.454000+02:00</published>
  </entry>
</feed>
