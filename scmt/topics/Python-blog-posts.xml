<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/Python-blog-posts.xml</id>
  <title>SAP Community - Python</title>
  <updated>2025-07-20T23:11:38.307137+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/Python/pd-p/f220d74d-56e2-487e-8e6c-a8cb3def2378" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>Python blog posts in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/sap-datasphere-external-access-overview-apis-cli-and-sql/ba-p/14078591</id>
    <title>SAP Datasphere External Access Overview: APIs, CLI and SQL</title>
    <updated>2025-04-22T10:55:27.647000+02:00</updated>
    <author>
      <name>henri_hosang</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1395426</uri>
    </author>
    <content>&lt;H1 id="toc-hId-1579351488"&gt;&lt;FONT color="#808080"&gt;&lt;STRONG&gt;Querying and Managing SAP Datasphere with Python, Postman, Open SQL and the Command Line Interface&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/H1&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1382837983"&gt;Introduction&lt;/H1&gt;&lt;P&gt;This blog post aims to provide an overview of different external tooling options for SAP Datasphere as these resources are scattered across different Help pages, the Business Accelerator Hub and other community Blogs. This blog post does not aim to be exhaustive or cover every detail, but lists the different possibilities to perform actions in Datasphere or create, read, update or delete objects and data using external tools like Postman, Python, the CLI or open SQL.&lt;/P&gt;&lt;P&gt;Here is an overview of Topics covered in the Blog Post:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Rest API: TLS server certificates API; Connections API; Data Sharing Cockpit API and SCIM 2.0 API for user management&lt;/LI&gt;&lt;LI&gt;Command Line Interface: Manage User Access, Spaces, Modeling Objects, the Data Marketplace, Tasks and Task Chains as well as Connectivity&lt;/LI&gt;&lt;LI&gt;OData API: Get assets from the SAP Datasphere Catalog; Consume the datasets and metadata from consumable data assets.&lt;/LI&gt;&lt;LI&gt;Open SQL schema and ODBC/JDBC: Query the SAP HANA Cloud database with database users using SQL Statements like SELECT; CREATE; UPDATE; INSERT and ALTER Tables and Views.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Every Agenda Item is split into two sections: What? and How? The first section explains which use cases are supported by the shown technology and provides links to the relevant documentation. Second, a simple example is shown for each technology using the appropriate tools like Postman, Python, SQL or the CLI. This example can then easily be adapted and extended for future options explained in the What? section following the documentation. Additionally further links are provided to gain a deeper understanding of possible use case scenarios. Often the same action can be achieved by multiple options. E.g. It is possible to create and list connections via the CLI or via the REST API.&lt;/P&gt;&lt;P&gt;Of course, there is also the option to integrate SAP Datasphere directly with third party applications via e.g. OData or ODBC/JDBC connections or pushing the data to target systems like AWS S3 or GCP Cloud Storage using Replication Flows. However, these options are not part of this blog post, because application specific scenarios must be considered.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1186324478"&gt;REST API&lt;/H1&gt;&lt;P&gt;REST APIs are based on a standard architecture that uses HTTP methods like GET, POST, PUT, and DELETE. They allow you to perform actions in Datasphere regarding User &amp;amp; Role Management, Connection &amp;amp; Certificate Management and the usage of the Data Sharing Cockpit. You can call them via an API Platform such as Postman or via Programming Languages like Python or Type Script.&lt;/P&gt;&lt;H2 id="toc-hId-1118893692"&gt;&lt;STRONG&gt;What?&lt;/STRONG&gt;&lt;/H2&gt;&lt;UL&gt;&lt;LI&gt;Use the Certificates API to create, read and delete TLS server certificates to Datasphere - &lt;A href="https://api.sap.com/api/CertificateManagement/overview" target="_blank" rel="noopener noreferrer"&gt;https://api.sap.com/api/CertificateManagement/overview&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;Use the Connections API to list, validate, delete, update or create connections in a space - &lt;A href="https://api.sap.com/api/ConnectionManagement/overview" target="_blank" rel="noopener noreferrer"&gt;https://api.sap.com/api/ConnectionManagement/overview&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;Use the Data Sharing Cockpit API to maintain your data provider profile; create and edit data product; manage licenses; create and publish releases and manage contexts - &lt;A href="https://api.sap.com/api/DataSharingCockpit/overview" target="_blank" rel="noopener noreferrer"&gt;https://api.sap.com/api/DataSharingCockpit/overview&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;Use the SCIM 2.0 API to create, read, modify and delete users; add roles and get information on the identity provider - &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/9f804b8efa8043539289f42f372c4862/1ca8c4a9467f43df9ae6d4ed3734f05a.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/9f804b8efa8043539289f42f372c4862/1ca8c4a9467f43df9ae6d4ed3734f05a.html&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-922380187"&gt;&lt;STRONG&gt;How?&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;Using the REST API involves generally two steps.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Creating an OAuth 2.0 Client to Authenticate Against SAP Datasphere&lt;/LI&gt;&lt;LI&gt;Using Postman or another technology to obtain an access token and then calling the REST API with the access token&lt;/LI&gt;&lt;/OL&gt;&lt;H3 id="toc-hId-854949401"&gt;1 Creating an OAuth 2.0 Client to Authenticate Against SAP Datasphere&lt;/H3&gt;&lt;P&gt;To create an OAuth2.0 Client users need the DW Administrator role. Under System -&amp;gt; Administration -&amp;gt; App Integration a new OAuth Client can be added.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_0-1744874906487.png" style="width: 593px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251773iA167760436FF3ABA/image-dimensions/593x304?v=v2" width="593" height="304" role="button" title="henri_hosang_0-1744874906487.png" alt="henri_hosang_0-1744874906487.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In the OAuth Client configuration enter a name and choose the following settings:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Purpose: API Access&lt;/LI&gt;&lt;LI&gt;Access: Select the appropriate access (e.g. User Provisioning if you want to use the SCIM 2.0 API)&lt;/LI&gt;&lt;LI&gt;Security: Client Credentials&lt;/LI&gt;&lt;LI&gt;Token Lifetime&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Click Add and copy the Client ID and Client Secret from the next screen (the client secret can only be copied now and you need to create a new client if you lose it!).&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_1-1744874906492.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251772iC1BB70D5DED411B8/image-size/medium?v=v2&amp;amp;px=400" role="button" title="henri_hosang_1-1744874906492.png" alt="henri_hosang_1-1744874906492.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Additionally, please copy the Authorization URL and Token URL from the App Integration overview as they are needed later to authenticate.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_2-1744874906497.png" style="width: 737px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251774iAC8248F25411BEFD/image-dimensions/737x232?v=v2" width="737" height="232" role="button" title="henri_hosang_2-1744874906497.png" alt="henri_hosang_2-1744874906497.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-658435896"&gt;2 Using Postman or another technology to obtain an access token and calling the REST API&lt;/H3&gt;&lt;P&gt;Now we can use the Authorization URL, Token URL, Client ID and Client Secret to first obtain an access token and then call the REST API that we need.&lt;/P&gt;&lt;P&gt;The next steps will be shown in (1) &lt;STRONG&gt;Postman&lt;/STRONG&gt; and (2) &lt;STRONG&gt;Python&lt;/STRONG&gt; as two alternative approaches&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;(1) Postman&lt;/STRONG&gt;: Create a collection and a new GET request within that collection. Provide the copied token URL and add grant_type=client_credentials in the Parameters.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_3-1744874906500.png" style="width: 781px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251776i61D60BEBFFD8C848/image-dimensions/781x186?v=v2" width="781" height="186" role="button" title="henri_hosang_3-1744874906500.png" alt="henri_hosang_3-1744874906500.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Then switch to the Authorization tab use Authorization type Basic Auth and enter the Client ID as username and the client secret as password. You can now send the request and get the access_token with its lifetime as result. Copy the token for the next step.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_4-1744874906512.png" style="width: 786px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251777iDE72C8AE7699B052/image-dimensions/786x408?v=v2" width="786" height="408" role="button" title="henri_hosang_4-1744874906512.png" alt="henri_hosang_4-1744874906512.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now we can call the REST API endpoint as documented in the resources linked in the &lt;STRONG&gt;What?&lt;/STRONG&gt; Section (mainly &lt;A href="https://api.sap.com/package/sapdatasphere/rest" target="_blank" rel="noopener noreferrer"&gt;https://api.sap.com/package/sapdatasphere/rest&lt;/A&gt;). For this simple example we will just get a list of connections from one of the Datasphere space by calling this endpoint:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_5-1744874906513.png" style="width: 767px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251775iF6CEF9816AAA8682/image-dimensions/767x46?v=v2" width="767" height="46" role="button" title="henri_hosang_5-1744874906513.png" alt="henri_hosang_5-1744874906513.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Follow these steps:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Create a new GET request in Postman&lt;/LI&gt;&lt;LI&gt;Enter the URL &lt;SPAN&gt;&lt;A target="_blank" rel="noopener"&gt;https://&amp;lt;host&amp;gt;/api/v1/datasphere/spaces/&amp;lt;spaceId&amp;gt;/connections&lt;/A&gt;&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;Host refers to the URL of your Datasphere Host; it can be copied from the browser. Copy everything until the first “/”&lt;/LI&gt;&lt;LI&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_6-1744874906515.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251778iF0DDCD5226D21DBA/image-size/medium?v=v2&amp;amp;px=400" role="button" title="henri_hosang_6-1744874906515.png" alt="henri_hosang_6-1744874906515.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;The space ID is the ID of the space from which you want to get the connections. You can see available spaces if you navigate to Space Management in Datasphere.&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;Add x-sap-sac-custom-auth=true in the Headers section in Postman&lt;/LI&gt;&lt;LI&gt;Specify the Auth Type as Bearer Token by using the Token from the previous step.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_7-1744874906519.png" style="width: 759px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251779iE43A99626A53A4F9/image-dimensions/759x184?v=v2" width="759" height="184" role="button" title="henri_hosang_7-1744874906519.png" alt="henri_hosang_7-1744874906519.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once you send the request you get a list of all connections from that space returned. You can now adapt this example to use any other REST API mentioned above by simply changing the URL + HTTP Method to the one specified in the documentation and adding relevant parameters.&lt;/P&gt;&lt;P&gt;Note: If you want to use the SCIM 2.0 API to create, modify or delete users you also need a so called CSRF Token by calling &lt;SPAN&gt;&lt;A target="_blank" rel="noopener"&gt;https://&amp;lt;host&amp;gt;/api/v1/csrf&lt;/A&gt;&lt;/SPAN&gt;&amp;nbsp;with the obtained access token and x-sap-sac-custom-auth=true and x-csrf-token=fetch as Headers.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;(2) Python&lt;/STRONG&gt;: The steps in Python are like the ones in Postman, using the same credentials and parameters. First an access_token needs to be obtained and then the connections API is called.&lt;/P&gt;&lt;P&gt;To simplify the scenario the Authorization URL, Token URL, Client ID and Client Secret are stored in global variables. However, in a productive scenario a secret store or environment variables should be used instead.&lt;/P&gt;&lt;P&gt;For this demonstration Python 3.9 is used. The only import that is needed is the requests library to make the API calls. Additionally, the credentials are stored as variables as mentioned. That is all for the setup.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import requests

token_url = xxx
username = xxx
password = xxx&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;To get the list of connections again two calls are made. (1) to get the access_token and (2) to the actual connections API endpoint. Each call is a function.&lt;/P&gt;&lt;P&gt;The get_token function specifies the authentication context using the client ID as username and the client secret as password. Via the request library the token_url is called with the defined authentication context. If the call was successful (code 200) the access_token is read from the API response.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;def get_token():
    
    # Use basic authentication with username and password
    auth = requests.auth.HTTPBasicAuth(username, password)
    
    # API call
    response = requests.get(token_url, auth=auth)
    
    # Check result and return
    if response.status_code == 200:
        return response.json()['access_token']
    else:
        print("HTTP Error occurred", response.status_code)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;In the second function the first function is called to get the access_token. Then it is passed on with the header x-sap-sac-custom-auth=true to the URL &lt;SPAN&gt;&lt;A target="_blank" rel="noopener"&gt;https://&amp;lt;host&amp;gt;/api/v1/datasphere/spaces/&amp;lt;spaceId&amp;gt;/connections&lt;/A&gt;&lt;/SPAN&gt;&amp;nbsp;as shown in the postman section.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;def get_connections():
    connection_url = xxx

    # Get Token
    bearer_token = get_token()
    
    # Define headers and use bearer  token as authentication method
    headers = {
        "Authorization" : f"Bearer {bearer_token}",
        "x-sap-sac-custom-auth" : "true",
        "Content-Type": "application/json"
    }
    
    # API call
    response = requests.get(connection_url, headers=headers)
    
    # Check result and return
    if response.status_code == 200:
        return response.json()
    else:
        print("HTTP Error occurred", response.reason)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;As with the Postman option you can now adapt this example to use any other REST API mentioned above by simply changing the URL + HTTP Method to the one specified in the documentation and adding relevant parameters.&lt;/P&gt;&lt;P&gt;To use the SCIM API, first a csrf token needs to be generated and then send in combination with the bearer token as headers to the Endpoint for deleting, modifying or creating users in the system. Instead of calling the API Endpoints directly from requests, a session needs to be created via &lt;EM&gt;requests.Session()&lt;/EM&gt; to obtain the csrf token and call the create user Endpoint from one session.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-203756953"&gt;Command Line Interface (CLI)&lt;/H1&gt;&lt;P&gt;The Command Line Interface is a business user friendly toolset to achieve a variety of tasks in Datasphere without needing to write any code or use API platforms. Datasphere end users can run simple one-line statements in the command line after authenticating to perform admin tasks as well as to work with modeling objects in Datasphere.&lt;/P&gt;&lt;H2 id="toc-hId-136326167"&gt;&lt;STRONG&gt;What?&lt;/STRONG&gt;&lt;/H2&gt;&lt;UL&gt;&lt;LI&gt;Work with Global &amp;amp; Scoped Roles; List, Add, Remove Users from Global and Scoped Roles; Manage Users&amp;nbsp;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/3a3d0ef3d4954797acac12afbcf9ab5d.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/3a3d0ef3d4954797acac12afbcf9ab5d.html&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;List, Read, Create, Update and Delete Spaces; Manage Space Users and Database Users; Set Space Priorities and Statement Limits - &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/5eac5b71e2d34c32b63f3d8d47a0b1d0.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/5eac5b71e2d34c32b63f3d8d47a0b1d0.html&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;List, Read, Create, Update and Delete Modeling Objects via the Command Line - &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/6f5c65f209004751aa48f9682ee2ec45.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/6f5c65f209004751aa48f9682ee2ec45.html&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;Manage the Data Providers, Products, Licenses, Releases and Contexts of the Data Marketplace via the Command Line - &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/5a815f6c21e9468eb96d0be95b9d2def.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/5a815f6c21e9468eb96d0be95b9d2def.html&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;Manage Tasks and Task Chains via the Command Line - &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/2b26a31f197444dea314495bc0008eae.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/2b26a31f197444dea314495bc0008eae.html&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;List, Upload and Delete TLS Certificates; List, Read, Create, Validate, Edit and Delete Connections - &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/8eb811898d1049fbb426339e44a2eb70.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/8eb811898d1049fbb426339e44a2eb70.html&lt;/A&gt;&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId--60187338"&gt;&lt;STRONG&gt;How?&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;To use the command line with SAP Datasphere it is recommended to use an OAuth 2.0 Client with interactive usage. The setup is quite similar to the one shown above for REST API, but some parameters have to be set up differently.&lt;/P&gt;&lt;P&gt;Again, to create an OAuth2.0 Client users need the DW Administrator role. Under System -&amp;gt; Administration -&amp;gt; App Integration a new OAuth Client can be added.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_8-1744874906534.png" style="width: 749px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251780i5249284A563C7866/image-dimensions/749x384?v=v2" width="749" height="384" role="button" title="henri_hosang_8-1744874906534.png" alt="henri_hosang_8-1744874906534.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In the OAuth Client configuration different settings are used to use that Client with the CLI instead of REST API:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Purpose: Interactive Usage&lt;/LI&gt;&lt;LI&gt;Authorization Grant: Authorization Code&lt;/LI&gt;&lt;LI&gt;Redirect URI: This is the URI the user will be redirected to after authorization. For the Command Line Interface, you can simply start a localhost server on your machine using &lt;A href="http://localhost:8080" target="_blank" rel="noopener nofollow noreferrer"&gt;&lt;EM&gt;http://localhost:8080&lt;/EM&gt;&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;Token Lifetime&lt;/LI&gt;&lt;LI&gt;Refresh Token Lifetime&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Click Add and copy the Client ID and Client Secret from the next screen (the client secret can only be copied now and you need to create a new client if you lose it!).&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_9-1744874906538.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251782i44B6025DDA336E0E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="henri_hosang_9-1744874906538.png" alt="henri_hosang_9-1744874906538.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Additionally, please copy the Authorization URL and Token URL from the App Integration overview as they are needed later to authenticate.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_10-1744874906544.png" style="width: 569px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251783i8FA0E5D8D1E68C76/image-dimensions/569x179?v=v2" width="569" height="179" role="button" title="henri_hosang_10-1744874906544.png" alt="henri_hosang_10-1744874906544.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--202849493"&gt;Using the Command Line Interface directly&lt;/H3&gt;&lt;P&gt;To use the CLI for Datasphere Node.js &amp;gt;= 18 and &amp;lt;= 22 as well as npm &amp;gt;= 8 and &amp;lt;= 10 need to be installed. Npm is automatically installed with Node.js. Node.js can be downloaded from &lt;A href="https://nodejs.org/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://nodejs.org/&lt;/A&gt;&lt;/P&gt;&lt;P&gt;You can test the installation by running the following commands in your command line&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;$ node -v
$ npm -v&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Then run the following command to install the datasphere related commands:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;$ npm install -g /datasphere-cli&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Some packages will be installed and you can check the successful installation by running&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;$ datasphere –version&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Here is the summary of the installation commands:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="henri_hosang_11-1744874906546.png" style="width: 470px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251781i94A932B6BEC496A9/image-dimensions/470x167?v=v2" width="470" height="167" role="button" title="henri_hosang_11-1744874906546.png" alt="henri_hosang_11-1744874906546.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Next step is to log in to Datasphere. As a best practice, make sure to always clean host, cache and secrets before logging in again. However, if this is the first time you are using the CLI no credentials will be available. Run these commands&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;$ datasphere config host clean
$ datasphere config cache clean
$ datasphere config secrets reset&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Then log in to Datasphere using the &lt;EM&gt;datasphere login&lt;/EM&gt; command. You will be prompted with the necessary credentials for log in. For this step you need the host URL you see when opening Datasphere in your browser (see above). Additionally, client ID and client secret that are copied from the OAuth client are needed.&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;$ datasphere login
✔ URL of the system to connect to: … &amp;lt;host&amp;gt;
✔ Please enter your client ID: … &amp;lt;client ID&amp;gt;
✔ Please enter your client secret: … &amp;lt;client secret&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;After entering the client secret a browser window to the redirect URI provided in the OAuth Client will open and the log in will be automatically handled. You can continue in the CLI, where you are logged in now. Just start running commands to Datasphere documented in the What? Section above. Here is a simple example to get all the spaces in your Datasphere Tenant.&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;$ datasphere spaces list -H &amp;lt;host&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Here are all commands:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="henri_hosang_12-1744874906548.png" style="width: 505px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251784i0ADF8C3DEEE52F4F/image-dimensions/505x192?v=v2" width="505" height="192" role="button" title="henri_hosang_12-1744874906548.png" alt="henri_hosang_12-1744874906548.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Note: For now you need to provide the host URL of the Datasphere Tenant via the -H option in every command. But the host can also be set as default and then it must not be used in every statement:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;$ datasphere config host set &amp;lt;host&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;And now you can run&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;$ datasphere spaces list&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Once you are done, log out from Datasphere again&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;$ datasphere logout&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="henri_hosang_13-1744874906549.png" style="width: 563px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251787iCFEDD262AD7F4680/image-dimensions/563x152?v=v2" width="563" height="152" role="button" title="henri_hosang_13-1744874906549.png" alt="henri_hosang_13-1744874906549.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;There are many more options when using the CLI to work with Datasphere. E.g. the credentials can be stored in a secrets file, so you don’t have to paste them every time you log in. Additionally, a refresh token can be extracted once you are logged in and passed on when running a command, so you do not have to log in at the beginning of every session. Please refer to the documentation for more details.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--399362998"&gt;Using the Command Line Interface within a scripting language&lt;/H3&gt;&lt;P&gt;While this introduction uses the CLI directly, it should be mentioned that users can also use scripting languages like Python to automate the CLI usage by calling the commands directly from their code. In Python, the &lt;EM&gt;subprocess&lt;/EM&gt; library is used to call CLI commands from code. This is a simple example to log in and list all available spaces in Datasphere. The credentials are stored in a JSON file:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import subprocess

subprocess.run("datasphere config host clean", shell=True)
subprocess.run("datasphere config cache clean", shell=True)
subprocess.run("datasphere config secrets reset", shell=True)

subprocess.run("datasphere login --host &amp;lt;host&amp;gt; --options-file ./dsp_cli_secrets.json", shell=True)

subprocess.run("datasphere spaces list -H &amp;lt;host&amp;gt;", shell=True)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Using this option is handy if you want to automate running CLI commands and chaining multiple commands together. An example would be to first get all spaces, then use a for loop to get all connections per space and use another command to validate all the connections.&lt;/P&gt;&lt;P&gt;Here is a great blog post that shows how you can combine the power of CLI and Python to generate views in Datasphere: &lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/sap-datasphere-view-generation-with-python-and-the-command-line-interface/ba-p/13558181" target="_blank"&gt;https://community.sap.com/t5/technology-blogs-by-sap/sap-datasphere-view-generation-with-python-and-the-command-line-interface/ba-p/13558181&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId--9070489"&gt;OData API&lt;/H1&gt;&lt;P&gt;So far REST APIs and the CLI are shown to perform certain actions in Datasphere. But what if you want to consume and report on data within the Datasphere Tenant? In that case, you can use the next two options: OData API and the OpenSQL schema can be used.&lt;/P&gt;&lt;H2 id="toc-hId--498987001"&gt;&lt;STRONG&gt;What?&lt;/STRONG&gt;&lt;/H2&gt;&lt;UL&gt;&lt;LI&gt;Catalog: List Spaces and Assets exposed for consumption&lt;UL&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/43509d67b8b84e66a30851e832f66911/7a453609c8694b029493e7d87e0de60a.html#loio7a453609c8694b029493e7d87e0de60a__section_catalog_service" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/43509d67b8b84e66a30851e832f66911/7a453609c8694b029493e7d87e0de60a.html#loio7a453609c8694b029493e7d87e0de60a__section_catalog_service&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://api.sap.com/api/DatasphereCatalog/resource/SAP_Datasphere_Consumption_Catalog" target="_blank" rel="noopener noreferrer"&gt;https://api.sap.com/api/DatasphereCatalog/resource/SAP_Datasphere_Consumption_Catalog&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;Consumption: Retrieve Analytic Models, retrieve views exposed for consumption, retrieve metadata of Assets&lt;UL&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/43509d67b8b84e66a30851e832f66911/7a453609c8694b029493e7d87e0de60a.html#loio7a453609c8694b029493e7d87e0de60a__section_analytical_data" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/43509d67b8b84e66a30851e832f66911/7a453609c8694b029493e7d87e0de60a.html#loio7a453609c8694b029493e7d87e0de60a__section_analytical_data&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://api.sap.com/api/DatasphereConsumption/overview" target="_blank" rel="noopener noreferrer"&gt;https://api.sap.com/api/DatasphereConsumption/overview&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId--695500506"&gt;&lt;STRONG&gt;How?&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;As mentioned, the OData API is mainly used to consume objects from Datasphere. It can be accessed directly from the browser, via an API Platform like Postman, a scripting language like Python or it can be used by 3rd party applications like SAP Analytics Cloud and PowerBI to consume data from Datasphere in a reporting scenario.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;H3 id="toc-hId--1185417018"&gt;Using the Browser to consume OData Requests&lt;/H3&gt;&lt;P&gt;If you are privileged to see objects in Datasphere you can directly access the OData API from the browser, you are already logged in to Datasphere, since the log in context is just reused for the OData API without any additional setup. If there is e.g. an analytic model that you build and want to consume via OData, you can directly do so by just opening a new window in the browser and pasting the OData request URL. The OData request URL can be crafted yourself by referring to the documentation or you can use the Generate OData request available from the Datasphere UI for all objects exposed for consumption.&lt;/P&gt;&lt;P&gt;To generate the OData request, open the asset from the data builder. If it is exposed for consumption (Analytic Models are exposed by default; Views have a switch in the details pane to expose them) an icon appears in the header section under “Tools” to generate the OData request.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_14-1744874906550.png" style="width: 488px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251786i2DD050F41A39EB8A/image-dimensions/488x76?v=v2" width="488" height="76" role="button" title="henri_hosang_14-1744874906550.png" alt="henri_hosang_14-1744874906550.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;A pop-up opens to customize the OData URL. In the top, there is a selection if the actual data of the object should be received or its metadata. Additionally, variables and query parameters can be defined – as shown below. If the generate OData request is opened to retrieve data and the default settings are used the OData request URL look like this:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Exposed Views: &amp;lt;host&amp;gt;/api/v1/dwc/consumption/&lt;STRONG&gt;relational&lt;/STRONG&gt;/&amp;lt;space Id&amp;gt;/&amp;lt;object technical name&amp;gt;/&amp;lt;object technical name&amp;gt;&lt;/LI&gt;&lt;LI&gt;Exposed Analytic Models: &amp;lt;host&amp;gt;/api/v1/dwc/consumption/&lt;STRONG&gt;analytical&lt;/STRONG&gt;/&amp;lt;space Id&amp;gt;/&amp;lt;object technical name&amp;gt;/&amp;lt;object technical name&amp;gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;As one can see the relational URL is used for views while the analytical is used for analytic models. This is because analytic models allow for more features like restricted measures and exception aggregations that are processed like a multidimensional statement and are dependent on the aggregation state defined via the variables and parameters. The relational URL for views just receives the result in a row-by-row fashion. Here is a Blog post exploring the differences in more detail: &lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/sap-datasphere-analytical-and-relational-odata-apis/ba-p/13573797" target="_blank"&gt;https://community.sap.com/t5/technology-blogs-by-sap/sap-datasphere-analytical-and-relational-odata-apis/ba-p/13573797&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Changes you do to the variables and query parameters are reflected in the OData request URL. Variables are defined during the objects modeling process. If a default value is set for a variable it is used by default. If no default value is set, you must set a value for the variable to call the OData request. On the other hand, query parameters are not defined in the modeling process but are used in only that specific OData request. Query parameters are standard URL parameters used to filter, sort and limit the result set. Here is an overview of the usable query parameters&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;$select – return only specified columns&lt;/LI&gt;&lt;LI&gt;$filter – restrict result according to the provided criteria&lt;/LI&gt;&lt;LI&gt;$orderby – sorts the result by the specified column&lt;/LI&gt;&lt;LI&gt;$count – returns the count of the number of records&lt;/LI&gt;&lt;LI&gt;$top – limits the number of returned records to &amp;lt;n&amp;gt;&lt;/LI&gt;&lt;LI&gt;$skip – excludes the first &amp;lt;n&amp;gt; items&lt;/LI&gt;&lt;LI&gt;sap-language – returns the data in the specified language (if available)&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;In this example an analytic model to monitor task chain runs is shown. It has one variable INCLUDE_FAILURES_ONLY with the default value YES and query parameters are set to show only task chain steps with replication flows, ordered by the end date of the task chain run and limited to show only the last 100 results.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_15-1744874906554.png" style="width: 562px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251788i1838F24C782DFE88/image-dimensions/562x538?v=v2" width="562" height="538" role="button" title="henri_hosang_15-1744874906554.png" alt="henri_hosang_15-1744874906554.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;To see the result of the OData request you can click Preview or copy the URL to a new browser window. If everything is configured correctly a value array of objects is shown, where each object is one result row. As mentioned, this works without any additional setup since the log in context from your browser is reused.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_16-1744874906562.png" style="width: 754px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251789iD60DCF01B58DA842/image-dimensions/754x328?v=v2" width="754" height="328" role="button" title="henri_hosang_16-1744874906562.png" alt="henri_hosang_16-1744874906562.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Note: There is the limitation, that a user can send a maximum of 300 OData requests per minute. Pagination is used by default with 50.000 records per page. Via $skip and $top parameters client-side pagination can be implemented.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--1381930523"&gt;Using Postman to consume OData Requests&lt;/H3&gt;&lt;P&gt;So far, we have seen, how to consume data in Datasphere via the OData API directly from the browser without any additional setup. However, if you want to use a 3rd party tool like Postman or Python to call OData requests you have to setup an OAuth client under System -&amp;gt; Administration -&amp;gt; App Integration with Interactive usage and a redirect URI. &lt;STRONG&gt;Please refer to the How? section under Command Line Interface (CLI) as the setup is the same&lt;/STRONG&gt;. Once you got the client id, client secret, authentication and token URL you can continue in Postman by creating a new GET request. Copy &amp;amp; Paste the URL that you generated via the generate OData request function in Datasphere. You will see that the query parameters are automatically shown in the Parameters section of Postman.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_17-1744874906570.png" style="width: 743px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251790i8BF42724E27B3125/image-dimensions/743x221?v=v2" width="743" height="221" role="button" title="henri_hosang_17-1744874906570.png" alt="henri_hosang_17-1744874906570.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The main step to use OData from Postman is to setup the Authorization correctly. Use Auth Type = OAuth 2.0 and header Prefix = Bearer (default).&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_18-1744874906580.png" style="width: 706px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251793i869B37D4BC8D349D/image-dimensions/706x293?v=v2" width="706" height="293" role="button" title="henri_hosang_18-1744874906580.png" alt="henri_hosang_18-1744874906580.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Then configure a New Token in the section below.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Grant type = Authorization Code&lt;/LI&gt;&lt;LI&gt;Callback URL = &amp;lt;Your Callback URL set in the OAuth client (&lt;A href="http://localhost:8080" target="_blank" rel="noopener nofollow noreferrer"&gt;http://localhost:8080&lt;/A&gt;)&amp;gt;&lt;/LI&gt;&lt;LI&gt;Auth URL = &amp;lt;Authorization URL copied from System -&amp;gt; Administration -&amp;gt; App Integration&amp;gt;&lt;/LI&gt;&lt;LI&gt;Access Token URL = &amp;lt;Token URL copied from System -&amp;gt; Administration -&amp;gt; App Integration&amp;gt;&lt;/LI&gt;&lt;LI&gt;Client ID = &amp;lt;Client ID copied from the OAuth client&amp;gt;&lt;/LI&gt;&lt;LI&gt;Client Secret = &amp;lt;Client secret copied from the OAuth client&amp;gt;&lt;/LI&gt;&lt;LI&gt;Client Authentication = Send as Basic Auth Header.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Then you have to click on “Get New Access Token”.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_19-1744874906594.png" style="width: 685px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251792i9A1DF676FF44E47B/image-dimensions/685x428?v=v2" width="685" height="428" role="button" title="henri_hosang_19-1744874906594.png" alt="henri_hosang_19-1744874906594.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Postman automatically handles the redirect and opens an embedded browser where you need to log in with your business user, using your normal Datasphere credentials. If the log in is successful, an Access Token Is generated, and you can click on Use Token.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_20-1744874906601.png" style="width: 497px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251791iA88BD31C62D3BF13/image-dimensions/497x266?v=v2" width="497" height="266" role="button" title="henri_hosang_20-1744874906601.png" alt="henri_hosang_20-1744874906601.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The Token has the lifetime defined in the OAuth client. After it is expired you just click on get new access Token again and use the new Token. Having the Token, you can now send the API request to consume an analytic model or exposed view. Here we consume the same analytic model as we did when we generated the OData request and opened the URL in the browser.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_21-1744874906619.png" style="width: 639px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251797i908B7AE4237050D8/image-dimensions/639x372?v=v2" width="639" height="372" role="button" title="henri_hosang_21-1744874906619.png" alt="henri_hosang_21-1744874906619.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;That’s it for consuming data via OData in the browser and via Postman. Of course, you can also use Python or another language to replicate Postman’s behavior in handling the redirect URI and authorization against Datasphere by calling the authorization URL and handling the callback via the redirect URI. Since this approach involves a bit more coding than the other consumption options, I will publish the scenario in a separate Blog post. Please see my upcoming blog post [TBD].&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId--991638014"&gt;HANA Database Explorer &amp;amp; Open SQL Schema&lt;/H1&gt;&lt;P&gt;The last option to consume data from Datasphere via external tools is using SQL Statements to access the HANA Cloud Database underneath Datasphere directly instead of querying the objects in the modeling UI of Datasphere. Because SQL provides two-dimensional results in a row-by-row fashion, only views and tables can be consumed. Analytic models are multidimensional statements, so the OData API should be used to consume them instead. Third party tools like Tableau and Power BI use a JDBC/ODBC connection to the HANA Cloud to report on data exposed in views. This section shows how you can use this connection to consume and create objects of the HANA Cloud via the HANA Database Explorer and via Python.&lt;/P&gt;&lt;H2 id="toc-hId--1481554526"&gt;&lt;STRONG&gt;What?&lt;/STRONG&gt;&lt;/H2&gt;&lt;UL&gt;&lt;LI&gt;Access the space schema and read data from the space using SQL SELECT statements and&lt;UL&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/be5967d099974c69b77f4549425ca4c0/3de55a78a4614deda589633baea28645.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/be5967d099974c69b77f4549425ca4c0/3de55a78a4614deda589633baea28645.html&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://userapps.support.sap.com/sap/support/knowledge/en/3428316" target="_blank" rel="noopener noreferrer"&gt;https://userapps.support.sap.com/sap/support/knowledge/en/3428316&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;Create Tables and Views to write data to a space&lt;UL&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/be5967d099974c69b77f4549425ca4c0/3de55a78a4614deda589633baea28645.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/be5967d099974c69b77f4549425ca4c0/3de55a78a4614deda589633baea28645.html&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://userapps.support.sap.com/sap/support/knowledge/en/3428316" target="_blank" rel="noopener noreferrer"&gt;https://userapps.support.sap.com/sap/support/knowledge/en/3428316&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;Write SQL Script Procedures and add them to a task chain - &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/c8a54ee704e94e15926551293243fd1d/59b9c773035a48c5beb54ce9bb29f1d8.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/c8a54ee704e94e15926551293243fd1d/59b9c773035a48c5beb54ce9bb29f1d8.html&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;Run Machine Learning Algorithms from HANA APL &amp;amp; PAL via open SQL&lt;UL&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/be5967d099974c69b77f4549425ca4c0/b78ad208f8c4494489aabf97284679b6.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/be5967d099974c69b77f4549425ca4c0/b78ad208f8c4494489aabf97284679b6.html&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/9f804b8efa8043539289f42f372c4862/287194276a7d4d778ec98fdde5f61335.html?q=PAL+APL" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/9f804b8efa8043539289f42f372c4862/287194276a7d4d778ec98fdde5f61335.html?q=PAL+APL&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://community.sap.com/t5/artificial-intelligence-and-machine-learning-blogs/hands-on-tutorial-machine-learning-with-sap-datasphere/ba-p/13796417" target="_blank"&gt;https://community.sap.com/t5/artificial-intelligence-and-machine-learning-blogs/hands-on-tutorial-machine-learning-with-sap-datasphere/ba-p/13796417&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId--1678068031"&gt;&lt;STRONG&gt;How?&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;To consume data via ODBC/JDBC you need either a database user or a database analysis user. The database user is limited to read from and/or write to an Open SQL schema with restricted access to the space schema whereas the Database analysis users have read only access to all space schemas (if configured).&lt;/P&gt;&lt;P&gt;To simplify the scenario, we will use a database analysis user for this introduction, because this user has default access to all the objects in Datasphere. To create a database analysis user, you need to be an administrator. Go to System -&amp;gt; Configuration -&amp;gt; Database Access -&amp;gt; Database Analysis User. Then click create to create a new user.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_22-1744874906627.png" style="width: 691px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251796i2E238D0353BFEA2F/image-dimensions/691x533?v=v2" width="691" height="533" role="button" title="henri_hosang_22-1744874906627.png" alt="henri_hosang_22-1744874906627.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The Database Analysis User starts with “DWCDBUSER#” and you have to provide a custom suffix for the user. Additionally enable Space Schema Access to also consume data that is available in the spaces of your datasphere tenant. Click Create&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_23-1744874906629.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251795i674753DA0E6C5D3E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="henri_hosang_23-1744874906629.png" alt="henri_hosang_23-1744874906629.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;After the user is created the database Host Name, Port, Password and Username are displayed. Copy all four credentials, as they are needed to log into the HANA cloud. In difference to OAuth Client used for the CLI and OData API you can simply request a new password for this user if you lose the old one.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_24-1744874906631.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251798i437E808F6798C8E6/image-size/medium?v=v2&amp;amp;px=400" role="button" title="henri_hosang_24-1744874906631.png" alt="henri_hosang_24-1744874906631.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;That is the setup for now if you want to access the HANA Cloud via the HANA Cockpit or HANA Database Explorer. To consume data in Datasphere, the HANA Database Explorer can be used. Open your HANA Database explorer (e.g. via Space Management -&amp;gt; Edit -&amp;gt; Database Access -&amp;gt; Select a Database User -&amp;gt; Open Database Explorer). To use the created Database Analysis user the HANA Database Instance has to be added again with the analysis user. Click on the “+” sign in the upper left corner, select SAP HANA Database as Instance type and paste the credentials from the user creation.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_25-1744874906637.png" style="width: 781px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251799iC5DDD10759A9206F/image-dimensions/781x603?v=v2" width="781" height="603" role="button" title="henri_hosang_25-1744874906637.png" alt="henri_hosang_25-1744874906637.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;You see the added connection in the upper left section of the HANA Database Explorer. The explorer helps you by automatically creating Select statements. To find an element to consume open the Instance and the Catalog Option. Choose Tables to consume Tables or Views to consume Views. By default, all Tables / Views from all schemas are shown. You can search for a specific Table / View or filter by schema. The schema option shows all schemas available on the HANA Cloud, but you can simply search for the name of one of your spaces that holds the object you want to consume.&lt;/P&gt;&lt;P&gt;In this example I select the table SalesOrders_TestUpload by selecting Tables from the catalog and filtering for my Space schema COE_EMEA_DW_DM and searching for test. By right clicking the table you have multiple options. To just consume the data via OpenSQL click “Generate SELECT Statement” and execute the statement. Data will be shown.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_26-1744874906648.png" style="width: 725px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251800iC069FFC73A363BED/image-dimensions/725x560?v=v2" width="725" height="560" role="button" title="henri_hosang_26-1744874906648.png" alt="henri_hosang_26-1744874906648.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Instead of using the HANA Database Explorer you can also consume data in the HANA Cloud from any other Database client (e.g. DBeaver) or from a scripting language like Python by defining a connection to that HANA Database. To consume assets from Python you first need to allowlist your environment’s external IP address. Go to System -&amp;gt; Configuration -&amp;gt; IP Allowlist -&amp;gt; Trusted IPs and add your external IP address. You can get your external IP Address by running the command &lt;EM&gt;curl ifconfig.me&lt;/EM&gt; on Linux/macOS or opening a website like &lt;A href="https://ifconfig.me/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://ifconfig.me/&lt;/A&gt;. If you are using a VPN client, investigate the settings of your client and check if the external IP address is provided there. For testing IP range 0.0.0.0/0 can be used.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="henri_hosang_27-1744874906661.png" style="width: 728px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251801i557AF390F7D20854/image-dimensions/728x562?v=v2" width="728" height="562" role="button" title="henri_hosang_27-1744874906661.png" alt="henri_hosang_27-1744874906661.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Then install the hdbcli extension module for Python. This defines the necessary API specification to directly send SQL queries to the HANA Cloud. You can find the documentation here: &lt;A href="https://pypi.org/project/hdbcli/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://pypi.org/project/hdbcli/&lt;/A&gt; and install it in the command line via the command:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;$ pip install hdbcli&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;In a new Python file import the dbapi from hdbcli and define the connection with the four credentials from the Database Analysis user similarly to the HANA Database Explorer. Write a SQL command or copy the one generated from the HANA Database Explorer and execute it. Finally, run &lt;EM&gt;cursor.fetchall()&lt;/EM&gt; to get a row-by-row result. Here is the full code&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from hdbcli import dbapi	

conn = dbapi.connect(
    address="&amp;lt;HANA host&amp;gt;", 
    port=443, 
    user="DWCDBUSER#&amp;lt;suffix&amp;gt;", 
    password="&amp;lt;DB Analysis User Password&amp;gt;",
)

sql = 'SELECT * FROM "COE_EMEA_DW_DM"."SalesOrders_TestUpload"'
cursor = conn.cursor()
cursor.execute(sql)
cursor.fetchall()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Certainly, you can now start creating more complex SQL statements or working with the result set by e.g. passing the &lt;EM&gt;fetchall()&lt;/EM&gt; command into a pandas DataFrame. As shown in the What? Section there are many more possibilities when working with the HANA Open SQL schema, like running SQL script procedures in Task Chains or executing HANA machine learning algorithms that are beyond this introductory blog post. Take a look at the articles linked in the What? Section to get you started with additional scenarios.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId--1412994838"&gt;Conclusion&lt;/H1&gt;&lt;P&gt;That’s it for this introduction to external access to Datasphere. By now you should have a good understanding of all the major ways to interact with Datasphere from tools like the CLI; Postman and Python. As mentioned in the beginning Replication Flows, OData and the ODBC/JDBC connection can also directly be used by 3rd party application to retrieve data from Datasphere. This was not part of this blog post as the configuration differs between all the possible targets. There is extensive documentation and there are many community blogs available to explain application specific setups.&lt;/P&gt;&lt;P&gt;If you have questions or noticed a scenario I didn’t cover, feel free to leave a comment below the blog post.&lt;/P&gt;&lt;P&gt;Cheers, Henri&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-datasphere-external-access-overview-apis-cli-and-sql/ba-p/14078591"/>
    <published>2025-04-22T10:55:27.647000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/automate-cpi-log-reporting-extract-custom-header-properties-and-load-into/ba-p/14086570</id>
    <title>Automate CPI Log Reporting: Extract Custom Header Properties and Load into SAP Analytics Cloud</title>
    <updated>2025-04-27T05:29:22.627000+02:00</updated>
    <author>
      <name>MJUDI</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/132271</uri>
    </author>
    <content>&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1580215364"&gt;How to Extract CPI Message Logs with Custom Header Properties and Report in SAP Analytics Cloud&lt;/H1&gt;&lt;H2 id="toc-hId-1512784578"&gt;1. Problem Statement: Why You Can’t Rely on CPI Monitoring Alone&lt;/H2&gt;&lt;P&gt;SAP’s Integration Suite (CPI) gives you visibility — but only just. If you want to check whether a message was delivered or inspect its Custom Header Properties, you can. But it’s manual. One message at a time. No consolidated view. No report.&lt;/P&gt;&lt;P&gt;Cloud ALM improves things slightly by centralising errors and alerts, but when it comes to &lt;EM&gt;reporting&lt;/EM&gt; on message metadata like Custom Header Properties, you're stuck. Neither CPI’s monitor nor Cloud ALM’s Integration &amp;amp; Exception Monitor gives you a way to extract all this data in bulk.&lt;/P&gt;&lt;P&gt;And that’s a problem. Because sometimes your business needs answers like:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;“Did all outbound invoice messages include the expected reference IDs?”&lt;/LI&gt;&lt;LI&gt;“Which messages failed for a specific customer or process?”&lt;/LI&gt;&lt;LI&gt;“Can we see everything we sent for this business object last month in one view?”&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;For many organisations, this isn’t just a nice-to-have — it’s a compliance or contractual requirement.&lt;/P&gt;&lt;P&gt;This is where the gap becomes critical: the data is there, but not accessible in a way that supports operational oversight, reporting, or auditing.&lt;/P&gt;&lt;P&gt;So, what’s the fix?&lt;/P&gt;&lt;P&gt;You build your own reporting pipeline — extracting message data via CPI’s APIs, enriching it with Custom Header Properties, and loading it into SAP Analytics Cloud (SAC).&lt;/P&gt;&lt;H2 id="toc-hId-1316271073"&gt;2. Extracting Messages and Header Properties&lt;/H2&gt;&lt;P&gt;To get the data you need out of SAP Cloud Integration (CPI), you’ll be working with two key APIs:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;/MessageProcessingLogs&lt;/STRONG&gt;&amp;nbsp;to retrieve a list of processed messages.&amp;nbsp;It is always advisable to test your APIs before using them in your application in Postman or Bruno for example:&lt;/LI&gt;&lt;/UL&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MJUDI_1-1745718306789.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255209iB42E47D7E276E05F/image-size/large?v=v2&amp;amp;px=999" role="button" title="MJUDI_1-1745718306789.png" alt="MJUDI_1-1745718306789.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;/MessageProcessingLogs('{MessageGuid}')/CustomHeaderProperties&lt;/STRONG&gt;&amp;nbsp;to fetch Custom Header Properties for each message.&lt;/LI&gt;&lt;/UL&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MJUDI_0-1745717875444.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255208i61E7424A51368835/image-size/large?v=v2&amp;amp;px=999" role="button" title="MJUDI_0-1745717875444.png" alt="MJUDI_0-1745717875444.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1248840287"&gt;Step 1: Authenticate Against the CPI API&lt;/H3&gt;&lt;P&gt;With basic authentication method, you can quickly test the API, however it's recommended to use a more secured method like OAuth 2.0 the way it's demonstrated in the attached script.&lt;/P&gt;&lt;PRE&gt;import requests
from requests.auth import HTTPBasicAuth

cpi_host = 'https://your-cpi-host.it-cpi.eu10.hana.ondemand.com'
username = 'your-technical-user'
password = 'your-password'&lt;/PRE&gt;&lt;H3 id="toc-hId-1052326782"&gt;Step 2: Get a List of Message GUIDs&lt;/H3&gt;&lt;PRE&gt;response = requests.get(
    f"{cpi_host}/api/v1/MessageProcessingLogs?$format=json",
    auth=HTTPBasicAuth(username, password)
)

messages = response.json().get('d', {}).get('results', [])&lt;/PRE&gt;&lt;H3 id="toc-hId-855813277"&gt;Step 3: Loop Through Messages to Fetch Header Properties&lt;/H3&gt;&lt;PRE&gt;all_data = []

for msg in messages:
    guid = msg.get('MessageGuid')
    hdr_response = requests.get(
        f"{cpi_host}/api/v1/MessageProcessingLogs('{guid}')/CustomHeaderProperties?$format=json",
        auth=HTTPBasicAuth(username, password)
    )
    
    custom_headers = hdr_response.json().get('d', {}).get('results', [])
    
    record = {
        'MessageGuid': guid,
        'IntegrationFlowName': msg.get('IntegrationFlowName'),
        'Timestamp': msg.get('LogStart'),
        'CustomHeaderProperties': {hdr['Name']: hdr['Value'] for hdr in custom_headers}
    }
    
    all_data.append(record)&lt;/PRE&gt;&lt;H3 id="toc-hId-659299772"&gt;Step 4: Store the Data&lt;/H3&gt;&lt;PRE&gt;import pandas as pd

df = pd.json_normalize(all_data, sep='_')
df.to_csv('cpi_message_headers.csv', index=False)&lt;/PRE&gt;&lt;H2 id="toc-hId-333703548"&gt;3. Preparing Your SAC Model&lt;/H2&gt;&lt;P&gt;To import the data you extracted out of SAP Cloud Integration (CPI) in SAP Analytics Cloud (SAC), you’ll be working with the following APIs:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;GET all Models with &lt;STRONG&gt;api/v1/dataimport/models&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;endpoint to return a list of all Models&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;GET Model Details with &lt;STRONG&gt;api/v1/dataimport/models/{modelID}&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;endpoint to give us the types of data we can import into this model&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;GET Model Metadata with &lt;STRONG&gt;api/v1/dataimport/models/{modelID}/metadata&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;endpoint&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;POST - Create a Job to be used later to import the data with &lt;STRONG&gt;api/v1/dataimport/models/{modelID}/importType&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;endpoint&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;POST - Load data into a job with &lt;STRONG&gt;api/v1/dataimport/jobs/{jobID}&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;endpoint&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;GET the list of jobs with &lt;STRONG&gt;api/v1/dataimport/jobs&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;endpoint&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;POST - Validate with &lt;STRONG&gt;api/v1/dataimport/jobs/{jobID}/validate&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;endpoint&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;POST - Run the job with &lt;STRONG&gt;api/v1/dataimport/jobs/{jobID}/run&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;endpoint&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;GET the status of the run with &lt;STRONG&gt;api/v1/dataimport/jobs/{jobID}/status&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;endpoint&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;However, there is a simple and quick way to import the data in one click mode with the&amp;nbsp;&lt;STRONG&gt;api/v1/import/{modelID}&lt;/STRONG&gt;&amp;nbsp;endpoint. This method is demonstrated in the sample attached script.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;Before you can load data into SAC, you must ensure the model exists and that you’ve verified its metadata.&lt;/P&gt;&lt;H3 id="toc-hId-266272762"&gt;Step 1: Get Model Info&lt;/H3&gt;&lt;PRE&gt;model_id = 'your-model-id'
sac_host = 'https://&amp;lt;your-sac-tenant&amp;gt;.sapbusinessobjects.cloud'
token = 'your-bearer-token'

headers = {
    'Authorization': f'Bearer {token}'
}

response = requests.get(
    f'{sac_host}/api/v1/dataimport/models/{model_id}',
    headers=headers
)

print(response.json())&lt;/PRE&gt;&lt;H3 id="toc-hId-69759257"&gt;Step 2: Get Model Metadata (Field Types)&lt;/H3&gt;&lt;PRE&gt;meta_response = requests.get(
    f'{sac_host}/api/v1/dataimport/models/{model_id}/metadata',
    headers=headers
)

metadata = meta_response.json()&lt;/PRE&gt;&lt;H2 id="toc-hId-91417390"&gt;4. Setting Up the Data Import Job&lt;/H2&gt;&lt;H3 id="toc-hId--398499122"&gt;Step 1: Create the Import Job&lt;/H3&gt;&lt;PRE&gt;import json

job_payload = {
    "importType": "Append"  # or "Full"
}

create_job_response = requests.post(
    f'{sac_host}/api/v1/dataimport/models/{model_id}/importType',
    headers={**headers, 'Content-Type': 'application/json'},
    data=json.dumps(job_payload)
)

job_info = create_job_response.json()
job_id = job_info.get('id')

print(f"Created import job with ID: {job_id}")&lt;/PRE&gt;&lt;H2 id="toc-hId--301609620"&gt;5. Loading Data into the Job&lt;/H2&gt;&lt;H3 id="toc-hId--791526132"&gt;Step 1: Prepare the Payload&lt;/H3&gt;&lt;PRE&gt;data_payload = {
    "data": [
        {
            "MessageGuid": "12345",
            "IntegrationFlowName": "InvoiceDispatch",
            "Timestamp": "2024-12-01T10:15:00Z",
            "BusinessObjectID": "INV-1001"
        },
        {
            "MessageGuid": "12346",
            "IntegrationFlowName": "InvoiceDispatch",
            "Timestamp": "2024-12-01T10:16:00Z",
            "BusinessObjectID": "INV-1002"
        }
    ]
}&lt;/PRE&gt;&lt;H3 id="toc-hId--988039637"&gt;Step 2: Load the Data Into the Job&lt;/H3&gt;&lt;PRE&gt;load_response = requests.post(
    f'{sac_host}/api/v1/dataimport/jobs/{job_id}',
    headers={**headers, 'Content-Type': 'application/json'},
    data=json.dumps(data_payload)
)

if load_response.status_code == 202:
    print("Data loaded into job successfully.")
else:
    print(f"Error loading data: {load_response.status_code} - {load_response.text}")&lt;/PRE&gt;&lt;H2 id="toc-hId--891150135"&gt;6. Managing and Monitoring Jobs&lt;/H2&gt;&lt;H3 id="toc-hId--1381066647"&gt;Step 1: Validate the Job&lt;/H3&gt;&lt;PRE&gt;validate_response = requests.post(
    f'{sac_host}/api/v1/dataimport/jobs/{job_id}/validate',
    headers=headers
)

if validate_response.status_code == 202:
    print("Validation successful. Ready to run the job.")
else:
    print(f"Validation failed: {validate_response.status_code} - {validate_response.text}")&lt;/PRE&gt;&lt;H3 id="toc-hId--1577580152"&gt;Step 2: Run the Job&lt;/H3&gt;&lt;PRE&gt;run_response = requests.post(
    f'{sac_host}/api/v1/dataimport/jobs/{job_id}/run',
    headers=headers
)

if run_response.status_code == 202:
    print("Job started successfully.")
else:
    print(f"Failed to start the job: {run_response.status_code} - {run_response.text}")&lt;/PRE&gt;&lt;H2 id="toc-hId--1480690650"&gt;7. Checking Job Status&lt;/H2&gt;&lt;H3 id="toc-hId--1970607162"&gt;Step 1: Poll the Job Status&lt;/H3&gt;&lt;PRE&gt;import time

while True:
    status_response = requests.get(
        f'{sac_host}/api/v1/dataimport/jobs/{job_id}/status',
        headers=headers
    )

    status_info = status_response.json()
    status = status_info.get('status')

    print(f"Current job status: {status}")

    if status in ["Completed", "Failed"]:
        break

    time.sleep(5)&lt;/PRE&gt;&lt;H2 id="toc-hId--1705533969"&gt;Conclusion&lt;/H2&gt;&lt;P&gt;If you’ve ever felt stuck manually digging through CPI logs just to answer simple business questions, now you know there’s a better way.&lt;/P&gt;&lt;P&gt;By using SAP’s APIs, a little Python, and the SAC Data Import API, you can build a repeatable pipeline to extract, load, and report on Custom Header Properties — at scale.&lt;/P&gt;&lt;P&gt;The steps you followed — extracting with /MessageProcessingLogs, staging data for SAC, validating, running, and monitoring — create a blueprint you can extend for other use cases too.&lt;/P&gt;&lt;P&gt;The data was always there. Now, you control it.&lt;/P&gt;&lt;P&gt;A sample Python script is attached to this blog, however, the script is following the one-click approach to import the data into SAC.&lt;/P&gt;&lt;H2 id="toc-hId--1902047474"&gt;Common Mistakes and How to Avoid Them&lt;/H2&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Mismatched Field Names:&lt;/STRONG&gt; Match your payload keys exactly to the SAC model field names (case-sensitive).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Wrong Date Format:&lt;/STRONG&gt; Use ISO 8601 date format (YYYY-MM-DDTHH:MM:SSZ).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Not Validating Before Running:&lt;/STRONG&gt; Always validate your job to catch issues early.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Overwriting When You Meant to Append:&lt;/STRONG&gt; Use &lt;EM&gt;Append&lt;/EM&gt; unless you intend to replace all data.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Token Expiry:&lt;/STRONG&gt; Ensure your OAuth token is valid or refresh it if needed.&lt;/LI&gt;&lt;/UL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/automate-cpi-log-reporting-extract-custom-header-properties-and-load-into/ba-p/14086570"/>
    <published>2025-04-27T05:29:22.627000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-data-flow-scripts-and-generic-odata-unpacking-nested-values/ba-p/14085615</id>
    <title>SAP Datasphere - Data flow scripts and generic OData - Unpacking nested values</title>
    <updated>2025-04-29T18:56:12.923000+02:00</updated>
    <author>
      <name>clsorensen911</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/768390</uri>
    </author>
    <content>&lt;H1 id="toc-hId-1580186353"&gt;Introduction&lt;/H1&gt;&lt;P&gt;SAP Datasphere is subset of the new SAP Business Data Cloud offering, which aims to&amp;nbsp;&lt;SPAN&gt;enables every data professional to deliver seamless and scalable access to mission-critical business data.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;Datasphere offers a host of connectors to all kinds of sources, SAP and non-SAP alike. One of the most versatile is the "Generic OData" connection, which allows consumption of a wide range of sources.&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;In this blog, we will see how we can utilize the Data Flow feature to consume complex OData responses.&amp;nbsp;&lt;/P&gt;&lt;P data-unlink="true"&gt;&lt;STRONG&gt;Note&lt;/STRONG&gt;: This is a rather niche guide to the Script Operator in Data Flows. If you were looking for more high-level information, I would recommend the official &lt;A title="SAP Datasphere" href="https://help.sap.com/docs/SAP_DATASPHERE?locale=en-US&amp;amp;state=PRODUCTION&amp;amp;version=cloud" target="_self" rel="noopener noreferrer"&gt;SAP Datasphere Documents&lt;/A&gt;, or the &lt;A title="Datasphere Blogs" href="https://community.sap.com/t5/c-khhcw49343/SAP+Datasphere/pd-p/73555000100800002141" target="_blank"&gt;Datasphere tag&lt;/A&gt; to browse blog posts.&lt;/P&gt;&lt;H2 id="toc-hId-1512755567"&gt;Summary&lt;/H2&gt;&lt;P&gt;The Generic OData connector in Datasphere can't "flatten" a nest structure, and will end up storing nested structures as strings. The script operator in Data Flows allows developers to handle complex OData entities with Python, but can be an cumbersome to say the least.&lt;/P&gt;&lt;P&gt;Your best option is to consider some sort of middleware or integration platform between the source and Datasphere, that better allows you to handle OData entities better.&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1316242062"&gt;Prerequisites&amp;nbsp;&lt;/H2&gt;&lt;P&gt;If you want to follow along, you will need:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Access to a Datasphere Tenant&lt;/LI&gt;&lt;LI&gt;Access to a development space, and the correct authorizations.&lt;/LI&gt;&lt;LI&gt;A basic idea of Datasphere objects: &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/c8a54ee704e94e15926551293243fd1d/e30fd1417e954577baae3246ea470c3f.html?source=productlink-webassistant" target="_blank" rel="noopener noreferrer"&gt;Data Flows&lt;/A&gt; and &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/c8a54ee704e94e15926551293243fd1d/2509fe4d86aa472b9858164b55b38077.html?source=productlink-webassistant" target="_blank" rel="noopener noreferrer"&gt;Local Tables&lt;/A&gt;&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;An OData source (I will use the &lt;A href="https://www.odata.org/odata-services/" target="_self" rel="nofollow noopener noreferrer"&gt;OData.org reference services&lt;/A&gt;, so you should be able to reproduce the results)&lt;/LI&gt;&lt;LI&gt;An understanding of the Python module Pandas, and dataframes&lt;/LI&gt;&lt;LI&gt;A deep and seething hate for &lt;A href="https://en.wikipedia.org/wiki/Regular_expression" target="_blank" rel="noopener nofollow noreferrer"&gt;Regular Expressions&lt;/A&gt;, but still see their value. I also hate regular expressions.&amp;nbsp;&amp;nbsp;&lt;/LI&gt;&lt;/OL&gt;&lt;H2 id="toc-hId-1119728557"&gt;Disclaimer: I don't like this solution any more than you do&lt;/H2&gt;&lt;P&gt;I want to be transparent going into this: I don't think this is a very good or elegant solution.&amp;nbsp;&lt;BR /&gt;In an ideal world, I would prefer some sort of integration platform, CIP or something else, between the OData service and Datasphere to correctly unpack and transform the data.&lt;/P&gt;&lt;P&gt;If you don't have that, you may consider the following.&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1052297771"&gt;Step 1: Establish the connections&lt;/H3&gt;&lt;P&gt;In your development space, you can set up a connection to the services.&lt;BR /&gt;OData.org exposes both V2 and V4 OData services.&lt;/P&gt;&lt;P&gt;&lt;A href="https://www.odata.org/odata-services/" target="_self" rel="nofollow noopener noreferrer"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_4-1745567846542.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254591i969AF0AB2B35924E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="clsorensen911_4-1745567846542.png" alt="clsorensen911_4-1745567846542.png" /&gt;&lt;/span&gt;&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Clicking on the service will provide you with the service URL:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_5-1745567909646.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254593iE44C15201DAC008C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="clsorensen911_5-1745567909646.png" alt="clsorensen911_5-1745567909646.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In Datasphere, create a Generic OData Connection:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_6-1745567997899.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254594i86FCC2E74E0FD386/image-size/medium?v=v2&amp;amp;px=400" role="button" title="clsorensen911_6-1745567997899.png" alt="clsorensen911_6-1745567997899.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-855784266"&gt;Step 2: Consume /Suppliers in a Data Flow&lt;/H3&gt;&lt;P&gt;Add the /Suppliers to a new Data Flow and preview the data.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_8-1745568141294.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254604i6ED788F3A604C5B8/image-size/medium?v=v2&amp;amp;px=400" role="button" title="clsorensen911_8-1745568141294.png" alt="clsorensen911_8-1745568141294.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt; You may get an error, that the source tables is not "Deployed".&amp;nbsp;&lt;BR /&gt;If you do, deploy the table and preview the data again.&lt;/P&gt;&lt;H3 id="toc-hId-659270761"&gt;Step 3 (Optional) : Understanding the problem&lt;/H3&gt;&lt;P&gt;If you try to consume the service in a service like postman, or just through a Python request, you will get the following JSON response:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_9-1745569294082.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254617iFF6ADE4266634691/image-size/medium?v=v2&amp;amp;px=400" role="button" title="clsorensen911_9-1745569294082.png" alt="clsorensen911_9-1745569294082.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;You can see that there are two dictionaries here. &lt;STRONG&gt;Properties&lt;/STRONG&gt;, which contain the keys (1) ID, (2) Name, (3) Address, and (4) Concurrency, and&amp;nbsp;then another under&amp;nbsp;&lt;STRONG&gt;Address&lt;/STRONG&gt;, which contains Street, City, State, ZipCode and Country.&amp;nbsp;&lt;/P&gt;&lt;P&gt;There are many ways to interpret this data, but the easiest would be to unpack it into the following table:&lt;/P&gt;&lt;TABLE border="1" width="100%"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;ID&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Name&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Address_Street&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Address_City&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Address_State&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Address_ZipCode&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Country&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Concurrency&lt;/STRONG&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="12.5%"&gt;0&lt;/TD&gt;&lt;TD width="12.5%"&gt;Exotic Liquids&lt;/TD&gt;&lt;TD width="12.5%"&gt;NE 228th&lt;/TD&gt;&lt;TD width="12.5%"&gt;Sammamish&lt;/TD&gt;&lt;TD width="12.5%"&gt;WA&lt;/TD&gt;&lt;TD width="12.5%"&gt;98074&lt;/TD&gt;&lt;TD width="12.5%"&gt;USA&lt;/TD&gt;&lt;TD width="12.5%"&gt;0&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;As you can see,&amp;nbsp;&lt;STRONG&gt;Address&lt;/STRONG&gt; is unpacked into it's four columns, and we get a lovely, simple table.&amp;nbsp;&lt;/P&gt;&lt;P&gt;However, the table deployed in Step 2, in Datasphere looks like this:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_10-1745569839164.png" style="width: 661px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254625i429F5CFCFAA5878F/image-dimensions/661x76?v=v2" width="661" height="76" role="button" title="clsorensen911_10-1745569839164.png" alt="clsorensen911_10-1745569839164.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Which is an absolute nightmare. Extracting the data in SQL views (graphical or otherwise) will be substring-hell, as there are no JSON interpreters in the &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/c8a54ee704e94e15926551293243fd1d/6d624a1956234d818d0bfdc77cbd0e09.html" target="_blank" rel="noopener noreferrer"&gt;HANA SQLScript&lt;/A&gt;.&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-462757256"&gt;Step 4: Add a Script Operator&lt;/H3&gt;&lt;P&gt;Alright, now let's transform the data with a Python Script.&lt;/P&gt;&lt;P&gt;Firstly, add a script to your canvas and connect the source.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_11-1745570218358.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254627i1918836127D4C53D/image-size/medium?v=v2&amp;amp;px=400" role="button" title="clsorensen911_11-1745570218358.png" alt="clsorensen911_11-1745570218358.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-266243751"&gt;Step 5: Add the new columns to the script operator&lt;/H3&gt;&lt;P&gt;The schema of the script operator is not dynamic. That means you will need to manually add the required columns to the operator:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_12-1745570438828.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254629i7F58289C817D7A75/image-size/medium?v=v2&amp;amp;px=400" role="button" title="clsorensen911_12-1745570438828.png" alt="clsorensen911_12-1745570438828.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-69730246"&gt;Step 6: Reorder the columns&lt;/H3&gt;&lt;P&gt;The absolute 'funniest' quirk is that the output of the script is based on the order of the columns, not the names / keys.&lt;/P&gt;&lt;P&gt;That means, if your resulting DataFrame has this schema:&lt;/P&gt;&lt;TABLE border="1"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;ID&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Name&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Address_Street&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Address_City&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Address_State&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Address_ZipCode&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Country&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="12.5%"&gt;&lt;STRONG&gt;Concurrency&lt;/STRONG&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;The columns must be in the same order.&lt;BR /&gt;Otherwise the value of ID will be written to the "State" column.&lt;BR /&gt;Fun stuff &lt;span class="lia-unicode-emoji" title=":slightly_smiling_face:"&gt;🙂&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Drag and drop until your columns are in the required order:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_13-1745570864565.png" style="width: 312px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254631i622C8396EE452FF3/image-dimensions/312x255?v=v2" width="312" height="255" role="button" title="clsorensen911_13-1745570864565.png" alt="clsorensen911_13-1745570864565.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt; This problem may very well be solved in the future, or it may be working-as-designed and always just be a massive pain in the donkey.&lt;/P&gt;&lt;H3 id="toc-hId--202014628"&gt;Step 7: Let's code away!&lt;/H3&gt;&lt;P&gt;Alrighty, so now we have the setup in place, we can begin to create a &lt;A title="SAP Documentation - Python Script in Data Flows" href="https://help.sap.com/docs/SAP_DATASPHERE/c8a54ee704e94e15926551293243fd1d/f3e2570966ac4036b552ebd998274af1.html" target="_blank" rel="noopener noreferrer"&gt;Python script&lt;/A&gt; to solve our problem.&amp;nbsp;&lt;/P&gt;&lt;H4 id="toc-hId--691931140"&gt;Script goals&lt;/H4&gt;&lt;P&gt;The Script, in simple terms, have to do two things:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Take the JSON string from the input, and convert it to a dictionary or a list of dictionaries.&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;Read the values from the result of step 1 and write them to the dataframe.&amp;nbsp;&lt;/LI&gt;&lt;/OL&gt;&lt;H4 id="toc-hId--888444645"&gt;Limitations&lt;/H4&gt;&lt;P&gt;However, the Python Environment in Datasphere is highly restricted and does not allow for additional imports.&amp;nbsp;&lt;BR /&gt;At the time of writing, the following libraries are supported:&lt;/P&gt;&lt;UL class=""&gt;&lt;LI&gt;time&lt;/LI&gt;&lt;LI&gt;dateutil.parser&lt;/LI&gt;&lt;LI&gt;datetime&lt;/LI&gt;&lt;LI&gt;calendar&lt;/LI&gt;&lt;LI&gt;random&lt;/LI&gt;&lt;LI&gt;math&lt;/LI&gt;&lt;LI&gt;re&lt;/LI&gt;&lt;LI&gt;Pandas (except I/O, like read_csv, write csv, ect.)&lt;/LI&gt;&lt;LI&gt;Numpy (Except I/O like read_file, from_file ect.)&lt;/LI&gt;&lt;LI&gt;buildints (Except I/O like print, breakpoint, input, open, import, exec, eval, ect.)&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;You can see the full list of supported and disabled features in &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/c8a54ee704e94e15926551293243fd1d/73e8ba1a69cd4eeba722b458a253779d.html" target="_blank" rel="noopener noreferrer"&gt;the documentation&lt;/A&gt;.&lt;/P&gt;&lt;H4 id="toc-hId--1084958150"&gt;Step 7.1: The code editor&lt;/H4&gt;&lt;P&gt;The base code editor looks like this:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_0-1745572477575.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254646i440F7E2DC8917AAD/image-size/medium?v=v2&amp;amp;px=400" role="button" title="clsorensen911_0-1745572477575.png" alt="clsorensen911_0-1745572477575.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;As your may notice, the script takes the form of a function - Transform - that takes one variable: data. The source data will be read just like you see it in the Data Preview, as a Pandas DataFrame called 'data'.&amp;nbsp;&lt;BR /&gt;A section has been marked in two strings of #, which is where you will add your code.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Note:&amp;nbsp;&lt;/STRONG&gt;At the time of writing, the editor has no code-completion, any sort of help or utilities, and does not allow you to place breakpoints or write an output to the console - or anywhere.&amp;nbsp;&lt;BR /&gt;This makes debugging extremely tedious.&amp;nbsp;&lt;/P&gt;&lt;H4 id="toc-hId--1281471655"&gt;Step 7.2: Script - Convert string to a Dictionary or List object.&lt;/H4&gt;&lt;P&gt;The JSON data is stored in Datasphere as a string, and we have to transform that without the JSON module, which would make the exercise trivial.&amp;nbsp;&lt;/P&gt;&lt;P&gt;So, will do the following:&amp;nbsp;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Find all the 'key' : 'value' pairs in the data - make sure we can also handle nested dictionaries.&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;Loop through the pairs and add them to a dictionary.&amp;nbsp;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;To accomplish step 1, we will use regular expressions that can identify the pairs. The following formats are supported:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;'Key' : 'Value' (both with and without whitespaces around the : is supported)&lt;/LI&gt;&lt;LI&gt;"key" : "Value"&amp;nbsp;(both with and without whitespaces around the : is supported)&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;That is, whether your data uses ' or " is okay.&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;r'["\'](\w+)["\']\s*:\s*(\{.*?\}|["\'].*?["\']|\d+)'&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Yes, I know it looks like a pocket-calculator having a stroke, but it works.&amp;nbsp;&lt;BR /&gt;You can use the &lt;A title="Test the Regex for yourself" href="https://www.regextester.com/?fam=155663#" target="_blank" rel="noopener nofollow noreferrer"&gt;regex-tester&lt;/A&gt; to play around with it for yourself.&lt;/P&gt;&lt;P&gt;Python allows a function to be defined within another function, so we can begin to package our logic into a function.&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;def process_dict(dict_str):
    # Assume the input string is a dictionary and parse it
    key_val_pattern = r'["\'](\w+)["\']\s*:\s*(\{.*?\}|["\'].*?["\']|\d+)'  # Matches key-value pairs, supporting ' and "
    matches = re.findall(key_val_pattern, dict_str)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The Variable "matches" will contain a list of all the pairs in the input.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Now, we can loop through the matches and create our dictionary:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;def process_dict(dict_str) -&amp;gt; dict:
    # Assume the input string is a dictionary and parse it
    key_val_pattern = r'["\'](\w+)["\']\s*:\s*(\{.*?\}|["\'].*?["\']|\d+)'  # Matches key-value pairs, supporting ' and "
    matches = re.findall(key_val_pattern, dict_str)
    
    parsed_dict = {}
    for key, value in matches:
        # Loop through and sotres keys as lower case, to support case-sentitivity. 
        if value.startswith('{'):  # If the value is a nested dictionary
            # Recursively process the nested dictionary
            parsed_dict[str(key).lower()] = process_dict(value)
        elif value.startswith('"') or value.startswith("'"):  # If the value is a string. 
            parsed_dict[str(key).lower()] = value.strip('"').strip("'")  # Remove quotes (either ' or ")
    
    return parsed_dict&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Note&lt;/STRONG&gt; in line 9, we which for a nested dictionary and recursively handle that.&amp;nbsp;&lt;/P&gt;&lt;P&gt;If we pass this string&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;"{'ID': 0, 'Name': 'Exotic Liquids', 'Address': { 'Street': 'NE 228th', 'City': 'Sammamish', 'State':  WA', 'ZipCode': 98074, 'Country': 'USA' }, 'Concurrency': 0 }"&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;We will get the following result:&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;{'id': 0, 'name': 'Exotic Liquids', 'address': { 'street': 'NE 228th', 'city': 'Sammamish', 'state':  WA', 'zipcode': 98074, 'country': 'USA' }, 'concurrency': 0 }&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Which we can then use to get the data we need.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt; The full script also contains handling for a list of dictionaries.&amp;nbsp;&lt;/P&gt;&lt;H4 id="toc-hId--1477985160"&gt;Step 7.3: Add the data to the DataFrame&lt;/H4&gt;&lt;P&gt;Now that you have your data in a variable, you can manipulate the DataFrame.&lt;/P&gt;&lt;P&gt;There is an infinite way of implementing this, but the most readable is a new function that uses the one above, and extracts the required info column by column.&amp;nbsp;&lt;BR /&gt;There are faster ways, but for the sake of the example, readability &amp;gt; speed.&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;def get_address_data(row, newcolumn : str):
    address = row["Address"]
    address_info = process_dict(address)
    return_value = address_info["address"].get(newcolumn.lower(),'')
    return return_value

data["State"] = data.apply(lambda row: get_address_data(row, "State"), axis = 1)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;In line 7, we create a new column, State and pass the entire row, and a value we want out.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Python now&amp;nbsp;iterates through the dataframe and applies the function.&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--1381095658"&gt;Step 8: The full script&lt;/H3&gt;&lt;P&gt;The full script will then look like this.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;def transform(data):
    """
    This function body should contain all the desired transformations on incoming DataFrame. Permitted builtin functions
    as well as permitted NumPy and Pandas objects and functions are available inside this function.
    Permitted NumPy and Pandas objects and functions can be used with aliases 'np' and 'pd' respectively.
    This function executes in a sandbox mode. Please refer the documentation for permitted objects and functions. Using
    any restricted functions or objects would cause an internal exception and result in a pipeline failure.
    Any code outside this function body will not be executed and inclusion of such code is discouraged.
    :param data: Pandas DataFrame
    :return: Pandas DataFrame
    """
    #####################################################
    def parse_string_to_list(data_str):
        result_list = []
        if ( data_str in ['','-','NULL',None] ):
            return result_list
        # Check if the string represents a list
        if data_str.startswith('['):
            # Extract individual elements of the list using regex
            # Matches nested dictionaries or flat dictionaries
            list_pattern = r'\{[^{}]*\{[^{}]*\}[^{}]*\}|\{[^{}]*\}'  
            list_items = re.findall(list_pattern, data_str)
        else:  
        # If it's not a list, treat the whole string as a single dictionary
            list_items = [data_str]

        # Step 2: Process each item in the list (or the single string)
        for item in list_items:
            result_list.append(process_dict(item))

        return result_list

    def process_dict(dict_str) -&amp;gt; dict:
        # Assume the input string is a dictionary and parse it
        key_val_pattern = r'["\'](\w+)["\']\s*:\s*(\{.*?\}|["\'].*?["\']|\d+)'  # Matches key-value pairs, supporting ' and "
        matches = re.findall(key_val_pattern, dict_str)
        
        parsed_dict = {}
        for key, value in matches:
            # Loop through and sotres keys as lower case, to support case-sentitivity. 
            if value.startswith('{'):  # If the value is a nested dictionary
                # Recursively process the nested dictionary
                parsed_dict[str(key).lower()] = process_dict(value)
            elif value.startswith('"') or value.startswith("'"):  # If the value is a string. 
                parsed_dict[str(key).lower()] = value.strip('"').strip("'")  # Remove quotes (either ' or ")
        
        return parsed_dict

    def get_address_data(row, newcolumn : str):
        # Get the value of the "Address" column
        address = row["Address"]
        # Process the input and read the first element of the list
        address_info = parse_string_to_list(address)[0]
        # get the requested value, and return an empty-string 
        return_value = address_info["address"].get(newcolumn.lower(),'')
        
        return return_value

    data["State"] = data.apply(lambda row: get_address_data(row, "State"), axis = 1)
    data["Zip"] = data.apply(lambda row: get_address_data(row, "zipcode"), axis = 1)
    data["Street"] = data.apply(lambda row: get_address_data(row, "Street"), axis = 1)
    data["Country"] = data.apply(lambda row: get_address_data(row, "Country"), axis = 1)
    data["City"] = data.apply(lambda row: get_address_data(row, "City"), axis = 1)
    #####################################################
    return data&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId--1577609163"&gt;Step 9: Add or select target table and run the Data Flow&lt;/H3&gt;&lt;P&gt;When you've added a target local table, you can run the data flow, and you should get the following result:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="clsorensen911_2-1745577716495.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254682iEFC7984C2BFEDC4C/image-size/large?v=v2&amp;amp;px=999" role="button" title="clsorensen911_2-1745577716495.png" alt="clsorensen911_2-1745577716495.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId--1480719661"&gt;Conclusion&lt;/H2&gt;&lt;P&gt;The support for nested OData entities, and python code, in Datasphere is lacking, and will hopefully be expanded greatly in the future.&amp;nbsp;&lt;BR /&gt;Whether you have the option to directly change the OData source, or you are using a public service, you should really consider some sort of middleware between the source and Datasphere.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Until then, you do have the option to manually transform JSON, stored as strings, in Datasphere, but this can be a massive headache.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-data-flow-scripts-and-generic-odata-unpacking-nested-values/ba-p/14085615"/>
    <published>2025-04-29T18:56:12.923000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/automating-meeting-insights-into-sap-bpa/ba-p/14086773</id>
    <title>Automating Meeting Insights into SAP BPA</title>
    <updated>2025-04-29T18:57:01.423000+02:00</updated>
    <author>
      <name>lporta</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/690935</uri>
    </author>
    <content>&lt;P&gt;How the extension works today:&lt;/P&gt;&lt;P&gt;1 - A SAP BPA flow triggers a small Python script.&lt;/P&gt;&lt;P&gt;2 - The script ingests a Word document transcript of the meeting.&lt;/P&gt;&lt;P&gt;3 - It sends the text to the OpenAI API, which returns a structured JSON with detected intents and action items.&lt;/P&gt;&lt;P&gt;4 - BPA bot reads the JSON and sends follow-up e-mails that execute specific requests voiced during the meeting — e.g., "Please check the status of ticket 90010," "Request an updated ETA from the printer-services vendor," etc. (not recap e-mails, which SAP Joule already covers). Future iterations will also create SAP objects such as tasks, quotations , purchase requisitions directl and etc.&lt;/P&gt;&lt;P&gt;Expected value:&lt;BR /&gt;Once operational, the assistant could save several hours of manual coordination per meeting, especially in management sessions where follow-up actions tend to be numerous and cross-functional.&lt;/P&gt;&lt;P&gt;Next milestone:&lt;BR /&gt;I plan to evolve the add-on into a real-time companion to SAP Joule by:&lt;/P&gt;&lt;P&gt;Capturing live audio transcripts instead of relying on Word uploads;&lt;/P&gt;&lt;P&gt;Enriching context with CRM/BTP data before inference;&lt;/P&gt;&lt;P&gt;Feeding the final JSON back into SAP Build for straight-through processing across multiple languages.&lt;/P&gt;&lt;P&gt;Combined with SAP Joule, this would complete the full loop: listen → understand → act → monitor.&lt;/P&gt;&lt;P&gt;I’d appreciate your thoughts on the architecture, technology and positioning before moving to a wider pilot. At the moment I think SAP Joule coud send events after meetings, or executions to BPA, so the bot will be able&amp;nbsp; to be trigerred.&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;What I need from you&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;I’m looking for feedback on the project’s overall architecture and guidance on the best SAP BTP technologies to use.&lt;BR /&gt;SAP has announced that Joule will soon integrate with Copilot, so I’d also like your view on whether we should eventually replace GPT with Copilot.&lt;BR /&gt;In short, is the idea solid, what existing BTP services or components can we leverage today, and how should we evolve the solution for the future?&lt;/P&gt;&lt;P class=""&gt;Lets create Julio hahahah the Husband of Joule.&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;Workflow:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="lporta_1-1745617996326.png" style="width: 651px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254898i3945A854B00CA3B5/image-dimensions/651x524?v=v2" width="651" height="524" role="button" title="lporta_1-1745617996326.png" alt="lporta_1-1745617996326.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;For full explanation watch te following video:&lt;/P&gt;&lt;P&gt;&lt;A href="https://www.youtube.com/watch?v=oyvg3O-acaw" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.youtube.com/watch?v=oyvg3O-acaw&lt;/A&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/automating-meeting-insights-into-sap-bpa/ba-p/14086773"/>
    <published>2025-04-29T18:57:01.423000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-cli-amp-python-exporting-modeling-objects-to-csv-files-for/ba-p/14087080</id>
    <title>SAP Datasphere CLI &amp; Python: Exporting Modeling Objects to CSV Files for Each Artifact</title>
    <updated>2025-04-29T18:57:17.498000+02:00</updated>
    <author>
      <name>vikasparmar88</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1528256</uri>
    </author>
    <content>&lt;H1 id="toc-hId-1382837983" id="toc-hId-1580240381"&gt;Introduction&lt;/H1&gt;&lt;P&gt;In this blog post, we'll explore how to use Python alongside SAP Datasphere CLI to extract modeling objects and export them to CSV files. The script allows users to handle artifacts such as remote tables, views, replication flows, and more, for each space in SAP Datasphere.&lt;BR /&gt;This solution is particularly useful for automating repetitive tasks and ensuring structured data handling across different modeling objects&lt;/P&gt;&lt;P&gt;&lt;FONT size="5" color="#000000"&gt;&lt;STRONG&gt;Prerequisites&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;Steps to install SAP Datasphere CLI:&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/f7d5eddf20a34a1aa48d8e2c68a44e28.html/" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/f7d5eddf20a34a1aa48d8e2c68a44e28.html/&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/sap-datasphere-external-access-overview-apis-cli-and-sql/bc-p/14086942#M180986/" target="_blank"&gt;https://community.sap.com/t5/technology-blogs-by-sap/sap-datasphere-external-access-overview-apis-cli-and-sql/bc-p/14086942#M180986/&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT size="5" color="#000000"&gt;&lt;STRONG&gt;Step-by-Step Process&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 1: Prepare Login.Json file&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Create OAuth Client with Purpose as Interactive Usage and Redirect URL as &lt;EM&gt;&lt;A href="http://localhost:8080" target="_blank" rel="noopener nofollow noreferrer"&gt;http://localhost:8080&lt;/A&gt;&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;Retrieve the necessary field values for the secret JSON file by running the following command.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;datasphere config secrets show&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;Prepare the Login_&amp;lt;TENANT&amp;gt;_DSP.json file for both DEV and PRD Tenants.&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;{
    "client_id": "",
    "client_secret": "",
    "authorization_url": "",
    "token_url": "",
    "access_token": "",
    "refresh_token": "",
    "host": "",
    "browser": ""
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;STRONG&gt;Step 2: Create Model_Object.py file with below code&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;!--  StartFragment   --&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;dsp_host&lt;/STRONG&gt; – Provide the URL for both DEV and PRD Datasphere tenants.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;secrets_file&lt;/STRONG&gt; – Specify the path to the Login_&amp;lt;TENANT&amp;gt;_DSP.json file.&lt;!--  EndFragment   --&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import subprocess
import pandas as pd
import sys
import json

def login_to_datasphere(Tenant):
    """
    Step 1: Logs into Datasphere using the appropriate credentials based on the tenant.
    - If `Tenant` is 'PRD', it uses production credentials.
    - Otherwise, it uses quality assurance credentials.
    - It also ensures the session is fresh by logging out first.
    """
    if Tenant == 'PRD':
        dsp_host = '&amp;lt;PRD URL&amp;gt;'
        secrets_file = '&amp;lt;PATH&amp;gt;/Login_PRD_DSP.json'
    else:
        dsp_host = '&amp;lt;DEV URL&amp;gt;'
        secrets_file = '&amp;lt;PATH&amp;gt;/Login_Q_DSP.json'

    # Logout first to ensure a fresh session
    subprocess.run("datasphere logout", shell=True)
    print(f'Set Host : datasphere config host set {dsp_host}')
    
    # Configure the Datasphere host based on the environment
    subprocess.run(f'datasphere config host set {dsp_host}', shell=True)
    
    # Perform login using the secrets file
    print(f'Login : datasphere login --host {dsp_host} --secrets-file {secrets_file}')
    subprocess.run(f'datasphere login --host {dsp_host} --secrets-file {secrets_file}', shell=True)
    
    print("Login to "+Tenant+" is successful")
        
    # Step 2: Retrieve and manage predefined modeling objects
    manage_Modeling_Object('spaces')
    manage_Modeling_Object('local-tables')
    manage_Modeling_Object('views')
    manage_Modeling_Object('analytic-models')
    manage_Modeling_Object('replication-flows')
    manage_Modeling_Object('remote-tables')
    manage_Modeling_Object('task-chains')
    manage_Modeling_Object('transformation-flows')
    manage_Modeling_Object('data-flows')
    manage_Modeling_Object('intelligent-lookups')
    manage_Modeling_Object('data-access-controls')

    return dsp_host  # Returning host info if needed in other operations


def fetch_modeling_objects(space_id, modeling_object="views", batch_size=200):
    """
    Step 4: Retrieves modeling objects using pagination.
    - Loops through available objects in batches of `batch_size` (default 200).
    - Uses Datasphere CLI commands to retrieve data dynamically.
    """

    all_objects = []  # List to store all retrieved modeling objects.
    skip = 0  # Offset for pagination, increasing in multiples of 200 to retrieve objects in batches.
    print(f"Checking {modeling_object.upper()} for space: {space_id.replace('"', '').replace(',', '')}")
    
    # Keep checking for objects unitil it return blank data
    while True:
       
        # Fetch modeling objects in batches using CLI
        command = f'datasphere objects {modeling_object} list --space {space_id} --top {batch_size} --skip {skip}'
        subprocess.run(command, capture_output=True, shell=True, text=True)
        result = subprocess.run(command, capture_output=True, shell=True, text=True)

        try:
            output = json.loads(result.stdout)
        except json.JSONDecodeError:
            print(f"Error decoding JSON: {result.stdout}")
            break

        if not output:
            break # Stop when no more objects are found
        
        # Clean the fetched data to write in csv file
        for obj in output:
            cleaned_flow = obj.get("technicalName", "").strip()
            all_objects.append({
                'Space ID': space_id,
                'Technical Name': cleaned_flow,
                'TYPE': modeling_object[:-1].upper()
            })

        skip += batch_size # Increment batch offset

    return all_objects

def manage_Modeling_Object(Modeling_Object):
    """
    Step 3: Retrieves all spaces in tenant.
    - Loops through available spaces and get the models for each space.
    - prepate csv file with all retrived data.
    """
    
    # Retrieve a list of all spaces in JSON format
    command = ['datasphere', 'spaces', 'list', '--json']
    result_spaces = subprocess.run(command, capture_output=True, shell=True, text=True)  # Run the command and capture output
    
    # Parse the list of spaces from the command's output
    spaces = result_spaces.stdout.splitlines()  # Split output into individual lines
    
    ModelingObject_data = []  # Initialize a list to store Modeling Object data
    
    # Check if the Modeling Object is 'spaces'
    if Modeling_Object == 'spaces':
        for space in spaces:
            if space == "[" or space == "]":
                continue  # Skip brackets in the JSON output
            space_id = space.strip().replace('"', '').replace(',', '')  # Extract space ID
            
            # Add space details to the data list
            ModelingObject_data.append({
                'Space ID': space_id.replace('"', '').replace(',', ''),
                'Technical Name': space_id.replace('"', '').replace(',', ''),
                'TYPE': Modeling_Object[:-1].upper()  # Set the TYPE as uppercase version of the input Modeling Object name
            })
    
    # Process Modeling Objects for each space
    else:
        for space in spaces:
            if space == "[" or space == "]":
                continue  # Skip brackets in the JSON output
            space_id = space.strip().replace('"', '').replace(',', '')  # Extract space ID
            
            # Get all the objects from the given space
            objects = fetch_modeling_objects(space_id, Modeling_Object)
            ModelingObject_data.extend(objects)
    
    # Write the collected data into a CSV file
    if ModelingObject_data:
        df = pd.DataFrame(ModelingObject_data)  # Create a DataFrame from the data list
        df.to_csv(Modeling_Object.upper()+'.csv', index=False)  # Save the DataFrame to a CSV file without the index
        print("Space vise all "+Modeling_Object.upper()+" have been written to "+Modeling_Object.upper()+".csv.")  # Log success message
    else:
        print("No Modeling Objects found.")  # Log message if no data was collected
    
    print('------------------------------------------------------------------------------------------------------------------------------------')  # Separator for readability
        
if __name__ == "__main__":
    # Check if two arguments are provided via the command line
    if len(sys.argv) &amp;gt; 1:
        Tenant = sys.argv[1]
        login_to_datasphere(Tenant)
    else:
        print("Please provide Tenant as argument.")  # Log error message if argument is missing&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 3: Open command prompt and execute the Model_Objects.py file&lt;/STRONG&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;python Model_Objects.py DEV&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="vikasparmar88_0-1748408323008.png" style="width: 635px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/266738iDB3D90E2D1BE6874/image-dimensions/635x246?v=v2" width="635" height="246" role="button" title="vikasparmar88_0-1748408323008.png" alt="vikasparmar88_0-1748408323008.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once the program execution is done it will generate CSV files for all the Datasphere artifactes mention in python code&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="vikasparmar88_1-1745646877909.png" style="width: 633px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255124i2D0343903B2ECFC7/image-dimensions/633x280?v=v2" width="633" height="280" role="button" title="vikasparmar88_1-1745646877909.png" alt="vikasparmar88_1-1745646877909.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;!--  StartFragment   --&gt;&lt;/P&gt;&lt;P&gt;Each generated CSV file will contain three columns:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Space ID&lt;/STRONG&gt; – The name of the space.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Technical Name&lt;/STRONG&gt; – The exact technical name of the object.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Type&lt;/STRONG&gt; – The category of the object (e.g., view, local-table, remote-table, replication flow, etc.)&lt;/LI&gt;&lt;/OL&gt;&lt;H1 id="toc-hId-1382837983" id="toc-hId-1383726876"&gt;Conclusion&lt;/H1&gt;&lt;P&gt;This script demonstrates how Python and SAP Datasphere CLI can collaborate to streamline artifact management and export data systematically. By following the steps provided, users can extend or adapt the code to suit their requirements.&lt;/P&gt;&lt;P&gt;Best regards,&lt;BR /&gt;Vikas Parmar&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-cli-amp-python-exporting-modeling-objects-to-csv-files-for/ba-p/14087080"/>
    <published>2025-04-29T18:57:17.498000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-cli-amp-python-automation-extract-all-artifacts-of/ba-p/14087857</id>
    <title>SAP Datasphere CLI &amp; Python Automation : Extract All Artifacts of Datasphere in CSV files.</title>
    <updated>2025-05-05T10:47:20.047000+02:00</updated>
    <author>
      <name>VikasParmar055</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1716232</uri>
    </author>
    <content>&lt;H1 id="toc-hId-1382837983" id="toc-hId-1580247983"&gt;Introduction&lt;/H1&gt;&lt;P&gt;&lt;BR /&gt;In this post, we'll look at how to use Python with SAP Datasphere CLI to extract data objects and save them as CSV files. The script helps you manage items like remote tables, views, replication flows, and more for every space in SAP Datasphere. It's a great tool for automating repeated tasks and keeping data organized across different objects.&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;H1 id="toc-hId-1382837983" id="toc-hId-1383734478"&gt;Usecases:&lt;/H1&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;1. &lt;STRONG&gt;Validate Namig Convesion&lt;/STRONG&gt; : Generated files can be used as source in Datasphere to validate the naming convension for all artifactes&lt;/SPAN&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;2. Identify and Delete unncessary objects from Datasphere Tenant.&lt;/SPAN&gt;&lt;/P&gt;&lt;H1 id="toc-hId-1382837983" id="toc-hId-1187220973"&gt;&lt;STRONG&gt;Prerequisites&lt;/STRONG&gt;&lt;/H1&gt;&lt;P&gt;Steps to install SAP Datasphere CLI:&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/f7d5eddf20a34a1aa48d8e2c68a44e28.html/" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/f7d5eddf20a34a1aa48d8e2c68...&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/sap-datasphere-external-access-overview-apis-cli-and-sql/bc-p/14086942#M180986/" target="_blank"&gt;https://community.sap.com/t5/technology-blogs-by-sap/sap-datasphere-external-access-overview-apis-cl...&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT size="5" color="#000000"&gt;&lt;STRONG&gt;Step-by-Step Process&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 1: Prepare Login.Json file&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Create OAuth Client with Purpose as Interactive Usage and Redirect URL as&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;A href="http://localhost:8080/" target="_blank" rel="noopener nofollow noreferrer"&gt;&lt;EM&gt;http://localhost:8080&lt;/EM&gt;&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Get the value of all below fields from the OAuth Client and prepare the Login.json file.&lt;/P&gt;&lt;PRE&gt;{
"client_id": "",
"client_secret": "",
"authorization_url": "",
"token_url": "",
"access_token": "",
"refresh_token": ""
}&lt;/PRE&gt;&lt;P&gt;&amp;nbsp;&lt;STRONG&gt;Step 2: Create Model_Object.py file with below code&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;dsp host&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;: give URL of Datasphere Tenant.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;secrets_file&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;: Give Path of Login.json file.&lt;/P&gt;&lt;PRE&gt;import subprocess
import pandas as pd
import sys

def manage_Modeling_Object(Modeling_Object):
    # Step 1: Login to Datasphere using host and secrets file
    dsp_host = '&amp;lt;URL of Datasphere&amp;gt;'
    secrets_file = '&amp;lt;path&amp;gt;/Login.json'
    command = f'datasphere login --host {dsp_host} --secrets-file {secrets_file}'
    subprocess.run(command, shell=True)  # Execute the login command
    
    # Step 2: Retrieve a list of all spaces in JSON format
    command = ['datasphere', 'spaces', 'list', '--json']
    result_spaces = subprocess.run(command, capture_output=True, shell=True, text=True)  # Run the command and capture output
    
    # Step 3: Parse the list of spaces from the command's output
    spaces = result_spaces.stdout.splitlines()  # Split output into individual lines
    
    ModelingObject_data = []  # Initialize a list to store Modeling Object data
    
    # Step 4: Check if the Modeling Object is 'spaces'
    if Modeling_Object == 'spaces':
        for space in spaces:
            if space == "[" or space == "]":
                continue  # Skip brackets in the JSON output
            space_id = space.strip()  # Extract space ID
            
            # Add space details to the data list
            ModelingObject_data.append({
                'Space ID': space_id.replace('"', '').replace(',', ''),
                'Technical Name': space_id.replace('"', '').replace(',', ''),
                'TYPE': Modeling_Object[:-1].upper()  # Set the TYPE as uppercase version of the input Modeling Object name
            })
    
    # Step 5: Process Modeling Objects for each space
    else:
        for space in spaces:
            if space == "[" or space == "]":
                continue  # Skip brackets in the JSON output
            space_id = space.strip()  # Extract space ID
            
            # Step 6: Retrieve Modeling Objects for the current space
            command = ['datasphere', 'objects', Modeling_Object, 'list', '--space', space_id.replace('"', '').replace(',', '')]
            result_ModelingObject = subprocess.run(command, capture_output=True, shell=True, text=True)  # Run the command
            
            # Step 7: Parse the Modeling Object data from the output
            ModelingObject_info = result_ModelingObject.stdout.splitlines()  # Split output into individual lines
            print("Checking "+Modeling_Object.upper()+" for space : "+space_id.replace('"', '').replace(',', ''))  # Log the space being checked
            
            # Step 8: Process each Modeling Object
            if len(ModelingObject_info) &amp;gt; 1:
                for flow in ModelingObject_info:
                    if '{' in flow or '}' in flow or '[' in flow or ']' in flow:
                        continue  # Skip brackets or braces in the output
                    cleaned_flow = flow.replace('"technicalName":', '').replace('"', '').strip()  # Clean up the output
                    
                    # Step 9: Add Modeling Object details to the data list
                    ModelingObject_data.append({
                        'Space ID': space_id.replace('"', '').replace(',', ''),
                        'Technical Name': cleaned_flow,
                        'TYPE': Modeling_Object[:-1].upper()  # Set the TYPE as uppercase version of the input Modeling Object name
                    })
    
    # Step 10: Write the collected data into a CSV file
    if ModelingObject_data:
        df = pd.DataFrame(ModelingObject_data)  # Create a DataFrame from the data list
        df.to_csv(Modeling_Object.upper()+'.csv', index=False)  # Save the DataFrame to a CSV file without the index
        print("Space vise all "+Modeling_Object.upper()+" have been written to "+Modeling_Object.upper()+".csv.")  # Log success message
    else:
        print("No Modeling Objects found.")  # Log message if no data was collected
    
    print('------------------------------------------------------------------------------------------------------------------------------------')  # Separator for readability
        
if __name__ == "__main__":
    # Check if an argument is provided via the command line
    if len(sys.argv) &amp;gt; 1:
        # Pass the first argument to the method
        manage_Modeling_Object(sys.argv[1])
    else:
        print("Please provide a Modeling Object name as an argument.")  # Log error message if no argument is provided
        
# Execute for predefined Modeling Objects
manage_Modeling_Object('remote-tables')
manage_Modeling_Object('local-tables')
manage_Modeling_Object('views')
manage_Modeling_Object('intelligent-lookups')
manage_Modeling_Object('data-flows')
manage_Modeling_Object('replication-flows')
manage_Modeling_Object('transformation-flows')
manage_Modeling_Object('task-chains')
manage_Modeling_Object('analytic-models')
manage_Modeling_Object('data-access-controls')&lt;/PRE&gt;&lt;P&gt;&lt;STRONG&gt;Step 3: Open command prompt and execute the Model_Objects.py file&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VikasParmar055_0-1745819896727.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255331iD13C18E5F83CA56D/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VikasParmar055_0-1745819896727.png" alt="VikasParmar055_0-1745819896727.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Once the program execution is done it will generate CSV files for all the Datasphere artifactes mention in python code&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VikasParmar055_1-1745819896735.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255332iD2C8108036EAC9AD/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VikasParmar055_1-1745819896735.png" alt="VikasParmar055_1-1745819896735.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;each CSV file will have 3 columns :&amp;nbsp;&lt;/P&gt;&lt;P&gt;1) Space ID : Name of the space&lt;/P&gt;&lt;P&gt;2) Technical Name : Exact Technical Name of Object&amp;nbsp;&lt;/P&gt;&lt;P&gt;3) Type : Type of Object&amp;nbsp;( i.e view, local-table, remote-table, replication flw etc)&lt;/P&gt;&lt;H1 id="toc-hId-1382837983" id="toc-hId-990707468"&gt;Conclusion&lt;/H1&gt;&lt;P&gt;This script demonstrates how Python and SAP Datasphere CLI can collaborate to streamline artifact management and export data systematically. By following the steps provided, users can extend or adapt the code to suit their requirements.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-cli-amp-python-automation-extract-all-artifacts-of/ba-p/14087857"/>
    <published>2025-05-05T10:47:20.047000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/designing-a-lightweight-sales-forecasting-prototype-in-sap-datasphere-with/ba-p/14097236</id>
    <title>Designing a Lightweight Sales Forecasting Prototype in SAP Datasphere with ChatGPT and Python</title>
    <updated>2025-05-12T22:17:11.842000+02:00</updated>
    <author>
      <name>AAGDAMAR</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/179388</uri>
    </author>
    <content>&lt;H3 id="toc-hId-1839331113"&gt;&lt;SPAN&gt;Introduction&lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;This blog post is a follow-up to my previous article &lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/example-of-python-script-usage-in-sap-datasphere/ba-p/13572244" target="_blank"&gt;&lt;SPAN&gt;Example of Python Script Usage in SAP Datasphere&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;. In that article, we explored how to use the Python operator inside a Datasphere data flow. This time, I wanted to push the boundaries a little further and design a lightweight sales forecasting and aggregation prototype directly within Datasphere using Python and no external tools.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The sales dataset used here is manually generated with the help of ChatGPT to simulate a realistic structure. During the process, several versions of Python code were tested and iterated as certain functions and libraries are restricted in the Datasphere Python sandbox. We learned through trial and error and found alternative implementations where needed.&lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1642817608"&gt;&lt;SPAN&gt;Dataset and Tables Overview&lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The work is built around these key components:&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;sales_order_sample&lt;/SPAN&gt;&lt;SPAN&gt;: the simulated source table including &lt;/SPAN&gt;&lt;SPAN&gt;OrderDate&lt;/SPAN&gt;&lt;SPAN&gt;, &lt;/SPAN&gt;&lt;SPAN&gt;ProductName&lt;/SPAN&gt;&lt;SPAN&gt;, &lt;/SPAN&gt;&lt;SPAN&gt;Region&lt;/SPAN&gt;&lt;SPAN&gt;, &lt;/SPAN&gt;&lt;SPAN&gt;Quantity&lt;/SPAN&gt;&lt;SPAN&gt;, and &lt;/SPAN&gt;&lt;SPAN&gt;SalesAmount&lt;/SPAN&gt;&lt;SPAN&gt;.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;Sales Optimization DF&lt;/SPAN&gt;&lt;SPAN&gt;: data flow used to perform time-based aggregation and prepare the data.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;daily_sales_output&lt;/SPAN&gt;&lt;SPAN&gt;: an alternative target that stores daily aggregated outputs.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Forecast DF&lt;SPAN&gt;: This data flow handled the forecast using rolling average and trend estimation.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;T_SalesData_SMA&lt;/SPAN&gt;&lt;SPAN&gt;: final table containing both historical and forecasted sales data using simple techniques.&lt;BR /&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1446304103"&gt;&lt;SPAN&gt;Step 1: Data Aggregation and Preparation (&lt;/SPAN&gt;&lt;SPAN&gt;Sales Optimization DF&lt;/SPAN&gt;&lt;SPAN&gt;)&lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AAGDAMAR_4-1746786701481.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/259140i9967622983A6177C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="AAGDAMAR_4-1746786701481.png" alt="AAGDAMAR_4-1746786701481.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;In the first step, we load the &lt;/SPAN&gt;&lt;SPAN&gt;sales_order_sample&lt;/SPAN&gt;&lt;SPAN&gt; table and prepare the dataset using a Python script within a data flow. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AAGDAMAR_5-1746787548367.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/259153i54FAFBC6617A88BD/image-size/medium?v=v2&amp;amp;px=400" role="button" title="AAGDAMAR_5-1746787548367.png" alt="AAGDAMAR_5-1746787548367.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AAGDAMAR_6-1746787593452.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/259154iF723E7FB67DC981D/image-size/medium?v=v2&amp;amp;px=400" role="button" title="AAGDAMAR_6-1746787593452.png" alt="AAGDAMAR_6-1746787593452.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The main tasks performed here are:&lt;/SPAN&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;Converting &lt;/SPAN&gt;&lt;SPAN&gt;OrderDate&lt;/SPAN&gt;&lt;SPAN&gt; into datetime format.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;Ensuring &lt;/SPAN&gt;&lt;SPAN&gt;SalesAmount&lt;/SPAN&gt;&lt;SPAN&gt; is numeric.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;Sorting by date.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;Grouping sales by date to get daily totals.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;PRE&gt;&lt;SPAN&gt;# Python script used in Sales Optimization DF

data['OrderDate'] = pd.to_datetime(data['OrderDate'], errors='coerce')
data['SalesAmount'] = pd.to_numeric(data['SalesAmount'], errors='coerce')
data = data.dropna(subset=['OrderDate', 'SalesAmount'])
data = data.sort_values('OrderDate')

daily_sales = data.groupby('OrderDate', as_index=False)['SalesAmount'].sum()

return daily_sales&lt;/SPAN&gt;&lt;/PRE&gt;&lt;P&gt;&lt;SPAN&gt;The result is stored in the &lt;/SPAN&gt;&lt;SPAN&gt;daily_sales_output&lt;/SPAN&gt;&lt;SPAN&gt; table and serves as the input for the forecasting step.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AAGDAMAR_3-1746787473222.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/259151i89174F239C7A6906/image-size/medium?v=v2&amp;amp;px=400" role="button" title="AAGDAMAR_3-1746787473222.png" alt="AAGDAMAR_3-1746787473222.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AAGDAMAR_4-1746787509272.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/259152iA5B317208AA0BA89/image-size/medium?v=v2&amp;amp;px=400" role="button" title="AAGDAMAR_4-1746787509272.png" alt="AAGDAMAR_4-1746787509272.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1249790598"&gt;&lt;SPAN&gt;Step 2: Forecasting Using Rolling Average and Trend (&lt;/SPAN&gt;&lt;SPAN&gt;Forecast DF&lt;/SPAN&gt;&lt;SPAN&gt;)&lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AAGDAMAR_5-1746786822576.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/259142i1678C59C772C758E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="AAGDAMAR_5-1746786822576.png" alt="AAGDAMAR_5-1746786822576.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;We implemented a simple linear regression model based on the last 7 days of data.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Here are the key steps:&lt;/SPAN&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;Calculate a 7-day rolling average (SMA) over historical data.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;Extract the last 7 days and fit a linear trend line using &lt;/SPAN&gt;&lt;SPAN&gt;np.polyfit&lt;/SPAN&gt;&lt;SPAN&gt;.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;Use this trend to project the next 30 days.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;Generate future dates and apply the forecasted values.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;SPAN&gt;Combine the future forecast with the historical dataset.&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;PRE&gt;&lt;SPAN&gt;# Python script used in Forecast DF

data['OrderDate'] = pd.to_datetime(data['OrderDate'], errors='coerce')
data['SalesAmount'] = pd.to_numeric(data['SalesAmount'], errors='coerce')
data = data.dropna(subset=['OrderDate', 'SalesAmount'])
data = data.sort_values('OrderDate')

data['SalesAmount_SMA'] = data['SalesAmount'].rolling(window=7, min_periods=1).mean()

# Linear regression on last 7 days
last_7 = data.tail(7)
x = np.arange(1, 8)
y = last_7['SalesAmount'].values
coef = np.polyfit(x, y, deg=1)
trend = np.poly1d(coef)

# Forecast next 30 days
date_start = data['OrderDate'].max() + pd.Timedelta(days=1)
future_dates = pd.date_range(start=date_start, periods=30)
future_x = np.arange(8, 38)
forecast = trend(future_x)

future_df = pd.DataFrame({
    'OrderDate': future_dates,
    'SalesAmount': forecast,
    'SalesAmount_SMA': pd.Series(forecast).rolling(window=7, min_periods=1).mean()
})

result = pd.concat([data, future_df], ignore_index=True)
return result[['OrderDate', 'SalesAmount', 'SalesAmount_SMA']]&lt;/SPAN&gt;&lt;/PRE&gt;&lt;P&gt;&lt;SPAN&gt;The output is written to &lt;/SPAN&gt;&lt;SPAN&gt;T_SalesData_SMA&lt;/SPAN&gt;&lt;SPAN&gt; and includes both past sales and 30-day projections.&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AAGDAMAR_2-1746787402144.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/259149i0199E3AB98A2ACF6/image-size/medium?v=v2&amp;amp;px=400" role="button" title="AAGDAMAR_2-1746787402144.png" alt="AAGDAMAR_2-1746787402144.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AAGDAMAR_1-1746787386123.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/259148i89A951DD14F2AD64/image-size/medium?v=v2&amp;amp;px=400" role="button" title="AAGDAMAR_1-1746787386123.png" alt="AAGDAMAR_1-1746787386123.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The increase in row count from 336 to 366 confirms the forecast was appended. these are the lines including January 2024 data with 30 rows.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AAGDAMAR_0-1746787361462.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/259147i4378334A0363C9DE/image-size/medium?v=v2&amp;amp;px=400" role="button" title="AAGDAMAR_0-1746787361462.png" alt="AAGDAMAR_0-1746787361462.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;DIV&gt;&lt;HR /&gt;&lt;/DIV&gt;&lt;H3 id="toc-hId-1053277093"&gt;&lt;SPAN&gt;Conclusion&lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;This example demonstrates how you can build a minimal yet functional forecasting pipeline in SAP Datasphere using only built-in Python capabilities. Although certain external libraries (like Prophet) are not available in the sandboxed environment, alternatives such as rolling averages and basic linear regression provide effective approximations.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The project also highlights how conversational AI (ChatGPT) can play an important role in rapid prototyping, testing, and iteratively refining technical solutions. Most code samples here were the result of trial, error, and creative iteration.&lt;/SPAN&gt;&lt;/P&gt;&lt;DIV&gt;&lt;HR /&gt;&lt;/DIV&gt;&lt;P&gt;&lt;SPAN&gt;&lt;EM&gt;Thanks for reading!&lt;/EM&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/designing-a-lightweight-sales-forecasting-prototype-in-sap-datasphere-with/ba-p/14097236"/>
    <published>2025-05-12T22:17:11.842000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/agentic-ai-evaluation-observability-traceability-amp-metrics-that-matter/ba-p/14056316</id>
    <title>Agentic AI Evaluation: Observability, Traceability &amp; Metrics That Matter</title>
    <updated>2025-05-14T13:56:33.273000+02:00</updated>
    <author>
      <name>Avinash_Vaidya</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/120687</uri>
    </author>
    <content>&lt;P&gt;&lt;U&gt;&lt;EM&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Introduction&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/EM&gt;&lt;/U&gt;&lt;/P&gt;&lt;P&gt;Today, enterprises are creating agents, either to automate some manual processes or to optimize existing once. No matter what is the use case, we have already entered the &lt;STRONG&gt;Economy&lt;/STRONG&gt; &lt;STRONG&gt;of&lt;/STRONG&gt; &lt;STRONG&gt;Agents&lt;/STRONG&gt;. This is similar to last several decades where software engineers, developers or consultants developed production grade applications.&lt;/P&gt;&lt;P&gt;Software development evolved over decades which gave us some time to adapt to it and accept new solutions/frameworks. Also the pace with which we were developing applications was slow as compared to the pace with which agentic solutions are being developed.&lt;/P&gt;&lt;P&gt;The critical difference between traditional software solutions/applications and agentic solutions is the very nature. Traditional software solutions are deterministic in nature as opposed to agentic solutions which are non deterministic in nature to an extent.&lt;/P&gt;&lt;P&gt;Quality Gate for traditional software development has evolved over years of iterations and given us some robust test automation tools and frameworks. The harsh truth is - &lt;STRONG&gt;we still find production bugs&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;Now, imagine a non deterministic agentic software application for which testing is hard to define or predict at times. This may lead to totally unpredictable production bugs or unexpected behaviour. This might cost us time&amp;nbsp;and money, that too - exponentially.&lt;/P&gt;&lt;P&gt;That is the reason, evaluation of Agentic solutions is very important and should be considered top priority for enterprises to ensure we produce good quality of Agentic applications.&lt;/P&gt;&lt;P&gt;This blog is not to scare you, but to give you a spark to think and act.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;So, gear up! and let's start&amp;nbsp;&lt;SPAN class="lia-unicode-emoji"&gt;&lt;span class="lia-unicode-emoji" title=":rocket:"&gt;🚀&lt;/span&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;I will breakdown the article into following parts&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;What is agent evaluation?&lt;/LI&gt;&lt;LI&gt;Types of agent evaluation&lt;/LI&gt;&lt;LI&gt;Evaluation Tools&lt;/LI&gt;&lt;LI&gt;Evaluation framework (Block Diagram)&lt;/LI&gt;&lt;LI&gt;Why OpenTelemetry?&lt;/LI&gt;&lt;LI&gt;Code walkthrough&lt;/LI&gt;&lt;LI&gt;Available Agentic Evaluation frameworks&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;U&gt;&lt;EM&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;What is Agent Evaluation?&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/EM&gt;&lt;/U&gt;&lt;/P&gt;&lt;P&gt;Agent evaluation is validating the output of an agent. This differs slightly from the typical software development testing. In a software testing, we know what is a input and what is the expected output.&lt;/P&gt;&lt;P&gt;But in case of agentic solutions, as the response is given by the underlying LLM, the output varies due to lot of factors such as prompts, LLM used etc.&lt;/P&gt;&lt;P&gt;So, agentic AI testing is done in a different way. It is based on some pre-defined metrics such as response times, underlying tools used by the agent, token consumption, cost of total response etc. to name a few.&lt;/P&gt;&lt;P&gt;Based on the evaluation results, the respective developer can tweak the solution either by enhancing the prompts, changing the underlying LLM, introducing additional tool which will reduce the over all response time and token consumption, but also ensuring the expected output is provided.&lt;/P&gt;&lt;P&gt;Agent evaluation is a evolving space and a lot of advancements are being done to streamline it.&lt;/P&gt;&lt;H2 id="toc-hId-1706525418"&gt;&lt;U&gt;&lt;EM&gt;&lt;STRONG&gt;Types of Agent Evaluation&lt;/STRONG&gt;&lt;/EM&gt;&lt;/U&gt;&lt;/H2&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Code based evaluation:&amp;nbsp;&lt;/STRONG&gt;It is a pro-code type of evaluation and you will get a glimpse of it in this tutorial/POC. In code based evaluation, code is injected in the Agentic AI application which captures the metric data when the agent it executing any request. &lt;STRONG&gt;It is well suited to validate objectivity of the solution&lt;/STRONG&gt;. By that, I mean it is well suited to validate the quantitative attributes of the agentic solution, for example - latency, response time, token consumption etc.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;LLM as a judge:&lt;/STRONG&gt; This is kind of low-code type of evaluation. This is not covered in this tutorial/POC. As the name suggests, here LLM is a reviewer. It validates the correctness of the output provided by the agentic application.&amp;nbsp;&lt;STRONG&gt;It is well suited to validate subjectivity of the solution&lt;/STRONG&gt;. By that, I mean it is well suited to validate the qualitative attributes of the agentic solution, for example - correctness of output response, reasoning, planning etc.&lt;/LI&gt;&lt;/OL&gt;&lt;H2 id="toc-hId-1510011913"&gt;&lt;U&gt;&lt;EM&gt;&lt;STRONG&gt;Evaluation Tools&lt;/STRONG&gt;&lt;/EM&gt;&lt;/U&gt;&lt;/H2&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;&lt;STRONG&gt;Pre-requisite:&lt;/STRONG&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;For running this observability stack on your local machine, you should have docker desktop installed. Once done, install below docker images.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;OL&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;STRONG&gt;Prometheus&lt;/STRONG&gt;:&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;Time series data store for collecting metric data and alerting.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;STRONG&gt;Grafana Tempo&lt;/STRONG&gt;:&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;A distributed tracing backend that simplifies storing and visualizing trace data.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;STRONG&gt;OpenTelemetry Collector&lt;/STRONG&gt;:&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;Acts as a central hub for receiving traces and exporting telemetry data to observability backends.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;STRONG&gt;Grafana&lt;/STRONG&gt;:&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;Grafana is an interactive data visualization and monitoring platform that allows users to query, visualize, and understand data from various source.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;/DIV&gt;&lt;P&gt;&lt;U&gt;&lt;EM&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Evaluation Framework (Block Diagram)&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/EM&gt;&lt;/U&gt;&lt;/P&gt;&lt;P&gt;&lt;U&gt;&lt;EM&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Figure-1" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/253746i61E17436952466DB/image-size/large?v=v2&amp;amp;px=999" role="button" title="agent_evaluation.png" alt="Figure-1" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;Figure-1&lt;/span&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/EM&gt;&lt;/U&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;U&gt;&lt;EM&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Why OpenTelemetry?&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/EM&gt;&lt;/U&gt;&lt;/P&gt;&lt;P&gt;A very obvious question after looking at the above block diagram is "Why OpenTelemetry?"&lt;/P&gt;&lt;P&gt;OpenTelemetry is an open standard for collecting and exporting telemetry data like metrics and traces.&lt;/P&gt;&lt;P&gt;I would summarize in &lt;STRONG&gt;5&amp;nbsp;important points:&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Vendor neutral&lt;/STRONG&gt; and can integrate with any backend for visualization&lt;/LI&gt;&lt;LI&gt;Provides &lt;STRONG&gt;diverse language support&lt;/STRONG&gt; (Python, Node.js etc)&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Batch processing&lt;/STRONG&gt; which helps to speed up the trace collection&lt;/LI&gt;&lt;LI&gt;Provides &lt;STRONG&gt;standard&lt;/STRONG&gt; format for collection of observability data&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Powerful tracing&lt;/STRONG&gt;&lt;SPAN&gt; providing parent-child relationship and context propagation&lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;SPAN&gt;If you want to deep dive into open telemetry, I have added a link in the reference section.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;U&gt;&lt;EM&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Code Walkthrough&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/EM&gt;&lt;/U&gt;&lt;/P&gt;&lt;P&gt;Till now we have discussed the theory and block diagram, now it's time to deep dive in the code. The &lt;STRONG&gt;Agent Evaluation&lt;/STRONG&gt; section of the &lt;A href="https://github.com/avinashvaidya09/multi_agent_system_demo/blob/main/README.md" target="_self" rel="nofollow noopener noreferrer"&gt;README&lt;/A&gt; details out each and every step to help you get started. I would like to mention some important files in this section for you to give extra attention when you are browsing the code&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;A href="https://github.com/avinashvaidya09/multi_agent_system_demo/tree/main/observability" target="_self" rel="nofollow noopener noreferrer"&gt;observability&lt;/A&gt; folder has all the config files for open telemetry collector, tempo and prometheus.&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://github.com/avinashvaidya09/multi_agent_system_demo/blob/main/mas_autogen/app/utils/agent_observability.py" target="_self" rel="nofollow noopener noreferrer"&gt;agent_observability.py&lt;/A&gt;&amp;nbsp;&lt;/SPAN&gt;- This singleton class is the core of observability. This holds all the methods for capturing the metrics and traces. I have created decorators which are applied on the actual functions to capture traces. Custom attributes like&amp;nbsp;request_size_in_bytes, agent_name, response_time are captured. You can add more attributes here such as token_consumption etc.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://github.com/avinashvaidya09/multi_agent_system_demo/blob/main/mas_autogen/app/utils/prompt_config.py" target="_self" rel="nofollow noopener noreferrer"&gt;agent_service.py&lt;/A&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;- In this file, you will see the decorator applied to the &lt;STRONG&gt;"/chat"&lt;/STRONG&gt; endpoint method.&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://github.com/avinashvaidya09/multi_agent_system_demo/blob/main/mas_autogen/app/functions/weather_functions.py" target="_self" rel="nofollow noopener noreferrer"&gt;weather_functions.py&lt;/A&gt; - In this file, you will see the decorator applied to all the weather functions.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;I have applied the tracing only to weather agent, but can be extended to finance agent.&lt;/P&gt;&lt;P&gt;But there are over the shelf evaluation frameworks available which can be leveraged and provide certain level of customizations. The next section talks about it.&lt;/P&gt;&lt;P&gt;&lt;U&gt;&lt;EM&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Available Agentic Evaluation Frameworks&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/EM&gt;&lt;/U&gt;&lt;/P&gt;&lt;P&gt;I have listed few agentic AI evaluations frameworks available and are good starting point to start learning and understanding the importance of agent evaluation.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;LangSmith -&amp;nbsp;&lt;A href="https://www.langchain.com/langsmith" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.langchain.com/langsmith&lt;/A&gt;&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;Phoenix - &lt;A href="https://docs.arize.com/phoenix" target="_blank" rel="noopener nofollow noreferrer"&gt;https://docs.arize.com/phoenix&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;DeepEval -&amp;nbsp;&lt;A href="https://www.deepeval.com" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.deepeval.com&lt;/A&gt;&amp;nbsp;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;U&gt;&lt;EM&gt;&lt;STRONG&gt;Conclusion&lt;/STRONG&gt;&lt;/EM&gt;&lt;/U&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;Drawing from my experience, I must emphasize that these insights can serve as a starting point, though their applicability may vary based on specific scenarios.&amp;nbsp;This project will surely give you a starting point from design and development of Agentic AI evaluation.&lt;/P&gt;&lt;P class=""&gt;&lt;SPAN&gt;Along with the theory, my intention is to showcase a fully functional prototype which is publicly available on -&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://github.com/avinashvaidya09/multi_agent_system_demo/tree/main" target="_self" rel="nofollow noopener noreferrer"&gt;GitHub&lt;/A&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;SPAN&gt;&lt;STRONG&gt;Disclaimer&lt;/STRONG&gt;: This is not an official reference application or documentation. The thoughts outlined in this blog are based on my experience and learnings about Agentic AI and agent evaluation.&lt;/SPAN&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;&lt;EM&gt;Feel free to “like“, “Share“, “Add a Comment” and to get more updates about my next blogs follow me!&lt;/EM&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;&lt;EM&gt;&lt;U&gt;&lt;FONT size="5"&gt;References&lt;/FONT&gt;&lt;/U&gt;&lt;/EM&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;A href="https://opentelemetry.io/docs/languages/python/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://opentelemetry.io/docs/languages/python/&lt;/A&gt;&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://grafana.com/blog/2021/05/04/get-started-with-distributed-tracing-and-grafana-tempo-using-foobar-a-demo-written-in-python/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://grafana.com/blog/2021/05/04/get-started-with-distributed-tracing-and-grafana-tempo-using-foobar-a-demo-written-in-python/&lt;/A&gt;&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://prometheus.io/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://prometheus.io/&lt;/A&gt;&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://opentelemetry.io/docs/what-is-opentelemetry/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://opentelemetry.io/docs/what-is-opentelemetry/&lt;/A&gt;&amp;nbsp;&lt;/LI&gt;&lt;/OL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/agentic-ai-evaluation-observability-traceability-amp-metrics-that-matter/ba-p/14056316"/>
    <published>2025-05-14T13:56:33.273000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-cli-amp-python-automation-add-1000-users-in-datasphere-space/ba-p/14101128</id>
    <title>SAP Datasphere CLI &amp; Python Automation : ADD 1000+ Users in Datasphere space in few seconds</title>
    <updated>2025-05-16T09:59:17.308000+02:00</updated>
    <author>
      <name>vikasparmar88</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1528256</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;This blog is part of a blog series from SAP Datasphere CLI &amp;amp; Python Automation with the focus on SAP Datasphere &amp;amp; Python capabilities:&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;FONT size="4"&gt;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-cli-amp-python-automation-extract-all-artifacts-of/ba-p/14087857" target="_blank"&gt;SAP Datasphere CLI &amp;amp; Python Automation : Extract All Artifacts of Datasphere in CSV files.&lt;/A&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H1 id="toc-hId-1382837983" id="toc-hId-1601303401"&gt;&lt;FONT size="6"&gt;Introduction&lt;/FONT&gt;&lt;/H1&gt;&lt;P&gt;Managing users in SAP Datasphere can take a lot of time, especially when there are hundreds or thousands of users. Adding them one by one is slow and tiring. This blog explains an easy way to automate the process using Python and SAP Datasphere CLI. With this method, you can add over 1000 users in just a few seconds, saving time and effort.&lt;/P&gt;&lt;H1 id="topic-title" id="toc-hId-1404789896"&gt;Install or Update the&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN class=""&gt;SAP Datasphere&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;Command Line Interface&lt;/H1&gt;&lt;P&gt;&lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/f7d5eddf20a34a1aa48d8e2c68a44e28.html/" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_DATASPHERE/d0ecd6f297ac40249072a44df0549c1a/f7d5eddf20a34a1aa48d8e2c68a44e28.html/&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1208276391"&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Step-by-Step Process&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/H1&gt;&lt;P&gt;&lt;STRONG&gt;Step 1: Prepare Login.Json file&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Create OAuth Client with Purpose as Interactive Usage and Redirect URL as&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;EM&gt;&lt;A href="http://localhost:8080" target="_blank" rel="noopener nofollow noreferrer"&gt;http://localhost:8080&lt;/A&gt;&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;Get the Refresh Token and access Token by executing below command&amp;nbsp;&lt;/EM&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;datasphere config secrets show&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Get the value of all below fields from the OAuth Client and prepare the Login.json file.&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;{
"client_id": "",
"client_secret": "",
"authorization_url": "",
"token_url": "",
"access_token": "",
"refresh_token": ""
}&lt;/code&gt;&lt;/pre&gt;&lt;H1 id="toc-hId-1382837983" id="toc-hId-1011762886"&gt;&lt;FONT size="4"&gt;Step-2: Prepare USERS.CSV File for Input:&lt;/FONT&gt;&lt;/H1&gt;&lt;P&gt;&lt;FONT size="4"&gt;There are 3 columns in CSV file.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="4"&gt;1) &lt;STRONG&gt;Space&lt;/STRONG&gt; : Space Name&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="4"&gt;2) &lt;STRONG&gt;User&lt;/STRONG&gt; : User ID in Datasphere&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="4"&gt;3) &lt;STRONG&gt;Role&lt;/STRONG&gt; : Scope Role name, required for user.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="4"&gt;As shown below, There are 1357 users need to be assigned to Datasphere space with given role in Datasphere.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-05-14 132712.png" style="width: 361px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/260915iC37BF11D608DEDB0/image-dimensions/361x385?v=v2" width="361" height="385" role="button" title="Screenshot 2025-05-14 132712.png" alt="Screenshot 2025-05-14 132712.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H1 id="toc-hId-1382837983" id="toc-hId-815249381"&gt;&lt;FONT size="4"&gt;Step-3:&amp;nbsp;Space_User_Role_Json&lt;STRONG&gt;.py file with below code&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/H1&gt;&lt;P&gt;&lt;STRONG&gt;The Code: Automating User Assignments&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The following Python script simplifies bulk user assignments by:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Reading user-role mappings from a CSV file.&lt;/LI&gt;&lt;LI&gt;Dynamically creating JSON files containing space-user-role mappings.&lt;/LI&gt;&lt;LI&gt;Executing SAP Datasphere CLI commands to automate user additions.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;dsp host&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;: give URL of Datasphere Tenant.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;secrets_file&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;: Give Path of Login.json file.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import subprocess  # For OS commands on DSP CLI
import json  # For handling the JSON file format
import pandas as pd  # For reading the CSV file
import os  # For creating directories dynamically
import sys  # For accessing command-line arguments

def create_json_file(space_name, user_role_data, directory):
    """
    Create a JSON file for the given space name and associated user-role data, saving it to the specified directory.

    Args:
        space_name (str): The name of the space.
        user_role_data (list): A list of dictionaries containing user and role mappings.
        directory (str): The directory where the file should be saved.
    """
    # Define the JSON structure
    data = [
        {
            "id": user_role["User"],
            "roles": [user_role["Role"]]  # Roles are explicitly wrapped in a list
        }
        for user_role in user_role_data
    ]


    # Specify the file name and path
    file_name = f"{space_name}.json"
    file_path = os.path.join(directory, file_name)

    # Ensure the directory exists
    os.makedirs(directory, exist_ok=True)

    # Convert `data` to a JSON string with the desired format
    json_content = json.dumps(data, indent=2, separators=(',', ': '))

    # Remove unncessary new lines and spaces for Role
    json_content = json_content.replace("[\n", "[").replace("\n    ]","]").replace("[      ","[")

    # Create the JSON file with the updated content
    with open(file_path, "w") as json_file:
        json_file.write(json_content)

    print(f"JSON file created successfully for space : {space_name}")
    return file_path

def manage_spaces(csv_file_path):
    """
    Reads a CSV file to verify columns, then processes spaces, users, and roles to create JSON files
    and execute Datasphere CLI commands.

    Args:
        csv_file_path (str): The path to the CSV file containing Space, User, and Role columns.
    """
    try:
        # Check if the argument is passed
        if not csv_file_path:
            raise ValueError("csv_file_path argument is required.")
        
        # Check if the argument is a string and contains ".csv"
        if not isinstance(csv_file_path, str) or not csv_file_path.endswith(".csv"):
            raise ValueError("The csv_file_path must be a string and end with '.csv'.")
        
        print(f"Argument received: {csv_file_path}")
        
        # Login to Datasphere using host and secrets file
        dsp_host = '&amp;lt;DATASPHERE URL&amp;gt;'
        secrets_file = '&amp;lt;PATH&amp;gt;/Login.json'
        command = f'datasphere login --host {dsp_host} --secrets-file {secrets_file}'
        subprocess.run(command, shell=True)  # Execute the login command

        # Replace forward slashes with backslashes for consistency
        csv_file_path = csv_file_path.replace("/", "\\")
        print(f"Formatted csv_file_path: {csv_file_path}")
        
        # Read the CSV file
        data = pd.read_csv(csv_file_path)

        # Validate columns
        required_columns = ['Space', 'User', 'Role']
        if not set(required_columns).issubset(data.columns):
            raise ValueError("CSV file must contain 'Space', 'User', and 'Role' columns.")

        # Extract unique spaces
        spaces = data['Space'].unique()

        # Process each space
        for space in spaces:
            
            #For each space find users and their role given in csv file
            space_data = data[data['Space'] == space]
            user_role_data = space_data[['User', 'Role']].to_dict(orient='records')
            
            # Check if the space exists
            check_space_command = f'datasphere spaces read --space {space}'
            result = subprocess.run(check_space_command, shell=True, capture_output=True, text=True)
            
            # Create JSON file for each space
            path = csv_file_path.rsplit('\\', 1)[0] + "\\"
            json_file_path = create_json_file(space, user_role_data, path)
              
            # Add users to the space using the generated JSON file
            add_users_command = f'datasphere spaces users add --space "{space}" --file-path "{json_file_path}"'
            print(f"Adding Users to {space} space now...")
            try:
                result = subprocess.run(add_users_command, shell=True, capture_output=True, text=True)
                if result.returncode == 0:
                    print(f"Successfully added users to space '{space}' using file '{json_file_path}'.")
                else:
                    print(f"Failed to add users to space '{space}'. Error: {result.stderr}")
            except Exception as e:
                print(f"An error occurred while adding users to space '{space}': {e}")

    except FileNotFoundError:
        print(f"CSV file '{csv_file_path}' not found.")
    except ValueError as ve:
        print(f"Argument error: {ve}")
    except Exception as e:
        print(f"An error occurred: {e}")

# Check if the script is run with the required argument
if len(sys.argv) &amp;gt; 1:
    manage_spaces(sys.argv[1])
else:
    print("Please provide the CSV file path as an argument when running the script.")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Step 4: Open command prompt and execute the&amp;nbsp;&lt;FONT size="4"&gt;Space_User_Role_Json.py&amp;nbsp;&lt;/FONT&gt;file&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Give the path of USERS.csv file as argument&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;python Space_User_Role_Json.py('C:/DataSphere/USERS.csv')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Execution will take few seconds to complete and Once it's done you can see all users ( User count 1356 in my case ) are added to respective space with role assigned in USERS.csv file.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="vikasparmar88_2-1747214928113.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/260980iACEA161A6FA8D830/image-size/medium?v=v2&amp;amp;px=400" role="button" title="vikasparmar88_2-1747214928113.png" alt="vikasparmar88_2-1747214928113.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;!--    StartFragment     --&gt;&lt;/P&gt;&lt;H1 id="toc-hId-1382837983" id="toc-hId-618735876"&gt;&lt;FONT size="6"&gt;Conculsion&lt;/FONT&gt;&lt;/H1&gt;&lt;P&gt;With this automation, SAP Datasphere user management becomes seamless and scalable. Python scripting combined with Datasphere CLI simplifies user assignments and minimizes human effort. Whether managing hundreds or thousands of users, this method enhances efficiency while maintaining structured access control.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;If you have questions or noticed a scenario I didn’t cover, feel free to leave a comment below the blog post.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;Thank&lt;/P&gt;&lt;P&gt;Vikas Parmar&lt;/P&gt;&lt;P&gt;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Datasphere/pd-p/73555000100800002141" class="lia-product-mention" data-product="16-1"&gt;SAP Datasphere&lt;/a&gt;&amp;nbsp; &lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+HANA/pd-p/73554900100700000996" class="lia-product-mention" data-product="639-1"&gt;SAP HANA&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/OData/pd-p/551580658536717501828021060147962" class="lia-product-mention" data-product="323-1"&gt;OData&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SQL/pd-p/122888716930844301706258287775555" class="lia-product-mention" data-product="326-1"&gt;SQL&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/Python/pd-p/f220d74d-56e2-487e-8e6c-a8cb3def2378" class="lia-product-mention" data-product="126-1"&gt;Python&lt;/a&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;!--    EndFragment     --&gt;&lt;/P&gt;&lt;P&gt;&lt;!--    EndFragment     --&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/sap-datasphere-cli-amp-python-automation-add-1000-users-in-datasphere-space/ba-p/14101128"/>
    <published>2025-05-16T09:59:17.308000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/semantic-querying-with-sap-hana-cloud-knowledge-graph-using-rdf-sparql-and/ba-p/14109200</id>
    <title>Semantic Querying with SAP HANA Cloud Knowledge Graph using RDF, SPARQL, and Generative AI in Python</title>
    <updated>2025-05-22T12:40:07.914000+02:00</updated>
    <author>
      <name>jing_wen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1923466</uri>
    </author>
    <content>&lt;P&gt;SAP Knowledge Graph is now generally available (Q1 2025) and is poised to fundamentally change how data relationships are mapped and queried. With grounded intelligence, knowledge graphs are crucial in enabling AI agents for reasoning and retrieval with context and high accuracy. SAP Knowledge Graph Engine includes a native RDF triplestore and supports SQL/SPARQL interoperability, allowing both semantic and relational access.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="1. SAP HANA.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/265022i384F499585C329E4/image-size/medium?v=v2&amp;amp;px=400" role="button" title="1. SAP HANA.png" alt="1. SAP HANA.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;A few key concepts when working with SAP Knowledge Graph:&lt;BR /&gt;&amp;nbsp;&lt;BR /&gt;&lt;STRONG&gt;Resource Description Framework (RDF): &lt;/STRONG&gt;Graph-like format utilizing the relationship between entities to connect information&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;RDF Triples&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Subject&lt;/STRONG&gt;&amp;nbsp;- The entity being described (e.g., a product, person, or organization).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Predicate&lt;/STRONG&gt;&amp;nbsp;- The relationship between the subject and the object (e.g., "manufactures," "owns," "located in").&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Object&lt;/STRONG&gt;&amp;nbsp;- The value or entity linked to the subject (e.g., a location, another person, or an attribute).&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;RDF enables storing and querying relationships dynamically, making it a key foundation for knowledge graphs and AI-driven reasoning.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;URI (Uniform Resource Identifier): &lt;/STRONG&gt;Unique identifier for an entity or relationship within the knowledge graph.&lt;/P&gt;&lt;P&gt;This blog covers an integration of SAP HANA Cloud Knowledge Graph with Gen AI Hub on Python, uploading and querying an RDF graph. For starters, refer to the SAP Discovery Center Mission – &amp;nbsp;&lt;A href="https://discovery-center.cloud.sap/missiondetail/4568/4856/" target="_blank" rel="noopener nofollow noreferrer"&gt;Building Intelligent Data Applications with SAP HANA Cloud Knowledge Graphs&lt;/A&gt;. &lt;STRONG&gt;&lt;BR /&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="2. HANA Cloud Knowledge Graph.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/265023i6F4426457B4BCFF2/image-size/large?v=v2&amp;amp;px=999" role="button" title="2. HANA Cloud Knowledge Graph.png" alt="2. HANA Cloud Knowledge Graph.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;U&gt;Prerequisites&lt;/U&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Access to SAP HANA Cloud Knowledge Graph Engine&lt;/LI&gt;&lt;LI&gt;Access to SAP Generative AI Hub SDK (SAP AI Core on SAP BTP)&lt;/LI&gt;&lt;LI&gt;A Python environment&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Step 1: Set up an SAP HANA Cloud instance where Triple Store is enabled&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Within SAP HANA Database, enable ‘Triple Store’ on SAP HANA Cloud Central tool during instance provisioning&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Step 5: Advanced Setting tab&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;Prerequisite: 3 vCPUs compute / 48 GB memory or more&lt;/LI&gt;&lt;LI&gt;Recommended: At least 8 vCPUs &amp;amp; more for enhanced performance&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="3. SAP HANA Triple Store Enablement.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/265024i96E229A2276C2CE5/image-size/large?v=v2&amp;amp;px=999" role="button" title="3. SAP HANA Triple Store Enablement.png" alt="3. SAP HANA Triple Store Enablement.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The following steps uses Python programmatically.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 2: Create Knowledge Graphs (RDF format)&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;We start by loading RDF/XML file into an RDFLib graph. RDFLib is a Python library that supports the creation and manipulation of RDF triples programmatically. The RDF file used in this example refers to the open-source &lt;A href="https://catalog.data.gov/dataset/financial-plan-statements-cash-flow/resource/bee3ae1b-657b-4bea-a02c-213a103ff6af" target="_blank" rel="noopener nofollow noreferrer"&gt;Financial Plan Statements – Cash Flow&lt;/A&gt;. The raw data contains many predicates, but for this use case, we will filter triples containing specific predicates like rowID, dscrpt (description), and infl_outfl (inflow/outflow).&lt;/P&gt;&lt;P&gt;Define namespaces matching the RDF predicates. Create a new graph to store filtered triples that contain only relevant predicates. This reduces data noise and keeps the RDF data focused on important attributes.&lt;/P&gt;&lt;P&gt;Finally, the filtered data is saved in .ttl format for ingestion into SAP HANA.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from rdflib import Graph, Namespace

g = Graph()
g.parse("rows.rdf", format="xml")

ns1 = Namespace("http://www.socrata.com/rdf/terms#")
ns2 = Namespace("https://data.cityofnewyork.us/resource/_4ubz-8kkx/")
filtered = Graph()
filtered.bind("ns1", ns1)
filtered.bind("ns2", ns2)

for s, p, o in g:
    if p in (ns1.rowID, ns2.dscrpt, ns2.infl_outfl):
        filtered.add((s, p, o))
filtered.serialize(destination="rows_filtered_100.ttl", format="turtle")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Step 3: Loading RDF Graph into SAP HANA Cloud&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Using SAP HANA’s dbapi, the filtered RDF data is uploaded into a named RDF graph within SAP HANA Cloud via a stored procedure (SPARQL_EXECUTE). This makes the semantic data available for SPARQL querying within the database.&lt;/P&gt;&lt;P&gt;This integration enables leveraging SAP HANA’s graph engine and SPARQL query capabilities on the ingested RDF.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from hdbcli import dbapi

conn = dbapi.connect(user="USERNAME", password="PASSWORD", address="ADDRESS", port=443)
cursor = conn.cursor()

rdf_filename = "rows_filtered_100.ttl"
graphname = 'financial_plan_statements_cashflow_filtered_100'

with open(rdf_filename, 'r') as rdf_file:
    rdf_data = rdf_file.read()

request_hdrs = (
    'rqx-load-protocol: true\r\n'
    f'rqx-load-filename: {rdf_filename}\r\n'
    f'rqx-load-graphname: {graphname}\r\n'
)

cursor.callproc('SPARQL_EXECUTE', (rdf_data, request_hdrs, '', None))
cursor.commit()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Once ready, the filtered RDF graph is loaded into SAP HANA Cloud’s graph store. You can view the triples that you’ve uploaded via the HANA Cloud Central SQL Console. The SQL Console is configured to show a maximum number of 250,000 rows, configurable via settings.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="4. SAP HANA Cloud Central Database Objects.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/265026i2E79605FA21B5952/image-size/large?v=v2&amp;amp;px=999" role="button" title="4. SAP HANA Cloud Central Database Objects.png" alt="4. SAP HANA Cloud Central Database Objects.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="5. SAP HANA Cloud SPARQL.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/265027i92E54EB692D93BC8/image-size/large?v=v2&amp;amp;px=999" role="button" title="5. SAP HANA Cloud SPARQL.png" alt="5. SAP HANA Cloud SPARQL.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="6. SAP HANA Cloud SQL Console.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/265028i0AD13E407DD5829C/image-size/large?v=v2&amp;amp;px=999" role="button" title="6. SAP HANA Cloud SQL Console.png" alt="6. SAP HANA Cloud SQL Console.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="7. SAP HANA SQL Endpoint.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/265029i6B4FA085CE9AC575/image-size/large?v=v2&amp;amp;px=999" role="button" title="7. SAP HANA SQL Endpoint.png" alt="7. SAP HANA SQL Endpoint.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Note: Under Instances, copy SQL Endpoint (top right) to use for HANA Cloud API connectivity.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 4: Setting Up Generative AI Hub SDK&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The Generative AI Hub SDK provides an interface to LLMs.&lt;/P&gt;&lt;P&gt;To bridge natural language questions to RDF data queries, we configure an SAP AI Core client and proxy to use an LLM. In this case, anthropic—claude-3.5-sonnet is used. Do note you’ll have to deploy the model you’re using, and you can do so via SAP AI Launchpad.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from ai_core_sdk.ai_core_v2_client import AICoreV2Client
from gen_ai_hub.proxy.langchain.amazon import ChatBedrock
from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client

def setup(): 
    proxy_client = get_proxy_client('gen-ai-hub')
    anthropic = ChatBedrock(
        model_name="anthropic--claude-3.5-sonnet",
        proxy_client=proxy_client
    )

    # Connect to SAP HANA Cloud
    conn = dbapi.connect(
        user='',
        password='',  # alternatively, set up os.environ 
        address='',
        port=443,
    )

    return anthropic, conn&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Step 5: Extracting Triples from RDF&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This retrieves RDF triples. The results are parsed from XML into Python data structures.&amp;nbsp;These triples represent graph data, not traditional database tables or columns.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;def extract_schema(question: str, conn) -&amp;gt; list[dict]:
    sparql = """
    SELECT ?s ?p ?o WHERE {
        ?s ?p ?o.
        FILTER(STRSTARTS(STR(?s), "https://data.cityofnewyork.us/resource/_4ubz-8kkx"))
    }
    """
    # Execute SPARQL query via stored procedure
    # Parse response XML into triple dicts (subject, predicate, object)
    # Return list of triples as dictionaries or empty list if none found&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Step 6: Analyzing Triples with AI and Generating Natural Language Responses&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The extracted triples, combined with the user’s natural language question, are fed into Anthropic Claude (via Gen AI Hub SDK and LangChain integrations)&amp;nbsp;to generate a concise and coherent natural language answer.&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;def generate_response_structured(question: str, results: pd.DataFrame, anthropic) -&amp;gt; str:
    if results.empty:
        return "No results found for your query."
    
    prompt_template = """Convert the following query results into a natural language response to the user's question. 
    Keep the response concise but informative. Include relevant numbers and comparisons where appropriate.
    
    Question: {question}
    
    Results:
    {results}
    
    Response:
    """
    
    prompt = PromptTemplate.from_template(prompt_template).invoke({
        "question": question,
        "results": results.to_string()
    })
    
    response = anthropic.invoke(prompt)
    return response.content&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The output, adjusted to show only natural language:&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="LLM Output 1.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/265030i01290E04BD2FA406/image-size/large?v=v2&amp;amp;px=999" role="button" title="LLM Output 1.png" alt="LLM Output 1.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="LLM Output 2.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/265031iDD1BFB17DE0F4342/image-size/large?v=v2&amp;amp;px=999" role="button" title="LLM Output 2.png" alt="LLM Output 2.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This end-to-end system enables users to ask complex questions over RDF graphs stored in SAP HANA Cloud — all with natural language.&lt;/P&gt;&lt;P&gt;This pipeline showcases a powerful synergy of&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Semantic data&lt;/STRONG&gt; managed with RDF and SPARQL&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Enterprise-grade persistence and querying&lt;/STRONG&gt; on SAP HANA Cloud&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Generative AI&lt;/STRONG&gt; that interprets user intent and translates it into precise data queries&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Natural language explanations&lt;/STRONG&gt; that make complex data accessible&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;AI-assisted analytics and querying on complex RDF datasets is suitable for financial statements, geographical data, and more—delivering real-time insights.&lt;/P&gt;&lt;P&gt;Leave any comments below!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/semantic-querying-with-sap-hana-cloud-knowledge-graph-using-rdf-sparql-and/ba-p/14109200"/>
    <published>2025-05-22T12:40:07.914000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/ai-in-action-new-mission-available-to-enhance-sap-signavio-with-machine/ba-p/14112999</id>
    <title>AI in Action: New mission available to enhance SAP Signavio with Machine Learning</title>
    <updated>2025-05-27T20:23:26.890000+02:00</updated>
    <author>
      <name>hoangvu</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/315943</uri>
    </author>
    <content>&lt;P&gt;In today's rapidly evolving business landscape, organizations are continually seeking innovative ways to enhance operational efficiency and stay ahead of the competition. One groundbreaking approach is the integration of machine learning (ML) with process mining, a strategy that transforms static data into dynamic, predictive insights. SAP Signavio Process Intelligence, in conjunction with SAP Build, offers a robust platform to achieve this integration seamlessly.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Unlocking Predictive Process Management&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Traditionally, process mining involves analyzing historical event logs to understand past performance. While this retrospective analysis is valuable, it doesn't provide foresight into future outcomes. By embedding ML algorithms into your process mining activities, you can predict future events, identify potential bottlenecks before they occur, and make data-driven decisions that proactively enhance process efficiency.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Practical Applications&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Consider the challenge of predicting sales order delivery times. By analyzing historical event logs, ML models can forecast delivery dates based on factors like order size, product type, and current workload. These predictions, when fed back into SAP Signavio Process Intelligence, offer real-time insights, enabling better planning and improved customer satisfaction.&lt;/P&gt;&lt;P&gt;Another application is in customer support. By examining event logs, ML can predict customer satisfaction levels with support tickets, considering variables such as resolution speed and communication quality. This allows support teams to proactively address issues, enhancing the overall customer experience.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;New mission OUT NOW&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;We are excited to announce a new mission that showcases how you can realize these use cases using SAP Signavio in combination with SAP Build.&lt;/P&gt;&lt;P&gt;&lt;A href="https://developers.sap.com/mission.signavio-pi-and-sap-build.html" target="_blank" rel="noopener noreferrer"&gt;https://developers.sap.com/mission.signavio-pi-and-sap-build.html&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="2025-05-27_19-45-40.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/266617iD1303A2810ACEDC9/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-05-27_19-45-40.png" alt="2025-05-27_19-45-40.png" /&gt;&lt;/span&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Successfully implement the mission and earn a cool badge as a reward.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="2025-05-27_20-12-19.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/266624iF4B7D41FDC38D057/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-05-27_20-12-19.png" alt="2025-05-27_20-12-19.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;It will highlight your success of combining multiple SAP solutions and showcase your ability to tackle new topics and realize value from it!&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Seamless Integration with SAP Build&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;SAP Build, equipped with Python and Jupyter capabilities, serves as the bridge between raw data and actionable insights. It enables the extraction of event log data from SAP Signavio Process Intelligence, the application of ML algorithms, and the reintegration of enriched data back into the system. This seamless workflow ensures that your process management system evolves from reactive to proactive, continually learning and adapting to new data.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Getting Started&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Embarking on this transformative journey involves a few key steps:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Activate APIs: Enable the OData and Ingestion APIs in SAP Signavio Process Intelligence to facilitate data movement.&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Data Extraction: Utilize SAP Build to extract event log data via the OData API.&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Apply Machine Learning: Develop and train ML models within SAP Build to analyze and predict outcomes based on your data.&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;STRONG&gt;Data Reintegration: Push the enriched, predictive data back into SAP Signavio Process Intelligence through the Ingestion API.&lt;/STRONG&gt;&lt;/STRONG&gt;&lt;P&gt;For a comprehensive, step-by-step guide on implementing this integration, refer to the mission above.&lt;/P&gt;&lt;P&gt;By harnessing the combined power of SAP Signavio Process Intelligence and SAP Build, your organization can transition to a predictive process management paradigm, driving efficiency, foresight, and a competitive edge in your industry.&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/ai-in-action-new-mission-available-to-enhance-sap-signavio-with-machine/ba-p/14112999"/>
    <published>2025-05-27T20:23:26.890000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/expanding-sap-form-service-by-adobe-use-cases-out-of-sap-erp-context/ba-p/14123425</id>
    <title>Expanding SAP Form Service by Adobe Use Cases Out of SAP ERP Context</title>
    <updated>2025-06-10T07:01:59.412000+02:00</updated>
    <author>
      <name>tandx94</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/832653</uri>
    </author>
    <content>&lt;P&gt;This service is no stranger to most SAP customers as it is the go to service when comes to generation of interactive forms or static PDF forms based on pre-configured templates, that may be used as attachments for transactions or documents on ECC or S/4HANA.&lt;/P&gt;&lt;P&gt;However, with the advancement in technology over the years, I cannot stop to wonder, why do customers prefer or still using this two-decade old service even though there are other innovative solutions in the market?&amp;nbsp; I noticed another problem while researching on the service via the web, most of the blogs and SAP’s help documentation only focus on integration with ECC or S/4HANA using ABAP coding. This sounds like a good technology that can be used outside of SAP context and have led me to my next burning question, "Did anyone try to maximise this service beyond SAP context and with the use of python?" Sadly, there is limited information on this.&lt;/P&gt;&lt;P&gt;Recently, I had a chance to build and demonstrate a proof of concept with this service on BTP, based on an actual use case. Finally, I got all my answers. Hence, let’s dive into the details.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;U&gt;Use Case:&lt;/U&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Customer is keen on exploring BTP services to create an application for their ground staff to generate unique labels for their finished goods. These are some of their business requirements:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Ground staffs can input production data into the application.&lt;/LI&gt;&lt;LI&gt;Ground staffs can use the custom-built application to pull S/4HANA data and use it as part of label creation.&lt;/LI&gt;&lt;LI&gt;The label follows a standard format but, it comes with a unique QR code and contents.&lt;/LI&gt;&lt;LI&gt;Current label template is on SAP Form Service by Adobe, and customer has specifically instructed to leverage on existing service and template.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;U&gt;Solution:&lt;/U&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Create an application using SAP Build Apps, a low-code, no-code service for frontend development and a backend service using python, that integrates with database, object repository and SAP Form Service by Adobe. The backend service will be hosted on SAP Cloud Foundry Runtime.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;U&gt;Technical Architecture&lt;/U&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_0-1749528715143.png" style="width: 432px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272066i18F28086827AD2F7/image-dimensions/432x241?v=v2" width="432" height="241" role="button" title="tandx94_0-1749528715143.png" alt="tandx94_0-1749528715143.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;For this blog, I will be focusing only on using SAP Form Service by Adobe and calling the service via python with the standard APIs.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;U&gt;How to start?&lt;/U&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Prerequisite:&lt;/STRONG&gt; To create form templates, you will need to download and install Adobe Lifecycle Designer. There are some SAP Notes and SAP’s help documentation available online that can guide you on how to get this software. Please refer to this &lt;A href="https://help.sap.com/docs/successfactors-onboarding/implementing-onboarding/downloading-adobe-livecycle-designer" target="_self" rel="noopener noreferrer"&gt;link&lt;/A&gt; for more information.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 1:&lt;/STRONG&gt; Create a form template using Adobe Lifecycle Designer&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_1-1749528884480.png" style="width: 472px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272067iCED2B19292698674/image-dimensions/472x277?v=v2" width="472" height="277" role="button" title="tandx94_1-1749528884480.png" alt="tandx94_1-1749528884480.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;First realisation: Adobe lifecycle designer is a business user friendly software.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The drag and drop feature within Adobe Lifecycle Designer, enables user to create form template easily. It comes with a comprehensive object library containing the most commonly used objects (components) like button, check box, etc., for a form. It also allows user to embed a QR code in the template and specify the data beneath it. All the user needs to do is to drag their desired objects into the design panel and design the form template.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 2:&lt;/STRONG&gt; Create a data schema in xsd format&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_2-1749529092223.png" style="width: 489px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272068i8BC2A1BE9B5918BE/image-dimensions/489x186?v=v2" width="489" height="186" role="button" title="tandx94_2-1749529092223.png" alt="tandx94_2-1749529092223.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;These are the XML data that I wish to insert into the form template. Let’s convert the XML data into xml data schema in xsd format.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_3-1749529203032.png" style="width: 618px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272069i25A60C41A82652BF/image-dimensions/618x146?v=v2" width="618" height="146" role="button" title="tandx94_3-1749529203032.png" alt="tandx94_3-1749529203032.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 3:&lt;/STRONG&gt; Bind the data with the objects in the template and export the template&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_4-1749529243942.png" style="width: 411px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272070iE172282CC67C4098/image-dimensions/411x242?v=v2" width="411" height="242" role="button" title="tandx94_4-1749529243942.png" alt="tandx94_4-1749529243942.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;User has the option to bind with a sample XML data file to visualise the final form outcome before binding it with a xml schema. Once this is done, export the template in xdp format.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 4:&lt;/STRONG&gt; Activate SAP Form Service by Adobe via BTP cockpit. Access the UI to upload template and data schema.&lt;/P&gt;&lt;P&gt;You can refer to this &lt;A href="https://help.sap.com/docs/forms-service-by-adobe/sap-forms-service-cf/initial-steps-in-your-sap-btp-subaccount" target="_blank" rel="noopener noreferrer"&gt;link&lt;/A&gt; to learn more about the service setup on BTP cockpit.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_5-1749529779351.png" style="width: 512px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272071i2D0F6B89FF1F03BE/image-dimensions/512x226?v=v2" width="512" height="226" role="button" title="tandx94_5-1749529779351.png" alt="tandx94_5-1749529779351.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once the service is set up and with the appropriate roles assigned, you may access the SAP Form Service Landing page.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_6-1749529810241.png" style="width: 443px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272072i61101DD395F34517/image-dimensions/443x72?v=v2" width="443" height="72" role="button" title="tandx94_6-1749529810241.png" alt="tandx94_6-1749529810241.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 5:&lt;/STRONG&gt; Upload Form Template and Data Schema under “Template Store”&lt;/P&gt;&lt;P&gt;First, create a Form on SAP Form Service by Adobe. You can proceed to upload the form template (xdp file) and data schema (xsd file) into the service.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_7-1749529884703.png" style="width: 425px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272073i4FCC639AA914371B/image-dimensions/425x221?v=v2" width="425" height="221" role="button" title="tandx94_7-1749529884703.png" alt="tandx94_7-1749529884703.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Second realisation: Python can be used to create the necessary files for PDF rendering.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 6: &lt;/STRONG&gt;Create a backend python service&lt;/P&gt;&lt;P&gt;a. Use the SAP Form Service by Adobe standard API to pull the template from ADS service.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_8-1749529935034.png" style="width: 505px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272074i49D393DAE13623B9/image-dimensions/505x188?v=v2" width="505" height="188" role="button" title="tandx94_8-1749529935034.png" alt="tandx94_8-1749529935034.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;b. Generate encoded xml data encoded Base64 file using Xml.etree.Element tree library.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_9-1749530042209.png" style="width: 511px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272075i7B3D9E82679C1EEE/image-dimensions/511x196?v=v2" width="511" height="196" role="button" title="tandx94_9-1749530042209.png" alt="tandx94_9-1749530042209.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;c. Render PDF to generate label via API&lt;/P&gt;&lt;P&gt;When Render PDF API (&lt;EM&gt;labelled as ADS - Render Requests on SAP Business Accelerator Hub [&lt;A href="https://api.sap.com/api/CF_ADSRestAPI/path/renderingPDFPost" target="_self" rel="noopener noreferrer"&gt;link&lt;/A&gt;]&lt;/EM&gt;) is called with the necessary payload information, the response will return a Base64 encoded file of the rendered PDF. You will need to decode it and save it to your desired destination, either on local machine or into an object repository.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_10-1749530145976.png" style="width: 508px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272077iC114E35DAC1BE824/image-dimensions/508x302?v=v2" width="508" height="302" role="button" title="tandx94_10-1749530145976.png" alt="tandx94_10-1749530145976.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_11-1749530163061.png" style="width: 512px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272078iB16982EE9F37A0A2/image-dimensions/512x252?v=v2" width="512" height="252" role="button" title="tandx94_11-1749530163061.png" alt="tandx94_11-1749530163061.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;U&gt;Output&lt;/U&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="tandx94_12-1749530190154.png" style="width: 577px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272079i6F3CC6BBCE9EA76F/image-dimensions/577x336?v=v2" width="577" height="336" role="button" title="tandx94_12-1749530190154.png" alt="tandx94_12-1749530190154.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;U&gt;Conclusion&lt;/U&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;As you can see from above, SAP Form Service by Adobe can be further leverage by expanding the use cases outside of ERP context, with the use of a different coding language, python. I hope that this blog can serve as a good reference for the community to maximise the usage of this service.&lt;/P&gt;&lt;P&gt;Happy learning and exploring!&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/expanding-sap-form-service-by-adobe-use-cases-out-of-sap-erp-context/ba-p/14123425"/>
    <published>2025-06-10T07:01:59.412000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/identifying-sap-certificates-in-personal-security-environment-a/ba-p/14131296</id>
    <title>Identifying SAP Certificates in Personal Security Environment: A Comprehensive Guide</title>
    <updated>2025-06-18T19:35:52.547000+02:00</updated>
    <author>
      <name>mcharrison</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/149617</uri>
    </author>
    <content>&lt;H1 id="toc-hId-1604075140"&gt;Understanding Personal Security Environment (PSE) Fundamentals&lt;/H1&gt;&lt;P&gt;At its core, a Personal Security Environent (PSE) in SAP is a digital container designed to securely store cryptographic information, primarily digital certificates and their corresponding private keys. Think of it as a digital wallet for your SAP system's security credentials. PSEs are essential for enabling secure communication channels, such as those used in SSL/TLS, SNC (Secure Network Communications), and digital signatures.&lt;/P&gt;&lt;P&gt;There are several types of PSEs, each serving a specific purpose within the SAP ecosystem:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;System PSE (SSFS): Often used for internal system-to-system communication and secure storage of sensitive data like database credentials.&lt;/LI&gt;&lt;LI&gt;Application PSE: Employed by specific SAP applications for their secure communication needs.&lt;/LI&gt;&lt;LI&gt;Client PSE: Used by SAP clients (e.g., SAP GUI, external applications) to authenticate themselves to SAP servers.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;PSEs can also exist in different formats, primarily:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Legacy format (v2): An older format that might still be found in some older SAP installations.&lt;/LI&gt;&lt;LI&gt;Current format (v4): The modern and more secure format, offering enhanced cryptographic capabilities.&lt;/LI&gt;&lt;/UL&gt;&lt;H1 id="toc-hId-1407561635"&gt;The Structure and Components of a PSE&lt;/H1&gt;&lt;P&gt;To effectively identify certificates within a PSE, it's crucial to understand its internal structure and the components it typically contains:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Owner Certificate (with Private Key): This is the primary certificate associated with the PSE, along with its unique private key. This pair is used by the SAP system or application to identify itself and encrypt/decrypt data.&lt;/LI&gt;&lt;LI&gt;Certificate Chain: A sequence of certificates that links the owner certificate back to a trusted root Certificate Authority (CA). This chain establishes the trustworthiness of the owner certificate.&lt;/LI&gt;&lt;LI&gt;Trust Anchors (Trusted Certificates): These are certificates of trusted Certificate Authorities (CAs) or self-signed certificates from other systems that the SAP system explicitly trusts. They are used to validate the authenticity of incoming certificates.&lt;/LI&gt;&lt;LI&gt;Address Book (Optional): In some cases, a PSE might also contain an address book of trusted communication partners.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;PSE files are typically stored in the file system, often with a .pse extension. Common storage locations include the sec directory under the SAP instance directory (e.g., /usr/sap/&amp;lt;SID&amp;gt;/&amp;lt;Instance&amp;gt;/sec/). For certificates managed within the SAP HANA database, they might reside in database tables such as SYS.CERTIFICATES and SYS.PSE_CERTIFICATES.&lt;/P&gt;&lt;P&gt;To protect the sensitive private keys and certificates, PSEs employ several protection mechanisms:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;PIN Protection: A password or PIN is often used to encrypt the private key within the PSE, preventing unauthorized access.&lt;/LI&gt;&lt;LI&gt;File Permissions: Operating system file permissions are critical to restrict access to the PSE files themselves, ensuring only authorized users or processes can read or modify them.&lt;/LI&gt;&lt;LI&gt;Database Privileges: For in-database certificates, appropriate database privileges are essential to control who can view, modify, or delete certificate entries.&lt;/LI&gt;&lt;/UL&gt;&lt;H1 id="toc-hId-1211048130"&gt;Dissecting Certificate Structure for Identification:&lt;/H1&gt;&lt;P&gt;Before diving into identification methods, let's briefly review the key elements of a digital certificate that aid in its identification:&lt;/P&gt;&lt;P&gt;Distinguished Name (DN) Components: The DN is a unique identifier for the certificate's subject. Key components include:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Common Name (CN): Typically the hostname or application name.&lt;/LI&gt;&lt;LI&gt;Organization (O): The name of the organization.&lt;/LI&gt;&lt;LI&gt;Organizational Unit (OU): A specific department or unit within the organization.&lt;/LI&gt;&lt;LI&gt;Country (C): The two-letter country code.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Key Certificate Attributes: Beyond the DN, other attributes provide crucial identification details:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Serial Number: A unique identifier assigned by the Certificate Authority.&lt;/LI&gt;&lt;LI&gt;Validity Period: The start and end dates during which the certificate is considered valid.&lt;/LI&gt;&lt;LI&gt;Issuer Information: Details about the Certificate Authority that issued the certificate.&lt;/LI&gt;&lt;LI&gt;Key Usage: Defines the cryptographic purposes for which the public key contained in the certificate can be used (e.g., digital signature, key encipherment).&lt;/LI&gt;&lt;LI&gt;Signature Algorithm: The algorithm used to sign the certificate.&lt;/LI&gt;&lt;/UL&gt;&lt;H1 id="toc-hId-1014534625"&gt;Methods for Certificate Identification&lt;/H1&gt;&lt;P&gt;Identifying certificates in SAP PSEs can be approached through various methods, each with its own strengths and use cases.&lt;/P&gt;&lt;H2 id="toc-hId-947103839"&gt;1. Identification by Location&lt;/H2&gt;&lt;P&gt;The simplest form of identification is by knowing where PSE files are typically stored. Standard file paths and instance-specific locations are common starting points. For SAP HANA, certificates might also be found within database collections.&lt;/P&gt;&lt;H2 id="toc-hId-750590334"&gt;2. Identification by Attributes&lt;/H2&gt;&lt;P&gt;Once a certificate is accessed, its attributes can be used for precise identification:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Distinguished Name (DN) Matching: Comparing the DN components against expected values.&lt;/LI&gt;&lt;LI&gt;Serial Number Lookup: Searching for a specific certificate by its unique serial number.&lt;/LI&gt;&lt;LI&gt;Fingerprint Comparison: Using cryptographic hash functions (e.g., SHA-256) to generate a unique fingerprint of the certificate for comparison.&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-554076829"&gt;3. Identification by Purpose&lt;/H2&gt;&lt;P&gt;Certificates are often used for specific functions, which can also aid in their identification:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;SSL Server Certificates: Used by SAP servers to secure incoming connections.&lt;/LI&gt;&lt;LI&gt;SSL Client Certificates: Used by SAP clients to authenticate to servers.&lt;/LI&gt;&lt;LI&gt;SAML Certificates: Used for Security Assertion Markup Language (SAML) based single sign-on.&lt;/LI&gt;&lt;LI&gt;Signing Certificates: Used for digital signatures.&lt;/LI&gt;&lt;/UL&gt;&lt;H1 id="toc-hId-228480605"&gt;Tools for Certificate Identification&lt;/H1&gt;&lt;P&gt;SAP provides several tools, both command-line and GUI-based, to help with certificate identification and management.&lt;/P&gt;&lt;H2 id="toc-hId-161049819"&gt;Using the sapgenpse Tool&lt;/H2&gt;&lt;P&gt;sapgenpse is a powerful command-line utility provided by SAP for managing PSEs and certificates. It's particularly useful for scripting and automated tasks.&lt;/P&gt;&lt;P&gt;Key commands for identification include:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;sapgenpse get_my_cert -p &amp;lt;PSE_path&amp;gt; -v: Extracts and displays the owner certificate from a specified PSE file.&lt;/LI&gt;&lt;LI&gt;sapgenpse maintain_pk -p &amp;lt;PSE_path&amp;gt; -l: Lists all certificates contained within a PSE file.&lt;/LI&gt;&lt;LI&gt;sapgenpse maintain_pk: &lt;SPAN&gt;maintain the server's certificate list within a PSE&lt;/SPAN&gt;.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The output of these commands provides detailed certificate information, including validity status and trust chain information.&lt;/P&gt;&lt;H1 id="toc-hId--164546405"&gt;Using the STRUST Transaction&lt;/H1&gt;&lt;P&gt;For those who prefer a graphical interface, the STRUST transaction in SAP GUI is the primary tool for managing PSEs and certificates. It offers a user-friendly way to visualize and interact with certificate data.&lt;/P&gt;&lt;P&gt;Navigate to STRUST via the transaction code. Here, you can select and manage various PSE types. STRUST provides a visual certificate browser, allowing you to view detailed information about each certificate, including its chain, validity, and key attributes. It also supports import and export functionalities.&lt;/P&gt;&lt;H1 id="toc-hId-408680173"&gt;Python-Based Identification&lt;/H1&gt;&lt;P&gt;For advanced automation and integration with other systems, Python scripting offers a flexible and powerful approach to certificate identification. Libraries like cryptography or OpenSSL can be used to parse certificate files, while custom scripts can be developed to interact with SAP systems or database views.&lt;/P&gt;&lt;P&gt;Python-based solutions offer significant automation benefits, including bulk certificate discovery, automated metadata extraction, and proactive expiration monitoring.&lt;/P&gt;&lt;H1 id="toc-hId-212166668"&gt;Best Practices for SAP Certificate Management&lt;/H1&gt;&lt;P&gt;Effective certificate identification is just one piece of the puzzle. Implementing best practices ensures a secure and manageable SAP certificate landscape.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Naming Conventions: Adopt consistent Distinguished Name (DN) formats and use purpose-indicating Common Names (CNs). Include version tracking in comments or metadata.&lt;/LI&gt;&lt;LI&gt;Organization: Centralize PSE management where possible. Maintain comprehensive documentation of certificate purposes and regularly update your certificate inventory.&lt;/LI&gt;&lt;LI&gt;Monitoring: Implement automated expiration checks to prevent outages. Regularly validate trust chains and audit certificate usage to detect anomalies.&lt;/LI&gt;&lt;/UL&gt;&lt;H1 id="toc-hId-15653163"&gt;Common Challenges and Solutions&lt;/H1&gt;&lt;P&gt;Managing SAP certificates comes with its share of challenges. Here are some common ones and their practical solutions:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Challenge: Identifying certificates across distributed systems.&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Solution&lt;/STRONG&gt;: Implement a centralized certificate inventory system with location mapping to track all PSEs and certificates across your SAP landscape.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Challenge: Determining certificate purpose.&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Solution&lt;/STRONG&gt;: Enforce standardized naming conventions and metadata tagging during certificate creation to clearly indicate their intended use.&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Challenge: Legacy format detection.&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Solution&lt;/STRONG&gt;: Utilize version-aware tools (like sapgenpse with appropriate flags) and plan for systematic conversion of legacy PSEs to current formats.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Challenge: PIN-protected PSEs.&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Solution&lt;/STRONG&gt;: Implement secure PIN management strategies, potentially leveraging secure credential stores or automation tools that can securely provide PINs when needed.&lt;/LI&gt;&lt;/UL&gt;&lt;H1 id="toc-hId--180860342"&gt;Conclusion&lt;/H1&gt;&lt;P&gt;Identifying SAP certificates within the Personal Security Environment is a critical aspect of maintaining a secure and reliable SAP landscape. It requires a systematic approach, leveraging a combination of SAP-provided tools like sapgenpse and STRUST, alongside powerful scripting capabilities offered by Python.&lt;/P&gt;&lt;P&gt;By understanding the fundamentals of PSE, its structure, and the various identification methods, you can gain better control over your SAP security infrastructure. Adhering to best practices in naming, organization, and monitoring, coupled with proactive solutions to common challenges, will significantly enhance your ability to manage certificates effectively and prevent security vulnerabilities or system outages.&lt;/P&gt;&lt;P&gt;Ultimately, a comprehensive and up-to-date inventory of your SAP certificates forms the foundation for robust security and efficient operations. Embrace these strategies to ensure your SAP systems remain secure and trustworthy.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/identifying-sap-certificates-in-personal-security-environment-a/ba-p/14131296"/>
    <published>2025-06-18T19:35:52.547000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/debugging-a-python-sap-btp-service-locally-in-vscode/ba-p/14133839</id>
    <title>Debugging a Python SAP BTP Service Locally in VSCode</title>
    <updated>2025-06-22T23:44:11.989000+02:00</updated>
    <author>
      <name>alexandr_razinkin</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/756342</uri>
    </author>
    <content>&lt;P&gt;There is a lot of information available about creating and debugging Node.js services in SAP BTP. However, in some cases, we might need to use Python instead — for example, for tasks involving AI or data processing.&lt;/P&gt;&lt;P&gt;In this article, I’ll show you how to debug a Python-based SAP BTP service using VS Code&amp;nbsp;(Visual Studio Code) locally.&lt;/P&gt;&lt;H2 id="toc-hId-1733223024"&gt;Prerequisites&lt;/H2&gt;&lt;P data-unlink="true"&gt;Create an SAP BTP Trial Account. Please follow &lt;A href="https://developers.sap.com/tutorials/hcp-create-trial-account..html" target="_self" rel="noopener noreferrer"&gt;this tutorial&lt;/A&gt;&amp;nbsp;for detailed information.&amp;nbsp;&lt;/P&gt;&lt;P data-unlink="true"&gt;Add HANA to your SAP BTP trial account if you haven’t already.&lt;/P&gt;&lt;P data-unlink="true"&gt;To do this, refer to the section ‘Create an SAP HANA Cloud Instance’ of &lt;A href="https://developers.sap.com/tutorials/btp-cf-buildpacks-python-create..html" target="_self" rel="noopener noreferrer"&gt;this tutorial&lt;/A&gt;.&lt;/P&gt;&lt;P data-unlink="true"&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt; One of the steps in the tutorial above requires the &lt;EM&gt;Space ID&lt;/EM&gt;.&lt;BR /&gt;If you're not sure where to find it, navigate to your space in the SAP BTP Cockpit and copy the Space ID from the URL.&lt;/P&gt;&lt;P data-unlink="true"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="take_space_from_url.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277362i70A3E4CCA64E99EE/image-size/large?v=v2&amp;amp;px=999" role="button" title="take_space_from_url.png" alt="take_space_from_url.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P data-unlink="true"&gt;Install Visual Studio Code (VS Code). You can download it from &lt;A href="https://code.visualstudio.com/download" target="_self" rel="nofollow noopener noreferrer"&gt;this page&lt;/A&gt;.&lt;/P&gt;&lt;P data-unlink="true"&gt;Install the SAP Cloud Foundry CLI. Refer to &lt;A href="https://docs.cloudfoundry.org/cf-cli/install-go-cli.html" target="_self" rel="nofollow noopener noreferrer"&gt;this guide&lt;/A&gt; on installing the cf CLI&amp;nbsp;for detailed instructions.&lt;/P&gt;&lt;P data-unlink="true"&gt;Install the Python interpreter. Version 3.13 or higher is recommended.&lt;/P&gt;&lt;P&gt;Install the necessary extensions for VS Code:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Python extension by Microsoft&lt;/LI&gt;&lt;LI&gt;Python debugger extension by Microsoft&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="vscode_extensions.PNG" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277363i86F90CD02F58A99F/image-size/medium?v=v2&amp;amp;px=400" role="button" title="vscode_extensions.PNG" alt="vscode_extensions.PNG" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt; When installing the first extension (Python), the second one (Python Debugger) may be installed automatically. If not, you can install it manually.&lt;/P&gt;&lt;H2 id="toc-hId-1536709519"&gt;Steps to create a service&lt;/H2&gt;&lt;P&gt;Our service will not include authorization for the sake of simplicity, but it will use an SAP HANA service to demonstrate how to call a BTP service from the local environment.&amp;nbsp;We will use the initial setup from &lt;A href="https://developers.sap.com/tutorials/btp-cf-buildpacks-python-create..html" target="_self" rel="noopener noreferrer"&gt;this tutorial&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;In the following sections, I will replicate some of the steps from that tutorial in this blog post, with a few minor adjustments.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;In your local file system, create a new folder – &amp;nbsp;for example, &lt;EM&gt;python-debug&lt;/EM&gt;.&lt;/LI&gt;&lt;LI&gt;In Visual Studio Code, open the &lt;EM&gt;python-debug&lt;/EM&gt; folder.&lt;/LI&gt;&lt;LI&gt;Create a file named &lt;EM&gt;manifest.yml&lt;/EM&gt; with the following content:&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-yaml"&gt;&lt;code&gt;---
applications:
  - name: python-debug
    random-route: true
    path: ./
    memory: 128M
    buildpacks:
      - python_buildpack
    command: python server.py
    services:
      - python-debug-hana
​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;IMPORTANT&lt;/STRONG&gt;: Make sure you don’t already have another application named&amp;nbsp;python-debug&amp;nbsp;in your space.&amp;nbsp;If you do, use a different name and update the entire tutorial accordingly.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Specify the Python runtime version your application will use. To do this, create a file named&amp;nbsp;&lt;EM&gt;runtime.txt&lt;/EM&gt;&amp;nbsp;with the following content:&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;python-3.13.x​&lt;/code&gt;&lt;/pre&gt;&lt;UL&gt;&lt;LI&gt;This application will be a web server utilizing the Flask web framework. To specify Flask as a dependency, create a file named&amp;nbsp;&lt;EM&gt;requirements.txt&lt;/EM&gt;&amp;nbsp;with the following content:&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;Flask==2.3.*
cfenv==0.5.3
hdbcli==2.17.*&lt;/code&gt;&lt;/pre&gt;&lt;UL&gt;&lt;LI&gt;Create a file named server.py with the following application logic:&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import os
from flask import Flask
from cfenv import AppEnv
from hdbcli import dbapi

app = Flask(__name__)
env = AppEnv()

hana_service = 'hana'
hana = env.get_service(label=hana_service)

port = int(os.environ.get('PORT', 3000))
@app.route('/')
def hello():
    if hana is None:
        return "Can't connect to HANA service '{}' – check service name?".format(hana_service)
    else:
        conn = dbapi.connect(address=hana.credentials['host'],
                             port=int(hana.credentials['port']),
                             user=hana.credentials['user'],
                             password=hana.credentials['password'],
                             encrypt='true',
                             sslTrustStore=hana.credentials['certificate'])

        cursor = conn.cursor()
        cursor.execute("select CURRENT_UTCTIMESTAMP from DUMMY")
        ro = cursor.fetchone()
        cursor.close()
        conn.close()

        return "Current time is: " + str(ro["CURRENT_UTCTIMESTAMP"])

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=port)
​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;This is a simple server that will return the result of a basic HANA SQL query when requested (in our case, the current UTC time).&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Log in to Cloud Foundry using the following command in the command line:&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;cf login​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;When prompted, enter your API endpoint.&amp;nbsp;You can find it on the Account Overview page in your SAP BTP account.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="btp_subaccount_overview.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277364iEA3081B82C9C91A8/image-size/large?v=v2&amp;amp;px=999" role="button" title="btp_subaccount_overview.png" alt="btp_subaccount_overview.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Also, enter the registration email and password for your SAP BTP trial account.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Create a HANA service using the following command:&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;cf create-service hana hdi-shared python-debug-hana​&lt;/code&gt;&lt;/pre&gt;&lt;UL&gt;&lt;LI&gt;Deploy the application on Cloud Foundry. To do that, run the following command inside the &lt;EM&gt;python-debug&lt;/EM&gt;&amp;nbsp;directory:&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;cf push​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt; If you make any changes to the service file and want to deploy again, simply run the ‘cf push’ command again.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;After successful deployment, the&amp;nbsp;&lt;EM&gt;python-debug&lt;/EM&gt;&amp;nbsp;application should start automatically, and its details will be displayed in the command console.&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VSCode_address.PNG" style="width: 944px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277365i8296C672F5B88319/image-size/large?v=v2&amp;amp;px=999" role="button" title="VSCode_address.PNG" alt="VSCode_address.PNG" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;Open a browser and enter the application’s generated URL (you can find it under “routes”)&lt;BR /&gt;For example:&amp;nbsp;&lt;EM&gt;python-debug-zany-buffalo-zz.cfapps.us10-001.hana.ondemand.com&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="service_results.PNG" style="width: 773px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277366i93A7B3AAD3761924/image-size/large?v=v2&amp;amp;px=999" role="button" title="service_results.PNG" alt="service_results.PNG" /&gt;&lt;/span&gt;&lt;/EM&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-1340196014"&gt;Steps to debug the service locally&lt;/H2&gt;&lt;P&gt;Local debugging of applications running on SAP Business Technology Platform (SAP BTP) is not only possible, but also practical in many cases. Here’s why:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Globally Accessible Services:&lt;BR /&gt;In SAP BTP,&amp;nbsp; most service endpoints use globally routable addresses. This means that your application can access these services from any location, not just from within the SAP BTP environment. As a result, you can run and test your application locally while still interacting with cloud services such as databases, messaging queues, or authentication providers.&lt;/LI&gt;&lt;LI&gt;Minimal Environmental Differences:&lt;BR /&gt;SAP BTP does not provide a highly customized runtime environment. Apart from environment variables—which you can replicate locally—there are no special runtime conditions. This allows developers to simulate the production environment with high fidelity on their local machines by simply setting the appropriate environment variables.&lt;/LI&gt;&lt;LI&gt;If you encounter an issue where an SAP BTP service address is not globally reachable and a connection error occurs (e.g., when testing a task that calls an on-premise OData service through the Cloud Connector), please refer to&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-members/how-to-access-on-premise-odata-from-the-business-application-studio-capm/bc-p/13447085" target="_self"&gt;this blog&lt;/A&gt;&amp;nbsp;for possible resolution.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Thanks to these two factors, local development and debugging in SAP BTP is straightforward. It enables faster development cycles and easier troubleshooting without the need to redeploy for every change.&lt;/P&gt;&lt;P&gt;To enable local debugging of a Python-based service, follow these steps:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Since the SAP BTP environment provides necessary configuration through environment variables, you need to replicate them locally. In order to load local environment data, insert the following changed code to your Python server script:&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import os
from flask import Flask
from cfenv import AppEnv
from hdbcli import dbapi
from dotenv import load_dotenv
load_dotenv()

app = Flask(__name__)
env = AppEnv()

hana_service = 'hana'
hana = env.get_service(label=hana_service)

port = int(os.environ.get('PORT', 3000))
@app.route('/')
def hello():
    if hana is None:
        return "Can't connect to HANA service '{}' – check service name?".format(hana_service)
    else:
        conn = dbapi.connect(address=hana.credentials['host'],
                             port=int(hana.credentials['port']),
                             user=hana.credentials['user'],
                             password=hana.credentials['password'],
                             encrypt='true',
                             sslTrustStore=hana.credentials['certificate'])

        cursor = conn.cursor()
        cursor.execute("select CURRENT_UTCTIMESTAMP from DUMMY")
        ro = cursor.fetchone()
        cursor.close()
        conn.close()

        return "Current time is: " + str(ro["CURRENT_UTCTIMESTAMP"])

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=port)
​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;This new logic will let you automatically read the key-value pairs from your .env file and make them available via os.environ, just like in the cloud environment.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Update the requirements.txt to include the necessary libraries&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;Flask==2.3.*
cfenv==0.5.3
hdbcli==2.17.*
python-dotenv​&lt;/code&gt;&lt;/pre&gt;&lt;UL&gt;&lt;LI&gt;Create a Python Virtual Environment&lt;BR /&gt;&lt;P&gt;Every Python project should run in its own isolated environment to avoid dependency conflicts.&lt;/P&gt;In VS Code, open the Command Palette (Ctrl+Shift+P), and choose ‘Python: Create Environment…’&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="vscode_create_environment.png" style="width: 748px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277367i2A94F26E63331AFE/image-size/large?v=v2&amp;amp;px=999" role="button" title="vscode_create_environment.png" alt="vscode_create_environment.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;Then select the option ‘Venv Creates a ‘.venv’ virtual environment in the current workspace’:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="vscode_create_environment2.png" style="width: 751px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277368i25D42BCD16056A9E/image-size/large?v=v2&amp;amp;px=999" role="button" title="vscode_create_environment2.png" alt="vscode_create_environment2.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;Then select a Python Version (Python 3.13.x or higher is recommended):&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="vscode_create_environment3.png" style="width: 753px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277369iE55ACA58153F1952/image-size/large?v=v2&amp;amp;px=999" role="button" title="vscode_create_environment3.png" alt="vscode_create_environment3.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;On the next screen, confirm the option to install the dependencies:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="vscode_create_environment4.png" style="width: 752px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277370i94960E03E7E8391D/image-size/large?v=v2&amp;amp;px=999" role="button" title="vscode_create_environment4.png" alt="vscode_create_environment4.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt; You can also do this later using the command &lt;EM&gt;pip install -r requirements.txt&lt;/EM&gt;.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;A new virtual environment will be created in a .venv folder in your workspace:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="venv_created.PNG" style="width: 271px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277371i5B79E74D6E6AC4D8/image-size/large?v=v2&amp;amp;px=999" role="button" title="venv_created.PNG" alt="venv_created.PNG" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;Set the VCAP_SERVICES environment variable&lt;BR /&gt;Before running the service locally, we need to set the VCAP_SERVICES environment variable, which provides all the necessary information about SAP BTP services.&lt;BR /&gt;To retrieve its contents, use the following command:&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;cf env python-debug​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Now, copy the contents of the VCAP_SERVICES JSON block to your clipboard.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Before we can use the contents of the environment variable, we need to minimize the JSON into a single line.&amp;nbsp;You can use any online JSON minifier tool or the JSTool extension in Notepad++ to do this.&lt;/LI&gt;&lt;LI&gt;Now, create a .env file in your service folder (the same folder where the manifest.yml file is located), and add the environment variable contents to it in the following format:&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;VCAP_SERVICES=&amp;lt;minimized_json&amp;gt;​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="env_file.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277373i00272794F7007678/image-size/large?v=v2&amp;amp;px=999" role="button" title="env_file.png" alt="env_file.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Create a configuration in VSCode.&amp;nbsp;Before starting, open the server.py file in the editor.&lt;/LI&gt;&lt;LI&gt;Open the ‘Run and Debug’ section in VSCode and select ‘Create a launch.json file’:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="create_config.PNG" style="width: 436px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277374i5795B4B016859FCB/image-size/large?v=v2&amp;amp;px=999" role="button" title="create_config.PNG" alt="create_config.PNG" /&gt;&lt;/span&gt;&lt;BR /&gt;&lt;P&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt; If you have already created the configuration file, simply open it for edit.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;From the drop-down list, select ‘Python debugger’&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="create_config2.png" style="width: 745px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277375iF0568419B35F32D0/image-size/large?v=v2&amp;amp;px=999" role="button" title="create_config2.png" alt="create_config2.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;Select ‘Python File: Debug the currently active Python file’:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="create_config3.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277376i05C9C66C481A9DBB/image-size/large?v=v2&amp;amp;px=999" role="button" title="create_config3.png" alt="create_config3.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;In the created file, delete the commented-out lines starting with // to avoid syntax errors&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="delete_comments_launch_json.png" style="width: 861px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277377iEBA1C2F5495AACF5/image-size/large?v=v2&amp;amp;px=999" role="button" title="delete_comments_launch_json.png" alt="delete_comments_launch_json.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;Return to the server.py file, and start the debugging session&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="run_debug.PNG" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277378i893EC6505B6D2342/image-size/large?v=v2&amp;amp;px=999" role="button" title="run_debug.PNG" alt="run_debug.PNG" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;Start the debug session&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="run_debug_session.PNG" style="width: 432px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277379i08BF9A23E97E4B94/image-size/large?v=v2&amp;amp;px=999" role="button" title="run_debug_session.PNG" alt="run_debug_session.PNG" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;The debugging session is now running:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="server_executed.PNG" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277380i553A4F6DD7EF9995/image-size/large?v=v2&amp;amp;px=999" role="button" title="server_executed.PNG" alt="server_executed.PNG" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;Open the following address in a browser&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;http://127.0.0.1/​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The current date and time from the HANA server will be displayed&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="open_in_browser.PNG" style="width: 489px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277381i4DA42B906E4A3171/image-size/large?v=v2&amp;amp;px=999" role="button" title="open_in_browser.PNG" alt="open_in_browser.PNG" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Then, return to VSCode and set a break-point&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="set_a_breakpoint.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277382i987183D818D89ED7/image-size/large?v=v2&amp;amp;px=999" role="button" title="set_a_breakpoint.png" alt="set_a_breakpoint.png" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;LI&gt;Refresh the browser again, and the execution will pause at the breakpoint:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="debugger_stopped.PNG" style="width: 993px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277383iD6288CC8D78F2906/image-size/large?v=v2&amp;amp;px=999" role="button" title="debugger_stopped.PNG" alt="debugger_stopped.PNG" /&gt;&lt;/span&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Now, you can use all the Python debugger’s features to debug your program.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/debugging-a-python-sap-btp-service-locally-in-vscode/ba-p/14133839"/>
    <published>2025-06-22T23:44:11.989000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-and-ai-features-in-sap-hana-cloud-2025-q2/ba-p/14136079</id>
    <title>New Machine Learning and AI features in SAP HANA Cloud 2025 Q2</title>
    <updated>2025-06-24T21:40:03.946000+02:00</updated>
    <author>
      <name>ChristophMorgen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14106</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;With the &lt;STRONG&gt;SAP HANA Cloud 2025 Q2 release&lt;/STRONG&gt;, several &lt;STRONG&gt;new embedded Machine Learning / AI functions&lt;/STRONG&gt;&amp;nbsp;have been released with the SAP HANA Cloud Predictive Analysis Library (PAL) and the Automated Predictive Library (APL). &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Key new capabilities to be highlighted include &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;A &lt;STRONG&gt;new text embedding model version&lt;/STRONG&gt;, covering more languages and short-text embedding scenarios,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;more &lt;STRONG&gt;tabular AI functions&lt;/STRONG&gt; enhanced to support&amp;nbsp;&lt;STRONG&gt;vector data processing&lt;/STRONG&gt; like &lt;STRONG&gt;AutoML&lt;/STRONG&gt;, &lt;STRONG&gt;k-nearest neighbors&lt;/STRONG&gt; (k-NN),&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;outlier detection using &lt;STRONG&gt;isolation forest&lt;/STRONG&gt; supporting &lt;STRONG&gt;outlier explainability &lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;machine learning &lt;STRONG&gt;experiment tracking&lt;/STRONG&gt; and &lt;STRONG&gt;task scheduling&lt;/STRONG&gt; capabilities&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;STRONG&gt;data drift analysis&lt;/STRONG&gt; using the &lt;STRONG&gt;Automated Predictive Library&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;An enhancement summary is available in the What’s new document for &lt;A href="https://help.sap.com/whats-new/2495b34492334456a49084831c2bea4e?Category=Predictive+Analysis+Library&amp;amp;Valid_as_Of=2025-06-01:2025-06-30&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP HANA Cloud database 2025.14 (QRC 2/2025)&lt;/A&gt;.&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1733304833"&gt;&lt;SPAN&gt;Text processing, text embedding and vector processing using ML functions&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text tokenization&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-tokenize" target="_blank" rel="noopener noreferrer"&gt;text tokenization &lt;/A&gt;function has been released, allowing to &lt;STRONG&gt;split text into tokens&lt;/STRONG&gt;, a fundamental preparation step in natural language processing (NLP) like text analysis, and many other downstream text processing tasks like text embedding or vector similarity search. The new function support key tokenization capabilities like&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;removal of common stopwords (e.g., "the", "and", "is").&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;filtering out purely numeric and alphanumeric tokens&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;specifications of characters or symbols that should always be kept or removed &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;controls for stemming, language detection.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_0-1750792982539.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/278450iC65F3B44B14FB758/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_0-1750792982539.png" alt="ChristophMorgen_0-1750792982539.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text embedding &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new &lt;STRONG&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/no-content-for-file-textembedding-md?" target="_blank" rel="noopener noreferrer"&gt;text embedding&lt;/A&gt;&lt;/STRONG&gt; model version (&lt;/SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-embedding-model?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP_GXY.20250407&lt;/A&gt;&lt;SPAN&gt;) is made available, which has been fine-tuned based on a roberta-base-encoder model and more training data for improved retrieval accuracy, short text scenarios and extend multi-lingual &amp;amp; cross-lingual retrieval scenarios. New additional languages supported include Chinese (CH), Japanese (JP) and Italian (IT). The default token length for embedding functions has been increase to 512.&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Extended embedding vector processing by Machine Learning functions&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Unlocking the semantic understanding of your text data stored in SAP HANA Cloud, for use cases like similarity search, however moreover for machine learning scenarios like &amp;nbsp;document/text- classification and –clustering, and more has now been extended to even more PAL Machine Learning functions&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;K-nearest neighbor models (&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/knn-knn-f2440c6" target="_blank" rel="noopener noreferrer"&gt;K-NN&lt;/A&gt;) for classification/regression/similarity search&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/random-decision-trees-random-decision-trees-9ad576a" target="_blank" rel="noopener noreferrer"&gt;Random Decision Trees&lt;/A&gt;&lt;/SPAN&gt; &lt;SPAN&gt;for classification/regression models &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/automl-automl?" target="_blank" rel="noopener noreferrer"&gt;AutoML&lt;/A&gt; &lt;/SPAN&gt;scenarios for classification, regression and times series&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;including the fit, prediction, scoring, and pipeline procedures&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;support with all pipeline operators (algorithms), except for the Imputer and&lt;BR /&gt;&amp;nbsp;ImputeTS-operators&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_1-1750792982549.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/278449iA91EDCE14A4D9CEF/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_1-1750792982549.png" alt="ChristophMorgen_1-1750792982549.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1536791328"&gt;&lt;SPAN&gt;Machine Learning function enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Outlier detection enhancements using Isolation Forests&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The &lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/isolation-forest-isolation-forest-11345d9" target="_blank" rel="noopener noreferrer"&gt;Isolation Forest &lt;/A&gt;&amp;nbsp;function for &lt;STRONG&gt;outlier detection&lt;/STRONG&gt; has been enhanced with &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;support categorial columns as features in outlier models&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;a new massive outlier detection function for parallel analysis of multiple data subsets&lt;BR /&gt;(PAL_MASSIVE_ISOLATION_FOREST)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;a new outlier explanation method based on Shapley values (PAL_ISOLATION_FOREST_EXPLAIN)&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;providing local explanations for the predicted outlier classification,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;describing the contribution of each feature to the predicted classification,&lt;BR /&gt;based on a Tree-SHAP explainer model,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;options to configure the explanation function by setting contamination level (proportion of outliers), scope (explanations for outliers only or all predictions), top K contributions (set k number of features in explanations)&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&lt;EM&gt;Isolation Forest&lt;/EM&gt; is a strong and &lt;EM&gt;trending function for outlier detection&lt;/EM&gt;, which can be applied on any data for outlier analysis inside the database, hence especially suitable also for use cases where data shall not leave the system or is too big to be copied out for analysis like use cases for &lt;STRONG&gt;detecting outliers on your financial accounting&lt;/STRONG&gt;, like the &lt;STRONG&gt;universal journal data&lt;/STRONG&gt; (ACDOCA).&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_2-1750792982556.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/278448i1C259DFB5755E343/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_2-1750792982556.png" alt="ChristophMorgen_2-1750792982556.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Constraint Clustering&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/constrained-clustering" target="_blank" rel="noopener noreferrer"&gt;constraint clustering &lt;/A&gt;function is introduced, an advanced form of clustering that &lt;STRONG&gt;incorporates domain-specific constraints or prior information&lt;/STRONG&gt; to &lt;EM&gt;guide the clustering process&lt;/EM&gt;, ensuring more accurate and meaningful results tailored to specific analytical needs. Traditional clustering methods are mostly limited and cannot include prior knowledge about the data, often leading to challenges in achieving meaningful or contextually relevant groupings. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Prior contexts can be included in the clustering process as &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Pairwise constraints: Must-link / Must-Not-link constraints of data points to be / not in the same cluster&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Triplet Constraints: With an anchor instance (a), a positive instance (p), and a negative instance (n), the constraint shows that instance a is more similar to p than to n.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;A detailed introduction to the new function is given in the following blog post &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/clustering-text-documents-using-constrained-clustering/ba-p/14134157" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/clustering-text-documents-using-constrained-clustering/ba-p/14134157&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Further enhanced machine learning algorithms for Tabular AI scenarios&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The recently implemented &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/multi-task-multilayer-perceptron?" target="_blank" rel="noopener noreferrer"&gt;Multi-task MLP&lt;/A&gt; (&lt;STRONG&gt;multi-layer perceptron&lt;/STRONG&gt;) &lt;STRONG&gt;neural network&lt;/STRONG&gt; function, unlocking predictions for &lt;STRONG&gt;multiple targets / labels using a single model&lt;/STRONG&gt;, has now been enhanced with an improved built-in &lt;STRONG&gt;model evaluation and parameter search&lt;/STRONG&gt; interface, providing faster approach and productivity to achieve even better prediction outcomes.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The new optimization can be leveraged by calling the function directly or via its use within the Unified Classification/Regression functions and supports to search and select the following optimal neural network model parameter values&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;LEARNING_RATE, EMBEDDED_NUM, RESIDUAL_NUM, DROPOUT_PROB, HIDDEN_LAYER_SIZE, HIDDEN_LAYER_ACTIVE_FUNC, OPTIMIZER&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;In the domain of &lt;STRONG&gt;time series analysis and forecasting,&lt;/STRONG&gt; the &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/arima-arima-dbd52a1" target="_blank" rel="noopener noreferrer"&gt;ARIMA&lt;/A&gt; forecasting function now supports to keep context of the time horizon index and interval&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Trained ARIMA model keeps track of the final time index value and the determined index interval&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Subsequently,&amp;nbsp;ARIMA_PREDICT&amp;nbsp;will use this information to output forecast values with a continuous index&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1340277823"&gt;&lt;SPAN&gt;Machine Learning experiment tracking and task scheduling&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Experiment tracking and monitoring for PAL ML models&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Machine learning &lt;STRONG&gt;experimentation&lt;/STRONG&gt; requires robust &lt;STRONG&gt;tracking capabilities&lt;/STRONG&gt; to ensure reproducibility, comparison, and auditability of models. SAP HANA Cloud's new &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/pal-track?q=PAL_REMOVE_MLTRACK_LOG&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;ML tracking&lt;/A&gt; feature provides seamless integration with Predictive Analysis Library (PAL) procedures, enabling &lt;STRONG&gt;automatic logging of critical experiment artifacts&lt;/STRONG&gt;. This end-to-end tracking solution captures &lt;EM&gt;parameters, datasets, models, metrics, and visualizations&lt;/EM&gt; in a structured way, transforming how data scientists manage ML workflows.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The new execution &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/pal-track?q=PAL_REMOVE_MLTRACK_LOG&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;tracking of PAL &lt;/A&gt;procedure supports&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;use with al Unified Regression/Classification-, Pipeline-fit/score procedures&amp;nbsp;(with new interfaces suffix&amp;nbsp; “_TRACK” suffix)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;tracking of content including: Parameters, Dataset Metadata, Model Signature, Metrics(including Variable Importance), Figures(discrete and continuous), etc.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;management of tracking data in a built-in schema PAL_ML_TRACK and tables for metadata, log and header information&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;procedure parameters activate the tracking like LOG_ML_TRACK, TRACK_ID, etc.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;A more detailed introduction is provided in the following blog post &lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Task scheduling for PAL procedures&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new PAL &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/calling-pal-with-schedule?q=PAL_REMOVE_MLTRACK_LOG&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;task scheduling&lt;/A&gt; &lt;/SPAN&gt;allows you to run SQLScript procedures (calling PAL procedures) by the SAP HANA Cloud schedular asynchronously (&lt;SPAN&gt;cron-based).&lt;/SPAN&gt; The targeted SQLScript (PAL) procedure calls get mapped to a define task with task ID, task descriptions, owner, etc. A task can be scheduled to executed, a job is the instance of scheduled task.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;The built-in schema PAL_SCHEDULED_EXECUTION provides tables for storage of task definition/metadata, relationships, procedures parameters, TASK_SCHEDULE_JOB, task (operation) log&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;The actual job execution information is provided within the System views SCHEDULE_JOBS, M_SCHEDULE_JOBS&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;New PAL procedures are provided for task creation (AFLPAL_CREATE_TASK_PROC)&lt;BR /&gt;and removal, scheduled job creation for a task (AFLPAL_CREATE_TASK_SCHEDULE_PROC), altering, pausing, resuming and removing task jobs&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The python ML client adds additional interfaces and methods to leverage the new capabilities easily by experts developing HANA ML scenarios.&lt;/P&gt;&lt;H2 id="toc-hId-1143764318"&gt;&lt;SPAN&gt;Data Drift detector with the Automated Predictive Library (APL)&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;The new data drift detector in the APL helps you spot changes or deviations between a given dataset and a reference. Reference data could be a version in the past, or a particular segment of customers or employees, or an expected distribution (e.g. Benford). Use cases of data comparison are:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;This year employee survey results versus last year results by country&lt;/LI&gt;&lt;LI&gt;Machine learning inference dataset versus training dataset&lt;/LI&gt;&lt;LI&gt;Male staff versus female staff&lt;/LI&gt;&lt;LI&gt;Payment amounts by legal entity versus the Benford’s law to find potential fraud&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This feature from APL (Automated Predictive Library) is available for both Python and SQL. For more details see blog post on the&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/hana-ml-data-drift-detector/ba-p/14148518" target="_blank"&gt;HANA ML Data Drift Detector&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_0-1752234591748.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285456i75A1F6A79758D3C3/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_0-1752234591748.png" alt="ChristophMorgen_0-1752234591748.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-947250813"&gt;&lt;SPAN&gt;Python ML client (hana-ml) enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;EM&gt;The full list of new methods and enhancements with hana_ml 2.25&amp;nbsp; is summarized in the &lt;/EM&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/doc/cd94b08fe2e041c2ba778374572ddba9/2025_2_QRC/en-US/change_log.html" target="_blank" rel="noopener noreferrer"&gt;&lt;EM&gt;changelog for hana-ml 2.25&lt;/EM&gt;&lt;/A&gt; &lt;/SPAN&gt;&lt;EM&gt;as part of the documentation. The key enhancements in this release include&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text and vector processing enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;New embedding model version SAP_GXY.20250407&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Classification / regression function enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Use of Multi-task MLP with UnifiedClassification | Regression&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;Benefit from unified interface capabilities like score-function, resampling/parameter search and optimization, model-report, …&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;HGBT regressor with Linear Tree trend extrapolation&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;AutoML and pipeline modeling improvements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Faster random search with hyperband optimization support&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Progress monitor enhancements for fine-tuning and random search &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;HANA ML experiment tracking and task schedule execution&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Experiment tracking and experiment monitor UI (&lt;/SPAN&gt;detailed introduction is provided in the referenced &lt;A title="comprehensive-guide-to-mltrack-in-sap-hana-cloud" href="https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217" target="_self"&gt;blog post&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Enhanced PAL task schedule and job schedule execution UI&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;You can find an examples notebook illustrating the highlighted feature enhancements &lt;SPAN&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/pal/notebooks/25QRC02_2.25.ipynb" target="_blank" rel="noopener nofollow noreferrer"&gt;here 25QRC02_2.25.ipynb&lt;/A&gt;.&amp;nbsp; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-and-ai-features-in-sap-hana-cloud-2025-q2/ba-p/14136079"/>
    <published>2025-06-24T21:40:03.946000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/microsoft-autogen-v0-6-1-with-sap-ai-core/ba-p/14136999</id>
    <title>Microsoft AutoGen v0.6.1 with SAP AI Core</title>
    <updated>2025-06-25T19:45:24.629000+02:00</updated>
    <author>
      <name>Shivang11</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1616935</uri>
    </author>
    <content>&lt;H3 id="toc-hId-1862396263"&gt;Introduction&lt;/H3&gt;&lt;P data-unlink="true"&gt;As a part of&amp;nbsp;&lt;A href="https://help.sap.com/docs/SAP_INTELLIGENT_PRODUCT_RECOMMENDATION?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;Intelligent Product Recommendation&lt;/A&gt; team we are trying to use Autogen for agentic usecases.&amp;nbsp;I initially came across a helpful post&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/autogen-with-sap-ai-core/ba-p/13662908" target="_blank"&gt;AutoGen with SAP AI Core&lt;/A&gt; by&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/407116"&gt;@lars_gregori&lt;/a&gt;&amp;nbsp;, which explores the integration of autogen using &lt;STRONG&gt;pyautogen&lt;/STRONG&gt; and &lt;STRONG&gt;llm_config&lt;/STRONG&gt;. However, use of &lt;STRONG&gt;llm_config&lt;/STRONG&gt;&amp;nbsp;is deprecated in v0.6.1 of&amp;nbsp;&lt;A href="https://microsoft.github.io/autogen/stable//user-guide/agentchat-user-guide/quickstart.html" target="_self" rel="nofollow noopener noreferrer"&gt;AutoGen.&lt;/A&gt;&amp;nbsp; This blog will guide you how to integrate&amp;nbsp;AutoGen&amp;nbsp; with&amp;nbsp;SAP AI Core with the help of&amp;nbsp;&amp;nbsp;&lt;STRONG&gt;AzureOpenAIChatCompletionClient&lt;/STRONG&gt;&amp;nbsp;.&lt;/P&gt;&lt;H3 id="toc-hId-1665882758"&gt;Background&lt;/H3&gt;&lt;P data-unlink="true"&gt;Currently, IPR product is already using python&amp;nbsp;&lt;STRONG&gt;generative-ai-hub-sdk&amp;nbsp;&lt;/STRONG&gt;to call the LLM which takes in the 'AI-Resource-Group' as the required &lt;STRONG&gt;&lt;EM&gt;header&lt;/EM&gt;&lt;/STRONG&gt; and the &lt;STRONG&gt;&lt;EM&gt;model name&lt;/EM&gt;&lt;/STRONG&gt;. Now we have came accross a critical business usecase that requires the use of&amp;nbsp;Autogen&amp;nbsp;to implement the reflection pattern, which led me to explore&amp;nbsp;&lt;STRONG&gt;OpenAIChatCompletionClient &lt;/STRONG&gt;class&amp;nbsp;of Autogen library.&lt;/P&gt;&lt;P data-unlink="true"&gt;I tried using&amp;nbsp;&lt;STRONG&gt;OpenAIChatCompletionClient&amp;nbsp;&lt;/STRONG&gt;by passing&amp;nbsp;&lt;STRONG&gt;base_url&lt;/STRONG&gt; and &lt;STRONG&gt;token&lt;/STRONG&gt;&amp;nbsp;which returned&amp;nbsp;&lt;STRONG&gt;404 resource not found,&lt;/STRONG&gt; since all SAP AI Core requests redirect to Azure OpenAI platform that requires&amp;nbsp;&lt;STRONG&gt;api_version&lt;/STRONG&gt; as&amp;nbsp; a mandatory query parameter. But OpenAIChatCompletionClient class doesn't provides api_version to the LLM while calling it. After further deep dive I figured out&amp;nbsp;&lt;STRONG&gt;AzureOpenAIChatCompletionClient,&lt;/STRONG&gt;&amp;nbsp;which allows requests to be redirected successfully via SAP AI Core to Azure OpenAI by passing the api_version.&lt;/P&gt;&lt;H3 id="toc-hId-1469369253"&gt;Reason to use&amp;nbsp;&lt;STRONG&gt;AzureOpenAIChatCompletionClient&lt;/STRONG&gt;&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;OpenAIChatCompletionClient cannot be used directly.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Instead, we need:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;base_url&lt;/STRONG&gt;: The model deployment URL from SAP AI Core.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;api_key&lt;/STRONG&gt;: A bearer token from GenAI Hub (via SAP AI Core).&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;api_version&lt;/STRONG&gt;: Required by Azure for all chat completions.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Additional headers like AI-Resource-Group.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1272855748"&gt;Code Sample&lt;/H3&gt;&lt;P&gt;Below code sample shows how we can get deployment url and auth token using&amp;nbsp;&lt;SPAN&gt;generative-ai-hub-sdk, that can be passed to AzueOpenAIChatCompletionClient along with api_version.&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import AzureOpenAIChatCompletionClient
from autogen_core.models import ModelFamily
from gen_ai_hub.proxy import GenAIHubProxyClient
from ai_core_sdk.ai_core_v2_client import AICoreV2Client
from autogen_agentchat.ui import Console
import asyncio

# Fetch deployment URL from SAP AI Core
def get_deployment_url():
    try:
        ai_core_client = AICoreV2Client.from_env()
        resources = ai_core_client.deployment.query(resource_group="default", scenario_id="foundation-models").resources
        return resources[0].deployment_url if resources else None
    except Exception:
        return None

# Fetch token and prepare model client
base_url = get_deployment_url()
gen_ai_hub_proxy_client = GenAIHubProxyClient(resource_group='default')
token = gen_ai_hub_proxy_client.get_ai_core_token().replace("Bearer ", "")

model_client = AzureOpenAIChatCompletionClient(
    model="gpt-4.1",
    base_url=base_url,
    api_key=token,
    default_headers={'AI-Resource-Group': 'default'},
    model_info={
        "family": ModelFamily.GPT_41,
        "vision": False,
        "function_calling": True,
        "json_output": False
    },
    api_version="2023-05-15" // api_version as per SAP AI Core documentation
)

# Tool example
async def get_weather(city: str) -&amp;gt; str:
    return f"The weather in {city} is 73 degrees and Sunny."

# Define the agent
agent = AssistantAgent(
    name="weather_agent",
    model_client=model_client,
    tools=[get_weather],
    system_message="You are a weather assistant. Give complete details about the weather in the city requested by the user."
)

# Run the agent
async def main() -&amp;gt; None:
    await Console(agent.run_stream(task="What is the weather in New York?"))
    await model_client.close()

asyncio.run(main())&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-1076342243"&gt;Conclusion&lt;/H3&gt;&lt;P&gt;Above example is referred from&amp;nbsp;&lt;A href="https://microsoft.github.io/autogen/stable//user-guide/agentchat-user-guide/quickstart.html" target="_blank" rel="noopener nofollow noreferrer"&gt;Autogen&lt;/A&gt;&amp;nbsp;documentation. For api_version, ChatCompletionClient can be referred from&amp;nbsp;&lt;A href="https://help.sap.com/docs/AI_CORE/2d6c5984063c40a59eda62f4a9135bee/bf0373b1cf2a4680a7044e1a562d3853.html?locale=en-US&amp;amp;state=PRODUCTION&amp;amp;version=CLOUD&amp;amp;q=2023-05-15" target="_blank" rel="noopener noreferrer"&gt;SAP AI Core&lt;/A&gt; documentation.&amp;nbsp; Output from above code:&lt;/P&gt;&lt;P class="lia-indent-padding-left-60px" style="padding-left : 60px;"&gt;&lt;FONT face="courier new,courier" size="2"&gt;---------- TextMessage (user) ----------&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;What is the weather in New York?&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;---------- ToolCallRequestEvent (weather_agent) ----------&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;[FunctionCall(id='call_WJfl63g7skHT3dWnxMCwNtCr', arguments='{"city":"New York"}', name='get_weather')]&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;---------- ToolCallExecutionEvent (weather_agent) ----------&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;[FunctionExecutionResult(content='The weather in New York is 73 degrees and Sunny.', name='get_weather', call_id='call_WJfl63g7skHT3dWnxMCwNtCr', is_error=False)]&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;---------- ToolCallSummaryMessage (weather_agent) ----------&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier" size="2"&gt;The weather in New York is 73 degrees and Sunny.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;I hope this post helps other teams building solutions on SAP AI Core to successfully integrate newer versions of AutoGen to call the LLM and build multiple AI agents.&lt;/P&gt;&lt;P&gt;Elevate with AI !!&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/microsoft-autogen-v0-6-1-with-sap-ai-core/ba-p/14136999"/>
    <published>2025-06-25T19:45:24.629000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/application-development-and-automation-blog-posts/cloning-a-corporate-github-repository-python-to-vs-code-on-mac/ba-p/14142843</id>
    <title>Cloning a Corporate GitHub Repository (Python) to VS Code on MAC</title>
    <updated>2025-07-04T16:22:39.618000+02:00</updated>
    <author>
      <name>SugandhaSachdeva</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1485764</uri>
    </author>
    <content>&lt;P&gt;Working in a corporate environment often means using private repositories hosted on GitHub Enterprise. If you're on a Mac and prefer the Terminal, here’s a simple step-by-step guide to clone the repo and get started with VS Code.&lt;/P&gt;&lt;H2 id="toc-hId-1734116779"&gt;Prerequisites&lt;/H2&gt;&lt;UL&gt;&lt;LI&gt;&lt;A href="https://brew.sh/" target="_blank" rel="noopener nofollow noreferrer"&gt;Homebrew&lt;/A&gt; installed&lt;/LI&gt;&lt;LI&gt;Git installed - or run the following command from terminal&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;brew install git​&lt;/code&gt;&lt;/pre&gt;&lt;UL&gt;&lt;LI&gt;&lt;A href="https://code.visualstudio.com/" target="_blank" rel="noopener nofollow noreferrer"&gt;Visual Studio Code&lt;/A&gt; installed&lt;/LI&gt;&lt;LI&gt;Access to your company’s GitHub (e.g., GitHub Enterprise or another corporate Git)&lt;/LI&gt;&lt;LI&gt;Make sure you have a personal access token; if not, generate a new one&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="SugandhaSachdeva_1-1751625219727.png" style="width: 889px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/282696i278C25D79AEB5BA5/image-dimensions/889x351?v=v2" width="889" height="351" role="button" title="SugandhaSachdeva_1-1751625219727.png" alt="SugandhaSachdeva_1-1751625219727.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;UV installed: UV is a Python package/dependency manager; install it using&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;brew install uv​&lt;/code&gt;&lt;/pre&gt;&lt;H2 id="toc-hId-1537603274"&gt;Steps&lt;/H2&gt;&lt;H3 id="toc-hId-1470172488"&gt;&lt;STRONG&gt;1. Verify Git is installed&lt;/STRONG&gt;&lt;/H3&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;which git
git --version​&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-1273658983"&gt;&lt;STRONG&gt;2. Install GitHub Repositories Extension in VS Code&lt;/STRONG&gt;&lt;/H3&gt;&lt;H3 id="toc-hId-1077145478"&gt;&lt;STRONG&gt;3. Clone the Repository via Terminal&lt;/STRONG&gt;&lt;/H3&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;git clone https://github.company.com/your-team/your-repo.git​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;BR /&gt;If prompted, enter your GitHub username and your &lt;STRONG&gt;Personal Access Token&lt;/STRONG&gt; instead of a password.&lt;/P&gt;&lt;H3 id="toc-hId-880631973"&gt;&lt;STRONG&gt;4. Change into the Cloned Directory&lt;/STRONG&gt;&lt;/H3&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;cd your-repo​&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-684118468"&gt;5.&amp;nbsp;&lt;STRONG&gt;Open the Folder in VS Code&lt;/STRONG&gt;&lt;/H3&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;code .&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;BR /&gt;If code is not recognized, open VS Code → Cmd + Shift + P → “Shell Command: Install 'code' command in PATH”.&lt;/P&gt;&lt;H3 id="toc-hId-487604963"&gt;&lt;STRONG&gt;6. Install Python Extensions in VS Code&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;If you're working on a Python project, consider installing the following VS Code extensions:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Python&lt;/LI&gt;&lt;LI&gt;Jupyter&lt;/LI&gt;&lt;LI&gt;Black Formatter&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-291091458"&gt;&lt;STRONG&gt;7. Install Python Project Dependencies with uv&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;&lt;BR /&gt;In the VS Code terminal:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;uv sync&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/application-development-and-automation-blog-posts/cloning-a-corporate-github-repository-python-to-vs-code-on-mac/ba-p/14142843"/>
    <published>2025-07-04T16:22:39.618000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/hana-ml-data-drift-detector/ba-p/14148518</id>
    <title>HANA ML Data Drift Detector</title>
    <updated>2025-07-10T17:08:13.870000+02:00</updated>
    <author>
      <name>marc_daniau</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/187920</uri>
    </author>
    <content>&lt;P&gt;The release of HANA ML 2.23 includes a new function called: APL data drift detector. This drift detector helps you spot changes or deviations between a given dataset and a reference. Reference data could be a version in the past, or a particular segment of customers or employees, or an expected distribution (e.g. Benford). Use cases of data comparison are:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;This year employee survey results versus last year results by country&lt;/LI&gt;&lt;LI&gt;Machine learning inference dataset versus training dataset&lt;/LI&gt;&lt;LI&gt;Male staff versus female staff&lt;/LI&gt;&lt;LI&gt;Payment amounts by legal entity versus the Benford’s law to find potential fraud&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This feature from APL (Automated Predictive Library) is available for both Python and SQL.&lt;/P&gt;&lt;P&gt;The rest of this blog will walk you through a scenario with code snippets in Python as well as SQL that you can reuse and adapt to your own case.&lt;/P&gt;&lt;P&gt;We chose to work with Olympics athletes and results data. The dataset contains summer and winter games since 1896. We want to make a comparison over time.&lt;/P&gt;&lt;P&gt;First, we connect to the SAP HANA database using a Python notebook.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;DB_Host='host'  
DB_Port='port_number'
DB_User='user_name'
DB_Password='user_password'

from hana_ml import dataframe as hd
conn = hd.ConnectionContext(address = DB_Host, port = DB_Port, 
                            user = DB_User, password = DB_Password, 
                            encrypt = 'true', sslValidateCertificate = 'false' )
conn.connection.isconnected()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The reference dataframe comprises the Olympic games before 1970 …&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport" 
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;lt;= 1970  
order by "Id"
"""
hdf_ref= hd.DataFrame(conn, sql_cmd)
hdf_ref.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_Ref.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284591i95E55218053F1DBE/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_Ref.png" alt="Data_Ref.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-left" style="text-align : left;"&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;… and the comparison dataframe, after 1970:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport"
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;gt; 1970 
order by "Id"
"""
hdf_new= hd.DataFrame(conn, sql_cmd)
hdf_new.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_New.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284593i5A0C2A7E6A164C02/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_New.png" alt="Data_New.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The code to run the comparison is the following:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from hana_ml.algorithms.apl.drift_detector import DriftDetector
apl_model = DriftDetector()
results = apl_model.fit_detect(hdf_ref, hdf_new, build_report=True)
print(results.collect())&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Deviation_Over_time.png" style="width: 200px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284595iD85393F245D82537/image-size/small?v=v2&amp;amp;px=200" role="button" title="Deviation_Over_time.png" alt="Deviation_Over_time.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;All the variables appearing here have a deviation indicator over 0.95. This threshold can be changed with the syntax below:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;results = apl_model.fit_detect(hdf_ref, hdf_new, threshold=0.80)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Here is a report putting the two datasets side by side with their counts (aka weight) by category; the most changing categories (top 10 here) appear first:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;df = apl_model.get_debrief_report('Deviation_CategoryFrequencies').head(10).deselect(['Oid','Category Order']).collect()
format_dict = {
    'Ref Weight': '{:,.0f}', 'New Weight': '{:,.0f}', 'Change': '{:,.0f}', 
    'Ref % Weight': '{:.1f}', 'New % Weight': '{:.1f}', '% Change': '{:.1f}', 'Abs % Change': '{:.1f}'
}
df.style.format(format_dict).hide(axis='index')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Top_Changing.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284599iAD21273F45BCE584/image-size/large?v=v2&amp;amp;px=999" role="button" title="Top_Changing.png" alt="Top_Changing.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;KxMissing is a special category created by APL when finding empty or null values. With far less missing values on athletes’ height and weight, we see that data quality is getting better overtime.&lt;/P&gt;&lt;P&gt;More women are participating to the Olympic games after 1970. The male % change value mirrors the female % change value. The same remark applies to summer and winter seasons.&lt;/P&gt;&lt;P&gt;The following code brings the data drift results as charts:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;apl_model.generate_notebook_iframe_report()
# apl_model.generate_html_report('drift_olympics')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="HTML_Report.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284610i88BD0F5CB087BFE5/image-size/large?v=v2&amp;amp;px=999" role="button" title="HTML_Report.png" alt="HTML_Report.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;After comparing athletes across all types of sports, let’s compare them by sport. For that we must provide the drift detector with two dataframes sorted by Sport:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;## Reference Dataset
sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport" 
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;lt;= 1970  
order by "Sport", "Id"
"""
hdf_ref= hd.DataFrame(conn, sql_cmd)
hdf_ref.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_Ref-By_Sport.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284614i904817BDECD46EDB/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_Ref-By_Sport.png" alt="Data_Ref-By_Sport.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;## Dataset for comparison
sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport" 
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;gt; 1970  
order by "Sport", "Id"
"""
hdf_new= hd.DataFrame(conn, sql_cmd)
hdf_new.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_New-By_Sport.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284615iA1B4FC007FBA9463/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_New-By_Sport.png" alt="Data_New-By_Sport.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;You specify the segment for drift detection the same way as for segmented forecasting, regression or classification scenarios:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;col_segment= 'Sport'    
from hana_ml.algorithms.apl.drift_detector import DriftDetector
apl_model = DriftDetector(segment_column_name= col_segment, max_tasks= 4)
results = apl_model.fit_detect(hdf_ref, hdf_new, threshold=0.95)
print(results.sort(["Segment","Variable"]).collect())&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The deviating variables appear for each sport:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Deviation_Over_time-By_Sport.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284619iEDD5AE5373CE1C3B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Deviation_Over_time-By_Sport.png" alt="Deviation_Over_time-By_Sport.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;We check if there are segments with status ‘Failed’:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;my_filter = "KEY in ('AplTaskStatus') and VALUE ='Failed'"
df = apl_model.get_summary().filter(my_filter).select('OID').collect()
failed_segments = df['OID'].tolist()
print('Preview of failed segments')
print(failed_segments[:5])&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Failed_Segments.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284621iAC4A5C8B2A51FC6B/image-size/large?v=v2&amp;amp;px=999" role="button" title="Failed_Segments.png" alt="Failed_Segments.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The log contains the cause of failure:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;df = apl_model.get_fit_operation_log().filter("LEVEL = 0").select('OID','ORIGIN','MESSAGE').head(5).collect()
df.columns = [col_segment, 'Cause', 'Error']
df.style.hide(axis='index')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Cause_Of_Failure.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284622iAC753A3C7B57F4AE/image-size/large?v=v2&amp;amp;px=999" role="button" title="Cause_Of_Failure.png" alt="Cause_Of_Failure.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;These sports were introduced after 1970. Thus, there is no reference data to compare against.&lt;/P&gt;&lt;P&gt;To obtain the Data Drift report, you must provide a segment value as in the example below:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;seg_value = "Swimming"
apl_model.build_report(segment_name=seg_value)
apl_model.generate_notebook_iframe_report()
#apl_model.generate_html_report('Sport_Report')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;We are nearing the end of this post, and you have not yet seen how to run a comparison with the SQL interface. Here is the syntax for calling the new APL function COMPARE_DATA from a SQL script:&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;drop view DATASET_1;
create view DATASET_1 as (
 select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport"
 from "APL_SAMPLES"."OLYMPICS" 
 where "Year" &amp;lt;= 1970  
 order by "Sport", "Id"
);

drop view DATASET_2;
create view DATASET_2 as (
 select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport"
 from "APL_SAMPLES"."OLYMPICS" 
 where "Year" &amp;gt; 1970  
 order by "Sport", "Id"
);

DO BEGIN
    declare header "SAP_PA_APL"."sap.pa.apl.base::BASE.T.FUNCTION_HEADER";
    declare config "SAP_PA_APL"."sap.pa.apl.base::BASE.T.OPERATION_CONFIG_EXTENDED";   
    declare var_desc "SAP_PA_APL"."sap.pa.apl.base::BASE.T.VARIABLE_DESC_OID";      
    declare var_role "SAP_PA_APL"."sap.pa.apl.base::BASE.T.VARIABLE_ROLES_WITH_COMPOSITES_OID";      
    declare out_log   "SAP_PA_APL"."sap.pa.apl.base::BASE.T.OPERATION_LOG";             
    declare out_summary  "SAP_PA_APL"."sap.pa.apl.base::BASE.T.SUMMARY";   
    declare out_metric   "SAP_PA_APL"."sap.pa.apl.base::BASE.T.DEBRIEF_METRIC_OID";      
    declare out_property "SAP_PA_APL"."sap.pa.apl.base::BASE.T.DEBRIEF_PROPERTY_OID";
 
    :header.insert(('Oid', 'Before-After 1970'));

    :config.insert(('APL/SegmentColumnName', 'Sport',null)); 

	:var_desc.insert((0,'Height','number','continuous',0,0,null,null,null,null));
	:var_desc.insert((1,'Weight','number','continuous',0,0,null,null,null,null));
	:var_desc.insert((2,'Age','integer','continuous',0,0,null,null,null,null));
    :var_desc.insert((3,'Medal','string','nominal',0,0,null,null,null,null));
	:var_desc.insert((4,'Gender','string','nominal',0,0,null,null,null,null));
	:var_desc.insert((5,'Season','string','nominal',0,0,null,null,null,null));
	:var_desc.insert((6,'Country','string','nominal',0,0,null,null,null,null));
	
	"SAP_PA_APL"."sap.pa.apl.base::COMPARE_DATA" (
	:header, :config, :var_desc, :var_role,'USER_APL','DATASET_1', 'USER_APL','DATASET_2', 
	out_log, out_summary, out_metric, out_property );
 
 	select value as "Status", count(*) as "Nb of Segments" from :out_summary where key = 'AplTaskStatus' group by value;
	select OID as "Sport", message as "Error" from :out_log where level=0;
	 	
    select * from SAP_PA_APL."sap.pa.apl.debrief.report::Deviation_ByVariable"(:out_property,:out_metric, Deviation_Threshold =&amp;gt; 0.9);
    select * from SAP_PA_APL."sap.pa.apl.debrief.report::Deviation_ByCategory"(:out_property,:out_metric, Deviation_Threshold =&amp;gt; 0.9); 
    select * from SAP_PA_APL."sap.pa.apl.debrief.report::Deviation_CategoryFrequencies"(:out_property,:out_metric) order by "Abs % Change" desc;
END;

-- Cases where a comparison is not possible
select "Sport" from "DATASET_1" minus select "Sport" from "DATASET_2"; -- Sports that have been removed 
select "Sport" from "DATASET_2" minus select "Sport" from "DATASET_1"; -- New Sports&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The APL drift detector supports also a 2-step approach to address the cases where you have a changing dataset that needs to be compared on a regular basis (e.g. every week or every month) to a fixed reference. The samples below illustrate how it works with Python:&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/apl/notebooks/63a_Data_Drift-Learn_and_Report.ipynb" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 1 notebook&lt;/A&gt;&amp;nbsp; &amp;nbsp;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/apl/notebooks/63b_Data_Drift-Detect_and_Report.ipynb" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 2 notebook&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;and with SQL:&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/APL-SQL/63a_Data_Drift-Learn_and_Report.sql" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 1 script&lt;/A&gt;&amp;nbsp; &amp;nbsp;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/APL-SQL/63b_Data_Drift-Detect_and_Report.sql" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 2 script&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Happy data drift detection with APL.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/viewer/p/apl" target="_self" rel="noopener noreferrer"&gt;To know more about APL&lt;/A&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/hana-ml-data-drift-detector/ba-p/14148518"/>
    <published>2025-07-10T17:08:13.870000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/exploring-sap-generative-ai-sdk-python-javascript-and-java-libraries/ba-p/14150705</id>
    <title>Exploring SAP Generative AI SDK: Python, JavaScript, and Java Libraries 🎁</title>
    <updated>2025-07-11T20:59:21.243000+02:00</updated>
    <author>
      <name>Yogananda</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/75</uri>
    </author>
    <content>&lt;P&gt;SAP's Generative AI SDK offers powerful tools for integrating AI capabilities into your business applications.&lt;/P&gt;&lt;P&gt;This blog will guide you through the libraries available for &lt;FONT color="#0000FF"&gt;Python, JavaScript, and Java&lt;/FONT&gt;, and how to use them effectively.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-07-11_20-51-00.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285646iE39F1A18CFDFB822/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-07-11_20-51-00.png" alt="2025-07-11_20-51-00.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-1993145073"&gt;1.&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":blue_circle:"&gt;🔵&lt;/span&gt;&amp;nbsp;&lt;/SPAN&gt;SAP Generative AI SDK for Python&lt;/H4&gt;&lt;P&gt;The SAP Generative AI SDK for Python allows developers to leverage generative models from the SAP AI Core. This SDK supports models from providers like OpenAI, Amazon, and Google, and integrates with LangChain for enhanced functionality.&lt;/P&gt;&lt;P&gt;Documentation and Examples :&amp;nbsp;&lt;A href="https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/index.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/doc/generative-ai-hub-sdk/CLOUD/en-US/index.html&lt;/A&gt;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Yogananda_1-1752259770526.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285644i13469DC27D9AC732/image-size/large?v=v2&amp;amp;px=999" role="button" title="Yogananda_1-1752259770526.png" alt="Yogananda_1-1752259770526.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Installation:&amp;nbsp;To install the SDK, use the following command:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;pip install sap-ai-sdk-gen[all]&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;SPAN&gt;You can also install specific model providers:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;pip install "sap-ai-sdk-gen[google, amazon]"&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Configuration:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Set up your environment variables or configuration file to authenticate and connect to SAP AI Core:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;export AICORE_CLIENT_ID="your_client_id"
export AICORE_CLIENT_SECRET="your_client_secret"
export AICORE_AUTH_URL="your_auth_url"
export AICORE_BASE_URL="your_base_url"&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Usage:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Here's a simple example to generate text using the OpenAI model:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from sap_ai_sdk_gen import OpenAI

client = OpenAI()
response = client.generate_text(prompt="Hello, world!")
print(response)&lt;/code&gt;&lt;/pre&gt;&lt;H4 id="toc-hId-1796631568"&gt;2.&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":blue_circle:"&gt;🔵&lt;/span&gt;&amp;nbsp;&lt;/SPAN&gt;SAP Generative AI SDK for JavaScript&lt;/H4&gt;&lt;P&gt;The JavaScript SDK enables Node.js applications to interact with SAP AI Core, providing seamless integration with generative models.&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP/ai-sdk-js" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/SAP/ai-sdk-js&lt;/A&gt;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Yogananda_0-1752259610583.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285643iBB7D6B6568C71C17/image-size/large?v=v2&amp;amp;px=999" role="button" title="Yogananda_0-1752259610583.png" alt="Yogananda_0-1752259610583.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Installation:&amp;nbsp;Install the SDK via npm:&lt;/P&gt;&lt;pre class="lia-code-sample language-javascript"&gt;&lt;code&gt;npm install -ai-sdk/ai-api&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Configuration:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Ensure your environment variables are set up correctly:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-javascript"&gt;&lt;code&gt;export AICORE_CLIENT_ID="your_client_id"
export AICORE_CLIENT_SECRET="your_client_secret"
export AICORE_AUTH_URL="your_auth_url"
export AICORE_BASE_URL="your_base_url"&lt;/code&gt;&lt;/pre&gt;&lt;H4 id="toc-hId-1600118063"&gt;&lt;STRONG&gt;Usage:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Here's a basic example to generate text:&lt;/SPAN&gt;&lt;/H4&gt;&lt;pre class="lia-code-sample language-javascript"&gt;&lt;code&gt;import { OpenAI } from '@sap-ai-sdk/ai-api';

const client = new OpenAI();
client.generateText('Hello, world!').then(response =&amp;gt; {
  console.log(response);
});&lt;/code&gt;&lt;/pre&gt;&lt;H4 id="toc-hId-1403604558"&gt;3.&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":blue_circle:"&gt;🔵&lt;/span&gt;&amp;nbsp;&lt;/SPAN&gt;SAP Generative AI SDK for Java&lt;/H4&gt;&lt;P&gt;The Java SDK integrates AI capabilities into Java-based applications, leveraging the SAP AI Core's generative models.&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP/ai-sdk-java" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/SAP/ai-sdk-java&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Installation:&amp;nbsp;Add the SDK to your Maven project:&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-java"&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;com.sap.ai&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;sap-ai-sdk&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;5.6.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Configuration:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Configure your application properties:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-java"&gt;&lt;code&gt;aicore.client.id=your_client_id
aicore.client.secret=your_client_secret
aicore.auth.url=your_auth_url
aicore.base.url=your_base_url&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Usage:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Here's an example to generate text:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-java"&gt;&lt;code&gt;import com.sap.ai.sdk.OpenAI;

public class Main {
    public static void main(String[] args) {
        OpenAI client = new OpenAI();
        String response = client.generateText("Hello, world!");
        System.out.println(response);
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-1078008334"&gt;Conclusion&lt;/H3&gt;&lt;P&gt;SAP's Generative AI SDKs for Python, JavaScript, and Java provide robust tools for integrating AI into your applications. By following the installation, configuration, and usage examples provided, you can start leveraging the power of generative AI in your projects.&lt;/P&gt;&lt;P&gt;Feel free to reach out if you have any questions or need further assistance! Happy coding!&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/exploring-sap-generative-ai-sdk-python-javascript-and-java-libraries/ba-p/14150705"/>
    <published>2025-07-11T20:59:21.243000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/using-python-in-sap-business-application-studio-my-notes/ba-p/14155516</id>
    <title>Using Python in SAP Business Application Studio – my notes</title>
    <updated>2025-07-18T13:55:15.744000+02:00</updated>
    <author>
      <name>Vitaliy-R</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/183</uri>
    </author>
    <content>&lt;P&gt;The &lt;STRONG&gt;Python Tools extension&lt;/STRONG&gt;, which enhances the Python coding experience, was introduced in SAP Business Application Studio (referred to as "BAS" below) exactly two years ago. Here are my notes from using it.&lt;/P&gt;&lt;P&gt;This post is not a tutorial or a comprehensive guide to best practices. It’s a collection of personal notes, which I hope you find helpful when working with Python in BAS. The &lt;STRONG&gt;focus here is on&lt;/STRONG&gt; &lt;STRONG&gt;running Python code in BAS&lt;/STRONG&gt;, not on deploying to SAP BTP runtimes like Cloud Foundry (CF) or Kyma. This is when you are usually working on &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/quot-getting-started-with-machine-learning-using-sap-hana-quot-as-a-new-sap/ba-p/13574098" target="_self"&gt;Machine Learning&lt;/A&gt; or AI projects in BAS,&amp;nbsp;like during SAP CodeJams.&lt;/P&gt;&lt;P&gt;I assume you're not an absolute beginner with SAP Business Application Studio—or at least you're familiar with Visual Studio Code.&lt;/P&gt;&lt;P&gt;For the examples in this post, I’ll be using the SAP Business Application Studio available in the SAP BTP Trial environment.&lt;/P&gt;&lt;H1 id="toc-hId-1606043981"&gt;Python runtime&lt;/H1&gt;&lt;P&gt;In SAP Business Application Studio, the dev space includes a system-level Python 3 binary at &lt;FONT face="terminal,monaco" color="#000080"&gt;/bin/python3&lt;/FONT&gt;, which is primarily intended for OS-level scripts and tooling. This version is tied to the base container image and is only updated when the image itself is refreshed.&lt;/P&gt;&lt;H3 id="toc-hId-1667695914"&gt;Managing Python versions&lt;/H3&gt;&lt;P&gt;For application development, developers typically use user-managed Python runtimes. Since &lt;A href="https://help.sap.com/docs/bas/sap-business-application-studio/2024-what-s-new-for-sap-business-application-studio?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;January 2024&lt;/A&gt;, you can select the Python version with which you want to work.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752787857188.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288194i63734250F432B502/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1752787857188.png" alt="VitaliyR_0-1752787857188.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;SAP Business Application Studio uses &lt;A href="https://asdf-vm.com/guide/introduction.html" target="_self" rel="nofollow noopener noreferrer"&gt;asdf&lt;/A&gt; to allow you to select which runtime versions to install and use for developing your application. You can check this in the BAS terminal with &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf current python&lt;/FONT&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752826029935.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288476i3AA3E4CCAB7C035F/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1752826029935.png" alt="VitaliyR_0-1752826029935.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;By default, SAP Business Application Studio provides only one officially supported Python version.&lt;/P&gt;&lt;P&gt;If you need another version of Python, you can install it with&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;FONT face="terminal,monaco" color="#000080"&gt;asdf install python &amp;lt;version&amp;gt;&lt;/FONT&gt;. If you want the latest minor version, then use&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;FONT face="terminal,monaco" color="#000080"&gt;latest:&lt;/FONT&gt;, like&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;FONT face="terminal,monaco" color="#000080"&gt;asdf install python latest:3.12&lt;/FONT&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;in the case of the 3.12 version of Python.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1752826587342.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288479i3F1AFA339D0457AC/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="VitaliyR_1-1752826587342.png" alt="VitaliyR_1-1752826587342.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;At the time of writing this post, the &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf&lt;/FONT&gt;&amp;nbsp;version used in BAS is 0.12.0. This version uses the &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf global&lt;/FONT&gt;&amp;nbsp;and &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf local&lt;/FONT&gt;&amp;nbsp;commands to set the actual runtime version. If you refer to the &lt;A href="https://asdf-vm.com/manage/commands.html" target="_self" rel="nofollow noopener noreferrer"&gt;asdf documentation&lt;/A&gt;, these commands have been replaced with &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf set&lt;/FONT&gt;, so don't get confused.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_4-1752832090379.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288513i2594100CA73554EA/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="VitaliyR_4-1752832090379.png" alt="VitaliyR_4-1752832090379.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1471182409"&gt;Runtime management from the command palette&lt;/H3&gt;&lt;P&gt;You can also install different versions from the command palette. Select &lt;STRONG&gt;&amp;gt; Runtime: Install&lt;/STRONG&gt;,&amp;nbsp;then Python, and the version you want to install. To set the default version of Python for execution, use the command &lt;STRONG&gt;&amp;gt; Runtime: Set Default&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_3-1752831488109.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288507iF7D44FFABFDAC454/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="VitaliyR_3-1752831488109.png" alt="VitaliyR_3-1752831488109.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://help.sap.com/docs/bas/sap-business-application-studio/runtime-version-management" target="_blank" rel="noopener noreferrer"&gt;These commands&lt;/A&gt; are provided by the built-in &lt;STRONG&gt;BAS Framework&lt;/STRONG&gt; extension.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_2-1752831268028.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288505i52FE94C88EEC6711/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="VitaliyR_2-1752831268028.png" alt="VitaliyR_2-1752831268028.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1274668904"&gt;You can now run your Python programs in BAS...&lt;/H3&gt;&lt;P&gt;...using a version of Python accordingly to your requirements.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752833019314.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288533iF1F4C8ABA0F83A9D/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="VitaliyR_0-1752833019314.png" alt="VitaliyR_0-1752833019314.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H1 id="toc-hId-819989961"&gt;Design-time&lt;/H1&gt;&lt;P&gt;Being a &lt;STRONG&gt;fork of Visual Studio Code - Open Source ("&lt;A href="https://github.com/microsoft/vscode" target="_self" rel="nofollow noopener noreferrer"&gt;Code - OSS&lt;/A&gt;")&lt;/STRONG&gt;—SAP Business Application Studio provides basic support for Python files and Jupyter notebooks out of the box.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752835179123.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288559i5DC7A0BAB2529980/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="VitaliyR_0-1752835179123.png" alt="VitaliyR_0-1752835179123.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-881641894"&gt;BAS additional extension "&lt;SPAN&gt;Python Tools&lt;/SPAN&gt;"&lt;/H3&gt;&lt;P&gt;To improve your Python coding experience, SAP Business Application Studio provides an additional extension called "&lt;SPAN&gt;Python Tools&lt;/SPAN&gt;". This extension includes IntelliSense, formatting, linting, and debugging support for Python files and Jupyter notebooks.&lt;/P&gt;&lt;P&gt;To add "Python Tools" to your BAS dev space, go to the configuration of a stopped or a newly created dev space, and select &lt;STRONG&gt;Python Tools&lt;/STRONG&gt; from&amp;nbsp;&lt;STRONG&gt;Additional SAP Extensions&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1752833807354.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288542i4B3C4AE1B211B686/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1752833807354.png" alt="VitaliyR_1-1752833807354.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Upon activation, you should see additional extensions listed now as built-in in BAS.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1752835746649.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288580i881221FC5560023D/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1752835746649.png" alt="VitaliyR_1-1752835746649.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Note&lt;SPAN&gt;&amp;nbsp;that BAS installs its extensions from &lt;A href="https://open-vsx.org/" target="_self" rel="nofollow noopener noreferrer"&gt;Open VSX&lt;/A&gt;, an open-source registry for VS Code extensions.&amp;nbsp;&lt;A href="https://github.com/Microsoft/vscode-python" target="_blank" rel="noopener nofollow noreferrer"&gt;VS Code's Python extension&lt;/A&gt;&amp;nbsp;is available&lt;/SPAN&gt;&amp;nbsp;at:&amp;nbsp;&lt;A href="https://open-vsx.org/extension/ms-python/python" target="_blank" rel="noopener nofollow noreferrer"&gt;https://open-vsx.org/extension/ms-python/python&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;You can see Python extensions in the file system:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;ls -lad /extbin/local/openvscode-server/extensions/ms-py*&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_2-1752837415019.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288590iAD09D0AB5EF7209B/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="VitaliyR_2-1752837415019.png" alt="VitaliyR_2-1752837415019.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;These are extensions selected and integrated by the BAS product team at SAP.&lt;/P&gt;&lt;H3 id="toc-hId-685128389"&gt;Additional notes:&lt;/H3&gt;&lt;P&gt;You can install other versions of the same extensions directly from&amp;nbsp;&lt;A href="https://open-vsx.org/," target="_blank" rel="noopener nofollow noreferrer"&gt;https://open-vsx.org/,&lt;/A&gt;&amp;nbsp;but there is no guarantee that they have been tested and will properly work with BAS. First of all, the extension version installed directly from the marketplace should be compatible with the version of SAP Business Application Studio (or the "Code—OSS" to be more precise).&lt;/P&gt;&lt;P&gt;For example, at the time of writing this post, the version of the Python extension at the VSX marketplace is 2025.04...&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752844419611.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288649i9D1EA9993790B188/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1752844419611.png" alt="VitaliyR_0-1752844419611.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;which is compatible with version&amp;nbsp;1.94.0 of Code-OSS and therefore BAS:&amp;nbsp;&lt;A href="https://github.com/microsoft/vscode-python/blob/v2025.4.0/package.json#L50" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/microsoft/vscode-python/blob/v2025.4.0/package.json#L50&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_1-1752844619669.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288650i4AACB703E4B1AB99/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="VitaliyR_1-1752844619669.png" alt="VitaliyR_1-1752844619669.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-488614884"&gt;Usage of the Python extension in BAS&lt;/H3&gt;&lt;P&gt;Upon installation of the Python extension in BAS, you can:&lt;/P&gt;&lt;P&gt;1/ Execute Python extension's commands from the palette:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_3-1752839390743.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288612iE7D273E2ECA1213B/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="VitaliyR_3-1752839390743.png" alt="VitaliyR_3-1752839390743.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;2/ Trigger an execution of a program from the editor:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_4-1752839526904.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288613i6971D9697275CE7D/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="VitaliyR_4-1752839526904.png" alt="VitaliyR_4-1752839526904.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;3/ modify its &lt;FONT face="terminal,monaco" color="#000080"&gt;@ext:ms-python.python&lt;/FONT&gt;&amp;nbsp;settings:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_5-1752839680256.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288616i88C848EA078DDAA6/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="VitaliyR_5-1752839680256.png" alt="VitaliyR_5-1752839680256.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Please share your tips using Python in SAP Business Application Studio!&lt;/P&gt;&lt;P&gt;------&lt;/P&gt;&lt;P&gt;Stay tuned for a separate post on the topic of using Jupyter notebooks.&lt;BR /&gt;-Vitaliy, aka&amp;nbsp;&lt;A href="https://bsky.app/profile/sygyzmundovych.bsky.social" target="_self" rel="nofollow noopener noreferrer"&gt;@Sygyzmundovych&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-python-in-sap-business-application-studio-my-notes/ba-p/14155516"/>
    <published>2025-07-18T13:55:15.744000+02:00</published>
  </entry>
</feed>
