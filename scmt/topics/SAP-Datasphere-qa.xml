<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/SAP-Datasphere-qa.xml</id>
  <title>SAP Community - SAP Datasphere</title>
  <updated>2026-01-16T00:12:46.488739+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/SAP Datasphere/pd-p/73555000100800002141" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>SAP Datasphere Q&amp;A in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-export-analytical-model-output-from-sap-datasphere-to-azure-data/qaq-p/14283304</id>
    <title>How to Export Analytical Model Output from SAP Datasphere to Azure Data Lake Storage?</title>
    <updated>2025-12-03T17:51:46.079000+01:00</updated>
    <author>
      <name>karteeksap</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2240010</uri>
    </author>
    <content>&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Hello Experts,&lt;/P&gt;&lt;P&gt;I am working on a requirement where I need to export the output of an &lt;STRONG&gt;Analytical Model&lt;/STRONG&gt; in &lt;STRONG&gt;SAP Datasphere&lt;/STRONG&gt; into &lt;STRONG&gt;Azure Data Lake Storage (ADLS)&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;Connections to both &lt;STRONG&gt;Datasphere&lt;/STRONG&gt; and &lt;STRONG&gt;Azure&lt;/STRONG&gt; are already established.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Question:&lt;/STRONG&gt;&lt;BR /&gt;Is there a way to export Analytical Model data into ADLS?&lt;/P&gt;&lt;P&gt;I attempted to create a &lt;STRONG&gt;Replication Flow&lt;/STRONG&gt; with Datasphere as the source. However, when selecting the source object, I only see:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Local Tables&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Fact Views&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Dimension Views&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The &lt;STRONG&gt;Analytical Models&lt;/STRONG&gt; do not appear as selectable source objects.&lt;/P&gt;&lt;P&gt;Has anyone implemented this scenario or knows if Analytical Models are supported in Replication Flows or if there is an alternative approach?&lt;/P&gt;&lt;P&gt;Thanks in advance!&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Datasphere/pd-p/73555000100800002141" class="lia-product-mention" data-product="16-1"&gt;SAP Datasphere&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/Cloud+Integration/pd-p/67837800100800006801" class="lia-product-mention" data-product="361-1"&gt;Cloud Integration&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/Cloud+Connector/pd-p/0f95abc4-29f3-477d-874c-7c758b81f779" class="lia-product-mention" data-product="1193-1"&gt;Cloud Connector&lt;/a&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-export-analytical-model-output-from-sap-datasphere-to-azure-data/qaq-p/14283304"/>
    <published>2025-12-03T17:51:46.079000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-datasphere-replication-flow-load-type-initial-and-delta-schedule/qaq-p/14286270</id>
    <title>SAP Datasphere - Replication Flow Load Type Initial and Delta Schedule</title>
    <updated>2025-12-08T20:42:38.284000+01:00</updated>
    <author>
      <name>Lauryn_Harvey</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2237640</uri>
    </author>
    <content>&lt;P&gt;&lt;FONT size="6"&gt;Is there any feature for Datasphere Replication Flows with load type "Initial and Delta" to be scheduled?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;Scenario 1&lt;/FONT&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;We want a replication flow with load type "Initial and Delta" to start at 9PM. In this scenario, the initial has not yet been loaded. Is there any way to trigger the replication flow&amp;nbsp;to begin at 9PM without having a user log in and manually click a button at 9PM?&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;Attempting to a schedule on the replication flow with load type "Initial and Delta" results in the error below.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;&lt;EM&gt;"&lt;SPAN&gt;For replication flows that contain objects with load type "Initial and Delta/Delta Only", no schedule can be created."&lt;/SPAN&gt;&lt;/EM&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;Attempting to add the replication flow with load type&amp;nbsp;"Initial and Delta"&amp;nbsp; to a task chain results in the error below.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;&lt;EM&gt;"Object '&amp;lt;ReplicationFlowName&amp;gt;' cannot be part of a task chain because it does not have an end (as it includes objects with load type Initial and Delta/Delta Only)."&lt;/EM&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;Scenario 2&lt;/FONT&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;We want the replication flow with load type "Initial and Delta" to check for new delta records at 9PM every day. The delta load may take anywhere from 15 minutes up to 1 hour depending on the number of the changes observed. &lt;U&gt;Is there any way to ensure that the replication flow will start to load deltas every day at 9PM?&lt;/U&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;If the frequency is set to 24 hours, we observe that the next delta will begin to be loaded 24 hours &lt;U&gt;after the previous delta load had finished&lt;/U&gt;. After some time, the timing will no longer be close to 9PM. We are aware we can change the update frequency to twice daily, or hourly. Updating on that frequency is not necessary for the use case and there is concern for efficiency.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-datasphere-replication-flow-load-type-initial-and-delta-schedule/qaq-p/14286270"/>
    <published>2025-12-08T20:42:38.284000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-bdc-object-store-vs-data-lake/qaq-p/14286893</id>
    <title>SAP BDC Object Store vs Data Lake</title>
    <updated>2025-12-09T11:54:30.152000+01:00</updated>
    <author>
      <name>arijitdaspwc</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/841910</uri>
    </author>
    <content>&lt;P&gt;Hello Experts,&lt;/P&gt;&lt;P&gt;Just curious to know - While deciding on the SAP BDC architecture, when should we use Data Lake storage vs when should we use Object Store?&lt;/P&gt;&lt;P&gt;In the BDC Sizing tool, once we add a Datasphere system, we can see that 1TB of Data Lake Storage will require ~560 CU/month. While, same amount of Object Store requires only ~80 CU/month. Refer to the attached screenshots.&lt;/P&gt;&lt;P&gt;What is the difference between these 2 storage options and what additional benefit is offered by the Data Lake Storage?&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="BDC Object Store.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/350208i6E8E666570FD3854/image-size/large?v=v2&amp;amp;px=999" role="button" title="BDC Object Store.png" alt="BDC Object Store.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="BDC Data Lake.png" style="width: 637px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/350207i7FAC58B0DF694AC2/image-size/large?v=v2&amp;amp;px=999" role="button" title="BDC Data Lake.png" alt="BDC Data Lake.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Thanks&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-bdc-object-store-vs-data-lake/qaq-p/14286893"/>
    <published>2025-12-09T11:54:30.152000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-do-we-join-and-delta-data-through-the-datasphere-system-and-out-to-an/qaq-p/14291482</id>
    <title>How do we join and delta data through the datasphere system and out to an external system</title>
    <updated>2025-12-16T11:42:05.238000+01:00</updated>
    <author>
      <name>RichardW</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1467571</uri>
    </author>
    <content>&lt;P&gt;We want to be able to stage and join SAP S/4 data through datasphere and into an external system.&lt;/P&gt;&lt;P&gt;This would involve creating some kind of view (lets say joining PO Item and PO History), adding logic and business semantics, and then passing out to an external system.&amp;nbsp;&lt;/P&gt;&lt;P&gt;So far so good. But we only want to pass changes to the data. Not full loads.&amp;nbsp;&lt;/P&gt;&lt;P&gt;The 2 CDS views covering this data trigger deltas independently of each other so we cant send the view every time 1 CDS triggers as the other may not have triggered. So in my eyes, we need to persist the joined up view and then send out changes. How is this handled. In BW this would have been staged to a common table (DSO) and this would have detected changes to the joined up data and passed it out of the system&lt;/P&gt;&lt;P&gt;We seem to have gone backwards here !? there seems to be no delta mechanism???&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;thanks -&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-do-we-join-and-delta-data-through-the-datasphere-system-and-out-to-an/qaq-p/14291482"/>
    <published>2025-12-16T11:42:05.238000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-connect-datasphere-to-microsoft-fabric-onelake/qaq-p/14291914</id>
    <title>How to connect Datasphere to Microsoft Fabric/OneLake</title>
    <updated>2025-12-16T20:51:37.879000+01:00</updated>
    <author>
      <name>RTT</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1569307</uri>
    </author>
    <content>&lt;P&gt;How do you connect SAP Datasphere to Microsoft OneLake? I cannot find the redirect URI, or the OAuth Endpoint. Steps are unclear on how to connect both systems, specifically bringing data from Datasphere into OneLake.&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-connect-datasphere-to-microsoft-fabric-onelake/qaq-p/14291914"/>
    <published>2025-12-16T20:51:37.879000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-use-azure-data-lake-gen2-parquet-files-as-source-for-sap-datasphere/qaq-p/14293169</id>
    <title>How to use Azure Data Lake Gen2 .parquet files as source for SAP DataSphere Flows?</title>
    <updated>2025-12-18T10:48:33.890000+01:00</updated>
    <author>
      <name>KCMT</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1887399</uri>
    </author>
    <content>&lt;P&gt;Hi all,&lt;/P&gt;&lt;P&gt;I want to use an Azure Data Lake Gen2 storage account as a source in DataSphere. SAP is steering us to only using replication flows and leave data flows behind. It would be nice if Replication Flows would be a valid option everywhere then. Here's what i found:&lt;BR /&gt;Replication flows don't support .parquet files in an Azure Data Lake Gen2 storage account, however it can read .csv files though.&lt;BR /&gt;Data flows support .parquet files and .csv files in a&amp;nbsp;Azure Data Lake Gen2 storage account.&lt;BR /&gt;&lt;BR /&gt;So now we're left with the question: Should i use a Data Flow with .parquet files, as .parquet files are preferred on the data lake side,&amp;nbsp; or should i use .csv files in my data lake, as replication flows are preferred on the DataSphere side?&lt;BR /&gt;&lt;BR /&gt;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Datasphere/pd-p/73555000100800002141" class="lia-product-mention" data-product="16-1"&gt;SAP Datasphere&lt;/a&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-use-azure-data-lake-gen2-parquet-files-as-source-for-sap-datasphere/qaq-p/14293169"/>
    <published>2025-12-18T10:48:33.890000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/best-practice-for-incremental-loading-raw-data-for-non-sap-sources-in/qaq-p/14293232</id>
    <title>Best Practice for incremental loading Raw Data for Non SAP Sources in DataSphere without CDC?</title>
    <updated>2025-12-18T12:19:45.406000+01:00</updated>
    <author>
      <name>KCMT</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1887399</uri>
    </author>
    <content>&lt;P&gt;Hi all,&lt;/P&gt;&lt;P&gt;I'm working on a DataSphere implementation with 5 external non SAP ERP sources. For S4HANA Cloud the replication flows work very well. However, for the Non SAP sources most of them don't have CDC.&amp;nbsp;&lt;/P&gt;&lt;P&gt;What is the best practice for incremental loading non SAP raw data without CDC enabled? Would it be creating 2 data flows for every table, 1 for a full load and 1 for the incremental load?&lt;/P&gt;&lt;P&gt;Thanks in advance!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/best-practice-for-incremental-loading-raw-data-for-non-sap-sources-in/qaq-p/14293232"/>
    <published>2025-12-18T12:19:45.406000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/datasphare-text-doesnt-show-when-using-associated-dimension/qaq-p/14293537</id>
    <title>Datasphare: Text doesnt show  when using associated dimension</title>
    <updated>2025-12-18T16:24:37.920000+01:00</updated>
    <author>
      <name>ejke</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1781362</uri>
    </author>
    <content>&lt;P&gt;Dear colleagues,&lt;/P&gt;&lt;P&gt;I have a problem, I cant see text next to &lt;SPAN&gt;Associated Dimensions but when I add same dimension directly in my model everything works fine:&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="ejke_0-1766067758292.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/353667iD77D6B645D31F083/image-size/medium?v=v2&amp;amp;px=400" role="button" title="ejke_0-1766067758292.png" alt="ejke_0-1766067758292.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="ejke_1-1766067958282.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/353669i41798940477582E6/image-size/medium?v=v2&amp;amp;px=400" role="button" title="ejke_1-1766067958282.png" alt="ejke_1-1766067958282.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Setup of associated dimension that doesnt show text:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="ejke_2-1766068091970.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/353670i2240E5B53F8E40D6/image-size/medium?v=v2&amp;amp;px=400" role="button" title="ejke_2-1766068091970.png" alt="ejke_2-1766068091970.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Am I missing something or this is just DSP limitation currently so we can not see texts of associated dimensions?&lt;/P&gt;&lt;P&gt;Thank you in advance.&lt;/P&gt;&lt;P&gt;Kind regards,&lt;BR /&gt;Stefan&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/datasphare-text-doesnt-show-when-using-associated-dimension/qaq-p/14293537"/>
    <published>2025-12-18T16:24:37.920000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/data-lake-files-physical-storage-and-object-store-in-datasphere-amp-bdc/qaq-p/14298147</id>
    <title>Data Lake Files physical storage and Object Store in Datasphere &amp; BDC context</title>
    <updated>2025-12-27T17:52:56.191000+01:00</updated>
    <author>
      <name>aalbis</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/744935</uri>
    </author>
    <content>&lt;P&gt;Greetings SAP experts!&lt;/P&gt;&lt;P&gt;For some time I am trying to understand some concepts in regards to the &lt;U&gt;Object Store&lt;/U&gt; and &lt;U&gt;Data Lake Files physical storage&lt;/U&gt; in Datasphere &amp;amp; BDC context.&lt;/P&gt;&lt;P&gt;First I will start with naming the main service components of the SAP HANA Cloud that you can subscribe in SAP BTP:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;SAP HANA Cloud, SAP HANA database&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;SAP HANA Cloud, Data&lt;/STRONG&gt; &lt;STRONG&gt;Lake&amp;nbsp;&lt;/STRONG&gt;further formed from:&lt;UL&gt;&lt;LI&gt;Data Lake Files&lt;/LI&gt;&lt;LI&gt;Data Lake Relational Engine&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;A href="https://help.sap.com/docs/hana-cloud/sap-hana-cloud-getting-started-guide/sap-hana-cloud-components" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/hana-cloud/sap-hana-cloud-getting-started-guide/sap-hana-cloud-components&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Now let's start with&amp;nbsp;&lt;STRONG&gt;SAP Datasphere&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;When we have a&amp;nbsp;&lt;U&gt;Customer Managed&lt;/U&gt; Space:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;With Storage Type &lt;U&gt;SAP HANA Database (Disk and In-Memory)&lt;/U&gt; -&amp;gt; I believe physical storage will be in &lt;STRONG&gt;SAP HANA Cloud, SAP HANA database&lt;/STRONG&gt; on which the Datasphere tenant itself relies on.&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;When it comes to Storage Type &lt;U&gt;SAP HANA Data Lake Files&lt;/U&gt;:&lt;UL&gt;&lt;LI&gt;Where are the Data Lake Files behind the Local Table(file) physically stored?&lt;UL&gt;&lt;LI&gt;In the Object Store?&lt;UL&gt;&lt;LI&gt;If yes - What kind of Object Store is used?&lt;UL&gt;&lt;LI&gt;SAP Managed Object Store (File Container)?&lt;/LI&gt;&lt;LI&gt;External Object Store (Azure Blob Storage / Azure Data Lake, AWS S3 bucket,&amp;nbsp;&lt;SPAN class=""&gt;Google Cloud Storage&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;bucket)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;In the SAP HANA Cloud, Data Lake Files (service component) of the SAP HAHA Cloud underlying SAP Datasphere tenant?&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Further, in &lt;STRONG&gt;BDC&lt;/STRONG&gt; context.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Let's say we activated a Data Package from BDC Cockpit, &lt;SPAN&gt;APRS starts pushing data to target HANA Data Lake Files i.e. SAP BDC Foundational services (FOS) layer.&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Again, where are these Data Lake Files physically stored?&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-data-lake/welcome-guide/sap-hana-cloud-data-lake-terminology" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/hana-cloud-data-lake/welcome-guide/sap-hana-cloud-data-lake-terminology&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/object-store/object-store-service-on-sap-btp/what-is-object-store" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/object-store/object-store-service-on-sap-btp/what-is-object-store&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Really appreciate any input helping me to clarify these topics.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Kind regards!&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/data-lake-files-physical-storage-and-object-store-in-datasphere-amp-bdc/qaq-p/14298147"/>
    <published>2025-12-27T17:52:56.191000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/why-trading-firms-running-sap-on-prem-need-sap-business-data-cloud-now/qaq-p/14300233</id>
    <title>Why Trading Firms Running SAP On‑Prem Need SAP Business Data Cloud Now</title>
    <updated>2026-01-01T21:38:40.372000+01:00</updated>
    <author>
      <name>Shashank_Garg88</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2257155</uri>
    </author>
    <content>&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;P class=""&gt;SAP Business Data Cloud (BDC) offers trading organizations a governed, cloud‑based data fabric that unifies on‑premise SAP trading systems (S/4HANA, BW/BW‑PCE) with non‑SAP and OT data to build reusable data products for business consumption, analytics, and AI.[1][2][3][4][5]&lt;/P&gt;&lt;P class=""&gt;***&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;From siloed trading data to governed data products&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Most trading firms run core processes on SAP S/4HANA and BW while capturing key operational technology (OT) and market data in non‑SAP platforms, files, or data lakes.[2][3][6]&lt;/P&gt;&lt;P class=""&gt;Bringing these sources together usually means heavy ETL, point‑to‑point interfaces, and copies of price curves, positions, and risk metrics across BW cubes, SQL marts, and spreadsheets, raising both cost and risk.[2][7][8]&lt;/P&gt;&lt;P class=""&gt;BDC replaces this pattern with a business data fabric where SAP and non‑SAP data remain in place or in low‑cost cloud storage, but are exposed as governed “data products” with shared semantics and lineage.[1][4][8][9]&lt;/P&gt;&lt;P class=""&gt;For trading, this means structured products, positions, P&amp;amp;L, reference data, market curves, and even sensor/OT data can be modeled once and reused by risk, finance, compliance, and commercial teams.[3][4][5]&lt;/P&gt;&lt;P class=""&gt;***&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Business benefits for trading organizations&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;1.&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;End‑to‑end trading insight&lt;/STRONG&gt;&lt;BR /&gt;- BDC connects S/4HANA trading, BW positions, and non‑SAP feeds (exchanges, brokers, weather, IoT) into unified data products, providing a single, governed view of exposures, margins, and liquidity.[2][3][5]&lt;BR /&gt;- Federation and zero‑copy access avoid constant extraction of SAP data into external warehouses, so risk and P&amp;amp;L dashboards and predictive models stay closer to real time.[1][4][8]&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;P class=""&gt;2.&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Faster innovation with analytics and AI&lt;/STRONG&gt;&lt;BR /&gt;- Predefined SAP‑managed data products shorten the path from SAP trading data to analytics, while native integration with Databricks and other platforms lets quants and data scientists build models on governed data, not ad‑hoc exports.[3][4][10]&lt;BR /&gt;- Output from AI/ML models (e.g., price forecasts, risk factors, credit scores) can be shared back as BDC data products and consumed by SAP Analytics Cloud, Insight Apps, or custom apps without rebuilding pipelines.[3][4][1]&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;P class=""&gt;3.&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Better governance and compliance&lt;/STRONG&gt;&lt;BR /&gt;- A central catalog, ownership model, and lineage in BDC give auditors and regulators transparency into how key trading metrics (VaR, P&amp;amp;L, limits) are built and where they are used.[1][11][12]&lt;BR /&gt;- Consistent access control across SAP and non‑SAP domains reduces the proliferation of unmanaged extracts, helping with data protection and trade surveillance requirements.[1][5][8]&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;P class=""&gt;***&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;H2 id="d6be" id="toc-hId-1787615618"&gt;Cost benefits and TCO impact&lt;/H2&gt;&lt;P class=""&gt;For organizations already running S/4 and BW on‑premise, BDC primarily improves TCO through reduced integration, storage, and operations cost while opening room to decommission legacy tooling over time.[2][4][8][13]&lt;/P&gt;&lt;P class=""&gt;-&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Less ETL and data duplication&lt;/STRONG&gt;&lt;BR /&gt;- The fabric approach lets you virtualize SAP data and only persist what adds value (e.g., harmonized trading positions with third‑party data), cutting replication volumes and integration tool spend.[1][4][8][14]&lt;BR /&gt;- SAP cites substantial TCO savings versus DIY data fabrics because Datasphere/BDC bundles integration, modeling, and governance rather than forcing you to assemble and run multiple components yourself.[8][4][7]&lt;/P&gt;&lt;P class=""&gt;-&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Optimized use of existing SAP BW and S/4 investments&lt;/STRONG&gt;&lt;BR /&gt;- Reference architectures show how BW content can be translated into transformation flows and then exposed as BDC data products, allowing reuse instead of rebuild, and enabling gradual reduction of BW infrastructure.[2][3][15]&lt;BR /&gt;- Integration with SAP S/4HANA (including private cloud editions) is productized, so trading data can be transferred into BDC with less custom work than typical third‑party stacks.[16][1][5]&lt;/P&gt;&lt;P class=""&gt;-&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Hybrid rather than “big bang”&lt;/STRONG&gt;&lt;BR /&gt;- A hybrid data strategy lets you keep mission‑critical trading execution close to S/4HANA on‑premise while using BDC for analytics, reporting, and AI, limiting initial migration risk and smoothing spend over time.[17][6][18][13]&lt;BR /&gt;- Over the medium term, running analytics in BDC instead of parallel on‑premise warehouses and external BI stacks can shrink infrastructure and license footprints, reducing duplicated costs common in hybrid estates.[2][4][13]&lt;/P&gt;&lt;P class=""&gt;***&lt;/P&gt;&lt;H2 id="07c3" id="toc-hId-1591102113"&gt;Pros and cons of moving trading data to BDC&lt;/H2&gt;&lt;BLOCKQUOTE&gt;&lt;P class=""&gt;&lt;STRONG&gt;Pros&lt;/STRONG&gt;&lt;BR /&gt;- Unified SAP + non‑SAP trading view with shared business semantics.[2][1][5][4]&lt;BR /&gt;- Stronger data products for risk, treasury, and front‑office teams, increasing trust and reuse.[3][11][12]&lt;BR /&gt;- Cloud‑scale analytics and AI on governed data instead of extracts.[4][10][19]&lt;BR /&gt;- Strategic roadmap for BW customers beyond classic on‑premise warehousing.[1][2][15]&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Cons / risks&lt;/STRONG&gt;&lt;BR /&gt;- Potential license and platform overlap if BW, external warehouses, and BDC all run without a decommissioning plan.[7][15][13]&lt;BR /&gt;- Need for new skills around data products, cloud security, and governance operating models.[4][20][18]&lt;BR /&gt;- Stronger dependence on cloud and vendor roadmaps, which must be balanced with latency, sovereignty, and regulatory constraints in some trading jurisdictions.[6][17][21]&lt;/P&gt;&lt;/BLOCKQUOTE&gt;&lt;P class=""&gt;***&lt;/P&gt;&lt;P class=""&gt;#SAPBDC #BusinessDataCloud #SAP #S4HANA #SAPBW #TradingAnalytics #DataProducts #DataFabric #HybridCloud #SAPDatasphere #SAPAnalyticsCloud #FinancialMarkets #RiskManagement #DataStrategy #CloudMigration&lt;/P&gt;&lt;P class=""&gt;Citations:&lt;BR /&gt;[1] SAP Business Data Cloud &lt;A href="https://www.sap.com/products/data-cloud.html" target="_blank" rel="noopener noreferrer"&gt;https://www.sap.com/products/data-cloud.html&lt;/A&gt;&lt;BR /&gt;[2] Modernizing SAP BW with SAP Business Data Cloud &lt;A href="https://architecture.learning.sap.com/docs/ref-arch/f5b6b597a6/4" target="_blank" rel="noopener noreferrer"&gt;https://architecture.learning.sap.com/docs/ref-arch/f5b6b597a6/4&lt;/A&gt;&lt;BR /&gt;[3] Innovating SAP BW in SAP Business Data Cloud - SAP Learning &lt;A href="https://learning.sap.com/courses/modernizing-sap-bw-with-sap-business-data-cloud/innovating-sap-bw-in-sap-business-data-cloud" target="_blank" rel="noopener noreferrer"&gt;https://learning.sap.com/courses/modernizing-sap-bw-with-sap-business-data-cloud/innovating-sap-bw-in-sap-business-data-cloud&lt;/A&gt;&lt;BR /&gt;[4] Understanding the benefits and impact of SAP Business ... &lt;A href="https://www.consultancy.eu/news/11749/understanding-the-benefits-and-impact-of-sap-business-data-cloud" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.consultancy.eu/news/11749/understanding-the-benefits-and-impact-of-sap-business-data-cloud&lt;/A&gt;&lt;BR /&gt;[5] SAP Business Data Cloud - PwC &lt;A href="https://www.pwc.com/gx/en/services/alliances/sap/sap-business-data-cloud.html" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.pwc.com/gx/en/services/alliances/sap/sap-business-data-cloud.html&lt;/A&gt;&lt;BR /&gt;[6] What Is an Enterprise Data Fabric, and Why Is a Hybrid ... &lt;A href="https://www.abiresearch.com/blog/what-is-an-enterprise-data-fabric-and-why-is-a-hybrid-cloud-approach-vital" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.abiresearch.com/blog/what-is-an-enterprise-data-fabric-and-why-is-a-hybrid-cloud-approach-vital&lt;/A&gt;&lt;BR /&gt;[7] SAP BDC (Business Data Cloud): What you need to know &lt;A href="https://barc.com/sap-bdc-barc-perspective/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://barc.com/sap-bdc-barc-perspective/&lt;/A&gt;&lt;BR /&gt;[8] Investing in a Business Data Fabric Architecture: Strategic ... &lt;A href="https://www.sap.com/resources/investing-in-a-businesss-data-fabric-architecture-goals-and-roi" target="_blank" rel="noopener noreferrer"&gt;https://www.sap.com/resources/investing-in-a-businesss-data-fabric-architecture-goals-and-roi&lt;/A&gt;&lt;BR /&gt;[9] SAP Business Data Cloud | All for One Poland &lt;A href="https://www.all-for-one.pl/en/whitepapers/sap-business-data-cloud/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.all-for-one.pl/en/whitepapers/sap-business-data-cloud/&lt;/A&gt;&lt;BR /&gt;[10] SAP Business Data Cloud: State of the solution - Expertum &lt;A href="https://expertum.net/sap-business-data-cloud-state-of-the-solution/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://expertum.net/sap-business-data-cloud-state-of-the-solution/&lt;/A&gt;&lt;BR /&gt;[11] SAP Business Data Cloud - External FAQ | PDF - Scribd &lt;A href="https://www.scribd.com/document/847109270/SAP-Business-Data-Cloud-External-FAQ" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.scribd.com/document/847109270/SAP-Business-Data-Cloud-External-FAQ&lt;/A&gt;&lt;BR /&gt;[12] The top 10 questions about SAP Business Data Cloud - IBsolution &lt;A href="https://www.ibsolution.com/academy/blog_en/data-and-analytics/sap-business-data-cloud/the-top-10-questions-about-sap-business-data-cloud" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.ibsolution.com/academy/blog_en/data-and-analytics/sap-business-data-cloud/the-top-10-questions-about-sap-business-data-cloud&lt;/A&gt;&lt;BR /&gt;[13] SAP Cloud vs. On-Premise vs. Hybrid &lt;A href="https://leverx.com/newsroom/sap-cloud-vs-on-premise-vs-hybrid" target="_blank" rel="noopener nofollow noreferrer"&gt;https://leverx.com/newsroom/sap-cloud-vs-on-premise-vs-hybrid&lt;/A&gt;&lt;BR /&gt;[14] SAP Business Data Cloud vs Microsoft Fabric &lt;A href="https://arpideas.com/en/articles/microsoft-technologies/sap-business-data-cloud-vs-microsoft-fabric-data-platform-comparison" target="_blank" rel="noopener nofollow noreferrer"&gt;https://arpideas.com/en/articles/microsoft-technologies/sap-business-data-cloud-vs-microsoft-fabric-data-platform-comparison&lt;/A&gt;&lt;BR /&gt;[15] What exactly is SAP BW PCE… and what it is not ! - SAP Community &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/what-exactly-is-sap-bw-pce-and-what-it-is-not/ba-p/14127149" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/what-exactly-is-sap-bw-pce-and-what-it-is-not/ba-p/14127149&lt;/A&gt;&lt;BR /&gt;[16] Integration with SAP Business Data Cloud - SAP Help Portal &lt;A href="https://help.sap.com/docs/SAP_S4HANA_ON-PREMISE/f5d3e1005efd4e86acf9a65abf428082/b83121ecbc49454d80abcd36e55d6e60.html" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/SAP_S4HANA_ON-PREMISE/f5d3e1005efd4e86acf9a65abf428082/b83121ecbc49454d80abcd36e55d6e60.html&lt;/A&gt;&lt;BR /&gt;[17] SAP S/4HANA On-Premise vs. Cloud: Deployment Options Explained &lt;A href="https://leverx.com/newsroom/on-premise-vs-cloud" target="_blank" rel="noopener nofollow noreferrer"&gt;https://leverx.com/newsroom/on-premise-vs-cloud&lt;/A&gt;&lt;BR /&gt;[18] Guide to Digital Transformation with SAP Hybrid Cloud Strategy &lt;A href="https://www.mbis.com.tr/en/sap-hybrid-cloud-strategy-and-digital-transformation/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.mbis.com.tr/en/sap-hybrid-cloud-strategy-and-digital-transformation/&lt;/A&gt;&lt;BR /&gt;[19] Unlocking the power of data with SAP Business Data Cloud and ... &lt;A href="https://www.capgemini.com/insights/expert-perspectives/unlocking-the-power-of-data-with-sap-business-data-cloud-and-databricks/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.capgemini.com/insights/expert-perspectives/unlocking-the-power-of-data-with-sap-business-data-cloud-and-databricks/&lt;/A&gt;&lt;BR /&gt;[20] SAP Activate Methodology for SAP Business Data Cloud &lt;A href="https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-sap/sap-activate-methodology-for-sap-business-data-cloud-new-roadmap-release-in/ba-p/14190974" target="_blank"&gt;https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-sap/sap-activate-methodology-for-sap-business-data-cloud-new-roadmap-release-in/ba-p/14190974&lt;/A&gt;&lt;BR /&gt;[21] SAP S/4HANA On-premise vs Cloud &lt;A href="https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-members/sap-s-4hana-on-premise-vs-cloud/ba-p/13425743" target="_blank"&gt;https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-members/sap-s-4hana-on-premise-vs-cloud/ba-p/13425743&lt;/A&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/why-trading-firms-running-sap-on-prem-need-sap-business-data-cloud-now/qaq-p/14300233"/>
    <published>2026-01-01T21:38:40.372000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-know-a-subscriber-id-from-what-replication-flow/qaq-p/14303489</id>
    <title>how to know a subscriber id from what replication flow</title>
    <updated>2026-01-08T09:34:07.559000+01:00</updated>
    <author>
      <name>Supatchj23</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2174079</uri>
    </author>
    <content>&lt;P&gt;Dear expert,&lt;/P&gt;&lt;P&gt;i have 2 replication flow will retrieve data from 1 CDS ( for inbound and passthrough). When i see in&amp;nbsp;DHCDCMON , i see 2 subscriber id but i don't know which subscriber for which replication flow.&lt;/P&gt;&lt;P&gt;Please suggest me to verify in this case.&lt;/P&gt;&lt;P&gt;Thank you for your help.&lt;/P&gt;&lt;P&gt;Best Regards,&lt;/P&gt;&lt;P&gt;new technician to use RF&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-know-a-subscriber-id-from-what-replication-flow/qaq-p/14303489"/>
    <published>2026-01-08T09:34:07.559000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-connect-datashpere-to-succsessfactors/qaq-p/14304065</id>
    <title>How to Connect DataShpere to SuccsessFactors</title>
    <updated>2026-01-09T05:43:39.816000+01:00</updated>
    <author>
      <name>sanae377990</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/153855</uri>
    </author>
    <content>&lt;P&gt;&lt;A class="" href="https://community.sap.com/t5/forums/postpage/choose-node/true/product-id/73555000100800002141/board-id/website-questions#" target="_blank"&gt;&lt;IMG src="https://community.sap.com/skins/images/76B9B5E9018B56E25DB2EBE7CABBC0F2/responsive_peak/images/icon_toggle_open_list_tree.png" border="0" alt="SAP Enterprise Support Value Maps カテゴリを折りたたむにはクリックします" title="SAP Enterprise Support Value Maps カテゴリを折りたたむにはクリックします" /&gt;&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT&gt;&lt;FONT&gt;Datasphere の試用版を SuccessFactors に接続しようとしていますが、うまくいきません。&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT&gt;&lt;FONT&gt;SAP が提供するオフライン ツールを使用して SAML アサーションを生成できません。IAS などを介して接続する方法を知りたいです。&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-connect-datashpere-to-succsessfactors/qaq-p/14304065"/>
    <published>2026-01-09T05:43:39.816000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/questions-about-sap-websites/i-can-t-see-sap-data-engineer-data-fabric-c-bw4h-2404/qaq-p/14304642</id>
    <title>I can't see SAP Data Engineer - Data Fabric - C_BW4H_2404</title>
    <updated>2026-01-09T15:46:05.661000+01:00</updated>
    <author>
      <name>300221</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/745084</uri>
    </author>
    <content>&lt;P&gt;Hi,&lt;/P&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp;I can't see this SAP certificate&amp;nbsp;SAP Data Engineer - Data Fabric - C_BW4H_2404, but I only see those two in sap certification web.&amp;nbsp; can anybody know why?&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="300221_0-1767966153329.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/359886i8C301AB52918805E/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="300221_0-1767966153329.png" alt="300221_0-1767966153329.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/questions-about-sap-websites/i-can-t-see-sap-data-engineer-data-fabric-c-bw4h-2404/qaq-p/14304642"/>
    <published>2026-01-09T15:46:05.661000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/use-of-sap-fiori-for-posting-data-in-s-4-hana-with-sap-business-data-cloud/qaq-p/14305456</id>
    <title>Use of SAP FIORI for posting data in S/4 HANA with SAP Business Data Cloud</title>
    <updated>2026-01-12T07:20:15.364000+01:00</updated>
    <author>
      <name>RohanShah</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/169079</uri>
    </author>
    <content>&lt;P&gt;Hello Experts,&lt;/P&gt;&lt;P&gt;We like to create custom FIORI app that connects with SAP Business Data Cloud to see some data (For example open purchase order) and based on the data we want to create Posting in S/4HANA system (Like creating delivery).&lt;/P&gt;&lt;P&gt;Is it possible to use FIORI based on S/4HANA to connect with SAP Business Data Cloud to read data and then create posting in S/4HANA based on this data?&lt;/P&gt;&lt;P&gt;Regards,&lt;/P&gt;&lt;P&gt;Rohan Shah&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/use-of-sap-fiori-for-posting-data-in-s-4-hana-with-sap-business-data-cloud/qaq-p/14305456"/>
    <published>2026-01-12T07:20:15.364000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/nse-on-hana-cloud-instance-for-sap-datasphere/qaq-p/14305520</id>
    <title>NSE on HANA cloud instance for SAP Datasphere</title>
    <updated>2026-01-12T09:37:34.834000+01:00</updated>
    <author>
      <name>Sharathmg</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/174516</uri>
    </author>
    <content>&lt;P&gt;Hi Experts,&amp;nbsp;&lt;/P&gt;&lt;P&gt;We have implemented NSE on HANA Cloud instance. However, with increased use of Datasphere, we were hoping to implement the same on Datasphere. As datasphere has its own instance of Hana cloud, can we not impleement the same?&amp;nbsp;&lt;/P&gt;&lt;P&gt;If yes, how do we get access to this instance?&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/nse-on-hana-cloud-instance-for-sap-datasphere/qaq-p/14305520"/>
    <published>2026-01-12T09:37:34.834000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/retrieval-of-detailed-information-about-replication-flows-through-the-sap/qaq-p/14305834</id>
    <title>Retrieval of detailed information about Replication Flows through the SAP HANA Database Explorer</title>
    <updated>2026-01-12T15:51:20.552000+01:00</updated>
    <author>
      <name>tom345</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1856039</uri>
    </author>
    <content>&lt;DIV&gt;Hello,&lt;/DIV&gt;&lt;DIV&gt;I need to find a way to automate the collection of information related to the run of a specific replication flow that is in delta mode. By looking at the REPLICATION_FLOW_RUN_DETAILS table in the 'Details' column, for replication flows in Delta, the information is limited. For example, it does not provide the number of records involved in the operation, and I specifically need this information. This is so I can format this column, as it contains data in JSON format, and automate the process of collecting the replication flow run parameters. For replication flows not in delta, the details are complete, while for those in delta—thus in 'Retrying' status—the information is partial; I only have the target and source names. Is there a way to retrieve this information even for replication flows in delta?&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;Thanks&lt;/DIV&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/retrieval-of-detailed-information-about-replication-flows-through-the-sap/qaq-p/14305834"/>
    <published>2026-01-12T15:51:20.552000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-bdc-tdd-create-data-product-object-store-required/qaq-p/14306597</id>
    <title>SAP BDC TDD - Create Data Product - Object Store required?</title>
    <updated>2026-01-13T14:19:51.050000+01:00</updated>
    <author>
      <name>eric2357</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/856919</uri>
    </author>
    <content>&lt;P&gt;Hello Community,&lt;/P&gt;&lt;P&gt;we have the SAP BDC TDD tenant, and we would like to create Data Products with it.&lt;/P&gt;&lt;P&gt;I want to follow this Blog:&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555" target="_blank"&gt;https://community.sap.com/t5/data-and-analytics-blog-posts/sap-business-data-cloud-create-a-custom-data-product-based-on-a-replication/ba-p/14238555&lt;/A&gt;&lt;/P&gt;&lt;P&gt;But for the creation of a data product, you need a SAP HANA Data Lake Files Space in Datasphere. For that, I assume I need to adjust the "Tenant Configuration" under "Systems". The minimal amount for the Object Store to run is 384 GB Storage, 128 GB Memory and in the Object Store itself it&amp;nbsp; is 1 TB storage, 1 Block-Hours, 1000 API Calls. This requires 4150 Datasphere CUs instead of 1578 CUs at the moment.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Is that correct, is the minimum amount of Datasphere CUs 4150 (divided by 2.5, it translates to 1660 BDC CUs) if you want to create Data Products within SAP BDC? Or is there another way, at least for the TDD version?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;If I adjust Tenant Configuration, I get this message at the bottom (see screenshot):&lt;/P&gt;&lt;P&gt;"Estimated Consumption&lt;/P&gt;&lt;P&gt;5.685 CU&lt;/P&gt;&lt;P&gt;per hour (4,150.05 CU per month)&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The sizes you’ve chosen consume&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;271%&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;of your subscribed capacity units."&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;And this one (see screenshot):&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;"Over Usage Alert&lt;/SPAN&gt;&lt;SPAN&gt;The configuration you selected is over your capacity unit limit, but you can try this configuration."&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;What happens if I try to click on "Save" in this scenario? I am aware that some adjustments cannot be changed back again, thats why I dont want to experiment with that.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Thank you in advance! Let me know if you have any questions!&lt;/P&gt;&lt;P&gt;Kind regards,&lt;/P&gt;&lt;P&gt;Eric&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-bdc-tdd-create-data-product-object-store-required/qaq-p/14306597"/>
    <published>2026-01-13T14:19:51.050000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-datasphere-monitoring-in-clouldalm/qaq-p/14307046</id>
    <title>SAP Datasphere Monitoring in CLouldALM</title>
    <updated>2026-01-14T07:50:13.188000+01:00</updated>
    <author>
      <name>SAPSupport</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/121003</uri>
    </author>
    <content>&lt;P&gt;&amp;nbsp;I am trying to set up SAP Datasphere monitoring in Cloud ALM, which includes the backend HANA database. I was able to add SAP Datasphere systems to Cloud ALM, however when I try to retrieve the backend HANA DB details, I don't get the setup details in cloud ALM.&amp;nbsp;&lt;/P&gt;&lt;P&gt;from this link&amp;nbsp;&lt;A href="https://support.sap.com/en/alm/sap-cloud-alm/operations/expert-portal/setup-managed-services/calm-setup-datasphere.html" target="_blank" rel="noopener noreferrer"&gt;https://support.sap.com/en/alm/sap-cloud-alm/operations/expert-portal/setup-managed-services/calm-setup-datasphere.html&lt;/A&gt;&amp;nbsp;i am able to open the SAP-Managed connectivity to use opentelementry based data to report monitoring data to SAP Cloud ALM.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Could you please advise if this is possible to monitor the backend HANA DB information into Cloud ALM for the respective SAP Datasphere services/instances?&amp;nbsp;&lt;/P&gt;&lt;BR /&gt;------------------------------------------------------------------------------------------------------------------------------------------------&lt;BR /&gt;&lt;B&gt;Learn more about the SAP Support user and program &lt;A target="_blank" href="https://community.sap.com/t5/enterprise-resource-planning-blogs-by-sap/maximizing-the-power-of-sap-community-at-product-support/ba-p/13501276"&gt;here&lt;/A&gt;.&lt;/B&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-datasphere-monitoring-in-clouldalm/qaq-p/14307046"/>
    <published>2026-01-14T07:50:13.188000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/dynamically-pivot-table/qaq-p/14308069</id>
    <title>Dynamically pivot Table</title>
    <updated>2026-01-15T14:18:14.951000+01:00</updated>
    <author>
      <name>NicolasRivas1991</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1976185</uri>
    </author>
    <content>&lt;P&gt;Hello,&lt;BR /&gt;&lt;BR /&gt;We need to dynamically pivot table. We have a table with an equipment and its type and each equipment type has certain characteristics names and values. We need to dynamically pivot this table so each characteristic name is a column with its own value for each equipment. I read a lot of the community and with gemini but I cant find anything dynamic.&lt;BR /&gt;&lt;BR /&gt;Here is an example&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="NicolasRivas1991_0-1768482816778.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/361664i9B15BA355986E1F7/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="NicolasRivas1991_0-1768482816778.png" alt="NicolasRivas1991_0-1768482816778.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This is a migration from QlikView to SAP Analytics cloud, where, in QlikView, we had a table that, when en equipment type was selected, ceratain columns where selected. We need to replicate that in SAP analytics Cloud.&lt;BR /&gt;&lt;BR /&gt;Thank you.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/dynamically-pivot-table/qaq-p/14308069"/>
    <published>2026-01-15T14:18:14.951000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/utctolocal-function-in-datasphere-based-on-plant-timezone/qaq-p/14308151</id>
    <title>UTCTOLOCAL Function in Datasphere based on Plant TimeZone</title>
    <updated>2026-01-15T16:11:33.786000+01:00</updated>
    <author>
      <name>deepika_yadav24</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2274777</uri>
    </author>
    <content>&lt;P&gt;We had the requirement from Business to convert the Date based on Plant's Mapped Local TimeZone. TimeZone is dynamic and picked up from TTZ5/TTZ5S table. Challenge was all the TimeZone mentioned in SAP table for plants wasn't working with UTCTOLOCAL function.&amp;nbsp;&lt;/P&gt;&lt;P&gt;This article provides instructions for installing and configuring timezone table in SAP Datasphere, including installing timezone tables (TTZD, TTZDF, TTZDV, TTZR, TTZZ) using Database Explorer and exporting them as per SNOTE 198411 and 1791342 with the export file HANATimezoneTables&lt;EM&gt;2023&lt;/EM&gt;V02.tar.gz . It details modifying the SAP Datasphere Cloud ini configuration to set the default timezone schema and dataset, requiring SAP assistance due to Datasphere being hosted on public cloud, and checking timezone data in the sys.TIMEZONES view . The UTCTOLOCAL function is used to convert UTC to local timezones, and timezone mappings for specific plants can be retrieved from SAP standard tables TTZ5 or TTZ5S.&lt;/P&gt;&lt;P&gt;1. Using DataBase Explorer in Sap DataSphere install the TimeZone Table in Schema.&lt;BR /&gt;TTZD, TTZDF, TTZDV, TTZR, TTZZ&lt;/P&gt;&lt;P&gt;Refer the SNOTE 198411 and 1791342 for TimeZone Table export.&lt;/P&gt;&lt;P&gt;2. Check the Table in source once exported:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="deepika_yadav24_0-1768489539855.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/361702iF152016EF9894000/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="deepika_yadav24_0-1768489539855.png" alt="deepika_yadav24_0-1768489539855.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;3.Change the parameter setting in ini configuration file. This would require SAP help as Datasphere is hosted on Public cloud.&lt;/P&gt;&lt;P&gt;a. Modify the default schema (&lt;STRONG&gt;mandatory &lt;/STRONG&gt;in HANA Cloud, because SYSTEM schema cannot be used)&lt;/P&gt;&lt;P&gt;ALTER SYSTEM ALTER CONFIGURATION ('indexserver.ini', 'SYSTEM') SET ('global', 'timezone_default_data_schema_name') = 'SpaceNAME#SchemaName'&amp;nbsp; WITH RECONFIGURE;&lt;/P&gt;&lt;P&gt;b. Set 'sap' dataset to default (optional)&lt;/P&gt;&lt;P&gt;ALTER SYSTEM ALTER CONFIGURATION ('indexserver.ini', 'SYSTEM') SET ('global', 'timezone_dataset') = 'sap' WITH RECONFIGURE;&lt;/P&gt;&lt;P&gt;4.&amp;nbsp;Check the data in sys.TimeZones View sap entries for TimeZone would have been populated. Plateform TimeZone entries by default available in the view. Post import of TimeZone Table sap TimeZone would reflect in TimeZones View.&lt;/P&gt;&lt;P&gt;Select * from sys. TIMEZONES;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="deepika_yadav24_1-1768489708407.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/361703i0DB14F497CE6A46F/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="deepika_yadav24_1-1768489708407.png" alt="deepika_yadav24_1-1768489708407.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;5.Use the UTCTOLOCAL function to convert TimeZone to local Timezone.&lt;/P&gt;&lt;P&gt;We can get the TimeZone mapped to specific plants from Sap standard tables TTZ5 or TTZ5S&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="deepika_yadav24_2-1768489863813.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/361704i0293B35CADECB3D7/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="deepika_yadav24_2-1768489863813.png" alt="deepika_yadav24_2-1768489863813.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Hope This helps !!&lt;BR /&gt;Happy Learning&amp;nbsp; &lt;span class="lia-unicode-emoji" title=":slightly_smiling_face:"&gt;🙂&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/utctolocal-function-in-datasphere-based-on-plant-timezone/qaq-p/14308151"/>
    <published>2026-01-15T16:11:33.786000+01:00</published>
  </entry>
</feed>
