<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/SAP-Datasphere-qa.xml</id>
  <title>SAP Community - SAP Datasphere</title>
  <updated>2025-07-28T23:12:32.299646+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/SAP Datasphere/pd-p/73555000100800002141" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>SAP Datasphere Q&amp;A in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/all-data-from-cds-view-not-replicated-to-datasphere/qaq-p/14150708</id>
    <title>All data from cds view not replicated to datasphere</title>
    <updated>2025-07-11T21:04:01.749000+02:00</updated>
    <author>
      <name>rmuhuri</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/241327</uri>
    </author>
    <content>&lt;P&gt;Hi&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;I have a cds view made of vbrp and vbrk and&amp;nbsp;prcd_elements joined with the delta extraction annotations. The cds count is 5136 but when I do a replication via replication flow&amp;nbsp; to SAP Datasphere : it shows&amp;nbsp;&lt;SPAN class=""&gt;Initial Load Operations : 5136 but when I see in the data preview its only&amp;nbsp;&lt;SPAN&gt;3715&lt;/SPAN&gt;&amp;nbsp;records.&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="rmuhuri_0-1752260243202.png" style="width: 821px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285647i0E857F7A1D4E214F/image-dimensions/821x78?v=v2" width="821" height="78" role="button" title="rmuhuri_0-1752260243202.png" alt="rmuhuri_0-1752260243202.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;but in datasphere it only shows 1 record , for example the MAC shows only 0 and not the 80.22&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="rmuhuri_1-1752260367714.png" style="width: 844px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285648i1E125DEAD45A62F1/image-dimensions/844x38?v=v2" width="844" height="38" role="button" title="rmuhuri_1-1752260367714.png" alt="rmuhuri_1-1752260367714.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Whats going wrong ? I have attached the cds code in the attachments.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/all-data-from-cds-view-not-replicated-to-datasphere/qaq-p/14150708"/>
    <published>2025-07-11T21:04:01.749000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/packages-for-migrate-between-spaces/qaq-p/14151515</id>
    <title>Packages for migrate between spaces</title>
    <updated>2025-07-14T09:52:30.985000+02:00</updated>
    <author>
      <name>Marc-82</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1659975</uri>
    </author>
    <content>&lt;P&gt;Hello,&lt;/P&gt;&lt;P&gt;We have a problem with packages in DataSphere.&lt;/P&gt;&lt;P&gt;We want migrate tables, views, etc between spaces.&lt;/P&gt;&lt;P&gt;We have created a package in one space which contain folders, view, tables etc and export works fine.&lt;/P&gt;&lt;P&gt;But when we try import the package, use overwrite preferences: don"t overwrite objects or data it doesn"t work because detect the same object in the space and not ignore the object: Error example " The object name(s) ["XX"] cannot be created because object(s) with same name(s) exist".&lt;/P&gt;&lt;P&gt;If we use the overwrite objects and data it doesn"t work too.&lt;/P&gt;&lt;P&gt;Could you help us please?&lt;/P&gt;&lt;P&gt;Thank you and regards,&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/packages-for-migrate-between-spaces/qaq-p/14151515"/>
    <published>2025-07-14T09:52:30.985000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/datasphere-install-sap-sample-data-error/qaq-p/14152008</id>
    <title>Datasphere - Install SAP Sample Data error</title>
    <updated>2025-07-14T15:55:21.377000+02:00</updated>
    <author>
      <name>eric2357</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/856919</uri>
    </author>
    <content>&lt;P&gt;Hi community,&lt;/P&gt;&lt;P data-unlink="true"&gt;I would like to install SAP Sample Data in Datasphere, like "&lt;SPAN&gt;Finance Sample Data for SAP Data Warehouse Cloud" or "Sales Sample Data for SAP Data Warehouse Cloud". When I click on Error using this &lt;A href="https://fujitsu-4.eu20.hcs.cloud.sap/dwaas-core/index.html#/catalogmpdataproducts&amp;amp;/odc/dataProduct/86b8d8b2-21c9-4ee6-ae30-717a86e5ec84" target="_self" rel="nofollow noopener noreferrer"&gt;Link&lt;/A&gt;,&amp;nbsp; I get the message "You are currently not a member of any space and cannot install this data product. Please contact your system or space administrator." (see screenshot "No_Member).&lt;/SPAN&gt;&lt;/P&gt;&lt;P data-unlink="true"&gt;&lt;SPAN&gt;But I have the Scoped_Data_Warehouse_Cloud_Space_Administrator Role for that Space (see screenshot "Space_Admin").&lt;/SPAN&gt;&lt;/P&gt;&lt;P data-unlink="true"&gt;&lt;SPAN&gt;Why can't I install this sample data?&lt;/SPAN&gt;&lt;/P&gt;&lt;P data-unlink="true"&gt;&lt;SPAN&gt;Kind regards,&lt;/SPAN&gt;&lt;/P&gt;&lt;P data-unlink="true"&gt;&lt;SPAN&gt;Eric&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/datasphere-install-sap-sample-data-error/qaq-p/14152008"/>
    <published>2025-07-14T15:55:21.377000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/optimizing-sap-datasphere-lifecycle-management-with-sap-cloud-alm/qaq-p/14153163</id>
    <title>Optimizing SAP Datasphere Lifecycle Management with SAP Cloud ALM</title>
    <updated>2025-07-15T17:21:07.015000+02:00</updated>
    <author>
      <name>WillianHeissler</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/3875</uri>
    </author>
    <content>&lt;P&gt;In today's data-driven world, organizations rely on robust solutions like &lt;STRONG&gt;SAP Datasphere&lt;/STRONG&gt; to connect, manage, and share trusted data across landscapes. However, to ensure successful implementation, seamless operation, and long-term scalability, governance and lifecycle management are critical. That’s where &lt;STRONG&gt;SAP Cloud ALM&lt;/STRONG&gt; steps in.&lt;/P&gt;&lt;P&gt;SAP Cloud ALM provides a unified platform to manage the entire lifecycle of cloud-based solutions, including SAP Datasphere. By leveraging key capabilities such as &lt;STRONG&gt;Task Management&lt;/STRONG&gt;, &lt;STRONG&gt;Change and Deployment Management&lt;/STRONG&gt;, &lt;STRONG&gt;Health Monitoring&lt;/STRONG&gt;, and &lt;STRONG&gt;Configuration &amp;amp; Security Analysis&lt;/STRONG&gt;, businesses can streamline their data projects and enhance operational excellence.&lt;/P&gt;&lt;H3 id="toc-hId-1864146145"&gt;1. Task Management: Aligning Teams and Priorities&lt;/H3&gt;&lt;P&gt;Implementing or expanding SAP Datasphere often involves multiple stakeholders across business and IT. SAP Cloud ALM’s &lt;A href="https://me.sap.com/roadmapviewer/group/658F507A-D6F5-4B78-9EE1-0300C5F1E40F/roadmapoverviewpage/e1fe45d654ef42e2aed42c8d13aca4d5" target="_self" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Task Management&lt;/STRONG&gt;&lt;/A&gt; feature ensures that every activity—whether it’s configuring data models, establishing pipelines, or integrating with source systems—is clearly defined, assigned, and tracked.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Project templates&lt;/STRONG&gt; help structure efforts for quick onboarding.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Role-based task assignments&lt;/STRONG&gt; ensure accountability.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Progress tracking&lt;/STRONG&gt; gives real-time visibility into implementation and operations.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;With these tools, teams stay aligned and avoid bottlenecks, keeping your Datasphere initiatives on schedule and on scope.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1667632640"&gt;2. Change and Deployment Management: Controlled Innovation&lt;/H3&gt;&lt;P&gt;SAP Datasphere evolves rapidly, and with it, so do your business requirements. SAP Cloud ALM enables controlled and transparent change processes through its &lt;STRONG&gt;Change and Deployment Management&lt;/STRONG&gt; capabilities.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Safely manage configuration and transport changes.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Align changes across environments with dependency checks.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Maintain traceability from change request to deployment.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This ensures that updates to your data models, transformations, or integrations are introduced with minimal risk and maximum governance.&lt;/P&gt;&lt;H3 id="toc-hId-1471119135"&gt;3. Health Monitoring: Real-Time Operational Insights&lt;/H3&gt;&lt;P&gt;Once your SAP Datasphere environment is live, &lt;A href="https://support.sap.com/en/alm/sap-cloud-alm/operations/expert-portal/health-monitoring.html" target="_self" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Health Monitoring&lt;/STRONG&gt;&lt;/A&gt; in SAP Cloud ALM helps you maintain high availability and performance.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Dashboards&lt;/STRONG&gt; provide real-time status of connected systems and components.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Alerts&lt;/STRONG&gt; notify teams about anomalies or performance degradation.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Historical data&lt;/STRONG&gt; helps in trend analysis and capacity planning.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This proactive monitoring approach reduces downtime, supports SLAs, and ensures your business users always have access to reliable data services.&lt;/P&gt;&lt;H3 id="toc-hId-1274605630"&gt;4. Configuration &amp;amp; Security Analysis: Governance You Can Trust&lt;/H3&gt;&lt;P&gt;Data security and compliance are non-negotiable, especially when dealing with sensitive or cross-border information. SAP Cloud ALM’s &lt;A href="https://support.sap.com/en/alm/sap-cloud-alm/operations/expert-portal/configuration-security-analysis.html" target="_self" rel="noopener noreferrer"&gt;&lt;STRONG&gt;Configuration and Security Analysis&lt;/STRONG&gt;&lt;/A&gt; tools empower your team to identify misconfigurations, enforce best practices, and close security gaps.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Analyze system settings for compliance with SAP recommendations.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Detect and remediate unauthorized changes.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Strengthen system hardening and data protection policies.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This is essential to meet internal governance policies and regulatory requirements, especially in data-centric platforms like SAP Datasphere.&lt;/P&gt;&lt;P&gt;More details &lt;A href="https://support.sap.com/en/alm/sap-cloud-alm/operations/expert-portal/configuration-security-analysis/csa-content.html?anchorId=section_1129804589" target="_self" rel="noopener noreferrer"&gt;HERE&lt;/A&gt;.&lt;/P&gt;&lt;H3 id="toc-hId-1078092125"&gt;Conclusion&lt;/H3&gt;&lt;P&gt;By integrating &lt;STRONG&gt;SAP Cloud ALM&lt;/STRONG&gt; with &lt;STRONG&gt;SAP Datasphere&lt;/STRONG&gt;, organizations gain more than just visibility, they gain control. From guiding implementation to ensuring secure and reliable operations, Cloud ALM acts as the backbone of sustainable data management in the cloud.&lt;/P&gt;&lt;P&gt;If you're looking to maximize the value of your data landscape, it's time to embrace SAP Cloud ALM, not just as a monitoring tool, but as a strategic enabler of trust, agility, and excellence in your Datasphere journey.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/optimizing-sap-datasphere-lifecycle-management-with-sap-cloud-alm/qaq-p/14153163"/>
    <published>2025-07-15T17:21:07.015000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-use-cds-view-annotation-in-the-datasphere/qaq-p/14153713</id>
    <title>How to use cds view annotation in the datasphere</title>
    <updated>2025-07-16T10:47:51.663000+02:00</updated>
    <author>
      <name>Lora_0121</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1993156</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;Hello. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;I made a cds view as follows and then replicated it in the datasphere.&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZBWTESTCDS02'
@EndUser​Text.label: 'Data Extraction for Actual Material Cost'
@AbapCatalog.preserveKey: true
@AccessControl.authorizationCheck: #NOT_REQUIRED

@Analytics: {
    dataCategory: #FACT,
    dataExtraction: {
        enabled: true,
        delta.changeDataCapture.automatic:true
    }
 }

define view ZBW_TEST_CDS02
as select from afpo a
inner join aufk b
   on a.aufnr = b.aufnr
  and a.mandt = b.mandt
inner join afko c
   on a.aufnr = c.aufnr
  and a.mandt = c.mandt
inner join aufm d
   on a.aufnr = d.aufnr
  and a.mandt = d.mandt
{
   key a.aufnr                                                as OrderID, 
   key b.werks                                                as Plant,
   key b.kokrs                                                as ControllingArea ,
   key d.matnr                                                as InputProduct,
   key d.budat                                                as PostingDate,
   d.mjahr                                                    as FiscalYear,
   b.auart                                                    as OrderType, 
   b.objnr                                                    as ObjectInternalID, 
   b.prctr                                                    as ProfitCenter ,
   a.matnr                                                    as Product,
   @Semantics.unitOfMeasure: true
   c.gmein                                                    as BaseUnit,
   d.meins                                                    as InputUnit,
   @Semantics.quantity.unitOfMeasure: 'BaseUnit'
   @DefaultAggregation: #SUM
   c.gamng                                                    as OrderPlannedTotalQty,
   @Semantics.quantity.unitOfMeasure: 'BaseUnit'
   @DefaultAggregation: #SUM
   c.igmng                                                    as OrderConfirmedYieldQty,
   cast(a.amein as productionunit preserving type)            as ProductionUnit,
   @Semantics.quantity.unitOfMeasure: 'ProductionUnit'
   @Aggregation.default: #SUM
   a.wemng                                                    as MfgOrderItemGoodsReceiptQty, 
   d.waers                                                    as TransactionCurrency,
   @Semantics.quantity.unitOfMeasure: 'InputUnit'
   sum(case when ( d.bwart = '261' or d.bwart = 'Z61' ) then d.menge when ( d.bwart = '262' or d.bwart = 'Z62' ) then -1 * d.menge else 0  end) as qty,
   @Semantics.amount.currencyCode : 'TransactionCurrency'
   sum(case when ( d.bwart = '261' or d.bwart = 'Z61' ) then d.dmbtr when ( d.bwart = '262' or d.bwart = 'Z62' ) then -1 * d.dmbtr else 0  end) as amt

}
-- skip -- 
where ~~ 
group by ~~ 
&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;BR /&gt;&lt;SPAN&gt;&lt;STRONG&gt;@Semantics.Annotation&lt;/STRONG&gt; specified in cds view is not recognized in datasphere.&lt;BR /&gt;Only the business name is replicated as it is. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The local table is designated as a relational dataset,&amp;nbsp; and the semantic type is None.&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Can't the annotation specified in csd view be used in the datasphere?&lt;BR /&gt;Is there a way to use the annotation specified in cds&amp;nbsp;view in the datasphere?&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;I want the following results.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="q.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/287177iED8927720BE11314/image-size/large?v=v2&amp;amp;px=999" role="button" title="q.png" alt="q.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Thank you.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-use-cds-view-annotation-in-the-datasphere/qaq-p/14153713"/>
    <published>2025-07-16T10:47:51.663000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/issue-with-quot-hierarchy-with-directory-quot-data-access-control-in-sap/qaq-p/14153797</id>
    <title>Issue with "Hierarchy with Directory" Data Access Control in SAP Datasphere (Permission Error)</title>
    <updated>2025-07-16T11:34:11.661000+02:00</updated>
    <author>
      <name>Prakash2</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/169567</uri>
    </author>
    <content>&lt;P&gt;Hello,&lt;/P&gt;&lt;P&gt;I am trying to implement &lt;STRONG&gt;"Hierarchy with Directory"&lt;/STRONG&gt; based &lt;STRONG&gt;Data Access Control (DAC)&lt;/STRONG&gt; in &lt;STRONG&gt;SAP Datasphere&lt;/STRONG&gt; on a cost center hierarchy. However, I am facing an &lt;STRONG&gt;insufficient privilege error&lt;/STRONG&gt; when trying to access a view with the DAC enabled.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;DAC Permission Table&lt;/STRONG&gt;:&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Prakash2_0-1752653965266.png" style="width: 552px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/287167i057B43B79C473991/image-dimensions/552x40?v=v2" width="552" height="40" role="button" title="Prakash2_0-1752653965266.png" alt="Prakash2_0-1752653965266.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;&lt;STRONG&gt;Error Message&lt;/STRONG&gt;:&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Prakash2_1-1752653990498.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/287168i88C99904A1D2E2A5/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Prakash2_1-1752653990498.png" alt="Prakash2_1-1752653990498.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Cost Center Hierarchy Table&lt;/STRONG&gt;:&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Prakash2_5-1752654064178.png" style="width: 625px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/287172i2C018AEF4B11DD8A/image-dimensions/625x100?v=v2" width="625" height="100" role="button" title="Prakash2_5-1752654064178.png" alt="Prakash2_5-1752654064178.png" /&gt;&lt;/span&gt;&lt;H4 id="toc-hId-1993234727"&gt;My Questions:&lt;/H4&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;What exactly triggers the error: Could not obtain all relevant structured filters?&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Is this error usually related to &lt;STRONG&gt;DAC setup&lt;/STRONG&gt;, &lt;STRONG&gt;view definition&lt;/STRONG&gt;, or &lt;STRONG&gt;user authorization&lt;/STRONG&gt;?&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Are there any known limitations or common mistakes when using &lt;STRONG&gt;Hierarchy with Directory DAC&lt;/STRONG&gt; in SAP Datasphere?&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;What are the correct steps to &lt;STRONG&gt;debug&lt;/STRONG&gt; and &lt;STRONG&gt;resolve&lt;/STRONG&gt; this issue?&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Any help, suggestions, or examples from your experience would be greatly appreciated!&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/LI&gt;&lt;/OL&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/issue-with-quot-hierarchy-with-directory-quot-data-access-control-in-sap/qaq-p/14153797"/>
    <published>2025-07-16T11:34:11.661000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/feature-engineering-in-sap-btp-sap-hana-cloud-in-built-ml-vs-sap-datasphere/qaq-p/14154172</id>
    <title>Feature Engineering in SAP BTP: SAP HANA Cloud In-built ML vs. SAP Datasphere</title>
    <updated>2025-07-16T17:19:20.369000+02:00</updated>
    <author>
      <name>pramod_kumar151</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/814291</uri>
    </author>
    <content>&lt;P&gt;Hello Team,&lt;/P&gt;&lt;P&gt;We are implementing a new predictive use case on SAP BTP. We've established our data ingestion strategy, where raw data from various enterprise sources (both SAP and non-SAP) is successfully ingested into SAP HANA Cloud via SAP Integration Suite.&lt;/P&gt;&lt;P&gt;Now, our primary focus is on the feature engineering phase for this data, which resides entirely within SAP HANA Cloud. We need to perform various transformations, including:&lt;/P&gt;&lt;P&gt;Calculating derived metrics (e.g., DaysSinceLastActivity, InteractionCount).&lt;/P&gt;&lt;P&gt;Aggregating historical data.&lt;/P&gt;&lt;P&gt;Leveraging capabilities for automated feature engineering.&lt;/P&gt;&lt;P&gt;Preparing the engineered features in a structured, consumable format for machine learning model training and inference.&lt;/P&gt;&lt;P&gt;Ensuring scalability, performance, governance, and reusability of these features.&lt;/P&gt;&lt;P&gt;We are specifically evaluating the best approach for this feature engineering. We see two primary paths within the SAP BTP landscape for data already in HANA Cloud:&lt;/P&gt;&lt;P&gt;Leveraging SAP HANA Cloud's In-built Machine Learning Capabilities: Utilizing its SQL/SQLScript, Predictive Analysis Library (PAL), Automated Predictive Library (APL), AutoML features, and Python Machine Learning Client directly within HANA Cloud.&lt;/P&gt;&lt;P&gt;Utilizing SAP Datasphere: Building and managing the feature engineering pipelines and feature store within Datasphere, which leverages HANA Cloud as its underlying engine.&lt;/P&gt;&lt;P&gt;Based on your experience with similar predictive projects on SAP BTP, we'd greatly appreciate your insights on the following:&lt;/P&gt;&lt;P&gt;For feature engineering on data already residing in SAP HANA Cloud, what are the key advantages and disadvantages of:&lt;/P&gt;&lt;P&gt;Relying primarily on SAP HANA Cloud's native ML and data manipulation capabilities?&lt;/P&gt;&lt;P&gt;Integrating SAP Datasphere into the architecture for feature engineering?&lt;/P&gt;&lt;P&gt;In which scenarios would you strongly recommend one approach over the other for a project like ours?&lt;/P&gt;&lt;P&gt;Are there specific types of feature engineering tasks (e.g., complex aggregations, specific derived metrics, automated feature generation) where one service truly excels when the data source is HANA Cloud?&lt;/P&gt;&lt;P&gt;Any architectural patterns, best practices, or practical experiences (including considerations for MLOps, governance, and long-term maintainability) would be highly valuable.&lt;/P&gt;&lt;P&gt;Thank you in advance for your contributions!&lt;/P&gt;&lt;P&gt;#SAPHANACloud, #SAPDatasphere, #MachineLearning, #FeatureEngineering&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/feature-engineering-in-sap-btp-sap-hana-cloud-in-built-ml-vs-sap-datasphere/qaq-p/14154172"/>
    <published>2025-07-16T17:19:20.369000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-integrate-sap-datasphere-to-sap-cpq-and-extract-data-from-datasphere/qaq-p/14154321</id>
    <title>how to integrate SAP Datasphere to SAP CPQ and extract data from Datasphere to SAP CPQ</title>
    <updated>2025-07-16T19:57:58.242000+02:00</updated>
    <author>
      <name>kr_pavankumar</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/182847</uri>
    </author>
    <content>&lt;P&gt;Hello &lt;STRONG&gt;Experts&lt;/STRONG&gt;,&lt;/P&gt;&lt;P&gt;Is it possible to integrate or direct connection between SAP Datasphere and SAP CPQ (without any middleware - BTP, DI or any ETL).&amp;nbsp;&lt;/P&gt;&lt;P&gt;Need is to send the data from SAP Datasphere Models to downstream system - SAP CPQ (Custom Tables). and data load frequency is real-time or at least 2 hours once.&amp;nbsp;&lt;BR /&gt;&lt;BR /&gt;Please provide some inputs on integration/connections and method/approach to send data from SAP Datasphere to SAP CPQ. Thanks!&lt;/P&gt;&lt;P&gt;--&lt;/P&gt;&lt;P&gt;KRPK&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-integrate-sap-datasphere-to-sap-cpq-and-extract-data-from-datasphere/qaq-p/14154321"/>
    <published>2025-07-16T19:57:58.242000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-q-a/table-change-not-possible-there-is-a-db-trigger-on-the-table/qaq-p/14154960</id>
    <title>Table change not possible. There is a db trigger on the table</title>
    <updated>2025-07-17T11:01:03.997000+02:00</updated>
    <author>
      <name>Prajwal_N1</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1399883</uri>
    </author>
    <content>&lt;P&gt;"Table change not possible. There is a DB trigger on the table." I am facing this issue; how to solve this?&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt; &lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-q-a/table-change-not-possible-there-is-a-db-trigger-on-the-table/qaq-p/14154960"/>
    <published>2025-07-17T11:01:03.997000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/mard-and-marc-table-delta-with-abap-cds-extractor-cdc-enabled-does-not-work/qaq-p/14155463</id>
    <title>MARD and MARC table delta with ABAP CDS Extractor (CDC Enabled) does not work</title>
    <updated>2025-07-17T18:04:55.353000+02:00</updated>
    <author>
      <name>vinay_lohakare5</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/191828</uri>
    </author>
    <content>&lt;P&gt;Hello Experts,&lt;/P&gt;&lt;P&gt;The tables MARC and MARD have a replacement objects in S4HANA. When a ABAP CDS view extractor (CDC enabled) is built on these tables , we have observed that the delta does not work if the record is changed but New records are coming as delta.&lt;/P&gt;&lt;P&gt;How do we handle delta for these tables ? Or do we have any alternate way to get the delta from table MARC and MARD in Datasphere.&lt;/P&gt;&lt;P&gt;Thanks,&lt;/P&gt;&lt;P&gt;Vinay&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/mard-and-marc-table-delta-with-abap-cds-extractor-cdc-enabled-does-not-work/qaq-p/14155463"/>
    <published>2025-07-17T18:04:55.353000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/end-user-consumption-of-datasphere-data-in-sac/qaq-p/14155695</id>
    <title>End-user consumption of Datasphere data in SAC</title>
    <updated>2025-07-17T22:43:46.625000+02:00</updated>
    <author>
      <name>AriFeldman</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1526431</uri>
    </author>
    <content>&lt;P&gt;Good afternoon,&lt;/P&gt;&lt;P&gt;We have SAP Datasphere and SAP Analytics Cloud products.&lt;/P&gt;&lt;P&gt;I have the following question that I didn't find an answer to in the documentation. I'm new to Datasphere and SAC.&lt;/P&gt;&lt;P&gt;For a user to view the data from the analytical model in a story, do we also need to enter it into Datasphere?&lt;/P&gt;&lt;P&gt;These are end users who should only see a data dashboard.&lt;/P&gt;&lt;P&gt;Thank you in advance for your help.&lt;/P&gt;&lt;P&gt;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Datasphere/pd-p/73555000100800002141" class="lia-product-mention" data-product="16-1"&gt;SAP Datasphere&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Analytics+Cloud/pd-p/67838200100800006884" class="lia-product-mention" data-product="3-1"&gt;SAP Analytics Cloud&lt;/a&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/end-user-consumption-of-datasphere-data-in-sac/qaq-p/14155695"/>
    <published>2025-07-17T22:43:46.625000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/datasphere-working-with-task-chain/qaq-p/14156134</id>
    <title>DataSphere. Working with task chain</title>
    <updated>2025-07-18T09:14:36.385000+02:00</updated>
    <author>
      <name>AlexF_ukr</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1861388</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;Hello, experts!&lt;/SPAN&gt;&lt;/SPAN&gt; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;Questions in task chains:&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;1. If a chain is launched on schedule once every 5 minutes and runs longer, then the next launch crashes with an error, is this normal?&lt;/SPAN&gt;&lt;/SPAN&gt; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;2. How to make the chain launch after the previous run.&lt;/SPAN&gt;&lt;/SPAN&gt; &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;Returning to the previous question, so far I have done it through the second chain that calls the first... a kind of infinite loop.&lt;/SPAN&gt;&lt;/SPAN&gt; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;3. And the third question, arising from the previous ones, can I interrupt the execution of the chain with some code (block) and place it in the chain at the end, for example.&lt;/SPAN&gt;&lt;/SPAN&gt; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;4. Can I launch the second chain inside the chain in asynchronous mode?&lt;/SPAN&gt;&lt;/SPAN&gt; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;This tool works here differently than in the classic BW....&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/datasphere-working-with-task-chain/qaq-p/14156134"/>
    <published>2025-07-18T09:14:36.385000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/question-unable-to-use-remote-tables-in-sap-datasphere-error-403-forbidden/qaq-p/14156344</id>
    <title>[Question] Unable to Use Remote Tables in SAP DataSphere — Error 403 Forbidden via Cloud Connector</title>
    <updated>2025-07-18T12:05:41.584000+02:00</updated>
    <author>
      <name>YLN</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1460081</uri>
    </author>
    <content>&lt;P&gt;Hello experts,&lt;/P&gt;&lt;P&gt;I'm trying to connect from SAP DataSphere to an SAP ABAP On-Premise system using SAP Cloud Connector. The connection is partially successful, but Remote Tables are not working as expected.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Environment&lt;/STRONG&gt;:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Source: SAP DataSphere (Cloud)&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Target: SAP ABAP System (On-Premise)&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Connection Method: RFC via SAP Cloud Connector (ODBCforABAP adapter)&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;HR /&gt;&lt;P&gt;&lt;STRONG&gt;Connection&lt;/STRONG&gt; &lt;STRONG&gt;status&lt;/STRONG&gt;:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Data flows: Enabled&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Replication flows: Enabled&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Remote Tables: Not working&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;HR /&gt;&lt;P&gt;Error message:&lt;/P&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="YLN_0-1752832974755.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288530i36E60979CFA7F105/image-size/medium?v=v2&amp;amp;px=400" role="button" title="YLN_0-1752832974755.png" alt="YLN_0-1752832974755.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;HR /&gt;&lt;P&gt;In SAP Cloud Connector, under Monitor (Cloud to On-Premise), I can see multiple successful RFC calls:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="YLN_1-1752833065295.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288535iC3F2D8B7D80BE36C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="YLN_1-1752833065295.png" alt="YLN_1-1752833065295.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;How can I fix this?&lt;/P&gt;&lt;P&gt;Thanks in advance for your help!&lt;/P&gt;&lt;P&gt;Best regards,&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/question-unable-to-use-remote-tables-in-sap-datasphere-error-403-forbidden/qaq-p/14156344"/>
    <published>2025-07-18T12:05:41.584000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-datasphere-versions-not-visible-in-sap-datasphere-quality-and/qaq-p/14156684</id>
    <title>SAP Datasphere: Versions Not Visible in SAP Datasphere (Quality and Production)</title>
    <updated>2025-07-18T17:13:32.565000+02:00</updated>
    <author>
      <name>EagleYeSAP</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/166103</uri>
    </author>
    <content>&lt;P&gt;Hi Team,&lt;/P&gt;&lt;P&gt;In SAP Datasphere, I am able to see the versions of RL( Reporting layer) but&amp;nbsp; for the same RL ,&amp;nbsp;&lt;STRONG&gt;versions are not visible&lt;/STRONG&gt; in both the &lt;STRONG&gt;Quality&lt;/STRONG&gt; and &lt;STRONG&gt;Production&lt;/STRONG&gt; environments.&lt;/P&gt;&lt;P&gt;Anyone know the reason for that issue. Even i have checked with basis team but they are also helpless.&lt;/P&gt;&lt;P&gt;Thanks in Advance..&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-datasphere-versions-not-visible-in-sap-datasphere-quality-and/qaq-p/14156684"/>
    <published>2025-07-18T17:13:32.565000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/approaches-for-reporting-on-datasphere-data-through-iceberg-table-format-in/qaq-p/14157605</id>
    <title>Approaches  for reporting on Datasphere data through Iceberg table format in Azure datalake.</title>
    <updated>2025-07-21T10:03:48.152000+02:00</updated>
    <author>
      <name>lars_oland</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/547133</uri>
    </author>
    <content>&lt;P&gt;Hi &lt;span class="lia-unicode-emoji" title=":slightly_smiling_face:"&gt;🙂&lt;/span&gt;&lt;/P&gt;&lt;P&gt;I am looking for any input on how to report on SAP Datasphere data from an Azure Datalake using Iceberg format tables that can be consumed either through Databricks or Snowflake using either federated access or persisted.&amp;nbsp;&lt;/P&gt;&lt;P&gt;I know the path of doing an outbound replication flow writing Parquet files into the Azure Datalake and then have the datalake process the parquet files into Iceberg format. But is there other ways of setting up integrations between Azure Datalake Iceberg tables and Datasphere ?&lt;/P&gt;&lt;P&gt;I know this question might also be more of an Azure Datalake question but thought that someone might have had the same integration scenario.&lt;/P&gt;&lt;P&gt;Regards&lt;/P&gt;&lt;P&gt;Lars&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/approaches-for-reporting-on-datasphere-data-through-iceberg-table-format-in/qaq-p/14157605"/>
    <published>2025-07-21T10:03:48.152000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/transport-export-is-queued-up/qaq-p/14158164</id>
    <title>Transport Export is queued up</title>
    <updated>2025-07-21T16:43:53.049000+02:00</updated>
    <author>
      <name>Ajantha</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1571642</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;Transport -&amp;gt; Export not started for long time. Status in the Transport monitor is 'Queued'. This was working fine before.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Screenshot 2025-07-21 at 8.10.15 PM.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/289419iE37C7536F25EE297/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Screenshot 2025-07-21 at 8.10.15 PM.png" alt="Screenshot 2025-07-21 at 8.10.15 PM.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/transport-export-is-queued-up/qaq-p/14158164"/>
    <published>2025-07-21T16:43:53.049000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/datasphere-hana-cloud-db-remote-table-insufficient-privileges-on-hdi/qaq-p/14158960</id>
    <title>Datasphere - HANA Cloud DB Remote Table (Insufficient privileges on HDI)</title>
    <updated>2025-07-22T12:15:04.665000+02:00</updated>
    <author>
      <name>Cristian</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/6658</uri>
    </author>
    <content>&lt;P&gt;Hi experts,&lt;/P&gt;&lt;P&gt;We have created a connection in Datasphere to visualize the access to a HANA Cloud DB.&lt;/P&gt;&lt;P&gt;The set up is correct and we are able to import the relevant tables as remote tables but when we are trying to view the data we are getting the error as follows:&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;internal error: Error opening the cursor for the remote database &amp;lt;DWC_IL_BTP_HANA_APPS_EU.HANA_BTP_APPS_EU&amp;gt; [SAP AG][LIBODBCHDB SO][HDBODBC] General error;258 insufficient privilege: Detailed info for this error can be found with guid 'E3A628E32FA90D4B90B99370A3C9CBC4'&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The issue is due to insufficient privileges of the user used in the Datasphere connection (DBAMIN) to access the HDI container where the table exist.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Cristian_0-1753179069710.png" style="width: 585px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/289749i3B50D9A06FACDDA3/image-dimensions/585x177?v=v2" width="585" height="177" role="button" title="Cristian_0-1753179069710.png" alt="Cristian_0-1753179069710.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;I understand that to solve the issue we need to assigned SELECT privilege to DBADMIN on the respective schema but, how can we do that?&lt;/P&gt;&lt;P&gt;Note that the HDI container has been created over an MTA so not sure how we can do to grant that permission.&lt;/P&gt;&lt;P&gt;Many thanks!&lt;/P&gt;&lt;P&gt;C.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/datasphere-hana-cloud-db-remote-table-insufficient-privileges-on-hdi/qaq-p/14158960"/>
    <published>2025-07-22T12:15:04.665000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-migrate-from-standalone-sap-analytics-cloud-tenant-to-the-sac/qaq-p/14159583</id>
    <title>How to Migrate from Standalone SAP Analytics Cloud tenant to the SAC component in SAP Business Data</title>
    <updated>2025-07-23T00:38:55.046000+02:00</updated>
    <author>
      <name>SivaKiran_Uppala</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2103117</uri>
    </author>
    <content>&lt;P class=""&gt;Are you moving from a standalone SAC tenant to the &lt;STRONG&gt;SAC component within SAP BDC&lt;/STRONG&gt;? Here's what you need to know &lt;span class="lia-unicode-emoji" title=":backhand_index_pointing_down:"&gt;👇&lt;/span&gt;&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="ember3777" id="toc-hId-1864328797"&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;✅&lt;/span&gt; Option 1: Export &amp;amp; Import via SAC Content Network (Quick but Limited)&lt;/H3&gt;&lt;P class=""&gt;Yes, you &lt;EM&gt;can&lt;/EM&gt; export and import SAC objects (stories, models, data actions) between tenants — even from standalone SAC to SAC component of BDC — using the &lt;STRONG&gt;Content Network&lt;/STRONG&gt;.&lt;/P&gt;&lt;P class=""&gt;But here’s the catch &lt;span class="lia-unicode-emoji" title=":backhand_index_pointing_down:"&gt;👇&lt;/span&gt; &lt;span class="lia-unicode-emoji" title=":stop_sign:"&gt;🛑&lt;/span&gt; This method doesn’t unlock the full power of BDC — you miss out on Access to &lt;STRONG&gt;BDC Data Products&lt;/STRONG&gt;, &lt;STRONG&gt;Seamless Planning&lt;/STRONG&gt;, and &lt;STRONG&gt;AI/ML integration&lt;/STRONG&gt; via Databricks or AI Core.&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="ember3780" id="toc-hId-1667815292"&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;✅&lt;/span&gt; Option 2: Recommended – Rebuild with BDC in Mind&lt;/H3&gt;&lt;P class=""&gt;&lt;STRONG&gt;SAC ObjectMigration Strategy&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":bar_chart:"&gt;📊&lt;/span&gt; Stories &amp;amp; Dashboards :: Export/import via Content Network → Repoint to BDC-backed models. Rebuild if needed.&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":chart_increasing:"&gt;📈&lt;/span&gt; Planning / Analytic Models :: Recreate in &lt;STRONG&gt;Datasphere component&lt;/STRONG&gt; of BDC→ Connect to SAC for visualization&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":repeat_button:"&gt;🔁&lt;/span&gt; Data Actions :: Rebuild manually in SAC component of BDC&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":electric_plug:"&gt;🔌&lt;/span&gt; Connections :: Must be recreated in BDC&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":counterclockwise_arrows_button:"&gt;🔄&lt;/span&gt; Seamless Planning :: Set up SAC integration with Datasphere → avoid data duplication&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="ember3787" id="toc-hId-1471301787"&gt;🧠 Think of it as: Lift, Evaluate, Rebuild Smartly&lt;/H3&gt;&lt;P class=""&gt;You're not just copying. You're &lt;STRONG&gt;migrating to a better foundation and following are some of the advantages with option 2&lt;/STRONG&gt;:&lt;/P&gt;&lt;P class=""&gt;&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;✅&lt;/span&gt; &lt;STRONG&gt;BDC Data Products&lt;/STRONG&gt; = reusable, governed assets&lt;/LI&gt;&lt;LI&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;🔗&lt;/span&gt; &lt;STRONG&gt;Seamless Planning&lt;/STRONG&gt; = real-time integration, no more data copies&lt;/LI&gt;&lt;LI&gt;&lt;span class="lia-unicode-emoji" title=":robot_face:"&gt;🤖&lt;/span&gt; &lt;STRONG&gt;AI/ML Capabilities&lt;/STRONG&gt; = unlock smart forecasting, predictive planning&lt;/LI&gt;&lt;LI&gt;🧩 &lt;STRONG&gt;Business Data Fabric&lt;/STRONG&gt; = unified, scalable architecture&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;HR /&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":pushpin:"&gt;📌&lt;/span&gt; &lt;EM&gt;Tip: Treat this as an opportunity to rethink your models, optimize performance, and align with SAP's future-ready data strategy.&lt;/EM&gt;&lt;/P&gt;&lt;P class=""&gt;#SAPBDC #SAPAnalyticsCloud #SAPDatasphere #SeamlessPlanning #SAPMigration #AIinSAP #BusinessDataCloud&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-migrate-from-standalone-sap-analytics-cloud-tenant-to-the-sac/qaq-p/14159583"/>
    <published>2025-07-23T00:38:55.046000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/quot-camel-execution-failed-error-on-fiori-registration-only-in-production/qaq-p/14161141</id>
    <title>"Camel execution failed” Error on Fiori Registration (Only in Production) / Impact of Variable Table</title>
    <updated>2025-07-24T11:15:49.012000+02:00</updated>
    <author>
      <name>tomohero</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1490324</uri>
    </author>
    <content>&lt;H2 id="toc-hId-1735927301"&gt;Title:&lt;/H2&gt;&lt;P&gt;“Camel execution failed” Error on Fiori Registration (Only in Production) / Impact of Variable Table Reference?&lt;/P&gt;&lt;HR /&gt;&lt;H2 id="toc-hId-1539413796"&gt;Question:&lt;/H2&gt;&lt;H3 id="toc-hId-1471983010"&gt;■ Overview&lt;/H3&gt;&lt;P&gt;In our Fiori application, an error occurs when clicking the &lt;STRONG&gt;Register&lt;/STRONG&gt; button on a transactional entry screen.&lt;BR /&gt;&lt;STRONG&gt;The same code works fine in the test environment, but fails in the production environment.&lt;/STRONG&gt;&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="toc-hId-1275469505"&gt;■ Environment Setup (Simplified)&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;CDS view is used to read cost department master data (name anonymized)&lt;/LI&gt;&lt;LI&gt;Backend is Node.js, accessing CDS via CAP service&lt;/LI&gt;&lt;LI&gt;The CDS view references a table, passed via variable in the service&lt;/LI&gt;&lt;/UL&gt;&lt;HR /&gt;&lt;H3 id="toc-hId-1078956000"&gt;■ Environment Differences&lt;/H3&gt;&lt;P&gt;The referenced table has a higher record count in production (e.g. test: 3,000 records, production: 3,500 records).&lt;BR /&gt;CDS view definitions and service logic are identical across environments.&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="toc-hId-882442495"&gt;■ Error Message (Excerpt)&lt;/H3&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/DIV&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;[SqlError: internal error: Camel execution failed. Reason: Cannot process result] { code: 403, sqlState: 'HY000' }&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;We noticed the generated SQL contains something like JSON_TABLE('{}'), which may be contributing to the failure when handling empty JSON input under certain conditions.&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="toc-hId-685928990"&gt;■ Code Example (with variable table name)&lt;/H3&gt;&lt;P&gt;Here is the original code using a variable for the table name:&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/DIV&gt;&lt;pre class="lia-code-sample language-javascript"&gt;&lt;code&gt;const result = await this.tx.run(
    SELECT.one.from(table).where(conditions)
);&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;This code causes a 403 error &lt;STRONG&gt;only in the production environment&lt;/STRONG&gt;.&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="toc-hId-489415485"&gt;■ Temporary Fix (working version)&lt;/H3&gt;&lt;P&gt;When we explicitly provided the table name as a string, the issue was resolved:&lt;/P&gt;&lt;pre class="lia-code-sample language-javascript"&gt;&lt;code&gt;const table = 'Z_ACTUAL_COST_DEPT_MASTER'; // ← anonymized actual table name const result = await this.tx.run( SELECT.one.from(table).where(conditions) );&lt;/code&gt;&lt;/pre&gt;&lt;HR /&gt;&lt;H3 id="toc-hId-292901980"&gt;■ Questions&lt;/H3&gt;&lt;OL&gt;&lt;LI&gt;What could be the root cause of the Camel execution failed. Reason: Cannot process result error in this context?&lt;/LI&gt;&lt;LI&gt;Could the use of JSON_TABLE('{}') in the CDS-generated SQL cause issues in production due to volume or empty JSON input?&lt;/LI&gt;&lt;LI&gt;Is it possible that using SELECT.from(variable) in CDS behaves differently across environments (e.g. due to view resolution)?&lt;/LI&gt;&lt;LI&gt;Are there any best practices for safely referencing tables via variables in CDS views, especially for production stability?&lt;/LI&gt;&lt;/OL&gt;&lt;HR /&gt;&lt;H3 id="toc-hId-96388475"&gt;■ Notes&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Table names and record counts are anonymized.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;I can provide HANA version and CDS definitions if needed.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/quot-camel-execution-failed-error-on-fiori-registration-only-in-production/qaq-p/14161141"/>
    <published>2025-07-24T11:15:49.012000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-refresh-data-automatically-in-sap-analytics-cloud-for-excel/qaq-p/14164266</id>
    <title>How to refresh data automatically in SAP Analytics Cloud for Excel</title>
    <updated>2025-07-28T11:39:01.237000+02:00</updated>
    <author>
      <name>Lora_0121</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1993156</uri>
    </author>
    <content>&lt;P&gt;Hello.&lt;/P&gt;&lt;P&gt;I am currently refreshing data manually in SAP Analytics Cloud for Excel.&lt;/P&gt;&lt;P&gt;Right now, my data goes up to July, but when August data becomes available, I want my Excel reports to automatically show data up to August—without having to refresh manually.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Is there a way to automatically refresh data at a specific time in the background?&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Lora_0121_1-1753695349999.png" style="width: 395px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/292532iFFF502D7BCE60B1C/image-dimensions/395x203/is-moderation-mode/true?v=v2" width="395" height="203" role="button" title="Lora_0121_1-1753695349999.png" alt="Lora_0121_1-1753695349999.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Thank you&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-refresh-data-automatically-in-sap-analytics-cloud-for-excel/qaq-p/14164266"/>
    <published>2025-07-28T11:39:01.237000+02:00</published>
  </entry>
</feed>
