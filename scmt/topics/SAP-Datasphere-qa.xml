<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/SAP-Datasphere-qa.xml</id>
  <title>SAP Community - SAP Datasphere</title>
  <updated>2025-10-09T11:12:46.008358+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/SAP Datasphere/pd-p/73555000100800002141" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>SAP Datasphere Q&amp;A in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/datasphere-backup/qaq-p/14225829</id>
    <title>Datasphere backup</title>
    <updated>2025-09-23T15:32:27.689000+02:00</updated>
    <author>
      <name>Neyaz</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1927592</uri>
    </author>
    <content>&lt;P&gt;Hi All,&lt;/P&gt;&lt;P&gt;Can anyone tell the steps on how to restore backup of Datasphere tenant in case of any adverse scenario?&lt;/P&gt;&lt;P&gt;Thanks.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/datasphere-backup/qaq-p/14225829"/>
    <published>2025-09-23T15:32:27.689000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-datasphere-delta-table/qaq-p/14226347</id>
    <title>SAP Datasphere: Delta Table</title>
    <updated>2025-09-24T07:37:25.021000+02:00</updated>
    <author>
      <name>p_m8</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/401599</uri>
    </author>
    <content>&lt;P&gt;&amp;nbsp;Hi,&lt;/P&gt;&lt;P&gt;I have created a new Local Table with "Delta Capture" option On.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;This will automatically create a new additional Delta table&amp;nbsp;this Local Table.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;But I can't find this Delta table in the repository, do you know where I can find it?&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Many thanks.&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-datasphere-delta-table/qaq-p/14226347"/>
    <published>2025-09-24T07:37:25.021000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/ndc-converter-2-0-automating-your-journey-from-businessobjects-to-cloud/qaq-p/14226676</id>
    <title>NDC Converter 2.0: Automating Your Journey from BusinessObjects to Cloud Analytics</title>
    <updated>2025-09-24T11:39:08.590000+02:00</updated>
    <author>
      <name>JurajKysel4</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2254330</uri>
    </author>
    <content>&lt;P&gt;SAP Business Data Cloud (BDC) provides a unified platform for data ingestion, semantic modeling, governance and analytics. For teams migrating from SAP BusinessObjects (BO), BDC enables:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;A governed semantic layer in SAP Datasphere that faithfully reproduces and extends your existing BO universes with standardized naming conventions, hierarchies and calculated measures.&lt;/LI&gt;&lt;LI&gt;Cloud-native analytics in SAC for reporting, planning and predictive scenarios, powered by either live data connections or scheduled replication jobs.&lt;/LI&gt;&lt;LI&gt;A clear modernization path for SAP BW/4HANA artifacts and non-SAP sources, preserving embedded business logic while consolidating disparate models.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;By porting Web Intelligence (WebI) content into BDC, you can retire legacy BO infrastructure and establish a sustainable foundation built on remote or replicated tables, graphical and SQL views and published semantic models that are fully consumable in SAC.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="JurajKysel4_0-1758706198184.png" style="width: 739px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/319400i4235957EF39EDA56/image-dimensions/739x229?v=v2" width="739" height="229" role="button" title="JurajKysel4_0-1758706198184.png" alt="JurajKysel4_0-1758706198184.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;In this follow-up to our NDC Converter &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/accelerate-migration-of-sap-businessobjects-web-intelligence-reports-to-sap/ba-p/13580516" target="_blank"&gt;introduction&lt;/A&gt;, we’ll showcase its newest capabilities and zoom in on how REST APIs, RPA and the SAP BDC stack work together to fully automate your migration workflow and eliminate uncertainty that is often associated with these sorts of projects.&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Analysis &amp;amp; clean-up&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;Migration kicks off with a thorough source analysis powered by our enhanced scanning engine. After installing a lightweight Windows executable in your environment, NDC Converter uses the BusinessObjects REST API to perform a repository-wide scan - cataloging WebI documents, variables, filters and data sources. Parallel processing enables multiple report structures to be inventoried simultaneously, cutting traditional analysis times from days to hours.&lt;/P&gt;&lt;P&gt;If BO access is restricted, you can export a full content catalog instead and NDC Converter will generate a self-service metadata report for rapid sizing and compliance checks. These automated scans deliver hard metrics on:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Volume: total reports, pages, charts and objects&lt;/LI&gt;&lt;LI&gt;Complexity: calculations, variables, dimensions and interactive features&lt;/LI&gt;&lt;LI&gt;Usage: inactive or overlapping content&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Armed with this detailed data, we can scope migration efforts accurately within days rather than weeks, giving prospects immediate insight into their BI landscape without manual, time-consuming analysis.&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Automated report migration&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;Once WebI queries are identified, the next step is to align them with target system (usually SAP Datasphere but other options available too – for reference see previous blog &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/accelerate-migration-of-sap-businessobjects-web-intelligence-reports-to-sap/ba-p/13580516" target="_blank"&gt;post&lt;/A&gt;). Steps here include:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Linking each WebI query to its target system&lt;/LI&gt;&lt;LI&gt;Generating the necessary migration definitions&lt;/LI&gt;&lt;LI&gt;Automatically provisioning and deploying the corresponding tables&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;If you’re working with many tables, the “mass deploy” feature lets you push them live in bulk—no tedious one-by-one clicks.&lt;/P&gt;&lt;P&gt;After tables are deployed, we configure on-demand or scheduled data replication to maintain synchronization between target and source systems, followed by creating graphical and SQL-based views to implement calculation logic. The final step is to publish these views to SAP Analytics Cloud where up-to-date data can be accessed.&lt;/P&gt;&lt;P&gt;The data source layer migration involves analyzing the BO repository, migrating universe metadata and/or transitioning live models based on BEx queries. Upon completion of the initial data migration, a comprehensive semantic model is introduced that mirrors your original WebI structures including dimensions, measures, hierarchies and data. This transformation provides a cloud-ready foundation for all SAP Analytics Cloud initiatives.&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;NDC Converter 2.0&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;With your semantic model live, we proceed with WebI reports migration into SAP Analytics Cloud as interactive stories with new high functional coverage. NDC Converter retrieves each report’s layout, structures, tables, charts, filters and visual elements via the BusinessObjects REST API. A blueprint compatible with RPA processing is produced, covering:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Layout &amp;amp; structure&lt;/STRONG&gt;: multi‑page documents, IDs, descriptions, pages/tabs.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Tables &amp;amp; crosstabs&lt;/STRONG&gt;: calculated and restricted measures, variables and common WebI calculations.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Charts&lt;/STRONG&gt;: Bar/Column, Line, Numeric Point, Pie, Donut, Heat Map, Tree Map, Bubble, Scatterplot.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Formatting &amp;amp; UX&lt;/STRONG&gt;: predefined template stories, titles, text, headers/footers, icons.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Filters &amp;amp; interactivity&lt;/STRONG&gt;: input controls, query filters, single object filters, drill, hyperlinks.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The RPA bot, delivered as a Chrome extension, reads this blueprint and automates the reconstruction of each report in SAC Story 2.0, preserving original tables, crosstabs, charts, parameters and filters. The resulting SAC Stories mirror your WebI reports while leveraging cloud-native data models.&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;What stays manual (and why)&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;NDC Converter automates routine migration tasks, allowing your team to focus on strategic design and governance – here are cases where automation does not bring added value:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Data model (business semantics) design:&lt;/STRONG&gt; turning technical structures into robust semantic layer requires continuous alignment on reporting vision.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Edge cases &amp;amp; redesign:&lt;/STRONG&gt; in situations where 1:1 replication isn’t optimal, we propose a workaround solution to comply with business and technical needs.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Environment setup:&lt;/STRONG&gt; Migrating users, roles and platform configurations using a mix of guided best practices and selective automation.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Collaborate end-end delivery&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;NDC Converter is an ideal tool for complex migration scenarios, automating the transfer of every structural element—from metadata and queries to filters and visual object definitions. Once the converter has recreated the report skeletons in SAC, your BI team can take over the final steps: refining layouts, adjusting chart properties and validating calculation logic. This collaborative workflow ensures that the most time-consuming technical migrations are handled automatically, while you retain full control over presentation, branding and business requirements.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/ndc-converter-2-0-automating-your-journey-from-businessobjects-to-cloud/qaq-p/14226676"/>
    <published>2025-09-24T11:39:08.590000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-datasphere-trial-resources-for-excercises-missing/qaq-p/14227218</id>
    <title>SAP Datasphere trial, resources for excercises missing</title>
    <updated>2025-09-24T21:21:33.963000+02:00</updated>
    <author>
      <name>StefaniaF</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1594865</uri>
    </author>
    <content>&lt;P&gt;Create Opportunity Fact View excercise: Resource MCT Opportunity items missing, such resource is not shared from the central data space as suggested by the workbook, nor available in the local space repository.&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-datasphere-trial-resources-for-excercises-missing/qaq-p/14227218"/>
    <published>2025-09-24T21:21:33.963000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-datasphere-transformation-flow-init-and-delta/qaq-p/14227368</id>
    <title>SAP Datasphere Transformation Flow, Init and Delta</title>
    <updated>2025-09-25T06:22:39.345000+02:00</updated>
    <author>
      <name>p_m8</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/401599</uri>
    </author>
    <content>&lt;DIV&gt;Hi,&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;1. In my Local Table (Employee Source), I have the Delta Capture option ON.&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;2. I use this as source table in my Transformation Flow and loaded into target table (Employee Target). I chose to load from table Delta Capture.&lt;/DIV&gt;&lt;DIV&gt;3. In the Employee Target table, I can see all records updated correctly, the field Change Type = I, Change Date = Sep 25, 2025, 3:51:01&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;4. Now in Local Table (Employee Source), I updated one record only - Employee 123.&lt;/DIV&gt;&lt;DIV&gt;5. Run data load again via Transformation Flow, again, all records updated. I can see the Change Date field updated with current run date/time for all the records.&lt;/DIV&gt;&lt;DIV&gt;6. Why are all records updated again? I thought it is only Employee 123 will be updated as I chose load from table Delta Capture, not All Active Records??&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;Please advise, thanks.&lt;/DIV&gt;&lt;/DIV&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-datasphere-transformation-flow-init-and-delta/qaq-p/14227368"/>
    <published>2025-09-25T06:22:39.345000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/count-not-returned-anymore-in-odata-calls-to-analytical-models-in-sap/qaq-p/14227580</id>
    <title>$count not returned anymore in OData calls to analytical models in SAP Datasphere</title>
    <updated>2025-09-25T09:57:26.045000+02:00</updated>
    <author>
      <name>JaumeG</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1487649</uri>
    </author>
    <content>&lt;P&gt;Hi everyone,&lt;/P&gt;&lt;P&gt;Until last week, our OData calls to analytical models in SAP Datasphere returned the $count value when using $count=true. Since this week, the requests still work but no longer return any count value.&lt;/P&gt;&lt;P&gt;Has anyone else noticed this change? Do you know if something changed recently in Datasphere OData services regarding $count support or if we need to adapt our queries?&lt;/P&gt;&lt;P&gt;Thanks!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/count-not-returned-anymore-in-odata-calls-to-analytical-models-in-sap/qaq-p/14227580"/>
    <published>2025-09-25T09:57:26.045000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/questions-on-sap-bdc-integration-scenarios-on-premise-car-ewm-performance/qaq-p/14227914</id>
    <title>Questions on SAP BDC Integration Scenarios (On-Premise, CAR/EWM, Performance)</title>
    <updated>2025-09-25T15:07:13.347000+02:00</updated>
    <author>
      <name>benhaddou</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/891003</uri>
    </author>
    <content>&lt;P&gt;Hello,&lt;/P&gt;&lt;P&gt;I have the following questions regarding SAP BDC and would appreciate any insights:&lt;/P&gt;&lt;OL class="lia-list-style-type-upper-alpha"&gt;&lt;LI&gt;What are the available options to connect SAP BDC with an &lt;STRONG&gt;on-premise SAP ERP&lt;/STRONG&gt;&amp;nbsp; system? Are there recommended best practices for such scenarios?&lt;/LI&gt;&lt;LI&gt;Are SAP-managed Data Products in SAP BDC available for &lt;STRONG&gt;on-premise S/4HANA systems&lt;/STRONG&gt;, or are on-premise customers limited to customer-managed Data Products only?&lt;/LI&gt;&lt;LI&gt;Is it already possible to integrate data from on-premise SAP solutions such as &lt;STRONG&gt;SAP CAR or SAP EWM&lt;/STRONG&gt; into SAP BDC, or is current support mainly focused on cloud solutions like Ariba or SuccessFactors?&lt;/LI&gt;&lt;LI&gt;Are there known performance considerations when integrating data via &lt;STRONG&gt;OData&lt;/STRONG&gt; directly or &lt;STRONG&gt;SAP Datasphere&lt;/STRONG&gt; as the integration layer? If so, what are the best practices for each approach?&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Many thanks in advance for your support!&lt;/P&gt;&lt;P&gt;Best regards&lt;/P&gt;&lt;P&gt;Thami&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/questions-on-sap-bdc-integration-scenarios-on-premise-car-ewm-performance/qaq-p/14227914"/>
    <published>2025-09-25T15:07:13.347000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-use-parameter-in-sap-datasphere-task-chain/qaq-p/14229693</id>
    <title>How to use parameter in SAP Datasphere Task Chain</title>
    <updated>2025-09-28T09:13:24.244000+02:00</updated>
    <author>
      <name>Nilesh92</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1515424</uri>
    </author>
    <content>&lt;P&gt;Hello Experts,&lt;/P&gt;&lt;P&gt;With the latest update, we got a parameterized Task chain in SAP Datasphere.&lt;/P&gt;&lt;P&gt;I have been struggling with using the parameter that i have created in one of a task chain.&lt;/P&gt;&lt;P&gt;use case:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;I have a parameterized data flow.&lt;/LI&gt;&lt;LI&gt;I have created a task chain with a parameter created in it.&lt;/LI&gt;&lt;LI&gt;I have added the dataflow from step 1 in this task chain.&lt;/LI&gt;&lt;LI&gt;Now i want to pass the Task chain parameter in the dataflow.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Can someone please help me with this?&lt;/P&gt;&lt;P&gt;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Datasphere/pd-p/73555000100800002141" class="lia-product-mention" data-product="16-1"&gt;SAP Datasphere&lt;/a&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-use-parameter-in-sap-datasphere-task-chain/qaq-p/14229693"/>
    <published>2025-09-28T09:13:24.244000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/transformation-flow-init-and-delta/qaq-p/14229927</id>
    <title>Transformation Flow, Init and Delta</title>
    <updated>2025-09-29T07:00:12.853000+02:00</updated>
    <author>
      <name>p_m8</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/401599</uri>
    </author>
    <content>&lt;DIV&gt;Hi,&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;1. In my Local Table (Employee Source), I have the Delta Capture option ON.&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;2. I use this as source table in my Transformation Flow and loaded into target table (Employee Target). I chose to load from table Delta Capture.&lt;/DIV&gt;&lt;DIV&gt;3. In the Employee Target table, I can see all records updated correctly, the field Change Type = I, Change Date = Sep 25, 2025, 3:51:01&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;4. Now in Local Table (Employee Source), I updated one record only - Employee 123.&lt;/DIV&gt;&lt;DIV&gt;5. Run data load again via Transformation Flow, again, all records updated. I can see the Change Date field updated with current run date/time for all the records.&lt;/DIV&gt;&lt;DIV&gt;6. Why are all records updated again? I thought it is only Employee 123 will be updated as I chose load from table Delta Capture, not All Active Records??&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;Please advise, thanks.&lt;/DIV&gt;&lt;/DIV&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/transformation-flow-init-and-delta/qaq-p/14229927"/>
    <published>2025-09-29T07:00:12.853000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/delta-table/qaq-p/14229928</id>
    <title>Delta Table</title>
    <updated>2025-09-29T07:02:39.859000+02:00</updated>
    <author>
      <name>p_m8</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/401599</uri>
    </author>
    <content>&lt;P&gt;&amp;nbsp;Hi,&lt;/P&gt;&lt;P&gt;I have created a new Local Table with "Delta Capture" option On.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;This will automatically create a new additional Delta table&amp;nbsp;this Local Table.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;But I can't find this Delta table in the repository, do you know where I can find it?&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Many thanks.&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/delta-table/qaq-p/14229928"/>
    <published>2025-09-29T07:02:39.859000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/missing-technical-link-from-datasphere-remote-tables-to-source-system/qaq-p/14230586</id>
    <title>Missing technical link from Datasphere remote tables to source system</title>
    <updated>2025-09-29T15:38:54.006000+02:00</updated>
    <author>
      <name>erik_pedersen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/500541</uri>
    </author>
    <content>&lt;P&gt;Hi experts,&lt;/P&gt;&lt;P&gt;I need to find the link between a select on a remote table in datasphere and the similar select on the source system. I am using DP Agent as connector between Datasphere and in this case a BW/4Hana system.&lt;/P&gt;&lt;P&gt;I can see the SQL select towards the source system in the M_REMOTE_STATEMENTS in datasphere - no problem. But how can I find the unique link to the SQL executed on the source system? By comparing starting time of the statement in Datasphere and source system I can actually find a kind of link when looking into M_EXPENSIVE_STATEMENTS on the source system.&lt;/P&gt;&lt;P&gt;I have tried to connect the 2 statements through transaction_id and/or Connection_id, but without any success. I think I need to access other interface tables, but which ones?&lt;/P&gt;&lt;P&gt;Any Good Ideas,&lt;/P&gt;&lt;P&gt;Regards&lt;/P&gt;&lt;P&gt;Erik Pedersen&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/missing-technical-link-from-datasphere-remote-tables-to-source-system/qaq-p/14230586"/>
    <published>2025-09-29T15:38:54.006000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-create-export-a-csv-file-from-datasphere/qaq-p/14230939</id>
    <title>How to create/export a CSV file from Datasphere?</title>
    <updated>2025-09-29T21:23:44.854000+02:00</updated>
    <author>
      <name>RafaelBizzotto</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2059878</uri>
    </author>
    <content>&lt;P&gt;Hi all,&lt;/P&gt;&lt;P&gt;I need to create a CSV file based in a table from Datasphere.&lt;/P&gt;&lt;P&gt;In the past we had a SAP BW sytems which was responsible to export some data saving it in a local share drive by a CSV file.&lt;/P&gt;&lt;P&gt;Is there any option for creating a CSV from Datasphere?&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-create-export-a-csv-file-from-datasphere/qaq-p/14230939"/>
    <published>2025-09-29T21:23:44.854000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-datasphere-local-file-table-merge-with-custom-application-goes-into/qaq-p/14232394</id>
    <title>SAP Datasphere: local file table Merge with custom application goes into error</title>
    <updated>2025-10-01T10:44:32.848000+02:00</updated>
    <author>
      <name>albertosimeoni</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/829608</uri>
    </author>
    <content>&lt;P&gt;Hello,&lt;/P&gt;&lt;P&gt;when I try to do a merge of a local table (file), with a "spark application" different from the standard (300).&lt;/P&gt;&lt;P&gt;I get an error from the SQL stored procedure that invoke the merge file task.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="albertosimeoni_0-1759307928893.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/321907iEBC86A27319BD43C/image-size/large?v=v2&amp;amp;px=999" role="button" title="albertosimeoni_0-1759307928893.png" alt="albertosimeoni_0-1759307928893.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;I am on a TDD Datasphere tenant with Object store activated through the new procedure via the correct ticket yesterday.&lt;/P&gt;&lt;P&gt;Do you also experience this problems with tasks invoked with different applicaiton than the standard defined in the space?&lt;/P&gt;&lt;P&gt;Have you got any workaround? I want to test which is the correct resource allocation to minimize compute costs in terms of CU,&lt;/P&gt;&lt;P&gt;for now seems to me a very high cost for a serverless applicaiton. As it is, it seems that the data lake it costs more than having the data "in memory" for my test (1GB table ~ 140Mi rows).&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Thanks,&lt;/P&gt;&lt;P&gt;Alberto&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-datasphere-local-file-table-merge-with-custom-application-goes-into/qaq-p/14232394"/>
    <published>2025-10-01T10:44:32.848000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/update-er-model/qaq-p/14233211</id>
    <title>Update ER Model</title>
    <updated>2025-10-02T09:02:29.686000+02:00</updated>
    <author>
      <name>p_m8</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/401599</uri>
    </author>
    <content>&lt;P&gt;Hi,&lt;/P&gt;&lt;P&gt;I have created a new ER Model with following:&lt;/P&gt;&lt;P&gt;Billing Transaction (Fact)&lt;/P&gt;&lt;P&gt;Customer (Dimension)&lt;/P&gt;&lt;P&gt;This is saved and deployed. Analytical Model created and deployed successfully on this.&lt;/P&gt;&lt;P&gt;Now I have updated the ER Model with new Store Dimension. I saved and deployed the ER Model successfully. However, this dimension is not available in my existing Analytical Model.&lt;/P&gt;&lt;P&gt;How can I propagate the Store Dimension into my existing Analytical Model?&lt;/P&gt;&lt;P&gt;Please advise, thank you.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/update-er-model/qaq-p/14233211"/>
    <published>2025-10-02T09:02:29.686000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/cannot-see-formation-option-under-data-provider-while-creating-dataprovider/qaq-p/14235135</id>
    <title>Cannot see Formation option under Data Provider while creating dataprovider profile in Datasphere</title>
    <updated>2025-10-06T03:59:20.955000+02:00</updated>
    <author>
      <name>yashcp</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/182976</uri>
    </author>
    <content>&lt;P&gt;Hello Team,&lt;/P&gt;&lt;P&gt;I am trying to create a data provider profile in SAP Datasphere. However, when i see the option Data Provider, I cannot see Formation under that. Is it something that will appear only if my Datasphere tenant is rewired to SAP BDC?&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="yashcp_0-1759715941648.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/322981i2B117562168D9696/image-size/medium?v=v2&amp;amp;px=400" role="button" title="yashcp_0-1759715941648.png" alt="yashcp_0-1759715941648.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/cannot-see-formation-option-under-data-provider-while-creating-dataprovider/qaq-p/14235135"/>
    <published>2025-10-06T03:59:20.955000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/migration-approach-from-sap-bw-7-0-to-datasphere/qaq-p/14235523</id>
    <title>Migration approach from SAP BW 7.0 to Datasphere</title>
    <updated>2025-10-06T10:41:35.004000+02:00</updated>
    <author>
      <name>Naiduz</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1385631</uri>
    </author>
    <content>&lt;P&gt;We are planning to Migrate our BW 7.0 production data from&amp;nbsp; BW info providers to Datasphere&amp;nbsp;&lt;BR /&gt;as One time activity.&lt;BR /&gt;&lt;BR /&gt;Please let me Migration approach to be followed.&lt;BR /&gt;We don't have Open hubs/ BODS / SLT&amp;nbsp; in our landscape&lt;BR /&gt;&lt;BR /&gt;Please let me know&amp;nbsp; possibility to connect Datasphere directly to BW 7.0&lt;BR /&gt;Not sure of Replication flows or connectors from Datasphere connectivity.&lt;BR /&gt;&lt;BR /&gt;Can we convert our BW info providers using Generate export data source and connect directly to Datasphere directly?&lt;BR /&gt;&lt;BR /&gt;&lt;BR /&gt;Please suggest&lt;BR /&gt;&lt;BR /&gt;&lt;BR /&gt;Regards,&lt;BR /&gt;NZ&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/migration-approach-from-sap-bw-7-0-to-datasphere/qaq-p/14235523"/>
    <published>2025-10-06T10:41:35.004000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/re-initialization-of-a-table-in-a-replication-flow/qaq-p/14235534</id>
    <title>Re-initialization of a Table in a Replication Flow</title>
    <updated>2025-10-06T10:51:09.449000+02:00</updated>
    <author>
      <name>tom345</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1856039</uri>
    </author>
    <content>&lt;P&gt;Hello!&lt;/P&gt;&lt;P&gt;I need to know whether, when I apply a change to my source table which is replicated through a Replication Flow in SAP Datasphere together with other tables—reinitializing the table in the Replication Flow requires restarting the entire Replication Flow (for all the tables in it) or only the specific table.&lt;BR /&gt;I’d like to know this for each of the three load types: Initial only, Delta only, and Initial and Delta.&lt;/P&gt;&lt;P&gt;In addition, I’d like to understand how to perform this reinitialization without affecting the other tables: should I remove the table from the Replication Flow and add it again, or is it sufficient to restart the replication process for that table? And does this procedure change depending on the load type (Initial only, Delta only, Initial and Delta)?&lt;/P&gt;&lt;P&gt;Thanks&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/re-initialization-of-a-table-in-a-replication-flow/qaq-p/14235534"/>
    <published>2025-10-06T10:51:09.449000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-datasphere-q-amp-a/qaq-p/14237672</id>
    <title>SAP Datasphere: Q&amp;A</title>
    <updated>2025-10-08T03:05:33.229000+02:00</updated>
    <author>
      <name>p_m8</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/401599</uri>
    </author>
    <content>&lt;P&gt;Hi,&lt;/P&gt;&lt;P&gt;I just wondering if this is right place/forum to discuss/post questions related to SAP Datasphere?&lt;/P&gt;&lt;P&gt;If not, pls direct me to the right forum.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Thank you.&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-datasphere-q-amp-a/qaq-p/14237672"/>
    <published>2025-10-08T03:05:33.229000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/unable-to-replicate-data-from-bw-7-5-dso-to-datasphere/qaq-p/14238718</id>
    <title>Unable to replicate data from BW 7.5 DSO to Datasphere</title>
    <updated>2025-10-08T22:20:29.329000+02:00</updated>
    <author>
      <name>Krisen_P</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2042048</uri>
    </author>
    <content>&lt;P&gt;Hi,&lt;/P&gt;&lt;P&gt;We have a requirement to replicate a specific set of data from BW 7.5 (On-Premise) to SAP Datasphere. We have the connection to BW setup via the cloud connector but we cannot see any of the DSOs when creating a dataflow. The client does not intend to have DPA or BW Bridge.&lt;/P&gt;&lt;P&gt;How can we replicate the data directly to Datasphere (without migration to BW Bridge or use of DPA)? The record counts to be replicated can be in excess of 100M records&lt;/P&gt;&lt;P&gt;Thanks&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/unable-to-replicate-data-from-bw-7-5-dso-to-datasphere/qaq-p/14238718"/>
    <published>2025-10-08T22:20:29.329000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/cannot-replicate-data-from-table-when-different-trigger-options-exist/qaq-p/14239052</id>
    <title>Cannot replicate data from table when different trigger options exist</title>
    <updated>2025-10-09T10:09:55.538000+02:00</updated>
    <author>
      <name>bhat_vaidya2</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/206951</uri>
    </author>
    <content>&lt;P&gt;Hi,&lt;/P&gt;&lt;P&gt;I am having error "&lt;SPAN&gt;Initial load partitioning failed due to the following error: Partitioning for object VBRP failed / Preparation steps in SLT failed. / Cannot replicate data from table ; different trigger options exist"&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;replicating table using new mass transfer Id.&lt;/P&gt;&lt;P&gt;I have looked at table&amp;nbsp;IUUC_LOGTAB_ID and could see multiple entries but MTD 006 has a different INDENT values. I am trying to use MTD 009 for replication.&amp;nbsp;&lt;/P&gt;&lt;P&gt;How do I resolve this issue&amp;nbsp;&lt;/P&gt;&lt;P&gt;thanks,&lt;/P&gt;&lt;P&gt;Bhat&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/cannot-replicate-data-from-table-when-different-trigger-options-exist/qaq-p/14239052"/>
    <published>2025-10-09T10:09:55.538000+02:00</published>
  </entry>
</feed>
