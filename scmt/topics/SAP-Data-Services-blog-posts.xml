<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/SAP-Data-Services-blog-posts.xml</id>
  <title>SAP Community - SAP Data Services</title>
  <updated>2025-08-24T11:12:41.800929+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/SAP Data Services/pd-p/01200314690800000395" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>SAP Data Services blog posts in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/moving-a-task-from-one-ci-ds-organization-to-another/ba-p/13599397</id>
    <title>Moving a Task from One CI DS Organization to Another</title>
    <updated>2024-02-13T09:39:40.899000+01:00</updated>
    <author>
      <name>Harshavardhan_N</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/124498</uri>
    </author>
    <content>&lt;P&gt;The process of importing a task from one SAP Cloud Integration for Data Services (CI DS) client to another is like copying a job or task. You can transfer a single task or all tasks within a project by exporting them and subsequently importing them into a different organization or a new datacenter.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Export Task:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Log in to the CI DS organization from where you wish to copy the task.&lt;/P&gt;&lt;P&gt;Choose the specific task or project that includes the tasks you want to export.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Harshavardhan_N_0-1707396072974.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/62764i5E1D4E804D9D2C42/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Harshavardhan_N_0-1707396072974.png" alt="Harshavardhan_N_0-1707396072974.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Click&amp;nbsp;&lt;STRONG&gt;More Actions &amp;gt; Export&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;A file is saved to your local Downloads directory. Single tasks are exported to a flat file in XMI format and saved with a&amp;nbsp;.xml&amp;nbsp;file extension. All tasks in a project are exported in a zip file.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Import Task:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;After exporting a single task or all tasks in a project, finalize the transfer by importing them into a new organization or datacenter. To import tasks, you must have the Administrator role. Tasks are imported into a project, so identify the project where you intend to import the tasks.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Choose the project where you intend to import the individually exported task or group of tasks from an exported project, then click on "More Actions" &amp;gt; "Import."&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Harshavardhan_N_1-1707396072979.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/62763iBA7D062D16491418/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Harshavardhan_N_1-1707396072979.png" alt="Harshavardhan_N_1-1707396072979.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once you click "Import," a new window will pop up. Follow the instructions on the screen to choose the file containing the task or project you want to import.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Harshavardhan_N_2-1707396072980.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/62762iC681819C8187675B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Harshavardhan_N_2-1707396072980.png" alt="Harshavardhan_N_2-1707396072980.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Browse to the location where you saved the exported task or project.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;If you exported a single task, the file has a .xml extension.&lt;/LI&gt;&lt;LI&gt;If you exported a project, the file has a .zip extension.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Additionally, provide the task name, source datastore name, and target datastore name. If the Datastore belongs to a File Format Group, check the box located on the right side of the Datastore details.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Harshavardhan_N_3-1707396072981.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/62766i0BA58F5BE8986887/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Harshavardhan_N_3-1707396072981.png" alt="Harshavardhan_N_3-1707396072981.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Click OK.&lt;/P&gt;&lt;P&gt;The task will be imported successfully. Now, you can change the target or source by editing the dataflow. You can modify the transformations, filters, and mappings as per the required.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/moving-a-task-from-one-ci-ds-organization-to-another/ba-p/13599397"/>
    <published>2024-02-13T09:39:40.899000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/sap-bi-4-x-installation-quot-error-quot-an-install-is-already-running-at/ba-p/13603909</id>
    <title>SAP BI 4.x Installation - "Error" An install is already running at this location on Linux</title>
    <updated>2024-02-14T09:34:56.200000+01:00</updated>
    <author>
      <name>Abhishek_Sinha</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/172574</uri>
    </author>
    <content>&lt;P&gt;Recently I was tasked to install SAP Data Services on Linux and while doing so I faced an issue where the installer failed with the error - &lt;STRONG&gt;"Install already in progress"&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;U&gt;&lt;STRONG&gt;Environment:&lt;/STRONG&gt;&lt;/U&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;Application:&lt;/STRONG&gt; Business Object Data Services&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;OS:&lt;/STRONG&gt; Linux&lt;/P&gt;&lt;P&gt;&lt;U&gt;&lt;STRONG&gt;Steps to reproduce the error&lt;/STRONG&gt;:&lt;/U&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Log on as a non-root user&lt;/LI&gt;&lt;LI&gt;Set the environment variables&lt;/LI&gt;&lt;LI&gt;Run &lt;STRONG&gt;./setup.sh&lt;/STRONG&gt; of the BI installer (IPS in this case)&lt;/LI&gt;&lt;LI&gt;Enter the install directory&lt;/LI&gt;&lt;LI&gt;The installer will fail with the error message - &lt;STRONG&gt;"Install already in progress"&lt;/STRONG&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="BODS_Issue.png" style="width: 508px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/64688i02F5B0C1AFAB9A64/image-size/large?v=v2&amp;amp;px=999" role="button" title="BODS_Issue.png" alt="BODS_Issue.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;I tried the below steps to resolve it but failed:&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;1. Delete and recreate the installation folder&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;2. Perform a reboot of the server&lt;/P&gt;&lt;P&gt;I found a few notes and blogs related to this error that pointed towards deleting all files &lt;STRONG&gt;".mutex"&lt;/STRONG&gt; in the &lt;STRONG&gt;/tmp&lt;/STRONG&gt; folder.&amp;nbsp;&lt;SPAN&gt;While trying to follow one of the SAP notes &lt;A href="https://me.sap.com/notes/0002790905" target="_self" rel="noopener noreferrer"&gt;2790905&lt;/A&gt;, I found no &lt;STRONG&gt;".mutex"&amp;nbsp;&lt;/STRONG&gt;file in the &lt;STRONG&gt;/tmp&lt;/STRONG&gt;&amp;nbsp;folder as no installer was running in parallel or the root user was used to perform a failed installation.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The logs were not helpful at this point as they were directing to an installer running in parallel or failing causing the issue.&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;To gather more helpful logs I tried running the trace as follows:&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;strace -f -o install.out ./setup.sh (followed by your normal patch install command arguments)&lt;/code&gt;&lt;/pre&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;(note, install.out needs to be written to a location this user has permission to write to. So you might need to run it like so: strace -f -o /tmp/install.out for example)&lt;/P&gt;&lt;P&gt;Once the installer fails, check the install.out file for "mutex" by running the below command&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;grep mutex install.out&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;In my case, the output showed that the user was unable to set the "mutex" file due to lack of permission and was assuming that the presence of another such file was preventing this hence the error message read - "Install already in progress"&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="mutex.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/64709iEDA4B354E43AC6B6/image-size/large?v=v2&amp;amp;px=999" role="button" title="mutex.png" alt="mutex.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;After setting the correct permission I ran the installer again and this time it moved past the error resulting in a successful installation.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="IPS.png" style="width: 852px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/64712i5F1A2CA12A816D1E/image-size/large?v=v2&amp;amp;px=999" role="button" title="IPS.png" alt="IPS.png" /&gt;&lt;/span&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Conclusion:&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;SPAN&gt;In case anyone comes across this issue and is unable to find any ".mutex" file in the /tmp folder to delete then perform a check on the write permissions of the non-root user being used to perform the installation. The strace command can also be run to ascertain the root cause.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Refer to the note:&amp;nbsp;&lt;A href="https://me.sap.com/notes/0002790905" target="_self" rel="noopener noreferrer"&gt;&lt;SPAN&gt;2790905 - An install is already running at this location on Linux in BI 4.x while performing update&lt;/SPAN&gt;&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/sap-bi-4-x-installation-quot-error-quot-an-install-is-already-running-at/ba-p/13603909"/>
    <published>2024-02-14T09:34:56.200000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/performance-tuning-in-sap-data-service/ba-p/13608857</id>
    <title>Performance tuning in SAP Data Service</title>
    <updated>2024-02-19T20:07:03.690000+01:00</updated>
    <author>
      <name>pallab_haldar</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/594699</uri>
    </author>
    <content>&lt;P&gt;Today I will discuss about performance tuning in SAP Data Service.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Performance tuning in SAP Data Service can be divided into two parts :&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Configurations/ Setting Changes :&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;1. &lt;/STRONG&gt;Use Degree of parallelism (DOP) option in the data flow to a value greater than one and 3-4. Use the data integrator features like Table partitioning, File multithreading , Degree of parallelism for data flows with DOP to get better performance.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;2.&lt;/STRONG&gt;&amp;nbsp; In Source database If we increase the size of database I/O, increase the size of the shared buffer to cache more data if will help to perform the&amp;nbsp;Select&amp;nbsp;statements quickly.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;3.&lt;/STRONG&gt; In Target Database disable the Archive logging, disable the Redo logging for all tables. It will help to perform&amp;nbsp;&lt;STRONG&gt;INSERT&lt;/STRONG&gt;&amp;nbsp;and&amp;nbsp;&lt;STRONG&gt;UPDATE&lt;/STRONG&gt;&amp;nbsp;quickly.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;4.&lt;/STRONG&gt; We need to increase the monitor sample rate to 40K or more as per standard to get more performance.&lt;/P&gt;&lt;P&gt;5. To avoid performance degradation we need to&amp;nbsp;exclude the Data Services logs from the virus scan if the virus scan is configured on the job server.&lt;/P&gt;&lt;P&gt;6.&amp;nbsp; For the first time execution&amp;nbsp;Select the option COLLECT STATISTICS FOR OPTIMIZATION . For the second time onwards. Use collected stats which is selected by default.&lt;/P&gt;&lt;P&gt;7. Design a job such a way that runs one&amp;nbsp;&lt;STRONG&gt;‘Al engine’&lt;/STRONG&gt;&amp;nbsp;process per CPU at a time.&amp;nbsp;&lt;/P&gt;&lt;P&gt;8. Based on the scenario ( for Large scale of data) increase the&amp;nbsp;Array Fetch size value&amp;nbsp; to avoid repetitively go to the database every time to fetch the data. Set it more than 800.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="pallab_haldar_3-1708369509382.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/67867iD584B3A26EDB5820/image-size/medium?v=v2&amp;amp;px=400" role="button" title="pallab_haldar_3-1708369509382.png" alt="pallab_haldar_3-1708369509382.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Design/Development Changes :&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;1.&lt;/STRONG&gt;&amp;nbsp; &lt;STRONG&gt;Push Down all the transformation logic implemented in SQL&lt;/STRONG&gt; to Database layer to&amp;nbsp;leverage the power of the database engine. To check the Optimized code pushed to the database engine please check the below -&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="pallab_haldar_0-1708367188988.png" style="width: 475px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/67851i491FF601A0AF2BAD/image-dimensions/475x112?v=v2" width="475" height="112" role="button" title="pallab_haldar_0-1708367188988.png" alt="pallab_haldar_0-1708367188988.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;But there are few restriction and clause for SQL push down operation.&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;When pushdown is not possible in a DF then enable Bulk Loader on the target table. Bulk loader is much faster than using direct load.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="pallab_haldar_1-1708367359361.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/67854i0B97F0FBA010FBFD/image-size/medium?v=v2&amp;amp;px=400" role="button" title="pallab_haldar_1-1708367359361.png" alt="pallab_haldar_1-1708367359361.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;In case there is a "&lt;STRONG&gt;select Distinct&lt;/STRONG&gt;" then the code will not push down fully. If we can not avoid to use it please use select distinct then use it in the last query transform before the target table.&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;Use Single Query Transform you want to use Group by and Order by.&lt;/LI&gt;&lt;LI&gt;Try to avoid&amp;nbsp;data type conversions which prevents full push down.&lt;/LI&gt;&lt;LI&gt;Always try to avoid&amp;nbsp;parallel execution of Query Transforms&amp;nbsp;which prevents full push down.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;2. Join Rank :&lt;/STRONG&gt; Please define the rank properly to make execution speed faster.&amp;nbsp;Open the Query Editor&amp;nbsp; assign the rank for larger tables. The highest ranked table will act as a driving table and execute .&amp;nbsp;Monitor log file allows you to see the order in which the&amp;nbsp;Data Services Optimizer performs the joins which&amp;nbsp;will help you to identify the performance improvement. To add the trace go to&amp;nbsp;&lt;STRONG&gt;Optimized Data Flow --&amp;gt;&amp;nbsp;&lt;/STRONG&gt;&lt;STRONG&gt;Trace&amp;nbsp;&lt;/STRONG&gt;tab --&amp;gt;&amp;nbsp;&amp;nbsp;&lt;STRONG&gt;Execution Properties&lt;/STRONG&gt;&amp;nbsp;dialog.&lt;/P&gt;&lt;P&gt;3. Set the &lt;STRONG&gt;"Rows per Commit"&lt;/STRONG&gt; value between 500 and 2000 where default is 1000.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="pallab_haldar_2-1708368449686.png" style="width: 521px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/67855i287D90E0BFFDA575/image-dimensions/521x249?v=v2" width="521" height="249" role="button" title="pallab_haldar_2-1708368449686.png" alt="pallab_haldar_2-1708368449686.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;4. Try to split complex logics of a single dataflow into multiple dataflows which is easy to maintenance and help to SQL pushdown.&amp;nbsp;&lt;/P&gt;&lt;P&gt;5.&amp;nbsp; Create index for columns which used in where clause as joining condition. This is a major point to improve performance&amp;nbsp;drastically.&lt;/P&gt;&lt;P&gt;6. Always&amp;nbsp;full pushdown is not possible. In that scenario if the dataset is larger enable the Bulk Loader on the target table.&amp;nbsp;&lt;/P&gt;&lt;P&gt;7. Use join instead of Lookup function if possible.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/performance-tuning-in-sap-data-service/ba-p/13608857"/>
    <published>2024-02-19T20:07:03.690000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/data-quality-audit/ba-p/13613355</id>
    <title>Data Quality Audit</title>
    <updated>2024-02-21T12:46:34.652000+01:00</updated>
    <author>
      <name>amitharayil</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/160304</uri>
    </author>
    <content>&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;One of the indispensables, &lt;STRONG&gt;essential and dominant parts of our lives is our smart phone&lt;/STRONG&gt;. You can almost say there is nothing a smart phone cannot do nowadays. However, &lt;STRONG&gt;technological advancements do not stop there&lt;/STRONG&gt;, we have continuous innovations been introduced into our surroundings.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;STRONG&gt;Over 20 years&lt;/STRONG&gt;, we saw the first mobile phones with antennas that &lt;STRONG&gt;evolved into faster, lighter, graphical, and more intuitive devices&lt;/STRONG&gt;. This is a splendid &lt;STRONG&gt;example of technological transformation&lt;/STRONG&gt;.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;We started off with just voice communication over analog signals which transformed into so much more. We can now access the &lt;STRONG&gt;world’s news and information at our fingertips&lt;/STRONG&gt;, &lt;STRONG&gt;communicate&lt;/STRONG&gt; and &lt;STRONG&gt;network&lt;/STRONG&gt; within our circle - even with strangers based on our geographic location - &lt;STRONG&gt;shop&lt;/STRONG&gt;, &lt;STRONG&gt;trade&lt;/STRONG&gt;, &lt;STRONG&gt;manage finances&lt;/STRONG&gt; and organize our lives globally from wherever we may be.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="amitharayil_0-1708442681695.png" style="width: 741px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/68401i0C90B2C259070682/image-dimensions/741x278?v=v2" width="741" height="278" role="button" title="amitharayil_0-1708442681695.png" alt="amitharayil_0-1708442681695.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;As mobiles get smarter and smarter, think about the &lt;STRONG&gt;data&lt;/STRONG&gt; that has been transferred from one device to another. And these transfers came with several implications and adjustments to the data over the years. For instance,&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;STRONG&gt;Compliance wise&lt;/STRONG&gt; – with the onset of international calling, phone numbers were suddenly required to be stored in international format.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;STRONG&gt;Competition wise&lt;/STRONG&gt; – amongst varied brands, more features kept pouring in terms of speed, additional fields, and memory to store more contacts and addresses.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="helvetica" size="2"&gt;Looking at &lt;STRONG&gt;technology trends&lt;/STRONG&gt; – devices now have the power of internet telephony, connecting themselves to self-driving cars and comprehensive mobile applications to become a pocket computer.&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Data quality is the least of our concern as we are focused on the &lt;STRONG&gt;outcome&lt;/STRONG&gt; to move to the new device and get started, by just ensuring that we retain the data in the new device in some form. The advanced intelligent machines assume implicitly that the data transferred to them is suitable for their intended purposes. We all know that transfers across platforms and vendors are limited by data models and technical limitations.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Consider this scenario: during the transfer of data between different device platforms, envision a situation where contact numbers or addresses are jumbled. You may have been consuming this data over years across devices manually, knowing the limitations and issues in the data, and deciding accordingly &lt;EM&gt;e.g., Mobile phone and Office phone fields have data interchanged during transfer, and postcode missed in the addresses during transfer from Apple to Google platform&lt;/EM&gt;. Now, imagine relying on this data on your mobile device with a self-driving car to navigate you to your destination e.g., AI considering only street name to navigate and deciding between multiple options!&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;How can you &lt;STRONG&gt;trust the data&lt;/STRONG&gt; that has been &lt;STRONG&gt;moved from your old devices into the newest device via multiple devices and platforms&lt;/STRONG&gt;?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Would you be able to &lt;STRONG&gt;use the full capability of the new AI self-driving cars&lt;/STRONG&gt;?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Is the data that we have been maintaining for decades &lt;STRONG&gt;fit to be used in these innovations without human intervention&lt;/STRONG&gt;?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Or more simply, is the &lt;STRONG&gt;data fit for the new intended purpose&lt;/STRONG&gt;?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="amitharayil_1-1708442703186.png" style="width: 743px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/68404i2285C3E599EF4F08/image-dimensions/743x339?v=v2" width="743" height="339" role="button" title="amitharayil_1-1708442703186.png" alt="amitharayil_1-1708442703186.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Now coming back to the corporate world and considering the business point of view for customers who have moved their enterprise data assets across multiple platforms over last few decades to SAP ECC or any other ERP system. Most of these customers are now in the process of transforming their technical landscape and business processes to get ready for the future, i.e., Cloud! Whether these organizations are moving to private or public cloud, RISE with SAP or GROW with SAP, going greenfield or brownfield; the transition mirrors the evolution we discussed earlier with mobile phones but, in this case, businesses are shifting from their familiar ERP ECC systems to the futuristic landscape of SAP S/4HANA. It involves migrating from mixed landscapes, including SAP, non-SAP, and legacy systems, into the innovative &lt;STRONG&gt;SAP S/4HANA platform&lt;/STRONG&gt;. The &lt;STRONG&gt;AI and Generative AI&lt;/STRONG&gt; capabilities embedded in SAP S/4HANA mimics &lt;STRONG&gt;driverless cars &lt;/STRONG&gt;we mentioned before. So, we find ourselves asking the same questions once again:&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;STRONG&gt;Does the data make sense for the S/4HANA system? Can we take advantage of the GenAI capabilities?&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;STRONG&gt;Can we rely on and trust the data for the system to predict your business outcomes or take business decisions?&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;STRONG&gt;In the end, is the data fit for intended purpose?&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;STRONG&gt;Data quality (DQ) is always the key focus and concern from the business at the beginning of the transformation, however as program evolves, DQ topic fades as the business priority moves to ensure processes are designed and tested. &lt;/STRONG&gt;The challenge is that no one could really quantify and establish the problem to define a business case to invest in data cleansing to save costs for the organization. By the time business users realize the scope of issues through migration, &lt;STRONG&gt;it is too late to fix this proble&lt;/STRONG&gt;&lt;STRONG&gt;m&lt;/STRONG&gt; and they are already testing the processes. If at the end they are successful in migration, they still end up with &lt;STRONG&gt;technically correct and not “business correct” data set&lt;/STRONG&gt;.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;This helps us see those businesses, like individuals with mobile phones, need to make sure their data is ready for the changes and innovations in their systems.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="4" color="#3366FF"&gt;&lt;STRONG&gt;How do we ensure data is fit for purpose?&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Let us address this topic again with the same mobile phone analogy. Consider this scenario: you are moving from an old Nokia phone to an iPhone. The former mobile phone saved contacts separately and did not have any tagging features to link landline or mobiles numbers of the same person together. However, the new iPhone has the feature to add multiple numbers with tags to a single contact. Now when you are moving to the new phone quite literally, the contacts can become redundant in your new device and cause confusion. &lt;STRONG&gt;How would you be able to tell apart which number is landline and which is mobile?&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Similarly, what if some mobile numbers were &lt;STRONG&gt;transferred incorrectly&lt;/STRONG&gt; and lead to &lt;STRONG&gt;missing information&lt;/STRONG&gt; in your contacts? Or during transfers and conversion of formats to comply with international codes, &lt;STRONG&gt;incorrect patterns&lt;/STRONG&gt; were transferred, or the numbers truncated?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="amitharayil_2-1708442703201.png" style="width: 749px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/68403iEF12553534FFCE79/image-dimensions/749x277?v=v2" width="749" height="277" role="button" title="amitharayil_2-1708442703201.png" alt="amitharayil_2-1708442703201.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;This would affect&lt;STRONG&gt; your new device’s ability to function as expected and for you to utilise innovative features&lt;/STRONG&gt; on your contacts.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="amitharayil_3-1708442703207.png" style="width: 746px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/68402i5C9599FB57C072EF/image-dimensions/746x360?v=v2" width="746" height="360" role="button" title="amitharayil_3-1708442703207.png" alt="amitharayil_3-1708442703207.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Many such examples can come up in various parts of the transfer journey between the devices especially when you are &lt;STRONG&gt;moving between technically diverse landscapes&lt;/STRONG&gt;. How do we ensure we &lt;STRONG&gt;do not move junk or bad data into our systems&lt;/STRONG&gt;? Or if we &lt;STRONG&gt;already have moved without auditing the data first&lt;/STRONG&gt;, how can we &lt;STRONG&gt;identify inferior quality data&lt;/STRONG&gt; in our current landscapes?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;The first step to check if data is fit for purpose is to &lt;STRONG&gt;understand the depth and extent of your data issues&lt;/STRONG&gt;. To &lt;STRONG&gt;understand&lt;/STRONG&gt; your data issues, you need to &lt;STRONG&gt;audit the data&lt;/STRONG&gt;. The data may appear clean, but the question is if it’s fit for the intended purpose.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="amitharayil_4-1708442703211.png" style="width: 752px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/68406i6BE5E47D31DD8152/image-dimensions/752x109?v=v2" width="752" height="109" role="button" title="amitharayil_4-1708442703211.png" alt="amitharayil_4-1708442703211.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;In the business world, the information spread across your systems is undeniably the most valuable asset. Achieving 100% data quality is a challenging task for any organization, but depending on how crucial each aspect is to the business, you can prioritize and make it feasible over time. For example, if there are 100 fields or attributes that require attention, and only 70% of them are essential for your business operations, you can identify key areas to concentrate on and begin planning for improvement. So, where do we begin?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#3366FF"&gt;&lt;STRONG&gt;&lt;FONT face="helvetica" size="4"&gt;What is Data Quality Audit?&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Data Quality Audit, a service offered by SAP, assesses, and checks the actual data stored in systems to uncover the existing issues and determine fitness for target systems like S/4HANA, C4C, ARIBA, MDG etc. Irrespective of the number of systems you have, or at which stage you are in your transformation journey, Data Quality Audit checks the ‘quality’ of the data in terms of ideal principles set by your business and generates a ‘scorecard’ along with a business impact ‘cost analysis’. This allows organizations to assess the status of their data and then help formulate their cleansing, resource and migration plans accordingly.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Let us briefly look at the steps that this service follows to achieve the results:&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="amitharayil_5-1708442703219.png" style="width: 758px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/68407iFB4962C60C63248F/image-dimensions/758x192?v=v2" width="758" height="192" role="button" title="amitharayil_5-1708442703219.png" alt="amitharayil_5-1708442703219.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Once scoping is established, data quality ‘rules’ are defined on the data with business or IT. The ‘rules’ originate from ideal principles of data quality: Accuracy, Completeness, Conformity, Consistency, Integrity, Timeliness, Uniqueness. SAP offers best practices content of data quality rules as a QuickStart to any quality audit.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;These ‘rules’ are then executed on the data, and ‘scorecards’ are established in a dashboard-like view. The scorecards also depict the associated cost impact analysis for the poor data quality. This then helps enterprises to assess their data, constantly review their data during the cleansing activities, supporting control and governance.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="amitharayil_6-1708442703220.png" style="width: 341px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/68405i032C52909D0955F6/image-dimensions/341x179?v=v2" width="341" height="179" role="button" title="amitharayil_6-1708442703220.png" alt="amitharayil_6-1708442703220.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;&lt;FONT size="4"&gt;&lt;STRONG&gt;&lt;FONT color="#3366FF"&gt;To conclude&lt;/FONT&gt;&lt;/STRONG&gt;&lt;STRONG&gt;&lt;FONT color="#3366FF"&gt;,&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Data Quality Audit is a service that is pivotal in the initial 'Get Clean' phase of your transformation. Unfortunately, these aspects are often underestimated, leading to the failure or delay of numerous transformations. Taking these steps seriously is crucial, as neglecting them can jeopardize the success of your large-scale investment, impede growth, and hinder the identification of business issues.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="helvetica" size="2"&gt;Consider these three key takeaways:&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;FONT face="helvetica" size="2"&gt;Recognize the vital role of Reference Data Quality Audit and Data Quality Audit in achieving a clean transformation. &lt;FONT color="#339966"&gt;&lt;EM&gt;Look out for a similar blog on &lt;STRONG&gt;Reference Data Quality Audit&lt;/STRONG&gt; - stay tuned!&lt;/EM&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="helvetica" size="2"&gt;Be mindful of the commonly underestimated nature of these steps, as it can significantly impact the success of your initiative.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="helvetica" size="2"&gt;Formulate robust 'Stay Clean' and ‘Get Clean’ plans based on the insights gained, avoiding pitfalls that have derailed many transformations."&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-quality-audit/ba-p/13613355"/>
    <published>2024-02-21T12:46:34.652000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/farewell-to-an-era-the-end-of-an-iconic-certification-of-sap-bods-c-ds-42/ba-p/13654158</id>
    <title>Farewell to an Era: The End of an Iconic Certification of SAP BODS - C_DS_42</title>
    <updated>2024-03-31T19:16:30.842000+02:00</updated>
    <author>
      <name>venkateshgolla</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/226126</uri>
    </author>
    <content>&lt;P&gt;Hello All,&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;continuing to the previous blogs on SAP DS 4.2 and 4.3&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;A class="" title="End of ERA - SAP BODS 4.2" href="https://community.sap.com/t5/technology-blogs-by-members/end-of-era-sap-bods-4-2/ba-p/13562152" target="_self"&gt;End of ERA - SAP BODS 4.2&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://blogs.sap.com/2021/10/06/sap-bods-data-services-road-map-ds-4.3/" target="_blank" rel="noopener noreferrer"&gt;SAP BODS / Data services road map DS 4.3 | SAP Blogs&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://blogs.sap.com/2022/05/14/sap-data-services-bods-4.3-release-installation-new-features-of-bods-4.3/" target="_blank" rel="noopener noreferrer"&gt;SAP Data services (BODS) 4.3 release / Installation / new features of BODS 4.3 | SAP Blogs&lt;/A&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Today, we're diving into a topic near and dear to the hearts of many in the data services realm: the legendary certification, C_DS_42, for BODS 4.2. For over a decade, this certification has been the holy grail for data services consultants, a badge of honor symbolizing expertise and proficiency in SAP's Data Services platform.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="venkateshgolla_0-1711905285942.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/88896i25AFD8410A3FED61/image-size/large?v=v2&amp;amp;px=999" role="button" title="venkateshgolla_0-1711905285942.png" alt="venkateshgolla_0-1711905285942.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;However, as with all good things, its time has come to an end. On the 28th of March 2024, the C_DS_42 certification officially expired, marking the end of an era for many professionals who have cherished and pursued it.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;What makes this transition even more surprising is the fact that its successor, C_DS_43, the certification for the latest version of Data Services, has also met the same fate, entering the realm of expired certifications.&lt;/P&gt;&lt;P&gt;For those who have dedicated countless hours to mastering BODS 4.2 and preparing for the C_DS_42 exam, this news may come as a bittersweet moment. It's a reminder of the ever-evolving nature of technology and the necessity of staying current in a field where innovation waits for no one.&lt;/P&gt;&lt;P&gt;But fear not, for every ending marks a new beginning. While bidding farewell to C_DS_42 may evoke a sense of nostalgia, it also presents an opportunity for renewal and growth. As the industry moves forward, so must we.&lt;/P&gt;&lt;P&gt;So what's next? For those who held C_DS_42 with pride, it's time to embark on a new journey. Whether it's upgrading to the latest version of Data Services or exploring other avenues within the data management landscape, there are plenty of opportunities to expand our horizons and continue making a meaningful impact.&lt;/P&gt;&lt;P&gt;As we reflect on the legacy of C_DS_42, let's remember the skills and knowledge it has imparted upon us. Let's honor the hard work and dedication that went into achieving this certification, and let's carry that same passion into the next chapter of our professional lives.&lt;/P&gt;&lt;P&gt;Farewell, C_DS_42. You may be expired, but your legacy lives on in the countless professionals you've inspired along the way.&lt;/P&gt;&lt;P&gt;Here's to new beginnings and the endless possibilities that lie ahead.&lt;/P&gt;&lt;P&gt;Thanks,&lt;/P&gt;&lt;P&gt;Venkatesh Golla&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/farewell-to-an-era-the-end-of-an-iconic-certification-of-sap-bods-c-ds-42/ba-p/13654158"/>
    <published>2024-03-31T19:16:30.842000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-members/futuristic-aerospace-or-defense-btp-data-mesh-layer-using-collibra-next/ba-p/13666113</id>
    <title>Futuristic Aerospace or Defense BTP Data Mesh Layer using Collibra, Next Labs ABAC/DAM, IAG and GRC</title>
    <updated>2024-04-11T19:00:57.747000+02:00</updated>
    <author>
      <name>STALANKI</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/13911</uri>
    </author>
    <content>&lt;H1 id="toc-hId-862635520"&gt;Background&lt;/H1&gt;&lt;P&gt;In this blog, we will explore few ideas for creating a domain-centric data mesh using SAP components, without engaging in the debate of whether data fabric or data mesh is the right approach.&lt;/P&gt;&lt;P&gt;We will focus on a futuristic use case within the Aerospace or Defense industry, which demands stringent data governance due to compliance requirements such as ITAR, EAR, BAFA, DOE 810, NERC/CIP, and SEC. Additionally, safeguarding intellectual property is a critical concern as business growth often relies on increased collaboration, both internally and externally, spanning product and engineering, supply chain, cross industry- partnerships, and joint ventures. I am happy to hear your ideas too!&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="aero.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/95260iED73CA1C7AC54354/image-size/large?v=v2&amp;amp;px=999" role="button" title="aero.png" alt="aero.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H1 id="toc-hId-666122015"&gt;Business Problem&lt;/H1&gt;&lt;P&gt;Aerospace and defense customers often face challenges in keeping up with rapid technological advancements due to the burden of data debts and the need to comply with stringent legal and regulatory data security requirements.&lt;/P&gt;&lt;P&gt;This challenge is further amplified when dealing with legacy ERP systems, as identifying and restricting sensitive data becomes complex, hindering the end-to-end data lifecycle management.&amp;nbsp;Moreover, the Aerospace and defense industry grapples with the formidable challenge of reducing IT costs, as the presence of significant data risks renders offshore operations an impractical option.&lt;/P&gt;&lt;P&gt;Let's consider the example of a product manager based in the United States, working for a US corporation. Their product is subject to ITAR regulations but has both government and commercial applications.&lt;/P&gt;&lt;P&gt;In order to comply with the business rule, the access to ITAR data in SAP should only be granted to US persons while they are in US locations. However, when this product manager is on a business trip to Singapore, meeting with suppliers at their APAC regional headquarters, exposing material data, CAD drawings, or BOMs stored in SAP would violate ITAR regulations.&lt;/P&gt;&lt;P&gt;In the context of a UK energy company establishing a joint venture with a local company in China to cater to the emerging market, an added layer of data security is required based on location. This ensures that access to BOM items and intellectual property not related to the joint venture is restricted, safeguarding sensitive information and preserving the integrity of the collaboration.&lt;/P&gt;&lt;P&gt;&lt;FONT face="georgia,palatino" color="#3366FF"&gt;&lt;EM&gt;&lt;STRONG&gt;In the context of the aerospace and defense , "Data is not only the ammunition that fuels engines but it is also an the armor that protects international and national peace"&lt;/STRONG&gt;&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;H1 id="toc-hId-469608510"&gt;BTP SAP S/4 HANA Data Mesh Pattern&lt;/H1&gt;&lt;P&gt;To solve the problem described above, we will hypothetically integrate Collibra, Next Labs ABAC/DAM, IAG and GRC&amp;nbsp; and SAP S/4 HANA&amp;nbsp; to provide data insights to users without compromising&amp;nbsp; data security requirements. Please note that is is hypothetical pattern and we have to review and apply it according to client specific data security requirements.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="BTP Data Mesh Architecture.jpg" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/95266i6D71E029D628C0A9/image-size/large?v=v2&amp;amp;px=999" role="button" title="BTP Data Mesh Architecture.jpg" alt="BTP Data Mesh Architecture.jpg" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;TABLE border="1" width="100%"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="50%" height="30px"&gt;&lt;STRONG&gt;&lt;FONT color="#3366FF"&gt;Solution Components&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="50%" height="30px"&gt;&lt;STRONG&gt;&lt;FONT color="#3366FF"&gt;Usage&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="50%" height="139px"&gt;Collibra&lt;/TD&gt;&lt;TD width="50%" height="139px"&gt;This component can be used to document and define data governance policies, meta data catalogue, end to end data lineage, data quality KPI's, data protection and data privacy rules for bill of materials.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="116px"&gt;SAP IAG&lt;/TD&gt;&lt;TD height="116px"&gt;&amp;nbsp;SAP IAG can handle the user access request and provisioning workflows to authenticate and authorize the user identity with the client's identity provider (ex: Active Directory)&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="139px"&gt;SAP GRC&lt;/TD&gt;&lt;TD height="139px"&gt;SAP GRC can provide the necessary controls and policies for access management and perform risk analysis and segregation of duties (SoD) checks, ensuring compliance with regulatory requirements across all SAP applications in the landscape.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="850px"&gt;Next Labs ABAC/DAM&lt;/TD&gt;&lt;TD height="850px"&gt;&lt;P&gt;Next Labs ABAC/DAM provides robust protection against unauthorized access to sensitive SAP data by implementing fine-grained access controls.&lt;/P&gt;&lt;P&gt;These controls can be applied at the level of individual data attributes or data ranges, enabling customers to safeguard their data while meeting compliance requirements. By examining the attributes of the data being accessed, the context of the request, and the user's identity, Next Labs ABAC/DAM allows organizations to control access to data, business transactions, and batch processes based on defined policies.&lt;/P&gt;&lt;P&gt;With SAP DAM, any changes in the attributes of the data or the user are dynamically considered, and the relevant policies are applied in real-time to enforce fine-grained access controls across various business functions. For example, a rule may specify that only US-based employees can access ITAR-classified materials from US locations. When a user attempts to access such materials, this rule is validated in real-time, ensuring that access is granted only to authorized individuals who meet the specified criteria.&lt;/P&gt;&lt;P&gt;Through the integration of Next Labs ABAC/DAM with SAP systems, organizations can effectively protect their sensitive data, maintain compliance, and enforce granular access controls across a wide range of business operations.&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="50px"&gt;SAP Data sphere&lt;/TD&gt;&lt;TD height="50px"&gt;&lt;P&gt;This is optional but we can use this if you want to provide flexible predictive analytics to the users.&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;SAP BTP AI Launch Pad&lt;/TD&gt;&lt;TD&gt;&lt;P&gt;This is optional and can be used to identify repeat breach patterns, time and detect security data anomalies in advance and add further access controls.&amp;nbsp;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H1 id="toc-hId-273095005"&gt;MVP- Bill of Material Data Mesh&lt;/H1&gt;&lt;P&gt;In the world of aerospace and defense, organizations face the challenge of managing bill of material (BOM) data across multiple systems. R By integrating diverse systems such as SAP S/4HANA, Team Center, and Siemens, they created a unified network of interconnected data mesh. This will enable seamless collaboration among internal and external engineering, supply chain, and product sales teams. With real-time visibility into BOMs, teams made informed decisions, optimized designs, synchronized manufacturing, and tailored offerings. The BOM data mesh can empower the organizations to achieve faster product development cycles, reduced costs, and improved customer satisfaction.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 1:&lt;/STRONG&gt; Define Role Requirements, Meta-data catalo Data Governance and access policies for BOM in Collibra&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Identify the specific role requirements based on your organization's needs and compliance regulations.&lt;/LI&gt;&lt;LI&gt;Determine the attributes that will be used for access control, such as user roles, data sensitivity, and contextual factors.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Step 2:&lt;/STRONG&gt; Understand BOM Creation and Editing Requirements&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;The organization requires that only users with specific engineering roles can create and edit BOMs. Additionally, certain fields in the BOM may be restricted for external supply chain users based on data sensitivity, such as pricing information.&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;Determine the functional access (actions user can perform) and data access (data records or fields users can see) and governance (rules for access)&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Step 3: &lt;/STRONG&gt;Define SAP S/4HANA Role&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Create a custom role named "BOM Specialist" or copy standard role in SAP S/4HANA.&lt;BR /&gt;Assign the authorization object M_BOM_GRP to the role, which controls access to BOM groups.&lt;/LI&gt;&lt;LI&gt;Assign transaction codes CS01 (Create BOM) and CS02 (Change BOM) to allow users with this role to perform BOM creation and editing tasks.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Step 4: Configure Next Lab ABAC DAM&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;SAP Next Lab ABAC DAM works natively with SAP and manages authorization logic through an externalized, standards-based policy framework. For instance, a rule may state, “Allow only US-based employees to access ITAR-classified materials from US locations.” When a user attempts to access materials, this rule is validated in real-time before access is granted.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&amp;nbsp;Configure Next Lab ABAC with attributes such as "User Role," "Data Sensitivity Level," and "Contextual Factors."&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;Define "User Role" as an attribute to determine the user's role in the organization.&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;Define "Data Sensitivity Level" as an attribute to classify BOMs based on their sensitivity, such as "Confidential" or "Public."&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;Define "Contextual Factors" as attributes to consider additional factors, such as project or department.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Step 5: Integrate SAP GRC and Next Lab ABAC&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This MVP use case leverages SAP GRC Access Control and SAP authorization for Governance and Functional Authorization and leverages ABAC for Data Authorization. It combines the features and fully integrated capabilities of SAP GRC Access Control and SAP authorization, such as ease of user assignment and role management, to efficiently supporting data attributes and avoiding the “role explosion” and custom development that would otherwise be necessary and costly.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Integrate SAP GRC and Next Lab ABAC to synchronize roles and access control policies.&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;Map the "BOM Specialist" role in SAP GRC to the corresponding role in Next Lab ABAC, ensuring consistency in access control.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Step 5: Define ABAC Policies&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&amp;nbsp;Define ABAC policies in Next Lab ABAC to enforce attribute-based access control for BOM creation and editing.&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;Create a policy that allows users with the "BOM Specialist" role (User Role attribute) to create and edit BOMs.&lt;/LI&gt;&lt;LI&gt;Create a policy that restricts access to certain fields in the BOM based on the "Data Sensitivity Level" attribute and user profile policy (&lt;STRONG&gt;Ex:&lt;/STRONG&gt; Manufacturing, Engineering, Supply Chain).&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Step 6: Test and Validate the Role using AI&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Train the model on different user profiles to validate data access using SAP BTP AI Launch Pad&lt;/LI&gt;&lt;LI&gt;Train the model further to auto-correct access issues and detect patterns to suggest changes to role access profiles (don’t let AI implement dynamic role access changes as it can be dangerous &lt;span class="lia-unicode-emoji" title=":smiling_face_with_smiling_eyes:"&gt;😊&lt;/span&gt;)&lt;/LI&gt;&lt;LI&gt;Perform supervised automated test to test the “BOM Specialist" role by assigning it to a user and verifying that they can successfully create and edit BOMs.&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;Validate that the ABAC policies.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Step 7: Integration SAP BTP Identity Access Governance to Active Directory&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;By integrating SAP BTP Identity Access Governance directly, users can seamlessly access data from multiple systems, including SAP S/4HANA, Team Center, Siemens, and other engineering, manufacturing, and supply chain systems. This integration enables a cohesive data mesh approach, allowing users to view and manage bill of materials across various systems.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 8: Integrate Collibra and Datasphere to Monetize and Publish bill of material insights to engineering, supply chain and product sales team.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;You have the ability to define and design self-service analytic insight reports, which can be monetized and shared with both your internal and external engineering, supply chain, and product sales teams.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-members/futuristic-aerospace-or-defense-btp-data-mesh-layer-using-collibra-next/ba-p/13666113"/>
    <published>2024-04-11T19:00:57.747000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/data-and-analytics-blog-posts/why-don-t-we-use-data-and-analytics-group-on-sap-community/ba-p/13666201</id>
    <title>Why Don't We Use Data and Analytics Group on SAP Community?</title>
    <updated>2024-04-18T18:28:14.375000+02:00</updated>
    <author>
      <name>TuncayKaraca</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/137163</uri>
    </author>
    <content>&lt;P&gt;Hey Data and Analytics Folks! Why Don't We Use &lt;A href="https://community.sap.com/t5/data-and-analytics/gh-p/data-analytics" target="_self"&gt;Data and Analytics&lt;/A&gt; Group on SAP Community instead of &lt;A href="https://community.sap.com/t5/technology/ct-p/technology" target="_self"&gt;Technology&lt;/A&gt;?&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="TuncayKaraca_1-1712778519559.png" style="width: 761px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/94808iB9F1693F79E6207B/image-dimensions/761x194?v=v2" width="761" height="194" role="button" title="TuncayKaraca_1-1712778519559.png" alt="TuncayKaraca_1-1712778519559.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Of course, it does not matter at the end. As long as if you tag your posts with SAP Managed tags everybody can find your posts. But there is a really one huge difference for usability that here in &lt;A href="https://community.sap.com/t5/interest-groups/ct-p/interests" target="_self"&gt;Interests Groups&lt;/A&gt; we can &lt;STRONG&gt;reply-the-reply&lt;/STRONG&gt; but under &lt;A href="https://community.sap.com/t5/products-and-technology/ct-p/products" target="_self"&gt;Products and Technology&lt;/A&gt;&amp;nbsp;we cannot! Check out this blog post&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/sap-datasphere-is-ready-to-take-over-the-role-of-sap-bw/bc-p/13666176" target="_self"&gt;SAP Datasphere is ready to take over the role of SAP BW&lt;/A&gt; by&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/705968"&gt;@kenneth_dalvik&lt;/a&gt;&amp;nbsp;and all responses that are very all boring sequential --there is no&amp;nbsp;&lt;STRONG&gt;reply-the-reply&lt;/STRONG&gt; option!&amp;nbsp;&lt;span class="lia-unicode-emoji" title=":upside_down_face:"&gt;🙃&lt;/span&gt;&lt;/P&gt;&lt;P&gt;So let's start using this group&amp;nbsp;Here is already available &lt;A href="https://community.sap.com/t5/data-and-analytics/gh-p/data-analytics" target="_self"&gt;Data and Analytics&lt;/A&gt;.&amp;nbsp; &amp;nbsp;The group will be definitely a perfect fit for &lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Analytics+Cloud/pd-p/67838200100800006884" class="lia-product-mention" data-product="3-1"&gt;SAP Analytics Cloud&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Datasphere/pd-p/73555000100800002141" class="lia-product-mention" data-product="16-1"&gt;SAP Datasphere&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Analytics+Cloud%25252C+hybrid+analytics/pd-p/464f79a9-d5e9-4113-8e9f-7ff61b577b4f" class="lia-product-mention" data-product="6-1"&gt;SAP Analytics Cloud, hybrid analytics&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+HANA+Cloud%25252C+SAP+HANA+database/pd-p/ada66f4e-5d7f-4e6d-a599-6b9a78023d84" class="lia-product-mention" data-product="40-1"&gt;SAP HANA Cloud, SAP HANA database&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Analytics+Cloud%25252C+connectivity/pd-p/0db4caf8-3039-4a93-9d11-543de33255a4" class="lia-product-mention" data-product="193-1"&gt;SAP Analytics Cloud, connectivity&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Analytics+Cloud%25252C+analytics+designer/pd-p/3f33380c-8914-4b7a-af00-0e9a70705a32" class="lia-product-mention" data-product="97-1"&gt;SAP Analytics Cloud, analytics designer&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+S%25252F4HANA+Cloud%25252C+extended+edition/pd-p/73b37c4d-a4aa-4de9-aeb9-a5dc59710b26" class="lia-product-mention" data-product="244-1"&gt;SAP S/4HANA Cloud, extended edition&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+S%25252F4HANA+Embedded+Analytics/pd-p/8492b555-b489-4972-8e37-83f2f27ae399" class="lia-product-mention" data-product="1067-1"&gt;SAP S/4HANA Embedded Analytics&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Business+Planning+and+Consolidation%25252C+version+for+SAP+NetWeaver/pd-p/01200615320800001016" class="lia-product-mention" data-product="460-1"&gt;SAP Business Planning and Consolidation, version for SAP NetWeaver&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Business+Warehouse+Accelerator/pd-p/01200615320800000698" class="lia-product-mention" data-product="722-1"&gt;SAP Business Warehouse Accelerator&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/BW+%252528SAP+Business+Warehouse%252529/pd-p/242586194391178517100436979900901" class="lia-product-mention" data-product="1-1"&gt;BW (SAP Business Warehouse)&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+BW%25252F4HANA/pd-p/73554900100800000681" class="lia-product-mention" data-product="466-1"&gt;SAP BW/4HANA&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/BW+SAP+BEx+Analyzer/pd-p/720735023700999283551380474299965" class="lia-product-mention" data-product="919-1"&gt;BW SAP BEx Analyzer&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/BW+SAP+BEx+Web/pd-p/835872679136515185293228681234825" class="lia-product-mention" data-product="920-1"&gt;BW SAP BEx Web&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+ASE+-+BW+Enablement/pd-p/758617099728293421716080695502398" class="lia-product-mention" data-product="1038-1"&gt;SAP ASE - BW Enablement&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/BW+SAP+HANA+Data+Warehousing/pd-p/337684911283545157914465705009179" class="lia-product-mention" data-product="921-1"&gt;BW SAP HANA Data Warehousing&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Data+Services/pd-p/01200314690800000395" class="lia-product-mention" data-product="527-1"&gt;SAP Data Services&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Data+Intelligence/pd-p/73555000100800000791" class="lia-product-mention" data-product="15-1"&gt;SAP Data Intelligence&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Data+Custodian/pd-p/73554900100700002051" class="lia-product-mention" data-product="1204-1"&gt;SAP Data Custodian&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Big+Data+Services/pd-p/73555000100800000691" class="lia-product-mention" data-product="439-1"&gt;SAP Big Data Services&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+BusinessObjects+-+Platform+Administration/pd-p/493706448058243238508632186627562" class="lia-product-mention" data-product="1051-1"&gt;SAP BusinessObjects - Platform Administration&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+BusinessObjects+-+Semantic+Layer/pd-p/280909257853820289811451573728573" class="lia-product-mention" data-product="1053-1"&gt;SAP BusinessObjects - Semantic Layer&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+BusinessObjects+Mobile/pd-p/01200314690800000346" class="lia-product-mention" data-product="337-1"&gt;SAP BusinessObjects Mobile&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+BusinessObjects+-+Semantic+Layer+-+SDK/pd-p/724814917412511087954547042734363" class="lia-product-mention" data-product="1054-1"&gt;SAP BusinessObjects - Semantic Layer - SDK&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+BusinessObjects+-+Web+Intelligence+%252528WebI%252529/pd-p/907900296036854683333078008146613" class="lia-product-mention" data-product="1055-1"&gt;SAP BusinessObjects - Web Intelligence (WebI)&lt;/a&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;These are welcome too &lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Master+Data+Governance/pd-p/67837800100800004488" class="lia-product-mention" data-product="697-1"&gt;SAP Master Data Governance&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+NetWeaver+Master+Data+Management/pd-p/01200615320800000588" class="lia-product-mention" data-product="739-1"&gt;SAP NetWeaver Master Data Management&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Data+Quality+Management+for+SAP+NetWeaver+MDM/pd-p/01200615320800002027" class="lia-product-mention" data-product="526-1"&gt;SAP Data Quality Management for SAP NetWeaver MDM&lt;/a&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;One thing I've noticed we cannot submit the blog posts directly. We need to "Submit for Review" only. You can still post discussions aka questions directly.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Thanks owners&amp;nbsp;@ColinC, @meganhoy, @moshenaveh, @caroleighdeneen, @craigcmehil for their support!&lt;/P&gt;&lt;P&gt;Regards,&lt;BR /&gt;Tuncay Karaca&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/data-and-analytics-blog-posts/why-don-t-we-use-data-and-analytics-group-on-sap-community/ba-p/13666201"/>
    <published>2024-04-18T18:28:14.375000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/bods-migration/ba-p/13695491</id>
    <title>BODS migration</title>
    <updated>2024-05-14T10:39:48.281000+02:00</updated>
    <author>
      <name>divikaus</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/853697</uri>
    </author>
    <content>&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;In this blog, I have detailed the steps taken for SAP BODS application migration from existing on premises to HANA database including the DR Testing Setup.&lt;/P&gt;&lt;P&gt;The Purpose of this blog is to provide a guidance path for migration of the BODS Application to HANA.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Existing Landscape Design:&lt;BR /&gt;&lt;/SPAN&gt;1. The IPS and DS version remain the same as on premises.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;In this landscape NW JAVA is used as underlying Web Application instead of Tomcat.&lt;/LI&gt;&lt;LI&gt;This landscape had additional WACS installation.&lt;/LI&gt;&lt;LI&gt;There is a single Central repository across the landscape.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Considerations prior to Migration:&lt;/SPAN&gt;&lt;BR /&gt;1. The Version history for Objects cannot be retained in case of a Migration of BODS application to another Database. SAP KBA 2768127.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;The migration is performed using the ATL code import mechanism.&lt;/LI&gt;&lt;LI&gt;Central Repository migration must be performed via ATL code import into local repository. i.e. An additional local repository needs to be created on prem for this activity.&lt;/LI&gt;&lt;LI&gt;For Installation and build the &amp;lt;SID&amp;gt;adm user should be using csh shell for IPS and NW JAVA.&lt;/LI&gt;&lt;LI&gt;For Installation and build the &amp;lt;SID&amp;gt;adm user should be using the bash shell for DS.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1123544859"&gt;Migration Steps:&lt;/H3&gt;&lt;OL&gt;&lt;LI&gt;Since the landscape consists of NW JAVA – Import / Export for NW JAVA via SWPM tool is used.&lt;/LI&gt;&lt;LI&gt;For the Database HANA MCD Setup is used. Corresponding users are created for each repository and the CMS &amp;amp; AUD repositories.&lt;/LI&gt;&lt;LI&gt;HANA Encryption performed as per the SAP Blog &lt;A href="https://community.sap.com/t5/technology-blogs-by-members/sap-hana-database-encryption/ba-p/13555367" target="_blank"&gt;SAP HANA Database Encryption - SAP Community&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;For HANA Database connectivity, UNIXodbc must be installed on all application servers for BODS.&lt;OL&gt;&lt;LI&gt;Can be checked by using ./odbcinst -j as root user.&lt;/LI&gt;&lt;LI&gt;Edit the odbc.ini file to allow for the connections to the HANA database from the BODS Application servers. The DSN entry could be for each user for the Repository / Single DSN used across the repositories, but the &amp;lt;CMS&amp;gt; and &amp;lt;AUD&amp;gt; DSN are mandatory. Examples below:&lt;BR /&gt;&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="divikaus_0-1715184048214.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/107615iADF29B9F59389B53/image-size/medium?v=v2&amp;amp;px=400" role="button" title="divikaus_0-1715184048214.png" alt="divikaus_0-1715184048214.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;The connection can be checked using the command as below as root user.&lt;OL&gt;&lt;LI&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; Command – isql &amp;lt;DSN&amp;gt; &amp;lt;USERNAME&amp;gt; &amp;lt;PASSWORD&amp;gt;&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Each BODS Application server requires its own IPS and DS installation.&lt;/P&gt;&lt;P&gt;Few important steps during the installation which needs to be considered:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;The IPS and DS Installation can be run directly using the patch download for the required version.&lt;/LI&gt;&lt;LI&gt;The Installation for IPS must be run with &amp;lt;SID&amp;gt;adm user under csh shell.&lt;/LI&gt;&lt;LI&gt;Once the CMS and AUD Repositories are confirmed on the HANA Database, select the option to manually deploy Web Applications&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="divikaus_1-1715184048226.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/107616i276670B29383009F/image-size/medium?v=v2&amp;amp;px=400" role="button" title="divikaus_1-1715184048226.png" alt="divikaus_1-1715184048226.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;The SIA name and port details need to be confirmed at this time to use &amp;lt;hostname&amp;gt; and port 6400 or any other port. We will cover cluster name change and cluster setup for IPS under step &amp;lt;f&amp;gt;.&lt;/LI&gt;&lt;LI&gt;In case of multiple Application servers for BODS – as mentioned above each server will require its own IPS and DS installation. While performing the second IPS installation for the CMS Information step, you will need to provide the hostname for the first IPS installation.&lt;/LI&gt;&lt;LI&gt;For changing the cluster name in case of multiple applications once the steps till &amp;lt;e&amp;gt; are completed, stop the IPS as per SAP note 2143877 - What is the correct start and stop order for Data Services components. Follow the SAP note 3169978 - How to change CMS cluster name in Linux for BI 4.x to update the cluster name. The input needed will be &amp;lt;hostname:port&amp;gt; while providing the new Cluster name – which will translate to &amp;lt;@hostname:port&amp;gt; while logging onto BOE/CMC &amp;amp; DSMC and Designer tool.&lt;/LI&gt;&lt;LI&gt;For DS Installation as well, run with &amp;lt;SID&amp;gt;adm user. The destination folder for the DS Installation can be pre-created.&lt;/LI&gt;&lt;LI&gt;For the CMS Logon during DS installation – provide each individual &amp;lt;hostname:port&amp;gt; information. Execute Step &amp;lt;f&amp;gt; at the end.&lt;/LI&gt;&lt;LI&gt;For our purpose we had re-used the DSConfig.txt from the on-premises, during the DS Installation – this helps to cover any added parameters into the DSCOnfig.txt file from on premises but does not help with the job server and repositories assignments – which must be repeated to be covered after step &amp;lt;l and m&amp;gt;&lt;/LI&gt;&lt;LI&gt;Since we had selected Web Application to be manually deployed, we will have to run Wdeploy to create the configuration files to be imported to NW JAVA via SUM Tool.&lt;OL&gt;&lt;LI&gt;Edit the file corresponding to the NW version under path &amp;lt;BODS Installation Directory&amp;gt;/enterprise_xi40/wdeploy/conf. The file name would be in the format config.sapappsvr&amp;lt;XX&amp;gt;&lt;/LI&gt;&lt;LI&gt;The inputs into this File would be against “as_sid”, “as_instance”, “as_admin_username” and “as_admin_password” fields&lt;/LI&gt;&lt;LI&gt;Run the command as ./wdeploy.sh sapappsvr&amp;lt;XX&amp;gt; predeployall&lt;/LI&gt;&lt;LI&gt;This creates the required files under path &amp;lt;BODS Installation Directory&amp;gt;/ enterprise_xi40/wdeploy/workdir/sapappsvr&amp;lt;XX&amp;gt;/application&lt;/LI&gt;&lt;LI&gt;Copy over these files to /usr/sap/trans/EPS/in&lt;/LI&gt;&lt;LI&gt;Run the SUM tool and import the components to the NW JAVA&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="divikaus_2-1715184048235.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/107617i2ADBE76BE2513253/image-size/medium?v=v2&amp;amp;px=400" role="button" title="divikaus_2-1715184048235.png" alt="divikaus_2-1715184048235.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;For WACS installation run the ./modifyOrRemoveProducts.sh under BODS installation directory and select the Information Platform Services to modify. Make sure to not remove any selections already showing – but only add the selection for “Web Application Container Service” in the Step and complete the installation providing the same information as provided during the IPS installation for each server.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="divikaus_3-1715184048254.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/107620i3D1DDA0A5972573B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="divikaus_3-1715184048254.png" alt="divikaus_3-1715184048254.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Create the Repositories corresponding to the Users created on the HANA Database using the below command.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Command to be run from &amp;lt;BODS installation Directory&amp;gt;/bin&lt;/P&gt;&lt;P&gt;./repoman -c -tlocal -U&amp;lt;USERNAME&amp;gt; -P&amp;lt;Password&amp;gt; -S&amp;lt;FQDN for the DB&amp;gt; -p&amp;lt;Tenant Port&amp;gt; -s -NHANA -Q&amp;lt;SID&amp;gt;&lt;/P&gt;&lt;P&gt;./repoman -c -tcentral -U&amp;lt;USERNAME&amp;gt; -P&amp;lt;Password&amp;gt; -S&amp;lt;FQDN for the DB&amp;gt; -p&amp;lt;Tenant Port&amp;gt; -s -NHANA -Q&amp;lt;SID&amp;gt;&lt;/P&gt;&lt;P&gt;For Central Repository the “Secure” option can be activated using the Repository Manager tool.&lt;/P&gt;&lt;P&gt;The Tenant port can be checked using the command from the SYSTEM Database&lt;/P&gt;&lt;P&gt;SELECT DATABASE_NAME, SQL_PORT FROM SYS_DATABASES.M_SERVICES&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Re-create the Job server and assign Repositories.&lt;OL&gt;&lt;LI&gt;Edit the DSConfig.txt file to remove the entries for Job Server, Access Server coming from On Premises. Find the Section [AL_JobServer] and remove the entries against fields “AL_JobServerName1” &amp;amp; “AL_JobServerPort1” and any more entries. Keep the Same Job Server name and port while recreating.&lt;/LI&gt;&lt;LI&gt;Find the Section [Access_Server] and remove the entry against “Connection_ID”&lt;/LI&gt;&lt;LI&gt;Once the above two are completed, when you run ./svrcfg it will prompt you to start creating Job Servers and assign Repositories against them. Re-create on each BODS Application server exactly as it was on Premises with the same port details.&lt;/LI&gt;&lt;LI&gt;For the usage of “Server Group” in DSMC – you will need to assign the same repository to multiple job servers on each BODS Application server.&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;LI&gt;You can source the al_env.sh and odbc.sh into the .bashrc file for the &amp;lt;SID&amp;gt;adm user by adding the below to entries to the file:&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;source /&amp;lt;BODS Installation Directory&amp;gt;/dataservices/DataDirect/odbc/odbc.sh&lt;/P&gt;&lt;P&gt;source /&amp;lt;BODS Installation Directory&amp;gt;/dataservices/bin/al_env.sh&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Once the above steps are completed – You can Export the LCMBIAR and ATL from the On-premises application and Import into the Target Environment.&lt;OL&gt;&lt;LI&gt;For LCMBIAR Export and Import Note that during the process, you will need to select each page and use the “select all” option above for each page. If not done, there could be some objects missed out.&lt;/LI&gt;&lt;LI&gt;Check the total objects being promoted from on premises and make sure the count is at least the same (could be more for target).&lt;/LI&gt;&lt;LI&gt;If the option “Hot Backup” is enabled under CMC in Settings each time you try to run the LCMBIAR File import and check the final count on promotable objects in the target it will show double – this is normal behaviour. Suggest deleting existing job and run a new job every time.&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;LI&gt;Login to CMC using the System details as &amp;lt;@Clustername:port&amp;gt; and under Data Services – you will need to delete and re-create each repository with the new hostname and port details.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-927031354"&gt;Disaster Recovery:&lt;/H3&gt;&lt;P&gt;The Disaster Recovery strategy used here is to have a pre-installed BODS Application and Database and during DR scenarios the latest available HANA backup is used to recover the Database on the DR Site. To achieve this, below steps were used.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;BODS Application including NW JAVA as described in the above section is pre-built on the DR VM provisioned along with the HANA tenant on the DR site.&lt;/LI&gt;&lt;LI&gt;Steps for LCMBIAR &amp;amp; ATL export/import, WACS Install, creation of repositories and Job Servers, Edit of the DSConfig.txt file are excluded in this build.&lt;/LI&gt;&lt;LI&gt;A VM Backup and HANA Database Backup is retained at this stage for future re-use.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;As part of the Disaster Recovery Test the below Steps are performed, without disturbing the existing Production Landscape.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;HANA backup from Production and Restore onto the DR Database.&lt;/LI&gt;&lt;LI&gt;Follow SAP note 1275068 to recreate SIA for the application.&lt;OL&gt;&lt;LI&gt;Select * from cms_infoobjects7 where parented=16 or parented=59;&lt;/LI&gt;&lt;LI&gt;Delete from cms_infoobjects7 where parented=16 or parented=59;&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;LI&gt;Re-create SIA using ./serverconfig.sh following SAP note 2206006. You will require the Cluster key and the CMS DSN user credentials to connect to the database from Production.&lt;/LI&gt;&lt;LI&gt;Change Cluster Name as detailed in the above section under step &amp;lt;f&amp;gt;.&lt;/LI&gt;&lt;LI&gt;For NW JAVA as the Database is coming in from Production backup – the only option is to uninstall – SAP Systems or Single Instances.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="divikaus_4-1715184048256.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/107618i41B260DE6BF21C97/image-size/medium?v=v2&amp;amp;px=400" role="button" title="divikaus_4-1715184048256.png" alt="divikaus_4-1715184048256.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Re-Install NW JAVA using the option Standard Installation under HANA Database, but using “Homogeneous System Copy” instead of “Standard System Copy” used during build.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="divikaus_5-1715184048259.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/107619i4A219BE33D65FF11/image-size/medium?v=v2&amp;amp;px=400" role="button" title="divikaus_5-1715184048259.png" alt="divikaus_5-1715184048259.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Provide the Existing Production Database SYSTEM and Schema details in the next steps along with the schema password and select “Data has already been Loaded”.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="divikaus_6-1715184048263.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/107621iEB2EEB4182BE6FEB/image-size/medium?v=v2&amp;amp;px=400" role="button" title="divikaus_6-1715184048263.png" alt="divikaus_6-1715184048263.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/bods-migration/ba-p/13695491"/>
    <published>2024-05-14T10:39:48.281000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/new-service-plan-lower-pricing-for-sap-data-quality-management/ba-p/13730090</id>
    <title>New Service Plan: Lower Pricing for SAP Data Quality Management, microservices for location data</title>
    <updated>2024-06-13T23:55:31.949000+02:00</updated>
    <author>
      <name>hozumi</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/36635</uri>
    </author>
    <content>&lt;H2 id="toc-hId-1017397365"&gt;Introduction:&lt;/H2&gt;&lt;P&gt;We are thrilled to announce an exciting update to &lt;A href="https://www.sap.com/products/technology-platform/data-quality-management.html" target="_blank" rel="noopener noreferrer"&gt;SAP Data Quality Management, microservices for location data&lt;/A&gt;. In our ongoing efforts to provide you with the best value and meet your evolving needs, we will be introducing a new, more affordable service plan available under the SAP BTP Enterprise Agreement (BTPEA) or Pay-As-You-Go for SAP BTP. The new &lt;EM&gt;Professional&lt;/EM&gt; plan will replace our existing &lt;EM&gt;Standard&lt;/EM&gt; plan, which will be gradually phased out in the coming months. We understand that change can be unsettling, but we assure you that this transition will bring numerous benefits and cost savings for all our valued customers.&lt;/P&gt;&lt;H2 id="toc-hId-820883860"&gt;Why the Change?&lt;/H2&gt;&lt;P&gt;As a customer-centric company, we continuously evaluate our offerings to ensure they align with your requirements and provide the best possible experience. After careful consideration and feedback from our customers, we have developed a new service plan that offers the same quality and features you love, but at a significantly lower cost. Our goal is to make our services more accessible and affordable to a wider range of customers.&lt;/P&gt;&lt;H2 id="toc-hId-624370355"&gt;What to Expect from the New Service Plan:&lt;/H2&gt;&lt;P&gt;Our new &lt;A href="https://discovery-center.cloud.sap/serviceCatalog/data-quality-services?region=all&amp;amp;tab=service_plan" target="_blank" rel="noopener nofollow noreferrer"&gt;&lt;EM&gt;Professional&lt;/EM&gt; plan&lt;/A&gt; will offer all the essential features and benefits of the existing &lt;EM&gt;Standard&lt;/EM&gt; plan, but at a reduced price point. The service will ensure backward compatibility with our service APIs, so you can simply migrate to the new service plan to work with your existing systems and workflows without any compatibility issues. However, the &lt;EM&gt;Professional&lt;/EM&gt; plan offers an opportunity for growth and expansion, so we encourage you to consider migrating to this plan when you are ready to leverage the benefits of future innovation.&lt;/P&gt;&lt;H2 id="toc-hId-427856850"&gt;Service Region Availability:&lt;/H2&gt;&lt;P&gt;We are happy to share the news that our service recently expanded its service operation in North America. We have now established operations in the United States and Germany, enabling customers in these regions to benefit from improved performance. By connecting to the service nearest to your environment, you can enjoy faster response times and a more seamless experience. The &lt;EM&gt;Professional&lt;/EM&gt; and &lt;EM&gt;Standard&lt;/EM&gt; plans are available in these regions; however, please remember that our future investment will only be in our &lt;EM&gt;Professional&lt;/EM&gt; plan.&lt;/P&gt;&lt;H2 id="toc-hId-231343345"&gt;How to get started:&lt;/H2&gt;&lt;P&gt;Getting started with the new service plan is simple and &lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/getting-started-with-sap-data-quality-management-microservices-for-location/ba-p/13527838" target="_blank"&gt;my previous article&lt;/A&gt; can still be a useful reference for you. If you have already tried our free plan, you can &lt;A href="https://help.sap.com/docs/data-quality-services/data-quality-services/upgrading-free-plan-service-to-standard-plan" target="_blank" rel="noopener noreferrer"&gt;upgrade to the professional plan&lt;/A&gt;. Alternatively, you can start directly with the &lt;EM&gt;Professional&lt;/EM&gt; plan by creating a new service instance in your subaccount on the SAP BTP Cockpit.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="hozumi_1-1718288856373.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/123318i944A158CD24A6D02/image-size/large?v=v2&amp;amp;px=999" role="button" title="hozumi_1-1718288856373.png" alt="hozumi_1-1718288856373.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;EM&gt;SAP BTP Cockpit Service Instance Creation&lt;/EM&gt;&lt;/P&gt;&lt;H2 id="toc-hId-34829840"&gt;What does this mean for existing customers?&lt;/H2&gt;&lt;P&gt;Don't worry, you can continue using your existing service plan until you are ready to switch over to the new service instance. This means that you can explore the new service plan at your own pace, without any disruptions to your current setup.&lt;/P&gt;&lt;H3 id="toc-hId--32600946"&gt;To update the service plan within your subaccount&lt;/H3&gt;&lt;P&gt;When you are ready to migrate to the new service plan, the simplest way is to update your existing service instance to the new service plan within your subaccount. You can follow &lt;A href="https://help.sap.com/docs/data-quality-services/data-quality-services/updating-to-professional-service-plan" target="_self" rel="noopener noreferrer"&gt;these simple but important steps&lt;/A&gt; to update your service plan correctly. The &lt;EM&gt;Professional&lt;/EM&gt; plan is available only in the Cloud Foundry environment. The update within your subaccount will retain your existing configurations and usage history.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="hozumi_2-1718288856388.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/123320iBF0AA0ECBEFE7657/image-size/large?v=v2&amp;amp;px=999" role="button" title="hozumi_2-1718288856388.png" alt="hozumi_2-1718288856388.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;EM&gt;SAP BTP Cockpit Service Instance Update&lt;/EM&gt;&lt;/P&gt;&lt;H3 id="toc-hId--229114451"&gt;To migrate to another subaccount&lt;/H3&gt;&lt;P&gt;If you want to migrate your service to another subaccount, you can create a new service instance in the target subaccount, configure the authentication method, and export any configuration files from your existing subaccount to your new subaccount if there is any custom configuration.&lt;/P&gt;&lt;P&gt;This process may be for your case if you are migrating from the Neo environment to the Cloud Foundry environment or moving to another data center.&lt;/P&gt;&lt;P&gt;To migrate from one subaccount to another, you can refer to our Neo to Cloud Foundry &lt;A href="https://help.sap.com/docs/data-quality-services/data-quality-services/migrating-data-quality-services-from-neo-to-cloud-foundry-environment" target="_blank" rel="noopener noreferrer"&gt;migration documentation&lt;/A&gt;. The process is also similar when moving between Cloud Foundry based subaccounts. However, please note that the transaction history data will not be transferred to the new subaccount. If you wish to retain a record of your past activities, you can optionally export the data before migrating.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="hozumi_3-1718288856397.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/123319iFC78842AFCDD9929/image-size/large?v=v2&amp;amp;px=999" role="button" title="hozumi_3-1718288856397.png" alt="hozumi_3-1718288856397.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;EM&gt;Data Quality Service UI Configuration Export&lt;/EM&gt;&lt;/P&gt;&lt;H2 id="toc-hId--554710675"&gt;Transition Timeline:&lt;/H2&gt;&lt;P&gt;We will soon announce the official deprecation date for the existing &lt;EM&gt;Standard&lt;/EM&gt; plan, and it will no longer be available for new customers. This means that new customers seeking to purchase our service plan will need to opt for the new &lt;EM&gt;Professional&lt;/EM&gt; plan under the &lt;A href="https://www.sap.com/products/technology-platform/pricing.html" target="_blank" rel="noopener noreferrer"&gt;SAP BTP Enterprise Agreement or Pay-As-You-Go for SAP BTP&lt;/A&gt;.&lt;/P&gt;&lt;H3 id="toc-hId--622141461"&gt;If you are using the service in the Cloud Foundry environment:&lt;/H3&gt;&lt;P&gt;Existing customers, however, can continue using the existing service plan until their contractual agreement is renewed. We value our long-standing customers and want to ensure a smooth transition for them. We suggest planning for the transition as soon as possible to take advantage of &lt;A href="https://discovery-center.cloud.sap/serviceCatalog/data-quality-services?region=all&amp;amp;tab=service_plan" target="_blank" rel="noopener nofollow noreferrer"&gt;the new pricing&lt;/A&gt; we offer with the new service plan.&lt;/P&gt;&lt;H3 id="toc-hId--893886335"&gt;If you are using the service in the Neo environment:&lt;/H3&gt;&lt;P&gt;&lt;FONT color="#FF0000"&gt;&lt;STRONG&gt;Warning!&lt;/STRONG&gt;&lt;/FONT&gt; We recommend you transition to the new environment as soon as possible, as the Neo environment will be deprecated in 2028. We will not add any new features to our deployments in the Neo environment. Please find additional details regarding the Neo deprecation in &lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/sap-business-technology-platform-neo-environment-sunset-questions-answers/ba-p/13557725" target="_blank"&gt;this article&lt;/A&gt;.&lt;/P&gt;&lt;H2 id="toc-hId--796996833"&gt;Conclusion:&lt;/H2&gt;&lt;P&gt;We are excited for the launch of our new service plan for SAP Data Quality Management, microservices for location data. The service is available in North America and Europe regions with attractive pricing options under SAP BTP Enterprise Agreement or Pay-As-You-Go for SAP BTP.&amp;nbsp; We believe the new lower-cost service plan with improved performance will provide significant value to our customers.&lt;/P&gt;&lt;P&gt;We encourage our existing customers to explore the &lt;A href="https://www.sap.com/products/technology-platform/data-quality-management.html" target="_blank" rel="noopener noreferrer"&gt;benefits of our service plan&lt;/A&gt; while we are committed to supporting their existing service operations based on the deprecation schedule outlined in their contractual agreement.&amp;nbsp; If you have any questions or concerns about the transition to the new service plan, please contact our customer support team. Thank you for your continued trust and support.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-service-plan-lower-pricing-for-sap-data-quality-management/ba-p/13730090"/>
    <published>2024-06-13T23:55:31.949000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/abap-cds-select-from-dynamic-data-source/ba-p/13748502</id>
    <title>ABAP CDS Select from dynamic data source</title>
    <updated>2024-07-08T14:20:49.192000+02:00</updated>
    <author>
      <name>AbdelrahmanZaki75</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/175819</uri>
    </author>
    <content>&lt;P&gt;Hello friends,&lt;BR /&gt;&lt;BR /&gt;I faced a little problem while reporting in Fund Management (FM) module as the tables are generated automatically while creating derivation rules with dynamic names and differs by system /client.&lt;/P&gt;&lt;P&gt;The rule entries are stored in the generated table "FMFMOAXXXYYYZZZZ", where XYZ symbols means as follows:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;XXX is the system specification (&lt;STRONG&gt;e.g., DE1 or QE1)&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;YYY is the client number (&lt;STRONG&gt;e.g., 120 or 200)&lt;/STRONG&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;ZZZZ is the number of the derivation rule (&lt;STRONG&gt;&lt;STRONG&gt;&lt;STRONG&gt;which you should have as per your table 31, 51, 64, or 61)&lt;/STRONG&gt;&lt;/STRONG&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;To be able to move my report / solution I had to selecting from dynamic source which is not supported in CDS!&lt;/P&gt;&lt;P&gt;After investing some time I came to try it using AMDP with table function&lt;/P&gt;&lt;P&gt;Now let's explain it as simple as possible.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;*Step 1 create a table function&amp;nbsp; *&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@EndUserText.label: 'demo table function' 
define table function zcds_amdp_demo_tf with parameters @Environment.systemField:#CLIENT clnt5 : abap.clnt, derivation : char4 
returns { 
MANDT : mandt ; 
SOUR1_FROM : ps_posid ;
SOUR1_TO : ps_posid ;
VALID_FROM : abaintab ;
TARGET1 : fistl;
DELETE_FLG : abadrdelflag;
ADDED_BY : abadrerfasser;
ADDED_ON : erdat; 

} 
implemented by method zcl_amdp_demo=&amp;gt;get_data; ​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;BR /&gt;&lt;STRONG&gt;*Step 2 Create the class &lt;SPAN&gt;zcl_amdp_demo*&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;CLASS zcl_amdp_demo DEFINITION PUBLIC FINAL CREATE PUBLIC.
PUBLIC SECTION.
INTERFACES: if_amdp_marker_hdb, if_oo_adt_classrun.

CLASS-METHODS get_data FOR TABLE FUNCTION zcds_amdp_demo_tf.
PROTECTED SECTION.
PRIVATE SECTION.
ENDCLASS.

CLASS zcl_amdp_demo IMPLEMENTATION. 
  METHOD get_data BY DATABASE FUNCTION FOR HDB LANGUAGE SQLSCRIPT OPTIONS READ-ONLY USING tadir.
    declare lv_fm_tab string; 
    declare tablename string; 
    declare clientnumber string; 
    declare systemid string; 
    declare deriv string;
*must be the same data types as consuming cds also in same order 
declare it_fm_tab table ( 
  MANDT nvarchar(3), 
  SOUR1_FROM nvarchar(24), 
  SOUR1_TO nvarchar(24), 
  VALID_FROM nvarchar(10), 
  TARGET1 nvarchar(16), 
  DELETE_FLG nvarchar(1), 
  ADDED_BY nvarchar(12),
  added_on nvarchar(10) ); 
  
* fmfmoaxxxyyyzzzz 
*fields from parameters 
clientnumber = clnt5; 
select srcsystem into systemid from tadir where pgmid = 'HEAD' and object = 'SYST';

*'COST' =&amp;gt; Cost Element = Commitment Item 
*'WBSE' =&amp;gt; wbs Element = Funds Center

  if derivation = 'COST' then
    if systemid = 'DS1' then deriv = '0051'; end if; 
    if systemid = 'QS1' then deriv = '0062'; end if; 
    if systemid = 'PS1' then deriv = '0051'; end if; 
  else
    if systemid = 'DS1' then deriv = '0052'; end if;
    if systemid = 'QS1' then deriv = '0064'; end if;
    if systemid = 'PS1' then deriv = '0041'; end if; 
  end if; 
  
  tablename = 'FMFMOA' || systemid || clientnumber || deriv; 
  
  EXECUTE immediate 'select MANDT, SOUR1_FROM, SOUR1_TO, VALID_FROM, TARGET1, DELETE_FLG, ADDED_BY, ADDED_ON from ' || tablename into it_fm_tab ;
  
  RETURN SELECT * FROM :it_fm_tab; ENDMETHOD.
ENDCLASS.
​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;STRONG&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;SPAN&gt;*&lt;STRONG&gt;Step 3 and final Create a sonsumable CDS view*&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZCDS_AMDP_DEMO_V' 
@AbapCatalog.compiler.compareFilter: true 
@AbapCatalog.preserveKey: true 
@AccessControl.authorizationCheck: #NOT_REQUIRED 
@EndUserText.label: 'CDS that consuming the TF' 
define view zcds_amdp_demo as select from zcds_amdp_demo_tf (clnt5 : $session.client, derivation : 'COST' ) 
//COST =&amp;gt; Cost Element = Commitment Item 
//WBSE =&amp;gt;WBS Element = Funds Center 
{ 
* 
}​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Output:&lt;/P&gt;&lt;P&gt;A Closer look: if you change the parameter from 'COST' to 'WBSE' the return changes which makes it dynamic selection now &lt;span class="lia-unicode-emoji" title=":slightly_smiling_face:"&gt;🙂&lt;/span&gt; .. congratulations!&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AbdelrahmanZaki_0-1720444829925.png" style="width: 766px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/133789i59E73C96096EA043/image-dimensions/766x324?v=v2" width="766" height="324" role="button" title="AbdelrahmanZaki_0-1720444829925.png" alt="AbdelrahmanZaki_0-1720444829925.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="AbdelrahmanZaki_1-1720444858014.png" style="width: 739px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/133790i4ED45EDBB7150539/image-dimensions/739x357?v=v2" width="739" height="357" role="button" title="AbdelrahmanZaki_1-1720444858014.png" alt="AbdelrahmanZaki_1-1720444858014.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;STRONG&gt;&lt;SPAN&gt;&lt;SPAN&gt;&lt;STRONG&gt;&lt;BR /&gt;&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/STRONG&gt;Please feel free to comment any observations, enhancements or recommendations.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;STRONG&gt;&lt;SPAN&gt;&lt;SPAN&gt;&lt;STRONG&gt;Regards,&lt;BR /&gt;Abdelrahman Zaki&lt;BR /&gt;&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/STRONG&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/abap-cds-select-from-dynamic-data-source/ba-p/13748502"/>
    <published>2024-07-08T14:20:49.192000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/statement-of-direction-sap-data-services-as-of-july-2024/ba-p/13762644</id>
    <title>Statement of Direction - SAP Data Services as of July 2024</title>
    <updated>2024-07-16T23:57:19.052000+02:00</updated>
    <author>
      <name>shibajee_dutta_gupta</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/480590</uri>
    </author>
    <content>&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="SAP-Logo.jpg" style="width: 126px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/137395i61B10CF313CC99BE/image-size/large?v=v2&amp;amp;px=999" role="button" title="SAP-Logo.jpg" alt="SAP-Logo.jpg" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="6"&gt;&lt;STRONG&gt;Statement of Direction – SAP Data Services&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;July 2024&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Introduction&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;As our matured products continues to have consistent traction in the market with emerging technologies and data platforms, it is essential for us to focus on extending its versions to meet the evolving needs of our customers. This Statement of Direction outlines our strategic approach to extending product versions, ensuring that we maintain our competitive edge in the on-premises data integration space as well as on-cloud and deliver value to our customers. Our primary objective is to understand and address the specific requirements of our customers, for the matured products as well as new and emerging technologies in the cloud. We will actively engage with our user base through feedback sessions, support channels, and market research to identify their pain points, challenges, and emerging needs.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Executive Summary&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This document provides guidance to our customers of SAP Data Management portfolio, with respect to SAP Data Services (DS) solution, on the product directions. &amp;nbsp;For Information Steward we will have a separate communication made available. This document is an extension of our&amp;nbsp; &lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/statement-of-direction-sap-data-services-and-sap-information-steward-as-of/ba-p/13577148" target="_self"&gt;blog&lt;/A&gt; post made on November 3, 2023, focused on SAP Data Services&lt;/P&gt;&lt;P&gt;SAP Data Management portfolio expanded further in the cloud with the introduction of SAP Datasphere in March 2023. SAP Datasphere is a comprehensive data service built only on SAP® Business Technology platform (SAP BTP) that enables every data professional to deliver seamless and scalable access to mission critical business data. It is the next generation of SAP® Data Warehouse Cloud, with new capabilities that enhance data discovery, modeling, and distribution. With a unified experience for data integration, data cataloging, semantic modeling, data warehousing, data federation, and data virtualization.&amp;nbsp; SAP Datasphere enables data professionals to easily distribute authoritative business data with business context and logic preserved across the data landscape.&lt;/P&gt;&lt;P&gt;As we define the future of SAP Data Management portfolio, with our stated data management strategy, current on-premise SAP Data Services customers can in fact leverage all their existing investments and efforts, repurposing those time-tested and trusted artifacts and configurations that are being used today in SAP Data Services (DS), while also extending the reach of their data management to the cloud, with SAP Datasphere, a native cloud solution. Yes, we are committed to our existing SAP Data Services and customer base too. In the current release of SAP Data Services, we do have the connector to SAP Datasphere to consume the raw, semi-processed as well as fully processed data from SAP Data Services connections. This capability enables to reduce the gap of heterogeneous sources and targets between SAP Data Services and SAP Datasphere.&lt;/P&gt;&lt;P&gt;“In 2022 we did a minor version upgrade of SAP Data Services to 4.3, allowing the compatibility with Business Intelligence BusinessObjects 4.3. As a result, our support policy extended the end of mainstream maintenance timeline to end of 2025 and priority 1 support to end of 2027 for both SAP Data Services and SAP Information Steward. &lt;EM&gt;We have made a change in Q3 of 2024, wherein the SAP Data Services and SAP Information Steward 4.3 timeline and extended the mainstream support till end of December 2026. Priority 1 support has been replaced with CSM (Customer Specific Maintenance)&lt;/EM&gt;. However, with the mainstream maintenance of version 4.3 of SAP Data Services suite ending in 2026, we do not want to leave our large customer base behind, and therefore we have decided to release an updated version, code named SAP Data Services 2025 to provide more time to our on-premises customers to adopt our rapidly evolving, state-of-the-art cloud data integration scenarios. As more of our customers shift their on-premises workloads to the cloud, we also offer SAP Data Services, private cloud edition (PCE), which runs the ETL and Data Quality solutions in a managed cloud environment operated by SAP. Many of our largest SAP Data Services customers already run both solutions side-by-side, during their transition to the managed cloud deployment.”&lt;/P&gt;&lt;TABLE width="100%"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;STRONG&gt;&lt;U&gt;SAP Data Services 2025 &lt;/U&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Our current plan to release a new version of the SAP Data Services in 2025 as a successor of SAP Data Services 4.3 remains unchanged and will be...&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;code named SAP Data Services 2025.&lt;/LI&gt;&lt;LI&gt;available on-premises and through managed cloud,&amp;nbsp;&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;focused on the most widely adopted on-premises scenarios: SAP Data Services for native ETL and Data Quality,&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;o&amp;nbsp;&amp;nbsp; Existing architecture and component map will be followed including Designer, Repository, Job Server, supported web applications and BI module.&lt;/P&gt;&lt;P&gt;o&amp;nbsp;&amp;nbsp; Compatible with proposed BI 2025 suite and planned to be released a quarter after BI 2025&lt;/P&gt;&lt;P&gt;o&amp;nbsp;&amp;nbsp; We have plans to release SAP Data Services 2025 by the end of Q2 2025 followed by ‘Fix Packages’ as needed.&lt;/P&gt;&lt;P&gt;o&amp;nbsp; We have plans to release a new version every alternate year and include continuous enhancements through patches and fix-packs.&amp;nbsp; This plan is aimed for faster enablement of improved and newly added functionalities.&lt;/P&gt;&lt;P&gt;o&amp;nbsp;&amp;nbsp; We will provide clear use case migration paths/workarounds for the components for the version we plan the end of support beyond 2027.&amp;nbsp;&lt;/P&gt;&lt;P&gt;o&amp;nbsp;&amp;nbsp; Continue to support Windows and Linux platforms only. AIX and Solaris support has already been discontinued in the 4.3 version of SAP Data Services.&lt;/P&gt;&lt;P&gt;o&amp;nbsp;&amp;nbsp; SAP &lt;STRONG&gt;&lt;EM&gt;private cloud edition (PCE) &lt;/EM&gt;&lt;/STRONG&gt;will continue to be primary option of availability for SAP Data Services on managed cloud as well as on premise.&amp;nbsp; The option to host on customers choice of private cloud and AWS EC3, Azure VM etc. remains unchanged.&lt;/P&gt;&lt;P&gt;o&amp;nbsp;&amp;nbsp; We do not foresee any impact to solutions and partners using SAP Data Services in an OEM mode.&amp;nbsp; &amp;nbsp;&lt;/P&gt;&lt;P&gt;o&amp;nbsp;&amp;nbsp; We also have plans to discontinue the support of few sources and targets based on their sunset timelines, market demand and popularity score.&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;STRONG&gt;We are committed to support you. &lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;We recognize the importance of continuously improving and innovating our product and yet manage a balance between our on-premises and cloud-based solutions. We will invest in research and development to explore new technologies, industry trends, and market demands yet support our existing customer base for the mature products. By fostering a culture of innovation and collaboration, we will ensure that our product versions remain cutting-edge and relevant in the ever-changing business landscape. We are committed to help and support our customers.&lt;/P&gt;&lt;P&gt;Many customers rely on SAP Data Services for critical use cases and will need to do so beyond 2025. Our support plan for SAP Data Services is as follows and our message is consistent. Please refer to the respective GA versions Product Availability Matrix for the support timelines. Please refer to SAP Note &lt;A href="https://me.sap.com/notes/3486924" target="_self" rel="noopener noreferrer"&gt;3486924&lt;/A&gt; for description of 'Customer Specific Maintenance'.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="RoadmapGraphPic.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251023iCCC878846FF6C3A2/image-size/large?v=v2&amp;amp;px=999" role="button" title="RoadmapGraphPic.png" alt="RoadmapGraphPic.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Your choice of deployment&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;With SAP Data Services, private cloud edition (PCE), we offer a predefined package operated by SAP on the main cloud platform providers, including software, support, technical managed services, and infrastructure. This also, opens an opportunity to shift from a maintenance contract to a subscription model while leveraging your existing investments in SAP Data Services solution.&lt;/P&gt;&lt;P&gt;Here are some of the key benefits:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;The latest version of SAP Data Services is always available, thanks to the periodical upgrades.&lt;/LI&gt;&lt;LI&gt;3-tier landscape: development/test, quality assurance and production by default, with optional additional tiers.&lt;/LI&gt;&lt;LI&gt;Pre-configured hardware landscapes optimized for performance,&lt;/LI&gt;&lt;LI&gt;Choice of cloud platform providers infrastructure includes AWS, Google Cloud Platform, Microsoft Azure.&lt;/LI&gt;&lt;LI&gt;End-to-end SLA 99.7%, backup and restore included within standard service scope.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;In the future, customers will continue to have the choice for their infrastructure for SAP Data Services solution, either on-premises or in a managed cloud operated by SAP. Additionally, our directions for the on-premises data integration and data governance scope with respect to SAP Data Services and SAP Information Steward remains mutually exclusive and unchanged due to the data integration and data governance scope within SAP’s cloud solutions.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;We have plans to stop or reduce the scope of few functionalities.&lt;/STRONG&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;PeopleTools&amp;nbsp; for PeopleSoft Applications&lt;/LI&gt;&lt;LI&gt;JD Edwards Application connectivity&lt;/LI&gt;&lt;LI&gt;SAP Sybase Replication Server&lt;/LI&gt;&lt;LI&gt;Siebel&lt;/LI&gt;&lt;LI&gt;SalesForce Adapter&lt;/LI&gt;&lt;LI&gt;Attunity aka Qlik Data Integration Platform&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;WE WANT TO HEAR FROM YOU&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;SAP Data Services remains as a key component of our Data Management portfolio, and we are committed to our customers. Please help us fine tune our roadmaps of SAP Data Services providing your input through the dedicated inbox:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;SAP Data Services:&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;sap.dataservices@sap.com&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;We appreciate your feedback and will answer your questions via our official communication channels.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/statement-of-direction-sap-data-services-as-of-july-2024/ba-p/13762644"/>
    <published>2024-07-16T23:57:19.052000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-members/unleashing-the-power-of-cds-views-in-sap-hana/ba-p/13775034</id>
    <title>Unleashing the Power of CDS Views in SAP HANA</title>
    <updated>2024-08-02T20:16:19.570000+02:00</updated>
    <author>
      <name>Avinashborate</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/894111</uri>
    </author>
    <content>&lt;H3 id="toc-hId-1150322941"&gt;Introduction to CDS Views in SAP HANA&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;Core Data Services (CDS)&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;views are a crucial aspect of SAP's data modeling capabilities, allowing for efficient and flexible data management. In this blog post, we'll explore what CDS views are, how they work, and why they are essential for SAP users and developers.&lt;/P&gt;&lt;H4 id="toc-hId-1082892155"&gt;Pre-requisites:SAP HANA Studio or Eclipse with ABAP Development Tools (ADT)&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;ABAP Backend System&lt;/LI&gt;&lt;LI&gt;Basic Knowledge of SQL and ABAP&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-757295931"&gt;What are CDS Views?&lt;/H3&gt;&lt;H4 id="toc-hId-689865145"&gt;Core Data Services (CDS)&lt;/H4&gt;&lt;P&gt;CDS is a framework for defining and consuming data models on SAP HANA, providing a powerful way to manage and retrieve data efficiently. Data models are fundamental in designing databases, ensuring data integrity, and optimizing data retrieval and manipulation. They serve as blueprints for how data is stored, accessed, and utilized across different SAP applications and modules.&lt;/P&gt;&lt;H3 id="toc-hId-364268921"&gt;Key Features and Benefits of CDS Views&lt;/H3&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Enhanced Performance:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;CDS views optimize data access, making it faster and more efficient.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Simplified Data Modelling:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;With CDS views, you can define complex data models using simple annotations and syntax.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Seamless Integration:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;CDS views integrate seamlessly with other SAP tools and applications.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;In ABAP, during select queries, it works like SELECT – SE11 – DB – SE11 – Query. In CDS, it works like SELECT – CDS – Query. Select options cannot be used in CDS Views; instead, annotations are required.&lt;/P&gt;&lt;H3 id="toc-hId-167755416"&gt;Components of CDS&lt;/H3&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;CDS Views:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;These are like database views but more powerful, allowing complex joins, associations, and calculations. They are defined using the CDS language and can be consumed in ABAP programs.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;CDS Entities:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;These are the core building blocks of CDS, representing data models that include tables, views, and associations.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Annotations:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;Annotations provide metadata about the CDS elements, such as descriptions, semantics, and UI information. They help in enhancing the functionality and integration with other SAP components.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Associations:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;Associations define relationships between CDS entities, making it easier to navigate and query related data.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;Step-by-Step Guide to ABAP CDS View Annotations and Buffering&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZVSQL_SAMPLE_01' // In this ABAP catalog, we can set the name for the DDIC.
@EndUserText.label: 'This is my first DDIC-based CDS' // Here we can set the description for this SQL view.
@AbapCatalog.preserveKey: true // With the help of this, we can set the key field as per our requirement.

@@@@@@@@@@@@@@@@@ If we Add Buffering then @@@@@@@@@@@@@@
@AbapCatalog: {
buffering: {
status: Buffering,
type: #NONE,
numberOfKeyFields: 000
},
dbHints: [{
dbSystem: '', // Here we can add a specific database
hint: ''
}],
ViewEnhancementCategory: [], // Here we can allow or not for CDS enhancement.
sqlViewName: '',
preserveKey: true,
compiler: {
compareFilter: true
}
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--28758089"&gt;Explanation&lt;/H3&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;@AbapCatalog.sqlViewName&lt;/STRONG&gt;: Sets the name for the DDIC.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;@EndUserText.label&lt;/STRONG&gt;: Sets the description for the SQL view.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;@AbapCatalog.preserveKey&lt;/STRONG&gt;: Allows setting the key field as per requirements.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Buffering Section&lt;/STRONG&gt;:&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;status&lt;/STRONG&gt;: Buffering status.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;type&lt;/STRONG&gt;: Type of buffering (#NONE means no buffering).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;numberOfKeyFields&lt;/STRONG&gt;: Number of key fields to be buffered.&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;dbHints&lt;/STRONG&gt;: Database hints section:&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;dbSystem&lt;/STRONG&gt;: Specifies the database system.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;hint&lt;/STRONG&gt;: Provides hints for the database.&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;ViewEnhancementCategory&lt;/STRONG&gt;: Allows or disallows CDS enhancements.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;compiler.compareFilter&lt;/STRONG&gt;: Compares the filter for the compiler.&lt;/LI&gt;&lt;/OL&gt;&lt;H3 id="toc-hId--225271594"&gt;Creating CDS Views in SAP&lt;/H3&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Open the SAP Development Environment:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;Launch SAP HANA Studio or Eclipse with ABAP Development Tools.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Create a New CDS View:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;Right-click on your project and select New &amp;gt; Other ABAP Repository Object &amp;gt; Data Definition.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Define the CDS View:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;Enter the required details, such as the name and description of the CDS view. Define the SQL-like syntax to specify the data model.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZC_MY_CDS_VIEW'
@AbapCatalog.compiler.compareFilter: true
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'My CDS View'
define view ZC_My_CDS_View as select from SFLIGHT {
    carrid,
    connid,
    fldate,
    price
}​&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;.Activate the CDS View:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;Once you've defined the view, activate it to make it available for use.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;STRONG&gt;Test the CDS View:&lt;/STRONG&gt;&amp;nbsp;Test the CDS view by executing it in the development environment to ensure it retrieves the expected data.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;SPAN&gt;&lt;STRONG&gt;CDS View Entity with Join and Literals&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;define view ZDDLS_SAMPLE as select from vbak inner join vbap on vbak.vbeln = vbap.vbeln {
    key vbak.vbeln as Sales_Order,
    vbak.vkorg as Sales_org,
    vbak.vkgrp,
    vbap.posar,
    vbap.matnr, 
    0.23 as num_lit,
    'CDS' as char_lit
}
where vbak.vbeln = '0237259939'&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;STRONG&gt;CDS View with Input Parameters&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;define view ZDDLS_SAMPLE with parameters p_vbeln : vbeln as select from vbak inner join vbap on vbak.vbeln = vbap.vbeln {
    key vbak.vbeln as Sales_Order,
    vbak.vkorg as Sales_org,
    vbak.vkgrp,
    vbap.posar,
    vbap.matnr, 
    0.23 as num_lit,
    'CDS' as char_lit
}
where vbak.vbeln = $parameters.p_vbeln&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Key Points to Remember&lt;/STRONG&gt;&lt;/P&gt;&lt;UL class="lia-list-style-type-square"&gt;&lt;LI&gt;We can give the SQL view name up to 16 characters.&lt;/LI&gt;&lt;LI&gt;Annotations provide vital metadata and enhance CDS functionality.&lt;/LI&gt;&lt;LI&gt;CDS views support various join types: inner join, left outer join, right outer join, union, and union all.&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId--421785099"&gt;Using Session Variables in CDS Views.&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;In SAP CDS views, session variables such as the current user or date are handled differently compared to traditional ABAP programming. When you need to use session variables like sy-uname (current user) or sy-datum (current date), you utilize the $session prefix in CDS views.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;define view ZDDLS_SAMPLE
as select from vbak
inner join vbap on vbak.vbeln = vbap.vbeln
{
    key vbak.vbeln as Sales_Order,
    vbak.vkorg as Sales_org,
    vbak.vkgrp,
    vbap.posar,
    vbap.matnr,
    0.23 as num_lit,
    'CDS' as char_lit,
    $session.user as current_user,
    $session.client as current_client,
    $session.system_language as current_language,
    $session.system_date as current_date
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--618298604"&gt;Explanation of Session Variables&lt;/H3&gt;&lt;OL class="lia-list-style-type-upper-roman"&gt;&lt;LI&gt;&lt;STRONG&gt;$session.user&lt;/STRONG&gt;: Retrieves the current user's ID.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;$session.client&lt;/STRONG&gt;: Retrieves the current client number.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;$session.system_language&lt;/STRONG&gt;: Retrieves the system language.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;$session.system_date&lt;/STRONG&gt;: Retrieves the current system date.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&amp;nbsp;Make sure you use the $session prefix followed by the appropriate keyword. Pressing Ctrl + Space after $session. will show you the available options, such as user, client, system_language, and system_date.&lt;/P&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;SAP CDS View String Operations&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;H3 id="toc-hId--890043478"&gt;1. Concatenating Strings&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;In CDS views, you can concatenate strings using the CONCAT keyword. However, by default, you can only concatenate two fields at a time. To concatenate more than two fields, you need to perform concatenation multiple times.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;define view ZCDS_CONCATENATION
as select from vbak
{
    key vbeln,
    erdat,
    ernam,
    concat(concat(vkorg, spart), 'additional_text') as concatenated_field
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--1086556983"&gt;2. Trimming Leading Characters&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The LTRIM function removes leading spaces or specific leading characters from a string.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZCDS_string_oper'
@AbapCatalog.compiler.compareFilter: true
@AbapCatalog.preserveKey: true
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'CDS string operations'
define view ZCDS_STRING_OPERATIONS 
as select from vbak
{
    key ltrim(vbeln, '0') as sales_order_no,
    erdat,
    ernam,
    ltrim(vkorg, '0') as vkorg,
    spart
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--1283070488"&gt;3. Trimming Trailing Characters&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The RTRIM function removes trailing spaces or specific trailing characters from a string..&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZCDS_string_oper'
@AbapCatalog.compiler.compareFilter: true
@AbapCatalog.preserveKey: true
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'CDS string operations'
define view ZCDS_STRING_OPERATIONS 
as select from vbak
{
    key ltrim(vbeln, '0') as sales_order_no,
    erdat,
    ernam,
    ltrim(vkorg, '0') as vkorg,
    spart,
    rtrim(vkorg, '0') as vkorg_trimmed
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--1479583993"&gt;4. Combining LTRIM and RTRIM&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;You can combine both LTRIM and RTRIM functions to clean up a string by removing leading and trailing characters.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZCDS_string_oper'
@AbapCatalog.compiler.compareFilter: true
@AbapCatalog.preserveKey: true
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'CDS string operations'
define view ZCDS_STRING_OPERATIONS 
as select from vbak
{
    key ltrim(vbeln, '0') as sales_order_no,
    erdat,
    ernam,
    ltrim(vkorg, '0') as vkorg,
    spart,
    rtrim(vkorg, '0') as vkorg_trimmed,
    ltrim(rtrim(vbeln, '0'), '0') as cleaned_vbeln
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--1676097498"&gt;5. Finding Substrings&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The INSTR function is used to find the position of a substring within a string.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZCDS_string_oper'
@AbapCatalog.compiler.compareFilter: true
@AbapCatalog.preserveKey: true
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'CDS string operations'
define view ZCDS_STRING_OPERATIONS 
as select from vbak
{
    key ltrim(vbeln, '0') as sales_order_no,
    erdat,
    ernam,
    ltrim(vkorg, '0') as vkorg,
    spart,
    rtrim(vkorg, '0') as vkorg_trimmed,
    ltrim(rtrim(vbeln, '0'), '0') as cleaned_vbeln,
    instr('Avinash Vasnat Borate', 'Borate') as position_of_substring
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--1872611003"&gt;6. Extracting Left Substrings&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The LEFT function extracts a specified number of characters from the beginning of a string.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZCDS_string_oper'
@AbapCatalog.compiler.compareFilter: true
@AbapCatalog.preserveKey: true
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'CDS string operations'
define view ZCDS_STRING_OPERATIONS 
as select from vbak
{
    key ltrim(vbeln, '0') as sales_order_no,
    erdat,
    ernam,
    ltrim(vkorg, '0') as vkorg,
    spart,
    rtrim(vkorg, '0') as vkorg_trimmed,
    ltrim(rtrim(vbeln, '0'), '0') as cleaned_vbeln,
    instr('Avinash Vasnat Borate', 'Borate') as position_of_substring,
    left('SAP ABAP HANA', 3) as left_substring
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--2069124508"&gt;7. Extracting Right Substrings&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The RIGHT function extracts a specified number of characters from the end of a string.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZCDS_string_oper'
@AbapCatalog.compiler.compareFilter: true
@AbapCatalog.preserveKey: true
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'CDS string operations'
define view ZCDS_STRING_OPERATIONS 
as select from vbak
{
    key ltrim(vbeln, '0') as sales_order_no,
    erdat,
    ernam,
    ltrim(vkorg, '0') as vkorg,
    spart,
    rtrim(vkorg, '0') as vkorg_trimmed,
    ltrim(rtrim(vbeln, '0'), '0') as cleaned_vbeln,
    instr('Avinash Vasnat Borate', 'Borate') as position_of_substring,
    left('SAP ABAP HANA', 3) as left_substring,
    right('SAP ABAP S4 HANA', 4) as right_substring
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-2029329283"&gt;8. Padding Strings&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The RPAD (Right Pad) function pads a string on the right side with a specified character until the string reaches a desired length.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZCDS_string_oper'
@AbapCatalog.compiler.compareFilter: true
@AbapCatalog.preserveKey: true
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'CDS string operations'
define view ZCDS_STRING_OPERATIONS 
as select from vbak
{
    key ltrim(vbeln, '0') as sales_order_no,
    erdat,
    ernam,
    ltrim(vkorg, '0') as vkorg,
    spart,
    rtrim(vkorg, '0') as vkorg_trimmed,
    ltrim(rtrim(vbeln, '0'), '0') as cleaned_vbeln,
    instr('Avinash Vasnat Borate', 'Borate') as position_of_substring,
    left('SAP ABAP HANA', 3) as left_substring,
    right('SAP ABAP S4 HANA', 4) as right_substring,
    rpad('EWM team', 6, 'XY') as padded_string
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1832815778"&gt;9. Replacing Substrings&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The REPLACE function replaces all occurrences of a specified substring within a string with another substring.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZCDS_string_oper'
@AbapCatalog.compiler.compareFilter: true
@AbapCatalog.preserveKey: true
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'CDS string operations'
define view ZCDS_STRING_OPERATIONS 
as select from vbak
{
    key ltrim(vbeln, '0') as sales_order_no,
    erdat,
    ernam,
    ltrim(vkorg, '0') as vkorg,
    spart,
    rtrim(vkorg, '0') as vkorg_trimmed,
    ltrim(rtrim(vbeln, '0'), '0') as cleaned_vbeln,
    instr('Avinash Vasnat Borate', 'Borate') as position_of_substring,
    left('SAP ABAP HANA', 3) as left_substring,
    right('SAP ABAP S4 HANA', 4) as right_substring,
    rpad('EWM team', 6, 'XY') as padded_string,
    replace('Avinash Borate', 'Avinash', 'Vicky') as updated_name
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1636302273"&gt;10. Extracting Substrings&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The SUBSTRING function extracts a specific portion of a string, starting from a given position and optionally for a specified length.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.sqlViewName: 'ZCDS_string_oper'
@AbapCatalog.compiler.compareFilter: true
@AbapCatalog.preserveKey: true
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'CDS string operations'
define view ZCDS_STRING_OPERATIONS 
as select from vbak
{
    key ltrim(vbeln, '0') as sales_order_no,
    erdat,
    ernam,
    ltrim(vkorg, '0') as vkorg,
    spart,
    rtrim(vkorg, '0') as vkorg_trimmed,
    ltrim(rtrim(vbeln, '0'), '0') as cleaned_vbeln,
    instr('Avinash Vasnat Borate', 'Borate') as position_of_substring,
    left('SAP ABAP HANA', 3) as left_substring,
    right('SAP ABAP S4 HANA', 4) as right_substring,
    rpad('EWM team', 6, 'XY') as padded_string,
    replace('Avinash Borate', 'Avinash', 'Vicky') as updated_name,
    substring(erdat, 5, 2) as month,
    substring(erdat, 1, 4) as year,
    substring(erdat, 7, 2) as date
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-members/unleashing-the-power-of-cds-views-in-sap-hana/ba-p/13775034"/>
    <published>2024-08-02T20:16:19.570000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/calling-rfc-in-bods-job-data-encryption-in-bods/ba-p/13779967</id>
    <title>Calling RFC in BODS job (Data Encryption in BODS)</title>
    <updated>2024-08-07T15:44:10.092000+02:00</updated>
    <author>
      <name>KALYANI_HEDAOO</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/863866</uri>
    </author>
    <content>&lt;P&gt;Scenario was to call the RFC which is used to create a custom key generation for encryption of data and use the custom key in BODS for certain fields for data encryption.&lt;/P&gt;&lt;P&gt;Steps to be done before using RFC in BODS,&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Create an RFC in given system with ABAP code.&lt;/LI&gt;&lt;LI&gt;Import the RFC in Data services repo, which is datastores in data services.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;After import of RFC,&lt;/P&gt;&lt;P&gt;To use the RFC in BODS , we require to use Row_Generation Transformation. This will act as a dummy input, After Row_Generation use Query Transformation in which RFC call can be made using normal function call in Query_encryption transformation as below,&lt;/P&gt;&lt;P&gt;Here, pass the required input parameters and get the output parameter, as shown below.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="KALYANI_HEDAOO_0-1722516958165.png" style="width: 556px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/145368i655CCD276C776B74/image-dimensions/556x357?v=v2" width="556" height="357" role="button" title="KALYANI_HEDAOO_0-1722516958165.png" alt="KALYANI_HEDAOO_0-1722516958165.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="KALYANI_HEDAOO_1-1722516958166.png" style="width: 645px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/145369iF156525314E38E69/image-dimensions/645x79?v=v2" width="645" height="79" role="button" title="KALYANI_HEDAOO_1-1722516958166.png" alt="KALYANI_HEDAOO_1-1722516958166.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Then after Query transformation for encryption, map the input data and the generated key transformation to new Query Transformation as below,&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="KALYANI_HEDAOO_2-1722516958167.png" style="width: 552px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/145370i273A865A73A0E247/image-dimensions/552x211?v=v2" width="552" height="211" role="button" title="KALYANI_HEDAOO_2-1722516958167.png" alt="KALYANI_HEDAOO_2-1722516958167.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Encrypt_aes is the standard Function available in BODS which accepts input as plain text, passphrase and AES key length.&lt;/P&gt;&lt;P&gt;In this way above custom logic for encryption can be utilized in BODS for encryption of data.&lt;/P&gt;&lt;P&gt;Refer Complete BODS job flow,&lt;/P&gt;&lt;P&gt;Here /BIC**291 is the table data from BW system and in Query_2 Transformation, key and data is available to use.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="KALYANI_HEDAOO_3-1722516958168.png" style="width: 603px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/145371i039352F33B4AFFEA/image-dimensions/603x151?v=v2" width="603" height="151" role="button" title="KALYANI_HEDAOO_3-1722516958168.png" alt="KALYANI_HEDAOO_3-1722516958168.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;After execution output will look like below,&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="KALYANI_HEDAOO_4-1722516958172.png" style="width: 651px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/145372i3BF6E6883FDCF290/image-dimensions/651x285?v=v2" width="651" height="285" role="button" title="KALYANI_HEDAOO_4-1722516958172.png" alt="KALYANI_HEDAOO_4-1722516958172.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/calling-rfc-in-bods-job-data-encryption-in-bods/ba-p/13779967"/>
    <published>2024-08-07T15:44:10.092000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/statement-of-direction-sap-information-steward/ba-p/13795111</id>
    <title>Statement of Direction – SAP Information Steward</title>
    <updated>2024-08-16T16:29:03.565000+02:00</updated>
    <author>
      <name>Lynne_Lintelman</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/135882</uri>
    </author>
    <content>&lt;P&gt;&lt;EM&gt;August 2024&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Introduction&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;As our matured products continue to have consistent traction in the market with emerging technologies and data platforms, it is essential for us to focus on extending its versions to meet the evolving needs of our customers. This Statement of Direction outlines our strategic approach to extending product versions, ensuring that we maintain our competitive edge in the on-premises data stewardship, data quality, metadata, and glossary space as well as on-cloud and deliver value to our customers. Our primary objective is to understand and address the specific requirements of our customers, for the matured products as well as new and emerging technologies in the cloud. We will actively engage with our user base through feedback sessions, support channels, and market research to identify their pain points, challenges, and emerging needs.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Executive Summary&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This document provides guidance to our customers of SAP Data Management portfolio, with respect to SAP Information Steward (IS) solution, on the product directions. &amp;nbsp;For Data Services (DS) we have a separate &lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/statement-of-direction-sap-data-services-as-of-july-2024/ba-p/13762644" target="_blank"&gt;blog&lt;/A&gt; communication made available. This document is an updated version of our&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/statement-of-direction-sap-data-services-and-sap-information-steward-as-of/ba-p/13577148" target="_blank"&gt;blog&lt;/A&gt;&amp;nbsp;post made on November 3, 2023, which focused on SAP Information Steward and SAP Data Services.&lt;/P&gt;&lt;P&gt;SAP Data Management portfolio expanded further in the cloud with the introduction of SAP Datasphere in March 2023. SAP Datasphere is a comprehensive data service built only on SAP® Business Technology platform (SAP BTP) that enables every data professional to deliver seamless and scalable access to mission critical business data. It is the next generation of SAP® Data Warehouse Cloud, with new capabilities that enhance data discovery, data catalog, metadata, modeling, and distribution. With a unified experience for data cataloging, semantic modeling, data integration, data warehousing, data federation, and data virtualization.&amp;nbsp; SAP Datasphere enables data professionals to easily distribute authoritative business data with business context and logic preserved across the data landscape.&lt;/P&gt;&lt;P&gt;As we define the future of SAP Data Management portfolio, with our stated data management strategy, current on-premise SAP Information Steward customers can leverage their existing investments and efforts, repurposing those time-tested and trusted artifacts and configurations that are being used today in SAP Information Steward (IS), while also extending the reach of their data management to the cloud, with SAP Datasphere, a native cloud solution. We are committed to our existing SAP Information Steward and customer base too.&lt;/P&gt;&lt;P&gt;In 2022 we did a minor version upgrade of SAP Information Steward to 4.3, allowing the compatibility with Business Intelligence BusinessObjects 4.3. As a result, our support policy extended the end of mainstream maintenance timeline to end of 2026 with Customer Specific Maintenance (CSM) to end of 2028 for both SAP Information Steward and SAP Data Services 4.3. However, with the mainstream maintenance of version 4.3 of SAP Information Steward ending in 2026, we do not want to leave our large customer base behind, and therefore we have decided to release an updated version, code named SAP Information Steward 2025 to provide more time to our on-premises customers to adopt our rapidly evolving, state-of-the-art cloud data quality and data governance scenarios. Many of our largest SAP Information Steward customers already run both solutions side-by-side, during their transition to the managed cloud deployment.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;TABLE width="100%"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;STRONG&gt;&lt;U&gt;SAP Information Steward 2025&lt;/U&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Our current plan to release a new version of the SAP Information Steward in 2025 as a successor of SAP Information Steward 4.3 remains unchanged and will be...&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Code named SAP Information Steward 2025&lt;/LI&gt;&lt;LI&gt;Available on-premises&lt;/LI&gt;&lt;LI&gt;Focused on the most widely adopted on-premises scenarios: SAP Information Steward for data stewardship, metadata, glossary, and data quality&lt;/LI&gt;&lt;LI&gt;Compatible with proposed BI 2025 suite and planned to be released a quarter after BI 2025&lt;/LI&gt;&lt;LI&gt;We have plans to release the first version by the end of Q3 2025 followed by ‘Fix Packages’ as needed.&lt;/LI&gt;&lt;LI&gt;We have plans to release a new version every alternate year and reduce the frequency of SAP Information Steward, (SP) Service Pack releases. The ‘Service Pack’ release has been planned to be deprecated.&lt;/LI&gt;&lt;LI&gt;Continue to support Windows and Linux platforms only.&lt;/LI&gt;&lt;LI&gt;We do not foresee any impact to solutions and partners using SAP Information Steward in an OEM mode.&amp;nbsp; &amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;&lt;STRONG&gt;We are committed to support you.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;We recognize the importance of continuously improving and innovating our product and yet manage a balance between our on-premises and cloud-based solutions. We will invest in research and development to explore new technologies, industry trends, and market demands yet support our existing customer base for the mature products. By fostering a culture of innovation and collaboration, we will ensure that our product versions remain cutting-edge and relevant in the ever-changing business landscape. We are committed to help and support our customers.&lt;/P&gt;&lt;P&gt;Many customers rely on SAP Information Steward for critical use cases and will need to do so beyond 2025. Our support plan for SAP Information Steward is as follows and our message is consistent. Please refer to the respective GA versions Product Availability Matrix for the support timelines.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Lynne_Lintelman_0-1752513445336.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286506iFFE380FFF375E670/image-size/large?v=v2&amp;amp;px=999" role="button" title="Lynne_Lintelman_0-1752513445336.png" alt="Lynne_Lintelman_0-1752513445336.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;WE WANT TO HEAR FROM YOU&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;SAP Information Steward remains as a key component of our Data Management portfolio, and we are committed to our customers. Please help us fine tune our roadmaps of SAP Information Steward providing your input through the dedicated inbox:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;SAP Information Steward:&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;sap.informationsteward.enhance@sap.com&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;We appreciate your feedback and will answer your questions via our official communication channels.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/statement-of-direction-sap-information-steward/ba-p/13795111"/>
    <published>2024-08-16T16:29:03.565000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/dataservices-salesforce-adapter-retirement-a-free-alternative-solution/ba-p/13969834</id>
    <title>DataServices Salesforce Adapter retirement - a free alternative solution within BODS</title>
    <updated>2024-12-24T16:04:08.405000+01:00</updated>
    <author>
      <name>marton_horvath2</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/223887</uri>
    </author>
    <content>&lt;P&gt;If you are here, you may already know the issue, but for the rest:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;The problem&lt;/STRONG&gt;: The current out-of-the-box way of connecting to Saleforce with DataServices won’t work after &lt;STRONG&gt;Salesforce retires its REST API v21&lt;/STRONG&gt;, in the summer of '25.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Regarding the end of Salesforce compatibility SAP is citing legal restrictions in the related SAP Note:&lt;/P&gt;&lt;P&gt;&lt;A href="https://userapps.support.sap.com/sap/support/knowledge/en/3004914" target="_self" rel="noopener noreferrer"&gt;3004914 - SAP Data Services and Salesforce.com compatibility&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Cause:&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;EM&gt;The Adapter for SFDC as a part of the Data Services using is indeed on SFDC API version 21 only. Due to&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;the legal restrictions, SAP applications do not connect to SFDC directly or provide direct interface into&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;SFDC systems.&amp;nbsp;Thus SAP Data Services cannot connect directly to SFDC as well. The supported version&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;21 is prior to the restrictions and thus it is being provided in an ‘as is’ state and no further enhancements&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;will be provided.&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;SAP proposes two possible solutions:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;with BODS: purchase a 3rd party adapter instead of the current one: &lt;A href="https://insightsoftware.com/drivers/salesforce-sap-ds/" target="_self" rel="nofollow noopener noreferrer"&gt;Simba Salesforce Adapter for SAP Data Services&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;leave BODS and resolve the Salesforce integration with &lt;A href="https://www.sap.com/products/technology-platform/data-intelligence.html" target="_self" rel="noopener noreferrer"&gt;SAP Data Intelligence Cloud&lt;/A&gt;.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;In this post I describe a solution which is free* and is within BODS. &lt;/STRONG&gt;If you have other data sources&amp;nbsp; besides Salesforce and have a large invesment in BODS; you may prefer to stick with it. With the below solution you can do it without additional cost.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;The key building blocks will be:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;A href="https://help.sap.com/docs/SAP_DATA_SERVICES/8092b085a68941f6aaa6708685a62b0d/57712de26d6d1014b3fc9283b0e91070.html?locale=en-US" target="_self" rel="noopener noreferrer"&gt;user defined transform&lt;/A&gt; + python + &lt;A href="https://github.com/simple-salesforce/simple-salesforce" target="_self" rel="nofollow noopener noreferrer"&gt;simple-salesforce&lt;/A&gt; + &lt;A href="https://developer.salesforce.com/docs/atlas.en-us.api_asynch.meta/api_asynch/bulk_api_2_0.htm" target="_self" rel="nofollow noopener noreferrer"&gt;Salesfroce Bulk API 2.0&lt;/A&gt; (+ CSV)&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;User defined transform (UDT)&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;In a nutshell, &lt;EM&gt;User Defined Transform&lt;/EM&gt; is the way to extend your BODS out-of-the-box capabilities with whatever you want. Well… as long as it fits into 255 varchar columns. This is quite a limitation in 2024, so&amp;nbsp;the work-around we will apply is to dump our Salesforce resultset into a local CSV. It is less elegant, but it works with longer fields as well.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Simple-salesforce&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Simple-salesforce is a Python library for... you guessed it, Salesforce. You may use the Salesforce API directly, but I found this library quite &lt;STRIKE&gt;simple&lt;/STRIKE&gt; useful. The latest version supports Bulk API 2.0 as well. To be able to use it within BODS, we would need to import it to our environment as follows:&lt;/P&gt;&lt;P&gt;Adding simple_salesforce to local python:&lt;BR /&gt;Add to the Environment variables:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;EM&gt;E:\SAP BusinessObjects\&lt;/EM&gt;Data Services\DataQuality\python&lt;/LI&gt;&lt;LI&gt;&lt;EM&gt;E:\SAP BusinessObjects\&lt;/EM&gt;Data Services\DataQuality\python\Scripts&lt;/LI&gt;&lt;LI&gt;&lt;EM&gt;E:\SAP BusinessObjects\&lt;/EM&gt;Data Services\bin&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Download and install pip&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;Documentation: &lt;A href="https://pip.pypa.io/en/stable/installation/#get-pip-py" target="_blank" rel="noopener nofollow noreferrer"&gt;https://pip.pypa.io/en/stable/installation/#get-pip-py&lt;/A&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;1. Download the script from&amp;nbsp;&lt;A href="https://bootstrap.pypa.io/get-pip.py" target="_blank" rel="noopener nofollow noreferrer"&gt;https://bootstrap.pypa.io/get-pip.py&lt;/A&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;2. Command prompt: python get-pip.py&lt;/P&gt;&lt;P&gt;Install simple_salesforce:&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;python -m pip install --target="&lt;EM&gt;E:\SAP BusinessObjects\&lt;/EM&gt;Data Services\DataQuality\python\Lib\site-packages" simple_salesforce&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Python code of the User Defined Transform&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from simple_salesforce import Salesforce, SalesforceLogin, SFType

# set salesforce connection details
username = 'aaa'       # !!!
password = 'bbb'       # !!!
security_token = 'ccc' # !!!
domain = 'xxx'         # !!!
sf_version = '59.0'

# login and get session
session_id, instance = SalesforceLogin(username=username,
password=password, security_token=security_token, sf_version=sf_version, domain=domain)
sf = Salesforce(instance=instance, session_id=session_id)

queryName = record.GetField(u'i_queryName')
querySOQL = record.GetField(u'i_querySOQL')

# execute query
results = sf.bulk2.Account.query(
query=querySOQL, max_records=None, column_delimiter='PIPE', line_ending='CRLF'
)

# write results to local drive as CSV -- !!!customize to your local folder!!!
for i, data in enumerate(results):
  with open(f"F:/FileDatasource/results/{queryName}-part-{i}.csv", "w", encoding="utf-8") as bos:
  bos.write(data)

o_result = queryName + ' loaded successfully'
record.SetField(u'o_result', o_result)

del queryName
del querySOQL
del o_result&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;A few notes regarding the above code:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;sf.bulk2.Account.query – Here Account doesn’t seem to matter at all. I have tried with sf.bulk2.blalba.query – and it worked the same way. What seem to matter is the SOQL query. Consequently, you can solve different Salesforce table loads with the same single UDT.&lt;/LI&gt;&lt;LI&gt;I used&amp;nbsp;PIPE as column delimiter, and&amp;nbsp;CRLF as line ending for the CSV. These are not the default settings for CSV-s in BODS. Keep it in mind when defining your CSV source. I used these becuase these are less frequently used characters in Salesforce content. It did the trick for me, but keep in mind that this is still not a bulletproof solution. You may want to check for these characters in your content before dumping as CSV.&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;Don't forget to customise the UDT to your environment:&lt;UL&gt;&lt;LI&gt;username&lt;/LI&gt;&lt;LI&gt;password&lt;/LI&gt;&lt;LI&gt;token&lt;/LI&gt;&lt;LI&gt;domain&lt;/LI&gt;&lt;LI&gt;CSV local folder&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;Unfortunately I have experienced that BODS crashed with ntdll.dll error, after closing the Python editor when opening from the Repository\Transforms (ie modifying the main &lt;EM&gt;object&lt;/EM&gt;) BUT less so when modifying an &lt;EM&gt;instance&lt;/EM&gt; of the same UDT object inside a dataflow. The trace I have found in the Windows event log points to: C:\Windows\SYSTEM32\ntdll.dll&lt;BR /&gt;A related SAP Note on the topic: &lt;A href="https://me.sap.com/notes/3485456/E" target="_self" rel="noopener noreferrer"&gt;3485456 - Designer crashes frequently without error message -&lt;/A&gt;&lt;BR /&gt;&lt;A href="https://me.sap.com/notes/3485456/E" target="_self" rel="noopener noreferrer"&gt;SAP BusinessObjects Data Services&lt;/A&gt;&lt;BR /&gt;Eventually, my recommendation is to develop Python code outside of BODS and later import the UDT from XML or ATL.&lt;/LI&gt;&lt;LI&gt;Unicode Getfield crash: &lt;A href="https://me.sap.com/notes/1256795/E" target="_self" rel="noopener noreferrer"&gt;1256795 - User Defined Transform with Python code is crashing - Data&lt;/A&gt;&lt;BR /&gt;&lt;A href="https://me.sap.com/notes/1256795/E" target="_self" rel="noopener noreferrer"&gt;Services&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Attached you can find the export of the User Defined Transform.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Summary&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;With the above UDT you can easily build dataflows to extract data from Salesforce:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;You may start with a &lt;EM&gt;Row Generator.&amp;nbsp;&lt;/EM&gt;&lt;/LI&gt;&lt;LI&gt;with a Query transform you may set the two incoming parameters:&lt;OL&gt;&lt;LI&gt;a query name - just to identify your query&lt;/LI&gt;&lt;LI&gt;the query itself&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;LI&gt;The next step is the UDT itslelf: you need to connect the inputs, and the output back to the dataflow. This transform should produce a single column with '&lt;EM&gt;[query] loaded successfully' &lt;/EM&gt;after the results were written as CSV to the local drive.&lt;/LI&gt;&lt;LI&gt;With a second dataflow you would need to process the CSV&amp;nbsp; &amp;nbsp;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;*If you find the above solution useful please leave a comment with your country / city&lt;/STRONG&gt;. I would like to create a map with pins - hopefully - around the globe.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/dataservices-salesforce-adapter-retirement-a-free-alternative-solution/ba-p/13969834"/>
    <published>2024-12-24T16:04:08.405000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/archiving-the-forgotten-hero-of-s4hana-the-tool-guide-you-want-to-have/ba-p/14003675</id>
    <title>Archiving: The forgotten hero of S4HANA. The Tool Guide You Want to Have.</title>
    <updated>2025-02-01T17:16:04.162000+01:00</updated>
    <author>
      <name>STALANKI</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/13911</uri>
    </author>
    <content>&lt;P class=""&gt;Forget robots just showing up – they're now creating and multiplying data robots! Deepseek's arrival is our AI Sputnik moment, a surprise launch into a whole new era. Could Deepseek be our "set-it-and-forget-it" solution for S/4HANA archiving in future ? Imagine: automatic data archiving that slashes costs on cleanup and keeps your S/4HANA projects running lean and mean.&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":collision:"&gt;💥&lt;/span&gt;Could there be SAP Data's Sputnik Moment? &lt;span class="lia-unicode-emoji" title=":collision:"&gt;💥&lt;/span&gt;&lt;/P&gt;&lt;PRE&gt;"Stop fearing your SAP data swamp. What if Deepseek could be the dynamite that blasts SAP Data open, cleaning and mopping the way for a data superhighway? Turn data nightmares into data sweet deep seek dreams?."&lt;/PRE&gt;&lt;P class=""&gt;While dreams are exciting, let's get down to business. This blog dives into a comparison of different SAP archiving tools, offering a clear perspective on their strengths and weaknesses. Keep in mind, these are my personal insights, independent of any company affiliation. Ultimately, the best tool for your needs requires your careful evaluation.&lt;/P&gt;&lt;H2 id="toc-hId-1701821508"&gt;Background&lt;/H2&gt;&lt;P class=""&gt;For example, &lt;STRONG&gt;DeepSeek’s&lt;/STRONG&gt;could analyze SAP data logs and suggest which files should be archived based on usage patterns, while &lt;STRONG&gt;DeepSeek’s AI-powered search&lt;/STRONG&gt; could instantly pull up archived records using context rather than keywords.. &lt;STRONG&gt;SAP archiving tools&lt;/STRONG&gt; like &lt;STRONG&gt;SNP Archiving&lt;/STRONG&gt;, &lt;STRONG&gt;OpenText&lt;/STRONG&gt;, &lt;STRONG&gt;SAP ILM&lt;/STRONG&gt;, and &lt;STRONG&gt;Proceed Group&lt;/STRONG&gt; are playing crucial roles in optimizing storage, improving compliance, and maintaining SAP system performance. Let’s break down how these tools stack up against each other based on &lt;STRONG&gt;real-world use cases&lt;/STRONG&gt;.&lt;/P&gt;&lt;P class=""&gt;Feeling the weight of years of data slowing down your SAP system? You're not alone. Many businesses struggle with bloated databases, sluggish performance, and the ever-present fear of non-compliance.&lt;/P&gt;&lt;P class=""&gt;But with so many archiving options available, choosing the right one can feel overwhelming. That's where this guide comes in. We'll break down the top contenders – SNP Archiving, Proceed Group, OpenText, SAP ILM, Data Lakes, and In-System Archiving – so you can find the perfect fit for your needs.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Understanding Your Archiving Needs&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Before diving into the tools, let's clarify your goals. Ask yourself:&lt;/P&gt;&lt;P class=""&gt;What's slowing us down? Is it slow report generation, long system backups, or something else?&lt;/P&gt;&lt;P class=""&gt;What kind of data are we dealing with? Is it mostly structured data within SAP, or do we have lots of documents, emails, and other unstructured data?&lt;/P&gt;&lt;P class=""&gt;How important is compliance? Are we in a heavily regulated industry with strict data retention requirements?&lt;/P&gt;&lt;P class=""&gt;What's our budget? Archiving solutions range from affordable to enterprise-grade.&lt;/P&gt;&lt;H1 id="toc-hId-1376225284"&gt;Comparing the Contenders&lt;/H1&gt;&lt;P class=""&gt;Now, let's meet the archiving all-stars:&lt;/P&gt;&lt;H3 id="toc-hId-1437877217"&gt;1. SNP Archiving: The Streamlined Solution&lt;/H3&gt;&lt;P class=""&gt;&lt;STRONG&gt;Overview: &lt;/STRONG&gt;SNP is a well-known SAP partner specializing in data management, system migration, and archiving. SNP’s archiving solution is specifically designed to optimize SAP system performance while ensuring compliance with data retention requirements.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Key Features:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;SAP-Optimized&lt;/STRONG&gt;: SNP focuses on delivering archiving solutions tailored to SAP systems, helping businesses remove old data from live environments and store it in a way that it remains accessible for compliance or auditing.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Automated Archiving:&lt;/STRONG&gt; The solution automates the archiving process, making it easier to migrate data from SAP systems to storage systems.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Integration with SAP&lt;/STRONG&gt;: Seamless integration with SAP S/4HANA, SAP ECC, and other SAP modules, ensuring minimal disruption to business operations.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Pros:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Designed specifically for SAP environments.&lt;/P&gt;&lt;P class=""&gt;Strong focus on compliance and audit-ability.&lt;/P&gt;&lt;P class=""&gt;Easy integration with other SAP modules.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Cons:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Limited flexibility for non-SAP data.&lt;/P&gt;&lt;P class=""&gt;May not be as versatile for broader, cross-platform archiving needs.&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1112280993"&gt;2. OpenText: The Content Management Powerhouse&lt;/H2&gt;&lt;P class=""&gt;&lt;STRONG&gt;Overview: &lt;/STRONG&gt;OpenText is one of the leaders in enterprise content management (ECM) and offers comprehensive archiving solutions for SAP users. OpenText’s solutions go beyond simple archiving, incorporating information lifecycle management, document management, and workflow optimization.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Key Features:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Enterprise Content Management (ECM):&lt;/STRONG&gt; OpenText provides a broad suite of ECM tools, including document management, records management, and data archiving.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;SAP Integration&lt;/STRONG&gt;: Seamlessly integrates with SAP applications (such as SAP S/4HANA), helping businesses manage their SAP documents and records efficiently.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Scalability:&lt;/STRONG&gt; OpenText’s archiving solution can scale with enterprise growth, offering flexible data storage options for high volumes of information.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Compliance and Security&lt;/STRONG&gt;: Strong features around compliance, audit trails, and security, ensuring that all archived data meets regulatory requirements.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Pros:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Rich ECM capabilities beyond simple data archiving.&lt;/P&gt;&lt;P class=""&gt;Extensive support for compliance and security.&lt;/P&gt;&lt;P class=""&gt;Strong SAP integration.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Cons:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Might be overkill for organizations seeking a simple SAP-only archiving solution.&lt;/P&gt;&lt;P class=""&gt;Higher cost due to comprehensive feature set.&lt;/P&gt;&lt;H2 id="toc-hId-915767488"&gt;3. Proceed Group: Tailored Solutions&lt;/H2&gt;&lt;P class=""&gt;&lt;STRONG&gt;Overview:&lt;/STRONG&gt; Proceed Group offers archiving solutions that are integrated into SAP environments and focus on optimizing data storage and retrieval, as well as improving overall system performance.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Key Features:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;End-to-End Integration:&lt;/STRONG&gt; Proceed Group’s solution integrates directly into SAP and enhances the performance of SAP systems by archiving obsolete or redundant data while ensuring the system stays efficient.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Data Segmentation: &lt;/STRONG&gt;Allows businesses to archive data in segments, making it easier to manage large datasets while retaining the ability to retrieve specific pieces of information quickly.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Cost-Efficiency: &lt;/STRONG&gt;Designed to reduce operational costs by offloading data from expensive, high-performance systems to lower-cost storage solutions.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Pros:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Effective for businesses looking for cost-effective SAP archiving solutions.&lt;/P&gt;&lt;P class=""&gt;Simple integration with SAP landscapes.&lt;/P&gt;&lt;P class=""&gt;Focus on maintaining system performance and accessibility.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Cons:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;May not offer as advanced features as other specialized archiving solutions.&lt;/P&gt;&lt;H2 id="toc-hId-719253983"&gt;4. SAP ILM (Information Lifecycle Management): The Native Solution&lt;/H2&gt;&lt;P class=""&gt;&lt;STRONG&gt;Overview:&lt;/STRONG&gt; SAP ILM is an SAP-native solution that offers an enterprise-grade approach to managing data throughout its lifecycle. It’s specifically designed to help businesses comply with legal data retention requirements while managing the storage of SAP data.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Key Features:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Data Lifecycle Management: &lt;/STRONG&gt;SAP ILM helps businesses manage the entire lifecycle of data, from creation through retention to deletion, ensuring compliance with legal and regulatory requirements.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Archiving and Data Destruction:&lt;/STRONG&gt; Features archiving as well as the automated destruction of data when it is no longer required by regulations.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Seamless SAP Integration:&lt;/STRONG&gt; ILM integrates natively with SAP systems, including SAP HANA and SAP S/4HANA, ensuring smooth operation without the need for external systems.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Retention Management:&lt;/STRONG&gt; Customizable retention policies allow businesses to define how long data should be kept, making it easier to comply with both internal and external requirements.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Pros:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Native integration with SAP systems.&lt;/P&gt;&lt;P class=""&gt;Comprehensive lifecycle management of data.&lt;/P&gt;&lt;P class=""&gt;Strong regulatory compliance features.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Cons:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Focused mainly on SAP environments; not as flexible for non-SAP data.&lt;/P&gt;&lt;P class=""&gt;The learning curve can be steep for users unfamiliar with SAP.&lt;/P&gt;&lt;H2 id="toc-hId-522740478"&gt;5. Data Lakes: The Data Insight Reservoir&lt;/H2&gt;&lt;P class=""&gt;&lt;STRONG&gt;Overview:&lt;/STRONG&gt; A Data Lake is an evolving concept in data storage, where data is stored in its raw form in a large, centralized repository. Although it’s not an archiving solution in the traditional sense, data lakes are increasingly being used for long-term storage and analysis of big data.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Key Features:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Storage of Raw Data: &lt;/STRONG&gt;Data lakes store data in its native format (structured, semi-structured, or unstructured), which means all data is available for future analysis without needing to be processed first.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Scalability:&lt;/STRONG&gt; Data lakes are built to scale horizontally, handling vast amounts of data with low-cost storage solutions, such as Hadoop or cloud-based services like AWS S3.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Data Exploration:&lt;/STRONG&gt; Provides businesses with the ability to run advanced analytics and machine learning algorithms on large datasets without the need for complex data transformation processes.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Flexibility: &lt;/STRONG&gt;Can store data from multiple sources, including SAP and non-SAP systems, and provide analytics and insights.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Pros:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Ideal for handling large-scale structured, unstructured, or semi-structured data.&lt;/P&gt;&lt;P class=""&gt;Highly flexible and scalable.&lt;/P&gt;&lt;P class=""&gt;Can be used for data exploration and advanced analytics.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Cons:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Not designed specifically for archiving; lacks out-of-the-box features for compliance or regulatory management.&lt;/P&gt;&lt;P class=""&gt;Requires specialized skills for managing and querying large datasets.&lt;/P&gt;&lt;P class=""&gt;Potentially high storage and data management costs without proper governance.&lt;/P&gt;&lt;H2 id="toc-hId-326226973"&gt;6. In-System Archiving: The Lightweight Option&lt;/H2&gt;&lt;P class=""&gt;&lt;STRONG&gt;Overview: &lt;/STRONG&gt;In-System Archiving stores archived data within the SAP system itself (database or storage infrastructure), simplifying management in SAP-centric environments.&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Key Features:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Data Stored in SAP&lt;/P&gt;&lt;P class=""&gt;Optimized for SAP Performance&lt;/P&gt;&lt;P class=""&gt;Transparency&lt;/P&gt;&lt;P class=""&gt;Simplified Data Management&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Pros:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Seamless SAP Integration&lt;/P&gt;&lt;P class=""&gt;Lower Costs for Smaller Systems&lt;/P&gt;&lt;P class=""&gt;Compliance and Security&lt;/P&gt;&lt;P class=""&gt;Simplicity&lt;/P&gt;&lt;P class=""&gt;&lt;STRONG&gt;Cons:&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Scalability limitations for large data volumes&lt;/P&gt;&lt;P class=""&gt;Limited flexibility for non-SAP environments&lt;/P&gt;&lt;P class=""&gt;Less advanced analytics capabilities&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="STALANKI_1-1738426526455.png" style="width: 647px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/220342i2E516BA86AA136BF/image-dimensions/647x106?v=v2" width="647" height="106" role="button" title="STALANKI_1-1738426526455.png" alt="STALANKI_1-1738426526455.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class=""&gt;The optimal choice for your organisation will depend on a variety of factors, including the size of your company, the volume of data you need to archive, your compliance requirements, and the complexity of your IT environment and hope this guide is useful for you as a starting point.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/archiving-the-forgotten-hero-of-s4hana-the-tool-guide-you-want-to-have/ba-p/14003675"/>
    <published>2025-02-01T17:16:04.162000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/http-status-500-internal-server-error-in-sap-businessobjects-intelligence/ba-p/14045151</id>
    <title>HTTP Status 500-Internal Server Error in SAP BusinessObjects Intelligence Platform and Data Services</title>
    <updated>2025-03-14T20:53:06.584000+01:00</updated>
    <author>
      <name>Abhishek_Sinha</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/172574</uri>
    </author>
    <content>&lt;P&gt;&lt;U&gt;&lt;STRONG&gt;Issue:&lt;/STRONG&gt;&lt;/U&gt;&amp;nbsp;HTTP Status 500-Internal Server Error&lt;BR /&gt;We have often seen this error in the SAP BI platform or Data Services, which rely on Tomcat services. This issue is observed when you try to access the application via the central management console. There might be a scenario where a few of the options work fine and a few give the below error message.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Abhishek_Sinha_0-1741979604204.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/237743i6E8D449BFF61925B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Abhishek_Sinha_0-1741979604204.png" alt="Abhishek_Sinha_0-1741979604204.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Even though sufficient memory is available on the VM to be utilized, this issue is still encountered. A quick resolution is to restart the Tomcat, which is not a sustainable solution.&lt;/P&gt;&lt;P&gt;&lt;U&gt;&lt;STRONG&gt;Cause:&lt;/STRONG&gt;&lt;/U&gt;&amp;nbsp;The main reason for this issue is the heap memory utilization of Tomcat.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Tomcat&lt;/STRONG&gt; is an essential component in SAP BusinessObjects (BO) architecture, particularly for hosting web applications.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Role of Tomcat in SAP BusinessObjects (BO)&lt;/STRONG&gt;&lt;BR /&gt;Apache Tomcat acts as the web application server for deploying SAP BO web applications such as:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Central Management Console (CMC)&lt;/STRONG&gt; — for managing and configuring the SAP BO platform.&lt;BR /&gt;&lt;STRONG&gt;BI Launch Pad&lt;/STRONG&gt; — for accessing reports, dashboards, and analytics.&lt;BR /&gt;&lt;STRONG&gt;Web Intelligence (WebI)&lt;/STRONG&gt; — for interactive report creation.&lt;BR /&gt;&lt;STRONG&gt;Crystal Reports Viewer&lt;/STRONG&gt; — for viewing detailed Crystal Reports.&lt;/P&gt;&lt;P&gt;Inefficient configuration of memory leads to crashes or out-of-memory errors.&lt;/P&gt;&lt;P&gt;It is a bit challenging to figure out the optimum configuration, hence, the issue of monitoring the heap memory utilization becomes critical.&lt;/P&gt;&lt;P&gt;A tool "&lt;STRONG&gt;jconsole&lt;/STRONG&gt;" is offered by SAPJVM, which is available in the Business Objects executable.&lt;/P&gt;&lt;P&gt;Steps to set up the console:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Set the below parameters in Tomcat configuration&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-java"&gt;&lt;code&gt;-Dcom.sun.management.jmxremote
-Dcom.sun.management.jmxremote.port=8008
-Dcom.sun.management.jmxremote.authenticate=false
-Dcom.sun.management.jmxremote.ssl=false&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Abhishek_Sinha_1-1741980672277.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/237744i206300186D37A6D8/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Abhishek_Sinha_1-1741980672277.png" alt="Abhishek_Sinha_1-1741980672277.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Restart the Tomcat for it to take effect.&lt;/P&gt;&lt;P&gt;Running the console&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Browse to the location of sapjvm, it is in the BI installation location - &amp;lt;install_location&amp;gt;\&lt;SPAN&gt;SAP BusinessObjects Enterprise XI 4.0\win64_x64\sapjvm\bin&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Execute the jconsole -&amp;nbsp;jconsole.exe &amp;lt;hostname&amp;gt;:8008&amp;nbsp; &amp;nbsp; (Here, 8008 is the port which is set in property)&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Abhishek_Sinha_2-1741981221561.png" style="width: 619px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/237745i60ADB9CF209682A3/image-dimensions/619x45?v=v2" width="619" height="45" role="button" title="Abhishek_Sinha_2-1741981221561.png" alt="Abhishek_Sinha_2-1741981221561.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Abhishek_Sinha_3-1741981265852.png" style="width: 566px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/237746i737EB1B87BE088BC/image-dimensions/566x275?v=v2" width="566" height="275" role="button" title="Abhishek_Sinha_3-1741981265852.png" alt="Abhishek_Sinha_3-1741981265852.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Abhishek_Sinha_0-1741982207177.png" style="width: 565px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/237749iBF18C8CD0976F3C8/image-dimensions/565x277?v=v2" width="565" height="277" role="button" title="Abhishek_Sinha_0-1741982207177.png" alt="Abhishek_Sinha_0-1741982207177.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Using the various tabs, real-time monitoring can be done, and it will lead to setting up the optimum memory parameters for the system to run smoothly without any issues. An ad-hoc garbage collection can also be performed from here.&lt;/P&gt;&lt;P&gt;&lt;U&gt;&lt;STRONG&gt;Conclusion:&lt;/STRONG&gt;&lt;/U&gt; It is a great offering within the SAPJVM which empowers us as admins to monitor the Tomcat heap memory and fine-tune the parameters for optimum performance.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/http-status-500-internal-server-error-in-sap-businessobjects-intelligence/ba-p/14045151"/>
    <published>2025-03-14T20:53:06.584000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/how-to-extract-long-text-from-ecc-and-prepare-a-dmc-template-for-loading/ba-p/14047480</id>
    <title>How to Extract Long Text from ECC and Prepare a DMC Template for Loading Long Text into S4/HANA</title>
    <updated>2025-03-18T17:06:53.690000+01:00</updated>
    <author>
      <name>Adarsh_Binukumar</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2045880</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;&lt;FONT size="5"&gt;Introduction&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Extracting long text from SAP systems may seem straightforward, but it often involves complexities that go beyond simple extraction methods. When traditional approaches fall short, leveraging Remote Function Calls (RFCs) can provide an effective solution for retrieving and integrating long text into SAP Business Objects Data Services (BODS) workflows. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;In this blog, we’ll explore how to use the RFC_READ_TEXT function module to efficiently extract long text from SAP systems and seamlessly incorporate it into BODS for further processing and analysis. Whether you're dealing with technical challenges or looking for a practical guide to streamline your data integration, this bog will help you leverage RFCs effectively to ensure a smoother and efficient workflow.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_0-1742232394457.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238737iAC8D067AA47B4D07/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_0-1742232394457.png" alt="Adarsh_Binukumar_0-1742232394457.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H5 id="toc-hId-2092881017"&gt;&lt;STRONG&gt;Key Functionalities of RFC_READ_TEXT&lt;/STRONG&gt;&lt;/H5&gt;&lt;P&gt;- Retrieval of long text data stored in SAP tables.&lt;BR /&gt;- Filtering of text data based on object type and other parameters.&lt;BR /&gt;- Returning retrieved text for further processing or display.&lt;/P&gt;&lt;H5 id="toc-hId-1896367512"&gt;&lt;STRONG&gt;Understanding the Output Structure&lt;/STRONG&gt;&lt;/H5&gt;&lt;P&gt;The output of RFC_READ_TEXT is structured in a tabular format with the following key fields:&lt;/P&gt;&lt;P&gt;TDLINE: Contains the actual text lines retrieved from SAP.&lt;BR /&gt;TDOBJECT: Indicates the object type (e.g., 'MAKT' for material descriptions, 'VBAK' for sales order headers, etc.)&lt;BR /&gt;&amp;nbsp;TDID: Identifies the specific object within the given object type.&lt;BR /&gt;&amp;nbsp;TDNAME: Specifies the type of long text (e.g., 'LTXT' for general long text, 'ATXT' for header text).&lt;BR /&gt;&amp;nbsp;TDSPRAS: Specifies the language of the retrieved text.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;H5 id="toc-hId-1699854007"&gt;Steps to Implement RFC_READ_TEXT in SAP BODS&lt;/H5&gt;&lt;P&gt;&amp;nbsp;- Create the structure based on the number of unique IDs available.&lt;BR /&gt;&amp;nbsp;- Group the dataset under a unique value to optimize processing.&lt;/P&gt;&lt;P&gt;&lt;EM&gt;&lt;FONT size="2"&gt;Fig 1: Creating the extraction structure and splitting data based on multiple IDs.&lt;/FONT&gt;&lt;BR /&gt;&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_1-1742232581082.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238738iFD6205FB4639EF60/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_1-1742232581082.png" alt="Adarsh_Binukumar_1-1742232581082.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;&lt;FONT size="2"&gt;Fig_2: Standard query inputs that need to be maintained.&lt;/FONT&gt;&lt;BR /&gt;&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_2-1742232612577.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238739i23509118A8AE0D57/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_2-1742232612577.png" alt="Adarsh_Binukumar_2-1742232612577.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="2"&gt;&lt;EM&gt;Fig_3: Standard schema structure.&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_3-1742232669998.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238740iA418264CAD93AA77/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_3-1742232669998.png" alt="Adarsh_Binukumar_3-1742232669998.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="2"&gt;&lt;EM&gt;Fig_4: Query read text input and RFC calling in BODS program.&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_0-1742233068068.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238741i08C6DCF838409081/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_0-1742233068068.png" alt="Adarsh_Binukumar_0-1742233068068.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="2"&gt;&lt;EM&gt;Fig_5: Input parameters for calling RFC_READ_TEXT.&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_1-1742233093066.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238742i88A76D685FB1420A/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_1-1742233093066.png" alt="Adarsh_Binukumar_1-1742233093066.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="2"&gt;&lt;EM&gt;Fig_6: Output parameters of RFC_READ_TEXT.&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_2-1742233131958.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238743iC179A476F68335F7/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_2-1742233131958.png" alt="Adarsh_Binukumar_2-1742233131958.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="2"&gt;&lt;EM&gt;Fig_7: Unnesting the query.&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_3-1742233156261.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238744i0FAB603D0F6924CD/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_3-1742233156261.png" alt="Adarsh_Binukumar_3-1742233156261.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;EM&gt;OUTPUT&lt;/EM&gt;&lt;/STRONG&gt;&lt;BR /&gt;&lt;BR /&gt;The RFC_READ_TEXT function returns a table containing long text along with key metadata fields. Here’s a breakdown of the main output fields:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;TDLINE&lt;/STRONG&gt;: Holds the actual text lines, with each entry representing a separate line.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;TDOBJECT&lt;/STRONG&gt;: Specifies the object type associated with retrieved text (e.g., MAKT for materials, VBAK for sales orders).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;TDID&lt;/STRONG&gt;: Uniquely identifies the text object (e.g., material number, sales order number).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;TDNAME&lt;/STRONG&gt;: Defines the type of long text (LTXT for general long text, ATXT for header text).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;TDSPRAS&lt;/STRONG&gt;: Indicates the language of the retrieved text.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;STRONG&gt;In essence, the RFC_READ_TEXT output provides the requested long text data along with essential metadata like the object type, object ID, text type, and language.&lt;/STRONG&gt; This output structure is crucial for correctly interpreting and utilizing the retrieved long text data within your application.&lt;/P&gt;&lt;P&gt;&lt;FONT size="2"&gt;&lt;EM&gt;Fig_8: Output Data&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_4-1742233218002.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238745i64AF49A224F86828/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_4-1742233218002.png" alt="Adarsh_Binukumar_4-1742233218002.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1116092345"&gt;Concatenating Rows in SAP BODS: A Custom Function Approach&lt;/H2&gt;&lt;P&gt;When working with SAP Business Objects Data Services (BODS), a common challenge is combining multiple rows into a single row. While BODS provides a built-in reverse pivot transform for this purpose, it requires a predefined number of rows to concatenate. This constraint becomes a hurdle when the row count is unknown or variable.&lt;/P&gt;&lt;P&gt;Let’s explore a more flexible and efficient solution to this problem by leveraging custom functions in BODS. We’ll also discuss the limitations of traditional methods, the performance implications of database-level XML functions, and how a custom function can provide a more robust and scalable solution.&lt;/P&gt;&lt;H4 id="toc-hId-1177744278"&gt;The Problem: Concatenating Rows with Unknown Counts&lt;/H4&gt;&lt;P&gt;In many data integration scenarios, multiple rows need to be concatenated into a single row based on a unique identifier (UNIQ_ID). The built-in reverse pivot transform in BODS works only if the number of rows is fixed, making it unsuitable for dynamic datasets.&lt;/P&gt;&lt;H4 id="toc-hId-981230773"&gt;Traditional Workarounds and Their Limitations&lt;/H4&gt;&lt;P&gt;Some common alternatives include database-level SQL functions, such as XMLAGG and XMLELEMENT. These functions can dynamically aggregate multiple rows into a single XML string, which can then be parsed and processed. While this method works, it has significant drawbacks:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Performance Overhead&lt;/STRONG&gt;: XML manipulation at database level can be resource-intensive, especially when dealing with large datasets, slowing down job execution and increasing memory consumption.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Scalability Issues&lt;/STRONG&gt;: Large datasets (millions of records) can lead to database bottlenecks, making XML functions impractical for high-volume data processing.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;A &lt;/STRONG&gt;more efficient approach is to create a custom function within BODS to handle row concatenation dynamically. This offers several benefits:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Flexibility:&lt;/STRONG&gt; No need to predefine the number of rows to be concatenated.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Improved Performance:&lt;/STRONG&gt; Potentially faster execution than database-level XML functions, especially for large datasets.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Reduced Memory Usage:&lt;/STRONG&gt; Optimized memory management for better performance.&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-526551830"&gt;Solution:&lt;/H2&gt;&lt;P&gt;A BODS Custom Function allows concatenation of multiple rows into a single row, even when the number of rows is undefined.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Advantages of Using a Custom Function:&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;No need to predefine the number of rows.&lt;/LI&gt;&lt;LI&gt;Enhanced job performance.&lt;/LI&gt;&lt;LI&gt;Reduced memory usage for cache.&lt;/LI&gt;&lt;LI&gt;Simple and straightforward implementation.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;EM&gt;Input Data:&lt;/EM&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The source table consists of four columns: UNIQ_ID, EBELN, TDID, and GEN_ROW_NO. The source data is structured as follows:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_5-1742233462801.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238748i0DC3895B8EFB862A/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_5-1742233462801.png" alt="Adarsh_Binukumar_5-1742233462801.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Pre-Requisites:&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Define parameters, local and global variables.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Generate a sequence number for each UNIQ_ID.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Group the dataset based on a unique value.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_6-1742233499441.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238749iF53908F7CEE0634B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_6-1742233499441.png" alt="Adarsh_Binukumar_6-1742233499441.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;&lt;STRONG&gt;Output Data:&lt;/STRONG&gt;&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_7-1742233527344.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238750i3D317786FE61E93A/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_7-1742233527344.png" alt="Adarsh_Binukumar_7-1742233527344.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-459121044"&gt;&lt;STRONG&gt;Data Loading into S4/HANA&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Once the extracted and transformed data is generated, it is stored in a structured file format at the designated file path. Since DMC is used as the loading mechanism, the file must strictly adhere to the DMC format. The generated content should be copied and pasted into the corresponding views within the DMC template.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_8-1742233566625.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238752iF6A6E12BC4139DD7/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_8-1742233566625.png" alt="Adarsh_Binukumar_8-1742233566625.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Adarsh_Binukumar_9-1742233572451.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/238753i32EA44E8E1BF047D/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Adarsh_Binukumar_9-1742233572451.png" alt="Adarsh_Binukumar_9-1742233572451.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once the file is created, it can be loaded into the system using the Data Migration Cockpit, after which the data can be reviewed in the S4HANA using transaction code ME23N.&lt;/P&gt;&lt;P&gt;&lt;EM&gt;Our references:&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Credits : Sami Mohammed&lt;/EM&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;SPAN&gt;&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blogs-by-members/calling-rfc-from-bods/ba-p/13125919" target="_blank"&gt;Calling RFC from BODS - SAP Community&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blogs-by-members/sap-bods-concatenate-custom-function/ba-p/12981551#:~:text=Solution%3A,a%20set%20is%20not%20defined." target="_blank"&gt;SAP BODS - Concatenate Custom Function - SAP Community&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/how-to-extract-long-text-from-ecc-and-prepare-a-dmc-template-for-loading/ba-p/14047480"/>
    <published>2025-03-18T17:06:53.690000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/ensure-smooth-integration-your-quick-guide-to-sap-data-services/ba-p/14145471</id>
    <title>Ensure Smooth Integration: Your Quick Guide to SAP Data Services Compatibility ✅</title>
    <updated>2025-07-17T20:46:58.318000+02:00</updated>
    <author>
      <name>EmelyModena</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1506099</uri>
    </author>
    <content>&lt;H3 id="toc-hId-1863285118"&gt;&lt;span class="lia-unicode-emoji" title=":loudspeaker:"&gt;📢&lt;/span&gt;Installation &amp;amp; Upgrade Guide for SAP Data Services &lt;span class="lia-unicode-emoji" title=":hammer_and_wrench:"&gt;🛠&lt;/span&gt;️&lt;/H3&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":light_bulb:"&gt;💡&lt;/span&gt;When installing or upgrading, compatibility questions are bound to arise since we deal with different databases, drivers, applications and other components.&lt;/P&gt;&lt;H3 id="toc-hId-1666771613"&gt;Compatibility Checklist&lt;/H3&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;✅&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Ensuring a Certified Environment&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;To confirm compatibility with your target (new) version of SAP Data Services, verify the following:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":magnifying_glass_tilted_left:"&gt;🔍&lt;/span&gt;&lt;STRONG&gt;Information platform services (IPS) /&amp;nbsp;Business Intelligence Platform (BIP)&lt;BR /&gt;&lt;/STRONG&gt;&lt;span class="lia-unicode-emoji" title=":magnifying_glass_tilted_left:"&gt;🔍&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Operating System&lt;BR /&gt;&lt;/STRONG&gt;&lt;span class="lia-unicode-emoji" title=":magnifying_glass_tilted_left:"&gt;🔍&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Database (Repository / Source &amp;amp; Target)&lt;BR /&gt;&lt;/STRONG&gt;&lt;span class="lia-unicode-emoji" title=":magnifying_glass_tilted_left:"&gt;🔍&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Drivers&lt;/STRONG&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-unicode-emoji" title=":magnifying_glass_tilted_left:"&gt;🔍&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Browser&lt;/STRONG&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-unicode-emoji" title=":magnifying_glass_tilted_left:"&gt;🔍&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Cloud Platforms&lt;/STRONG&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-unicode-emoji" title=":magnifying_glass_tilted_left:"&gt;🔍&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Cloud Storage&lt;/STRONG&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-unicode-emoji" title=":magnifying_glass_tilted_left:"&gt;🔍&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Message Client Library&lt;/STRONG&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-unicode-emoji" title=":magnifying_glass_tilted_left:"&gt;🔍&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Etc.&lt;/STRONG&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1470258108"&gt;Understanding the Compatibility Legend&lt;/H3&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":glowing_star:"&gt;🌟&lt;/span&gt;Make sure you understand its legend, as it is crucial to proceed:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;For example:&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;If item&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;y&lt;SPAN&gt;&amp;nbsp;wa&lt;/SPAN&gt;s certified in version&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;4.x SPx Patch x, it will be considered as supported/compatible for that version and above until the version being mentioned as deprecated in the PAM in the future.&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1273744603"&gt;&lt;span class="lia-unicode-emoji" title=":desktop_computer:"&gt;🖥&lt;/span&gt;Designer Client Tool&lt;/H3&gt;&lt;P&gt;Application client tool, named as Designer, needs to be under the same version, support pack and Patch of SAP Data Services Job Server to avoid any compatibility within the Job Server and CMS (component from IPS/BI application).&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Because of this need for harmony, the Designer tool can't share a machine with another BI/IPS installation, even if you're not using that CMS connection for SAP Data Services. But don't worry! If you need IPS/BI installed, just make sure it's compatible according to our compatibility matrix.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;🔗&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://me.sap.com/notes/3322026" target="_blank" rel="noopener noreferrer"&gt;3322026 - Can BOE/BI/IPS Platform Client Tools and Designer Client Tool coexist in the same machine? - SAP Data Services&lt;/A&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1077231098"&gt;&lt;span class="lia-unicode-emoji" title=":books:"&gt;📚&lt;/span&gt;Useful Resources&lt;/H3&gt;&lt;P&gt;Each SAP product has its&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Product Availability Matrix (PAM)&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;and&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;Maintenance Strategy&lt;/STRONG&gt;. For more information on how to access these, check out the KBA below:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;🔗&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://me.sap.com/notes/1338845" target="_blank" rel="noopener noreferrer"&gt;1338845 - How to find Product Availability Matrix (PAM) / Supported Platforms Documentation for SAP BusinessObjects products (BI/IPS, DS, IS)?&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Visit the&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;A href="https://help.sap.com/docs/SAP_DATA_SERVICES" target="_blank" rel="noopener noreferrer"&gt;SAP Data Services&lt;/A&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;for detailed information on Installation, Upgrade, and Migration steps. Remember to change the documentation version to your desired SAP Data Services version.&lt;/P&gt;&lt;H3 id="toc-hId-880717593"&gt;Recommendation&lt;/H3&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":light_bulb:"&gt;💡&lt;/span&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;We strongly recommend installing/upgrading to the latest certified version between IPS/BIP and SAP Data Services&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;to avoid any known issues that have been fixed.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;If upgrading is not possible&lt;/STRONG&gt;, before proceeding with the installation or upgrade, check the Release Notes for that version under the SAP Knowledge Base. There might be known issues that could affect your daily work.&lt;/LI&gt;&lt;LI&gt;This will help you identify and be prepared to apply any available workaround!&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":glowing_star:"&gt;🌟&lt;/span&gt;If you have any questions or need assistance, feel free to reach out to SAP Support and search under our &lt;A href="https://support.sap.com/en/my-support/knowledge-base.html" target="_blank" rel="noopener noreferrer"&gt;Knowledge Base&lt;/A&gt;!&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":pushpin:"&gt;📌&lt;/span&gt;If you found this helpful or interesting, I would really appreciate a 'Kudo' to let me know! Your feedback means a lot. &lt;span class="lia-unicode-emoji" title=":smiling_face_with_smiling_eyes:"&gt;😊&lt;/span&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/ensure-smooth-integration-your-quick-guide-to-sap-data-services/ba-p/14145471"/>
    <published>2025-07-17T20:46:58.318000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/avoiding-rfc-timeout-issues-during-sap-table-job-extraction-in-sap-data/ba-p/14182642</id>
    <title>Avoiding RFC Timeout Issues During SAP Table Job Extraction in SAP Data Services</title>
    <updated>2025-08-19T04:29:54.905000+02:00</updated>
    <author>
      <name>Praveen_NK</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1783141</uri>
    </author>
    <content>&lt;H2 id="toc-hId-1737808940"&gt;Avoiding RFC Timeouts: Executing SAP Table Extractions Jobs in Background via RFC Batch&amp;nbsp;&lt;/H2&gt;&lt;H3 id="toc-hId-1670378154"&gt;Introduction&lt;/H3&gt;&lt;P&gt;Extracting large volumes of data from SAP systems using &lt;STRONG&gt;SAP Data Services (BODS)&lt;/STRONG&gt; can be a real challenge — especially when working with standard (non-ABAP) dataflows. One of the most common issues encountered is the dreaded &lt;STRONG&gt;RFC timeout&lt;/STRONG&gt;, which occurs when a data extraction takes too long to return results, and the SAP session times out.&lt;/P&gt;&lt;P&gt;In many environments, using &lt;STRONG&gt;ABAP dataflows&lt;/STRONG&gt; to offload processing to SAP is restricted due to governance or lack of ABAP resources. So, how can we extract large datasets without ABAP Dataflow, and still avoid timeouts?&lt;/P&gt;&lt;P&gt;In this blog, we explore how executing jobs in &lt;STRONG&gt;RFC batch background mode&lt;/STRONG&gt; can help solve this problem.&lt;/P&gt;&lt;H3 id="toc-hId-1473864649"&gt;Understanding RFC Timeouts&lt;/H3&gt;&lt;P&gt;An &lt;STRONG&gt;RFC (Remote Function Call)&lt;/STRONG&gt; allows SAP Data Services to call SAP functions like&amp;nbsp; RFC_READ_TABLE to extract data. However, when these calls are executed in &lt;STRONG&gt;dialog mode&lt;/STRONG&gt; (default), they inherit the standard timeout settings of an interactive SAP user session — typically 600 to 1800 seconds (10–30 minutes).&lt;/P&gt;&lt;P&gt;When a query takes too long — due to high data volume, slow performance, or unfiltered extraction — the RFC session times out, causing the job to fail.&lt;/P&gt;&lt;H3 id="toc-hId-1277351144"&gt;What Is "Execute in Background Job in RFC Batch"?&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;"Execute in background job in RFC batch"&lt;/STRONG&gt; means:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;The RFC-connected extraction is &lt;STRONG&gt;not executed in foreground&lt;/STRONG&gt; (interactive user session).&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Instead, SAP &lt;STRONG&gt;submits the job to the background job scheduler&lt;/STRONG&gt;, and the logic is run as a &lt;STRONG&gt;batch job&lt;/STRONG&gt;.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;This background job is still triggered via RFC but runs &lt;STRONG&gt;asynchronously&lt;/STRONG&gt;, bypassing timeout limitations.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1080837639"&gt;Benefits of Executing in RFC Batch Background&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Avoids dialog session timeouts&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Allows longer-running data extraction jobs&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Reduces job failures in SAP Data Services&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;No need for ABAP code or ABAP dataflows&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-884324134"&gt;Steps to Enable Background Job Execution for SAP Table Extraction&lt;/H3&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Double-click on the SAP Table:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;In SAP Data Services Designer, double-click on the SAP table you want to extract (for example, &lt;STRONG&gt;EKKO&lt;/STRONG&gt;) to open its properties.&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Praveen_NK_0-1755503964381.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/301844iA26710E49EE73CF8/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Praveen_NK_0-1755503964381.png" alt="Praveen_NK_0-1755503964381.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Open Source Table Editor:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;This opens the &lt;STRONG&gt;Source Table Editor&lt;/STRONG&gt; options for that table.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Enable Background Execution:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;In the Source Table Editor, locate and enable the option &lt;STRONG&gt;Execute in Background (Batch)&lt;/STRONG&gt; .&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Praveen_NK_0-1755504918182.png" style="width: 595px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/301853iCF4A9DA59424CDFC/image-dimensions/595x199?v=v2" width="595" height="199" role="button" title="Praveen_NK_0-1755504918182.png" alt="Praveen_NK_0-1755504918182.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Save the Job:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Save your changes to the dataflow or job.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Run the Job:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Execute the job. The extraction will now run as a background RFC batch job, preventing timeout errors typical of foreground execution.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/OL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/avoiding-rfc-timeout-issues-during-sap-table-job-extraction-in-sap-data/ba-p/14182642"/>
    <published>2025-08-19T04:29:54.905000+02:00</published>
  </entry>
</feed>
