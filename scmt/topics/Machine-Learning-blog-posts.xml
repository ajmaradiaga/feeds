<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/Machine-Learning-blog-posts.xml</id>
  <title>SAP Community - Machine Learning</title>
  <updated>2025-07-29T11:10:56.562457+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/Machine Learning/pd-p/240174591523510321507492941674121" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>Machine Learning blog posts in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/crm-and-cx-blog-posts-by-sap/stay-certified-live-session-on-sap-sales-cloud-version-2-generative-ai-amp/ba-p/14075797</id>
    <title>Stay Certified Live Session on SAP Sales Cloud Version 2 - Generative AI &amp; Machine Learning!</title>
    <updated>2025-04-14T22:05:09.137000+02:00</updated>
    <author>
      <name>DeepaliJohnson</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/124577</uri>
    </author>
    <content>&lt;P&gt;Hello learners!&lt;/P&gt;&lt;P&gt;Mark your calendars for May 15th, 2025, because this is the event you wonâ€™t want to miss! We're thrilled to announce a Stay Certified live session that will delve into the cutting-edge capabilities of SAP Sales Cloud Version 2, focusing on the transformative power of Generative AI and Machine Learning.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Why Attend?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This session offers a valuable chance to stay updated on the latest technology in SAP Sales Cloud Version 2. You can also attempt the Stay Certified assessment for SAP Sales Cloud Version 2 with the knowledge you gain from this session.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Whether youâ€™re a seasoned sales professional or a consultant, this event is designed for you. Weâ€™ll explore the new features that can improve your lead generation, make your sales processes more efficient, and provide important customer insights. By attending, you'll gain a competitive edge and learn how to use advanced AI and Machine Learning capabilities to boost your sales success. You can also attempt the Stay Certified assessment for SAP Sales Cloud Version 2 with the knowledge you gain from this session.&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;What to Expect?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Our expert-led discussions and interactive demos will give you the inside scoop on how to leverage Machine Learning and Generative AI to supercharge your sales performance. Hereâ€™s a sneak peek of whatâ€™s lined up:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;1. Machine Learning Capabilities:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Lead Intelligence:&lt;/STRONG&gt; Uncover actionable insights that help you target the right leads at the right time.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Deal Intelligence:&lt;/STRONG&gt; Improve your deal-closing rates by predicting the most promising opportunities and crafting perfect pitches.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;2. Generative AI Capabilities:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Lead Booster:&lt;/STRONG&gt; Supercharge your lead generation process with AI-driven techniques that automate and enhance your outreach.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Account Synopsis:&lt;/STRONG&gt; Get a comprehensive, AI-generated summary of key accounts to tailor your sales approach and foster stronger client relationships.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;3. CX AI Toolkit:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Explore the Customer Experience (CX) AI Toolkit to create personalized experiences that delight your customers and drive loyalty. Learn how to utilize AI to summarize customer behavior, respond to their needs in real-time, and optimize your sales strategies for maximum impact.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;How to Register?&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Click &lt;A href="https://learning.sap.com/live-sessions/sap-sales-cloud-version-2-generative-ai-machine-learning" target="_self" rel="noopener noreferrer"&gt;here&lt;/A&gt; to register. Remember, a valid SAP Learning Hub subscription is required.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Save the Date: May 15th, 2025&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Join us and take the first step towards transforming your sales strategy. Sign up today for 'SAP Sales Cloud Version 2 - Generative AI &amp;amp; Machine Learning' and prepare to unlock the future of sales!&lt;/P&gt;&lt;P&gt;Stay ahead. Stay smart. Stay successful.&lt;/P&gt;&lt;P&gt;See you there!&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Register Now!&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Feel free to share this post with your network and spread the word about this exclusive learning opportunity. Let's redefine the future of sales together!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/crm-and-cx-blog-posts-by-sap/stay-certified-live-session-on-sap-sales-cloud-version-2-generative-ai-amp/ba-p/14075797"/>
    <published>2025-04-14T22:05:09.137000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-and-ai-features-in-sap-hana-cloud-2025-q1/ba-p/14078615</id>
    <title>New Machine Learning and AI features in SAP HANA Cloud 2025 Q1</title>
    <updated>2025-04-17T10:05:30.574000+02:00</updated>
    <author>
      <name>ChristophMorgen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14106</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;With the SAP HANA Cloud 2025 Q1 release, several new embedded Machine Learning / AI functions&amp;nbsp;have been released with the SAP HANA Cloud Predictive Analysis Library (PAL). Key new capabilities to be highlighted are introduction of text analysis, text vectorization, vector data as input to many more Machine Learning functions like classification and regression in the SAP HANA Cloud database. An enhancement summary is available in the Whatâ€™s new document for &lt;A href="https://help.sap.com/whats-new/2495b34492334456a49084831c2bea4e?Category=Predictive+Analysis+Library&amp;amp;Valid_as_Of=2025-03-01:2025-03-30&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP HANA Cloud database 2025.02 (QRC 1/2025)&lt;/A&gt;.&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1708434924"&gt;&lt;SPAN&gt;Text extraction and text search enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text extraction from binary files&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new &lt;STRONG&gt;Document Filter Library (DFL)&lt;/STRONG&gt; has been released, which provides functions to extract plain text from binary files like PDFs stored as BLOBs in SAP HANA Cloud tables. By use of the &lt;A href="https://help.sap.com/docs/hana-cloud/sap-hana-cloud-administration-guide/document-filters-library-plugin?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;DFL_EXTRACT_TEXT_FROM_DOCUMENTS&lt;/A&gt; procedure, application developers and data scientist are enabled to unlock the valuable insights from text hidden in those files. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_0-1744875447906.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251818iFA870C6549B86390/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_0-1744875447906.png" alt="ChristophMorgen_0-1744875447906.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Extracted text is made available for text preprocessing tasks like chunking, NLP (e.g. entity extraction, sentiment detection), text vectorization using SAP HANA Cloud embedding models and further downstream analysis tasks based on text vectors such as similarity search, text mining, clustering and classification. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;This enhancement not only widens the scope of your data analysis but also makes it easier to leverage text-based insights in your applications.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The &lt;STRONG&gt;Document Filter Library (DFL) &lt;/STRONG&gt;is provided as a SAP HANA Cloud &lt;EM&gt;plugin&lt;/EM&gt;. The &lt;A href="https://help.sap.com/docs/hana-cloud/sap-hana-cloud-administration-guide/document-filters-library-plugin?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;setup instructions&lt;/A&gt; are documented in the SAP HANA Cloud administration guide and include the following steps&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;the plugin needs to be installed and Script Server activated&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;SQL user privileges need to be granted&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_1-1744875447909.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251819iF7C3AC46480790F6/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_1-1744875447909.png" alt="ChristophMorgen_1-1744875447909.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Further note, the &lt;STRONG&gt;document filter library&lt;/STRONG&gt; in SAP HANA Cloud provides comparable &lt;EM&gt;text from binary files extraction&lt;/EM&gt;-capabilities like the &lt;EM&gt;text analysis&lt;/EM&gt; and &lt;EM&gt;full text indexing&lt;/EM&gt; from binary files features in SAP HANA Platform, for respective reference see the text analysis&amp;nbsp;SQL API for extraction of text from binary documents in the&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://help.sap.com/docs/SAP_HANA_PLATFORM/62e301bb1872437cbb2a8c4209f74a65/a3adb442cbc44a84a626d99014d3dbc9.html?q=document%20filtering&amp;amp;locale=en-US" target="_self" rel="noopener noreferrer"&gt;Text Analysis Developer Guide&lt;/A&gt;&amp;nbsp;or the &lt;A href="https://help.sap.com/docs/SAP_HANA_PLATFORM/691cb949c1034198800afde3e5be6570/ccc504cebb571014badd88b622a24cae.html?q=mime&amp;amp;locale=en-US" target="_self" rel="noopener noreferrer"&gt;SAP HANA search developer guide&lt;/A&gt; for document mime-type reference.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Keyword-based text search enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Information retrieval from text typically starts with text search techniques. The newly released keyword-based search function &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/bm25-search?" target="_blank" rel="noopener noreferrer"&gt;BM25 search &lt;/A&gt;(SEARCH_DOCS_BY_KEYWORDS) has been further enhanced to support &lt;STRONG&gt;complete natural sentences&lt;/STRONG&gt; as input to the BM25 search:&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_2-1744875940641.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251824i4D49FE0A2D40E3EB/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_2-1744875940641.png" alt="ChristophMorgen_2-1744875940641.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1511921419"&gt;&lt;SPAN&gt;Classification, regression, time series and AutoML model enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Hybrid Gradient Boosting Trees (HGBT) enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;HGBT now supports &lt;STRONG&gt;multi-target regression&lt;/STRONG&gt; and &lt;STRONG&gt;multi-label classification&lt;/STRONG&gt; models, alike MT_MLP modelling predictions for multiple columns using a single model.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Multiple DEPENDENT_VARIABLE values can be set as parameters to enable this&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;In addition, REAL_VECTOR columns are supported as target, and a multiple target regression model applied. &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;The objective functions supported for multi-target/label models&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;Regression &lt;SPAN&gt;OBJ_FUNC = 0 (Squared error)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Classification &lt;SPAN&gt;OBJ_FUNC = 7 (Softmax)&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Using the new parameter USE_VEC_LEAF, allows to control for each tree leaf to have a vector-value as a predictor (default is no)&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;As the prediction output incl. values for multiple targets or classes, a new function &lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/hybrid-gradient-boosting-tree-hybrid-gradient-boosting-tree-ca5106c" target="_blank" rel="noopener noreferrer"&gt;PAL_HGBT_MULTI_TASK_PREDICT&lt;/A&gt; is introduced generating the extended output&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_3-1744875979136.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251825i1D4F90C96D84803A/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_3-1744875979136.png" alt="ChristophMorgen_3-1744875979136.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;HGBT regression models with trend extrapolation for Time Series &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Tree-based models like Hybrid Gradient Boosting Trees are great at capturing patterns from the training data. However, they falter when it comes to projecting these patterns into the future, hence especially when models like HGBT regressors are applied in time series forecasting. A regular such model has no means to infer trends or patterns beyond the bounds of the training data, making true extrapolation impossible. For a detailed discussion see for example this blog post: &lt;A href="https://medium.com/@simon.peter.mueller/overcoming-the-limitations-of-tree-based-models-in-time-series-forecasting-c2c5bd71a8f1" target="_blank" rel="noopener nofollow noreferrer"&gt;overcoming the limitations of tree-based models in time series forecasting&lt;/A&gt;.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;HGBTs, now introduces a linear component to the tree-building process, allowing the model to capture linear patterns and thus trend extrapolation capabilities&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;New parameter &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/hybrid-gradient-boosting-tree-hybrid-gradient-boosting-tree-ca5106c?state=DRAFT&amp;amp;q=MODEL_TREE" target="_blank" rel="noopener noreferrer"&gt;MODEL_TREE&lt;/A&gt;&lt;/SPAN&gt;, when setting it to linear, the model will try to fit a linear model at each leaf node.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;With this key enhancement PAL Hybrid Gradient Boosting Tree (HGBT) now allows for building superior regression models, with improved trend extrapolation of value outside of the training data scope.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_4-1744875979141.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251826iA45F62C87BD73926/image-size/medium?v=v2&amp;amp;px=400" role="button" title="ChristophMorgen_4-1744875979141.png" alt="ChristophMorgen_4-1744875979141.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Unified classification / regression enhancements &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The modernized and much enhanced &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/multi-task-multilayer-perceptron" target="_blank" rel="noopener noreferrer"&gt;Multi-task MLP&lt;/A&gt; Neural Network modeling function, can now be used with the &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/unified-classification-unified-classification-8bd88cf?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;Unified Classification&lt;/A&gt;/&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/unified-regression-unified-regression-736b679?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;Regression&lt;/A&gt; function &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;This unlocks local explainability when using &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/multi-task-multilayer-perceptron" target="_blank" rel="noopener noreferrer"&gt;Multi-task MLP&lt;/A&gt; models, the predictions providing reason codes with Shapley explanations (using parameters BACKGROUND_SIZE, BACKGROUND_SAMPLING_SEED)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;However in the current update, the models are constrained a single target/label only when used via &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/unified-classification-unified-classification-8bd88cf?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;Unified Classification&lt;/A&gt;/&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/unified-regression-unified-regression-736b679?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;Regression&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;AutoML for time series &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;STRONG&gt;optimization &lt;SPAN&gt;enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/automl-automl?" target="_blank" rel="noopener noreferrer"&gt;AutoML&lt;/A&gt; introduces an improved hyperparameter&amp;nbsp;optimization for time series models&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;random-search optimization is now utilizing &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/optimization-optimization#ariaid-title7" target="_blank" rel="noopener noreferrer"&gt;Hyperband&lt;/A&gt; &lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;A new parameter WITH_HYPERBAND enables the enhancement in conjunction with SEARCH_METHOD set as "random"&lt;/LI&gt;&lt;LI&gt;The optimization now more efficiently allocates resources to different hyperparameter configurations, and significantly speeds up the optimization process&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1315407914"&gt;&lt;SPAN&gt;Python ML client (hana-ml) enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;EM&gt;The full list of new methods and enhancements with hana_ml 2.24&amp;nbsp; is summarized in the &lt;/EM&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/doc/cd94b08fe2e041c2ba778374572ddba9/2025_1_QRC/en-US/change_log.html" target="_blank" rel="noopener noreferrer"&gt;&lt;EM&gt;changelog for hana-ml 2.24&lt;/EM&gt;&lt;/A&gt; &lt;/SPAN&gt;&lt;EM&gt;as part of the documentation. The key enhancements in this release include&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Dataframe enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;New Vector- / vector-index management methods&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;New sort by vector-similarity &lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;AutoML and pipeline modeling improvements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Data-parallel/massive AutoML&lt;BR /&gt;progress monitor enhanced&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;New AutoML regression&lt;BR /&gt;outlier detection&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text processing enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;New Text Analysis, POS, NER, Sentiment Analysis &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Enhanced BM25 search by doc, sentence&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Further misc. enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;New Tree Debriefing to text for decision tree&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Enhanced CAP generation for AdditiveModelForecast, AutoML&lt;BR /&gt;and Unified APIs wrt use of input/output signatures&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_5-1744876082041.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251827iA96BAF7919D71EF5/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_5-1744876082041.png" alt="ChristophMorgen_5-1744876082041.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;You can find an examples notebook illustrating the highlighted feature enhancements &lt;SPAN&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/pal/notebooks/25QRC01_2.24.ipynb" target="_blank" rel="noopener nofollow noreferrer"&gt;here 25QRC01_2.24.ipynb&lt;/A&gt;.&amp;nbsp; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1118894409"&gt;&lt;SPAN&gt;Generative AI-toolkit for SAP HANA Cloud (hana-ai)&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Introduction&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The new &lt;A title="generative AI-toolkit for SAP HANA Cloud (hana-ai)" href="https://github.com/SAP/generative-ai-toolkit-for-sap-hana-cloud" target="_self" rel="nofollow noopener noreferrer"&gt;&lt;STRONG&gt;generative AI-toolkit for SAP HANA Cloud (hana-ai)&lt;/STRONG&gt;&lt;/A&gt; is an extension of the existing Python ML client for SAP HANA (hana-ml), mainly focusing on generative AI-assisted machine learning scenario development using hana-ml, thus streamlining embedding of ML capabilities with SAP BTP Cloud Application Programming (CAP) apps.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;It builds upon many leading-edge generative AI related open source Python libraries (e.g. langchain) and provides seamless integration with SAP HANA Cloud, HANA vector engine, and others Python libraries like &lt;A href="https://pypi.org/project/generative-ai-hub-sdk/" target="_blank" rel="noopener nofollow noreferrer"&gt;SAP GenAI Hub SDK&lt;/A&gt;.&amp;nbsp; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Key capabilities&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt; for AI-assisted HANA ML development and code generation&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Use &lt;STRONG&gt;code-template knowledge stores&lt;/STRONG&gt; and new &lt;STRONG&gt;hana-ml tools&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;Tools for code generation as well as executable tools for agentic-use of HANA ML for Forecasting&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;Conversational agent&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt; for HANA ML&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Generative AI&lt;/SPAN&gt; agent, utilizing executable tools targeted for HANA ML&lt;/LI&gt;&lt;LI&gt;Unlocking agentic, AI-assisted HANA ML development&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Further &lt;STRONG&gt;conversational interfaces&lt;/STRONG&gt; and &lt;STRONG&gt;agents&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;HANA &lt;STRONG&gt;dataframe agent&lt;/STRONG&gt; for invoke code template-based tasks using hana-ml in python&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;SQL agent&lt;/STRONG&gt; for invoking code template-based and langchain-db tool tasks via SQL generation and execution&lt;/LI&gt;&lt;LI&gt;Conversational &lt;STRONG&gt;SmartDataFrame interface&lt;/STRONG&gt;, for applying standard dataframe methods as well as code template-based tasks to a dataframe&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Highlighted features &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Using sample code knowledge stores&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Leverage hana-ml samples as knowledge store&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;Python | SQL default samples for PAL functions&lt;/LI&gt;&lt;LI&gt;Can be augmented with additional content, created with custom / best practice templates&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_6-1744876123179.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251829i220637EE530B46FD/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_6-1744876123179.png" alt="ChristophMorgen_6-1744876123179.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Using new set of agent-tools targeted for simplified use of HANA ML&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Library of executable hana-ml tools&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;Tools execute independently and generate results, beyond code generation&lt;/LI&gt;&lt;LI&gt;Initial set of tools focused on Time Series Forecasting&lt;/LI&gt;&lt;LI&gt;Time series analysis tools applied to the time series data,&lt;BR /&gt;determining guidance about which time series algorithms to apply&lt;/LI&gt;&lt;LI&gt;Can be augmented with additional, custom created tools&lt;/LI&gt;&lt;LI&gt;Utilized for automated and agentic-, generative AI-assisted&lt;BR /&gt;HANA ML development or via direct tool-usage&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_7-1744876123185.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251828i96A7774B8AE578ED/image-size/medium?v=v2&amp;amp;px=400" role="button" title="ChristophMorgen_7-1744876123185.png" alt="ChristophMorgen_7-1744876123185.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Using new set of agent-tools targeted for simplified use of HANA ML&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Library of executable hana-ml tools&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;Tools execute independently and generate results, beyond code generation&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Using a conversational agent for HANA ML&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;New Agent for HANA ML&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;Ready to use agent to build HANA Cloud PAL forecast models&lt;/LI&gt;&lt;LI&gt;Conversational agent session incl. chat history, based on langchain&lt;/LI&gt;&lt;LI&gt;Leverages executable tools specifically targeted for HANA ML&lt;/LI&gt;&lt;LI&gt;HANA ML-tools: initially focused on Time Series Forecasting like&lt;BR /&gt;automatic time series data analysis, forecast algorithm proposal&lt;BR /&gt;and fitting, or CAP project artifact generation&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_8-1744876123201.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/251830iDDE98DFDD3A0870F/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_8-1744876123201.png" alt="ChristophMorgen_8-1744876123201.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The new generative AI-toolkit unlocks and simplifies embedded AI SAP BTP application development with natural language assistance providing a faster getting-started experience, automated code generation based on template code samples, hana-ml tools for an conversational agent.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;For further details see the &lt;A href="https://github.com/SAP/generative-ai-toolkit-for-sap-hana-cloud/blob/main/INTRODUCTION.md" target="_blank" rel="noopener nofollow noreferrer"&gt;Introduction&lt;/A&gt; at &lt;A href="https://github.com/SAP/generative-ai-toolkit-for-sap-hana-cloud/blob/main/INTRODUCTION.md" target="_blank" rel="noopener nofollow noreferrer"&gt;github.com/SAP/generative-ai-toolkit-for-sap-hana-cloud&lt;/A&gt; and the documentation at &lt;A href="https://sap.github.io/generative-ai-toolkit-for-sap-hana-cloud/" target="_blank" rel="noopener nofollow noreferrer"&gt;sap.github.io/generative-ai-toolkit-for-sap-hana-cloud&lt;/A&gt;.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A sample python notebook using the conversational agent can be found at &lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/hana-ai%20examples/Generative-AI-toolkit-SAPHANACloud-Demo-SalesRefunds-Forecast.ipynb" target="_blank" rel="noopener nofollow noreferrer"&gt;github.com/SAP-samples/hana-ml-samples/.../Generative-AI-toolkit-SAPHANACloud-Demo-SalesRefunds-Forecasting&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Setup instruction for generative AI-toolkit (&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;hana-ai)&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Download the hana-ai package from &lt;A href="https://github.com/SAP/generative-ai-toolkit-for-sap-hana-cloud/releases" target="_blank" rel="noopener nofollow noreferrer"&gt;github releases&lt;/A&gt; and install it using _pip install generative-ai-toolkit-for-sap-hana-cloud-x.x.x.zip_, or use _pip install hana-ai_ for install from &lt;A href="https://pypi.org/project/hana-ai/1.0.25041100/" target="_blank" rel="noopener nofollow noreferrer"&gt;pypi.org/hana-ai&lt;/A&gt;.&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Setup of the&amp;nbsp;&lt;STRONG&gt;SAP generative AI hub SDK&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Install the required Python packages&amp;nbsp;&lt;STRONG&gt;pip install "generative-ai-hub-sdk[all]"&lt;/STRONG&gt;.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Create a&amp;nbsp;&lt;STRONG&gt;deployment for a generative AI model&lt;/STRONG&gt;&amp;nbsp;in the SAP BTP, for instructions see the SAP AI core documentation section&amp;nbsp;&lt;A href="https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/create-deployment-for-generative-ai-model-in-sap-ai-core" target="_blank" rel="noopener noreferrer"&gt;Create a Deployment for a Generative AI Model&lt;/A&gt;.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;The&amp;nbsp;&lt;STRONG&gt;generative AI hub SDK&lt;/STRONG&gt;&amp;nbsp;reuses configuration settings from the AI-core-SDK, these include client ID, client secret, authentication URL, base URL, and resource group. You can set these values as environment variables or via a config file. For detailed instructions see this&amp;nbsp;&lt;A href="https://learning.sap.com/learning-journeys/solving-your-business-problems-using-prompts-and-llms-in-sap-s-generative-ai-hub/identifying-the-need-for-using-generative-ai-hub-sdk" target="_blank" rel="noopener noreferrer"&gt;SAP Learning unit on using Generative-AI-Hub-SDK&lt;/A&gt;.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;Overall, again a great set of Machine Learning and AI capabilities enhancements with this SAP HANA Cloud release!&lt;/STRONG&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-and-ai-features-in-sap-hana-cloud-2025-q1/ba-p/14078615"/>
    <published>2025-04-17T10:05:30.574000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/%E6%8F%90%E4%BE%9B%E9%96%8B%E5%A7%8B-sap-help-portal-%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E3%82%92%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3%E3%81%A7%E5%8D%B3%E6%99%82%E3%81%AB%E7%BF%BB%E8%A8%B3/ba-p/14085252</id>
    <title>æä¾›é–‹å§‹ï¼šSAP Help Portal ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ©Ÿæ¢°ç¿»è¨³ã§å³æ™‚ã«ç¿»è¨³</title>
    <updated>2025-04-24T10:36:36.402000+02:00</updated>
    <author>
      <name>TakaneOzaki</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1727194</uri>
    </author>
    <content>&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Takane_0-1745483183467.png" style="width: 749px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254279i93AAEF3450658372/image-dimensions/749x176?v=v2" width="749" height="176" role="button" title="Takane_0-1745483183467.png" alt="Takane_0-1745483183467.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://help.sap.com" target="_blank" rel="noopener noreferrer"&gt;SAP Help Portal&lt;/A&gt; ã«&lt;STRONG&gt;æ©Ÿæ¢°ç¿»è¨³&lt;/STRONG&gt;&lt;STRONG&gt; (MT) &lt;/STRONG&gt;æ©Ÿèƒ½ãŒå°å…¥ã•ã‚Œã¾ã—ãŸã€‚ã“ã®æ–°æ©Ÿèƒ½ã§ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å³æ™‚ã« &lt;STRONG&gt;39 &lt;/STRONG&gt;&lt;STRONG&gt;ã®è¨€èª&lt;/STRONG&gt;ã«ç¿»è¨³ã§ãã‚‹ãŸã‚ã€ä»»æ„ã®è¨€èªã§å¿…è¦ãªæƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚&lt;BR /&gt;â€»ã“ã®è¨˜äº‹ã¯&lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/now-live-instantly-translate-sap-help-portal-content-with-machine/ba-p/14069360" target="_self"&gt;è‹±èªç‰ˆ&lt;/A&gt;ã®æ—¥æœ¬èªç¿»è¨³ã§ã™ã€‚ä½µã›ã¦ã”è¦§ãã ã•ã„ã€‚&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;ä½¿ã„æ–¹&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;ä»»æ„ã® &lt;A href="https://help.sap.com" target="_blank" rel="noopener noreferrer"&gt;SAP Help Portal&lt;/A&gt; ãƒšãƒ¼ã‚¸ã‚’é–‹ãã¾ã™ã€‚&lt;/LI&gt;&lt;LI&gt;ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰è¨€èªã‚’é¸æŠã—ã¾ã™ã€‚&lt;/LI&gt;&lt;LI&gt;ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã€&lt;A href="https://www.sap.com/germany/products/artificial-intelligence/translation-hub.html" target="_blank" rel="noopener noreferrer"&gt;SAP Translation Hub&lt;/A&gt; ã® AI æ©Ÿæ¢°ç¿»è¨³ã‚’ä½¿ç”¨ã—ã¦ã€æ•°ç§’ã§&lt;STRONG&gt;å³æ™‚ã«&lt;/STRONG&gt;ç¿»è¨³ã•ã‚Œã¾ã™ã€‚&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Untitled Project.gif" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/254305iD8E71A120C27763E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Untitled Project.gif" alt="Untitled Project.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ãŠé¡˜ã„&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;ãŠå®¢æ§˜ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ç¿»è¨³ã®ã©ã¡ã‚‰ã‚’æ”¹å–„ã™ã‚‹ä¸Šã§ã‚‚å¤§å¤‰é‡è¦ã§ã™ã€‚ãã®ãŸã‚ã€ç°¡å˜ã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãŠå¯„ã›ã„ãŸã ã‘ã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒšãƒ¼ã‚¸ã®å³å´ã«&lt;STRONG&gt;ã€ã€Œã“ã®ãƒšãƒ¼ã‚¸ã¯å½¹ã«ç«‹ã¡ã¾ã—ãŸã‹ã€&lt;/STRONG&gt;ã¨ã„ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚&lt;/LI&gt;&lt;LI&gt;ã€Œ&lt;STRONG&gt;ã„ã„ãˆ&lt;/STRONG&gt;ã€ã‚’é¸æŠã™ã‚‹ã¨ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒ&lt;STRONG&gt;ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®&lt;/STRONG&gt;å“è³ªã«é–¢ã™ã‚‹ã‚‚ã®ãªã®ã‹ã€æ©Ÿæ¢°&lt;STRONG&gt;ç¿»è¨³&lt;/STRONG&gt;ã«é–¢ã™ã‚‹ã‚‚ã®ãªã®ã‹ã‚’é¸æŠã§ãã¾ã™ã€‚&lt;/LI&gt;&lt;LI&gt;ã€Œ&lt;STRONG&gt;ã¯ã„&lt;/STRONG&gt;ã€ã‚’é¸æŠã•ã‚ŒãŸå ´åˆã€å‚è€ƒã«ãªã£ãŸç‚¹ã‚’ãœã²ãŠèã‹ã›ãã ã•ã„ã€‚è‚¯å®šçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯ã€ä½•ãŒã†ã¾ãæ©Ÿèƒ½ã—ã¦ã„ã‚‹ã‹ã‚’å¼Šç¤¾ãŒç†è§£ã™ã‚‹ä¸Šã§æœ‰ç”¨ã§ã™ã€‚&lt;/LI&gt;&lt;LI&gt;æ”¹å–„ãŒå¿…è¦ãªç‚¹ã«ã¤ã„ã¦ã€&lt;STRONG&gt;ãƒ•ãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ¡ãƒ³ãƒˆ&lt;/STRONG&gt;ã‚’è¿½åŠ ã„ãŸã ãã“ã¨ãŒã§ãã¾ã™ã€‚&lt;/LI&gt;&lt;LI&gt;SAP Help Portal ã«ãƒ­ã‚°ã‚¤ãƒ³ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€&lt;STRONG&gt;è¿½åŠ ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³&lt;/STRONG&gt;ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚é›»å­ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æ®‹ã™ã“ã¨ã§ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆè€…ã¨æ”¹å–„ç‚¹ã«ã¤ã„ã¦ç›´æ¥ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¸ã®å¯¾å¿œã«ã¤ã„ã¦&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;ã„ãŸã ã„ãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯&lt;STRONG&gt;ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆè€…&lt;/STRONG&gt;ã¾ãŸã¯&lt;STRONG&gt;è¨€èªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ&lt;/STRONG&gt;ã«ç›´æ¥é€ä¿¡ã•ã‚Œã€å¿…è¦ãªæ”¹å–„ãŒè¡Œã‚ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å…¨ä½“çš„ãªå“è³ªãŒå‘ä¸Šã—ã€ã‚ˆã‚Šå½¹ç«‹ã¤ã‚‚ã®ã«ãªã‚Šã¾ã™ã€‚&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":globe_showing_europe_africa:"&gt;ğŸŒ&lt;/span&gt;&lt;STRONG&gt;ä»Šã™ãæ©Ÿæ¢°ç¿»è¨³ã‚’ãŠè©¦ã—ã„ãŸã ãã€ã”æ„è¦‹ã‚’ãŠèã‹ã›ãã ã•ã„ã€‚&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;ğŸ”—&lt;/span&gt;&lt;STRONG&gt;è©³ç´°ã«ã¤ã„ã¦&lt;/STRONG&gt; &lt;A href="https://help.sap.com/whats-new/b5f16e1b61f34fbe9ac390468929bc31?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP Help Portal ã®æ–°æ©Ÿèƒ½&lt;/A&gt;ã€&lt;A href="https://help.sap.com/docs/SAP_TRANSLATION_HUB/ed6ce7a29bdd42169f5f0d7868bce6eb/document-translation-service-detailed-overview?locale=en-US&amp;amp;state=PRODUCTION&amp;amp;version=Cloud%20" target="_blank" rel="noopener noreferrer"&gt;SAP Translation Hub æ–‡æ›¸ç¿»è¨³ - æ¦‚è¦&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/%E6%8F%90%E4%BE%9B%E9%96%8B%E5%A7%8B-sap-help-portal-%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E3%82%92%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3%E3%81%A7%E5%8D%B3%E6%99%82%E3%81%AB%E7%BF%BB%E8%A8%B3/ba-p/14085252"/>
    <published>2025-04-24T10:36:36.402000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-members/artificial-intelligence-ai-amp-machine-learning-ml-in-sap-s-4hana/ba-p/14088281</id>
    <title>Artificial Intelligence(AI) &amp; Machine Learning(ML) in SAP S/4HANA:Transforming Enterprise Operations</title>
    <updated>2025-04-29T17:00:26.862000+02:00</updated>
    <author>
      <name>Ambarish_ad</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1484050</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;Artificial Intelligence (AI) and Machine Learning (ML) in SAP S/4HANA: Transforming Enterprise Operations&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;After working in SAP SD for over 15 years, I have seen the module evolve from being purely transactional to becoming a key driver of customer experience and revenue performance. What excites me about AI now is how it can finally unlock the next level moving from reactive order processing to intelligent, predictive selling.&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;AI can help us optimize pricing in real time, anticipate customer needs based on buying patterns, and even automate complex order management scenarios. Itâ€™s no longer just about automating tasks itâ€™s about transforming how sales and distribution contribute to the business.&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;With AI, I see huge potential to reduce order errors, improve delivery commitments, and give sales teams the insights they need right when they need them. Itâ€™s the kind of evolution that brings together both efficiency and strategy. And honestly, after a decade and a half in this space, thatâ€™s the kind of shift that gets me genuinely excited.&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;Letâ€™s talk about what is Artificial intelligence, Machine learning in simple term.&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;Artificial Intelligence (AI)&lt;/STRONG&gt; is the computers or machines being made to think and decide like humans. It's about putting machines in a position where they can do things that typically need to be done by human intelligence â€” like interpreting language, identifying pictures, solving mysteries, or making decisions.&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;Machine Learning (ML)&lt;/STRONG&gt; is either a sub-domain (or subset) of AI. It's the way that we're teaching machines to get intelligent independently. We're not writing each of the rules but giving them many data and that machine would observe patterns over this data. After that, whenever it could be able to independently make a choice or forecast.&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;Basic example:&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;If AI has to do something like instructing a robot about recognizing fruits&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;So ML is kind of like demonstrating the robot pictures of apples, bananas, and oranges â€” and letting it learn what each of them looks like, instead of explaining to it all the rules&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;Introduction of AI and ML in SAP&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;SAP S/4HANA, the cutting-edge ERP suite, is transforming the way businesses operate by incorporating advanced technologies like &lt;STRONG&gt;Artificial Intelligence (AI) and&lt;/STRONG&gt;&amp;nbsp;&lt;STRONG&gt;Machine Learning (ML)&lt;/STRONG&gt;. These innovations boost automation, refine decision-making, and maintain data integrity across a variety of industries. In this blog, weâ€™ll dive into how AI and ML are woven into SAP S/4HANA and explore their practical applications in the real world.&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;Artificial Intelligence (AI) &amp;amp; Machine Learning (ML) in SAP S/4HANA&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;SAP S/4HANA leverages AI and ML to automate processes, reduce manual work, and provide predictive insights. Below are some key functionalities:&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;Sales &amp;amp; Customer Experience&lt;/STRONG&gt;&lt;/P&gt;&lt;OL class="lia-align-justify" style="text-align : justify;"&gt;&lt;LI&gt;&lt;STRONG&gt;Automated Sales Order Processing: AI-powered chatbots process customer inquiries&lt;/STRONG&gt; and create sales orders automatically, improving response times.&lt;/LI&gt;&lt;/OL&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ambarish_ad_7-1745839508826.png" style="width: 738px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255516iE8386B4666BE7B54/image-dimensions/738x172?v=v2" width="738" height="172" role="button" title="Ambarish_ad_7-1745839508826.png" alt="Ambarish_ad_7-1745839508826.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ambarish_ad_8-1745839508829.png" style="width: 756px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255515iFA30040EC6EE50F0/image-dimensions/756x155?v=v2" width="756" height="155" role="button" title="Ambarish_ad_8-1745839508829.png" alt="Ambarish_ad_8-1745839508829.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;2.&amp;nbsp;&lt;STRONG&gt;Leverage Joule&lt;BR /&gt;&lt;BR /&gt;&lt;/STRONG&gt;Joule is capable of creating sales orders in both the SAP S/4HANA Cloud Private Edition and the Public Edition. Itâ€™s also a handy tool for managing various aspects of sales orders, including: -&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ambarish_ad_9-1745839508839.png" style="width: 725px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255517i9F4F9253F7DEAA74/image-dimensions/725x466?v=v2" width="725" height="466" role="button" title="Ambarish_ad_9-1745839508839.png" alt="Ambarish_ad_9-1745839508839.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL class="lia-align-justify" style="text-align : justify;"&gt;&lt;LI&gt;Creating sales orders based on other documents: Joule can generate new sales orders by referencing existing sales orders, quotes, or contracts.&lt;/LI&gt;&lt;LI&gt;Generating sales order requests: It can assist users in crafting sales order requests by pulling information from unstructured data like PDFs or images.&lt;/LI&gt;&lt;LI&gt;Modifying sales order fields: Users can easily update fields at both the header and item levels with Joule.&lt;/LI&gt;&lt;LI&gt;Addressing sales order fulfilment issues: Itâ€™s equipped to help users tackle any problems related to fulfilling sales orders.&lt;/LI&gt;&lt;LI&gt;Navigating to relevant apps: Joule can direct users to specific applications within SAP S/4HANA Cloud, such as the "Track Sales Orders" app.&lt;/LI&gt;&lt;LI&gt;Retrieving sales order information: It can deliver summaries and detailed insights about sales orders, including document flow and pricing condition&lt;/LI&gt;&lt;/UL&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;&amp;nbsp;3.&amp;nbsp;&lt;/STRONG&gt;AI-Based Sales Order Autocompletion:&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;Functionality: &lt;/STRONG&gt;SAP S/4HANA Cloud Public Edition offers AI-driven autocompletion, which uses historical data and machine learning to provide intelligent recommendations for completing sales order data.&amp;nbsp;&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ambarish_ad_10-1745839508851.png" style="width: 737px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255519i720B84DC7994D03F/image-dimensions/737x304?v=v2" width="737" height="304" role="button" title="Ambarish_ad_10-1745839508851.png" alt="Ambarish_ad_10-1745839508851.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;Example: &lt;/STRONG&gt;The system can suggest the correct shipping address, payment terms, or material details based on past orders with similar characteristics.&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;SAP Fiori App: &lt;/STRONG&gt;The "Monitor Recommendations for Sales Document Completion" app provides a central entry point to view incomplete sales orders and corresponding data field recommendations.&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;4. Importing Sales Orders from Excel Spreadsheets:&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;Functionality: &lt;/STRONG&gt;You can use the SAP Fiori app "Import Sales Orders" to batch-create sales orders directly from Excel files.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ambarish_ad_11-1745839508856.png" style="width: 752px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255518i3974D0EA825153AB/image-dimensions/752x346?v=v2" width="752" height="346" role="button" title="Ambarish_ad_11-1745839508856.png" alt="Ambarish_ad_11-1745839508856.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Process:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;UL&gt;&lt;LI&gt;Upload the Excel file containing the sales order data.&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;UL&gt;&lt;UL&gt;&lt;LI&gt;The system automatically creates sales order requests and populates the data.&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;UL&gt;&lt;UL&gt;&lt;LI&gt;You can then simulate or create the sales order.&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;SAP BTP Use Case:&lt;/STRONG&gt;&amp;nbsp; SAP Business Technology Platform (BTP) can be used to automate sales order creation from Excel files, leveraging robotic process automation (RPA) to extract data from Excel and create sales order documents in SAP S/4HANA.&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;5. Automating Sales Order Creation from Unstructured Data:&lt;/P&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;&lt;STRONG&gt;Functionality: &lt;/STRONG&gt;You can use SAP Build Process Automation to create an RPA bot to automate the processing of sales order requests received in the form of unstructured files like PDFs, images, etc&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ambarish_ad_12-1745839508880.png" style="width: 730px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255520i13A813CC292F862B/image-dimensions/730x385?v=v2" width="730" height="385" role="button" title="Ambarish_ad_12-1745839508880.png" alt="Ambarish_ad_12-1745839508880.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;STRONG&gt;Process:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;UL&gt;&lt;LI&gt;The bot scans emails for keywords in the subject line.&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;UL&gt;&lt;UL&gt;&lt;LI&gt;It extracts attachments from the emails and uploads them to the "Create Sales Orders - Automatic Extraction" app.&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;UL&gt;&lt;UL&gt;&lt;LI&gt;The app creates sales order requests and uploads the email attachments to a document information extraction service.&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;UL&gt;&lt;UL&gt;&lt;LI&gt;The service extracts relevant information from the email attachments.&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;P class="lia-align-justify" style="text-align : justify;"&gt;6. SAP Sales Cloud Version 2, duplicate detection&lt;BR /&gt;&lt;STRONG&gt;&lt;BR /&gt;&lt;/STRONG&gt;Sales agents can leverage the feature that performs a check, comparing the configured fields with the list of existing accounts within the system. As an administrator, they can configure the duplicate check for accounts. Once configured, any new account that is created is checked against the configured fields and the result displays a list of the existing accounts with a confidence score, which enables sales agents to take a decision whether or not to proceed with the account creation.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ambarish_ad_0-1745840213750.png" style="width: 756px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/255525i03105778C3B82A91/image-dimensions/756x295?v=v2" width="756" height="295" role="button" title="Ambarish_ad_0-1745840213750.png" alt="Ambarish_ad_0-1745840213750.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Benefits&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;UL&gt;&lt;LI&gt;Prevent from creating more duplicate records, improving data accuracy&lt;/LI&gt;&lt;LI&gt;Ensure a cleaner database for operations and sales forecasts&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-members/artificial-intelligence-ai-amp-machine-learning-ml-in-sap-s-4hana/ba-p/14088281"/>
    <published>2025-04-29T17:00:26.862000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/data-attribute-recommendation-12-month-support-window-for-new-and-existing/ba-p/14103178</id>
    <title>Data Attribute Recommendation: 12-Month Support Window for New and Existing Deployments</title>
    <updated>2025-05-16T10:01:51.515000+02:00</updated>
    <author>
      <name>juliana_morais</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/79151</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;As of September 1st, 2025,â€¯&lt;a href="https://community.sap.com/t5/c-khhcw49343/Data+Attribute+Recommendation/pd-p/73554900100800002858" class="lia-product-mention" data-product="400-1"&gt;Data Attribute Recommendation&lt;/a&gt;â€¯will only support the deployment of trained models that are less than 12 months old. Additionally, any existing deployments that are more than 12 months old will be retired automatically, ensuring that only up-to-date, high-quality models remain active.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1601363138"&gt;&lt;STRONG&gt;&lt;SPAN&gt;Why is this change being introduced?&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/H1&gt;&lt;P&gt;&lt;SPAN&gt;The overall goal is to strengthen&lt;/SPAN&gt;&lt;SPAN&gt; the security and enhance the&lt;/SPAN&gt;&lt;SPAN&gt; machine learning lifecycle of the service. To achieve this, we recommend that you, as a user of Data Attribute Recommendation, retrain and redeploy your models on a regular basis. This brings numerous benefits, including the following:&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;Security:&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt; Keeping all your deployments up to date makes sure that they constantly benefit from the security patches and fixes delivered with every release of the service.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;Data Drift&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;: Over time, the statistical properties of the data received by the model may change. This phenomenon is known as data drift and can cause the model's performance to degrade. Regular retraining helps the model adapt to these data changes.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;Concept Drift&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;: This is similar to data drift, but instead of the data changing, the relationship between the input data and the target variable(s) changes. Regular retraining helps the model capture these new relationships.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;Improved Data Availability&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;: Over time, more data usually becomes available. Training a new model with this additional data can improve its accuracy and robustness.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;Model Improvements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;: Machine learning is a rapidly evolving field where new algorithms, architectures, and techniques are constantly being developed. &lt;/SPAN&gt;&lt;SPAN&gt;Performance, efficiency, and scalability&lt;/SPAN&gt;&lt;SPAN&gt; improvements are regularly included in the Data Attribute Recommendation scenarios. Therefore, retraining regularly allows you to take full advantage of these continuous enhancements.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;Error Correction&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;: Regular retraining allows you to correct any errors or biases that were present in the initial training data or model.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;Retraining and redeploying models on a regular basis is a best practice that ensures your machine learning systems remain robust, relevant, and aligned with your organizationâ€™s strategic goals and operational requirements.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1404849633"&gt;&lt;STRONG&gt;&lt;SPAN&gt;How to keep your models up to date in Data Attribute Recommendation&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/H1&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Ensure the latest data is uploaded to the service.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Train a new model on the data: If you want to do this while the old model is still running, you must choose a different model name.&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Deploy the newly trained model.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Update the URL that you send your inference requests to. They should now go to the newly trained model.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Undeploy the old model.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;To complete these steps, we recommend that you consult our documentation:&amp;nbsp;&lt;A href="https://help.sap.com/docs/data-attribute-recommendation/data-attribute-recommendation/consuming-service-via-ai-api" target="_self" rel="noopener noreferrer"&gt;AI API Reference&lt;/A&gt;.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-attribute-recommendation-12-month-support-window-for-new-and-existing/ba-p/14103178"/>
    <published>2025-05-16T10:01:51.515000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/ai-assisted-support-query-resolution-with-intent-induction-and-matching/ba-p/14097093</id>
    <title>AI-Assisted Support Query Resolution with Intent Induction and Matching</title>
    <updated>2025-05-20T09:53:07.546000+02:00</updated>
    <author>
      <name>Chinmay_Kakatkar</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1892603</uri>
    </author>
    <content>&lt;H2 id="toc-hId-1710246655"&gt;Problem Context&lt;/H2&gt;&lt;P&gt;A number of ERP use cases are concerned with the resolution of support queries (e.g., reactive maintenance notifications in asset management, IT support tickets). In the absence of intelligent assistance, a support technician must manually go through each new support query and rely on existing business know-how to trigger downstream solution activities (e.g., carrying out a diagnostic test, ordering a replacement for a broken part). However, this fully manual approach to support query resolution is error-prone and hard to scale. Staffing support technicians is expensive, and these technicians may not always have the business know-how to accurately address the issues raised in the query.&lt;/P&gt;&lt;H3 id="toc-hId-1642815869"&gt;An Illustrative Example: Resolving Maintenance Notifications&lt;/H3&gt;&lt;P&gt;In reactive maintenance scenarios, a maintenance notification is created by a user to report a breakdown of an equipment at a manufacturing plant. The user enters data in the notification to describe the nature of the problem (e.g., equipment is affected, location, nature of the breakdown). For a given notification, a maintenance order can then be created to resolve the problem by carrying out a set of tasks (e.g., checking the equipment, removing the damaged piece, ordering a replacement). These steps can vary depending on the exact nature of the problem. AI can potentially assist the support technician in matching incoming support queries to appropriate downstream solution steps.&lt;/P&gt;&lt;H2 id="toc-hId-1317219645"&gt;Solution Approach&lt;/H2&gt;&lt;P&gt;In the following, a method of AI-assisted support query resolution using intent induction and matching is described, which can be implemented using SAP's suite of AI services.&lt;/P&gt;&lt;H3 id="toc-hId-1249788859"&gt;Concept of Intents&lt;/H3&gt;&lt;P&gt;In AI use cases where queries are matched with solutions, an &lt;EM&gt;intent&lt;/EM&gt; reflects what the user wants to achieve by raising and resolving the query. The intent may be latent, i.e., not directly mentioned in the raw query. In general, a query may be associated with one or more intents, depending on how specific the query is. Moreover, one intent may be satisfied by more than one solution.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Example:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Query = &lt;FONT face="courier new,courier"&gt;"I have forgotten my password"&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;Intents relevant to the above query = &lt;FONT face="courier new,courier"&gt;["Recover password", "Reset password"]&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;Solutions matching the above&amp;nbsp;intents = &lt;FONT face="courier new,courier"&gt;["Recover password by answering secret question", "Recover password by calling tech support", "Set new password"]&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1053275354"&gt;Workflows in Production&lt;/H3&gt;&lt;P&gt;Large language models (LLMs), such as those available via SAP's &lt;A href="https://help.sap.com/docs/ai-launchpad/sap-ai-launchpad/generative-ai-hub" target="_self" rel="noopener noreferrer"&gt;Generative AI Hub&lt;/A&gt;, can parse the semantic meaning of data and be used to induce intents from queries.&lt;/P&gt;&lt;P&gt;Having a historical database of queries and their associated solutions is a key prerequisite to kickstart the AI-based method of intent induction using LLMs.&amp;nbsp;To generate a corresponding intent database, an LLM is run over each query in the historical database to induce/generate one or more intents for them.&lt;/P&gt;&lt;P&gt;Now, whenever a new query comes in, an LLM is used to induce its intents (e.g., based on the query text). The intents of the new query are compared with the intents stored in the historical database to identify historical intents that are most similar. Solution steps related to these identified intents can then be provided as recommendations to the support technician.&amp;nbsp;Finally, the intents and solutions of the new query are added to the historical database to guide future recommendations; to avoid excessive redundant data storage, this is only done if the information is not already captured in the database.&lt;/P&gt;&lt;P&gt;Accurate recommendations can improve the speed and accuracy of the support technician's work. In particular, rather than comparing the new query with the historical queries directly, the intent-based method checks similarity at the level of intents, which can improve scoring accuracy (e.g., queries that look superficially different may imply similar intents).&lt;/P&gt;&lt;H3 id="toc-hId-856761849"&gt;Avenues for Optimization&lt;/H3&gt;&lt;P&gt;The intent-based approach can be optimized in several ways. First, the accuracy of solution recommendations can be improved over time by learning from the interactions with the support technicians during productive usage. In particular, whether the recommendations are accepted or rejected can provide a valuable signal for improving the relevance of future recommendations.&lt;/P&gt;&lt;P&gt;Second, components of the LLM-based intent induction architecture can be optimized, e.g., fine-tuning the prompt, using differentiated prompt templates per use case, and employing Retrieval Augmented Generation (RAG) to parse company-specific codes, shorthand and abbreviations. Translating all text data into a baseline English version can also simplify and improve the accuracy of intent induction and matching.&lt;/P&gt;&lt;P&gt;Third, as historical databases grow large, the AI-based matching can be optimized to reduce latency of recommendation retrieval. E.g., a cache of the most common intents can be separately maintained and checked first for matches before traversing the full database of historical intents. Furthermore, a map-reduce framework can be used to parallelize the search of the historical intent database.&lt;/P&gt;&lt;H2 id="toc-hId-531165625"&gt;Next Steps&lt;/H2&gt;&lt;P&gt;Customers can consider a few different options to enhance their existing SAP workflows with an approach to AI-assisted support query resolution such as the one described above. E.g., customers may choose to implement this in-house or with the help of external partners/consultants, which can allow for customization but also incur related development and maintenance costs. Another&amp;nbsp;option may be to&amp;nbsp;request AI-assisted support query resolution as a new feature in relevant upcoming SAP product releases. SAP can build the new feature in a way that ensures high product quality and reduces the total cost of ownership (TCO) for customers.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/ai-assisted-support-query-resolution-with-intent-induction-and-matching/ba-p/14097093"/>
    <published>2025-05-20T09:53:07.546000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/ai-in-action-new-mission-available-to-enhance-sap-signavio-with-machine/ba-p/14112999</id>
    <title>AI in Action: New mission available to enhance SAP Signavio with Machine Learning</title>
    <updated>2025-05-27T20:23:26.890000+02:00</updated>
    <author>
      <name>hoangvu</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/315943</uri>
    </author>
    <content>&lt;P&gt;In today's rapidly evolving business landscape, organizations are continually seeking innovative ways to enhance operational efficiency and stay ahead of the competition. One groundbreaking approach is the integration of machine learning (ML) with process mining, a strategy that transforms static data into dynamic, predictive insights. SAP Signavio Process Intelligence, in conjunction with SAP Build, offers a robust platform to achieve this integration seamlessly.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Unlocking Predictive Process Management&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Traditionally, process mining involves analyzing historical event logs to understand past performance. While this retrospective analysis is valuable, it doesn't provide foresight into future outcomes. By embedding ML algorithms into your process mining activities, you can predict future events, identify potential bottlenecks before they occur, and make data-driven decisions that proactively enhance process efficiency.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Practical Applications&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Consider the challenge of predicting sales order delivery times. By analyzing historical event logs, ML models can forecast delivery dates based on factors like order size, product type, and current workload. These predictions, when fed back into SAP Signavio Process Intelligence, offer real-time insights, enabling better planning and improved customer satisfaction.&lt;/P&gt;&lt;P&gt;Another application is in customer support. By examining event logs, ML can predict customer satisfaction levels with support tickets, considering variables such as resolution speed and communication quality. This allows support teams to proactively address issues, enhancing the overall customer experience.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;New mission OUT NOW&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;We are excited to announce a new mission that showcases how you can realize these use cases using SAP Signavio in combination with SAP Build.&lt;/P&gt;&lt;P&gt;&lt;A href="https://developers.sap.com/mission.signavio-pi-and-sap-build.html" target="_blank" rel="noopener noreferrer"&gt;https://developers.sap.com/mission.signavio-pi-and-sap-build.html&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="2025-05-27_19-45-40.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/266617iD1303A2810ACEDC9/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-05-27_19-45-40.png" alt="2025-05-27_19-45-40.png" /&gt;&lt;/span&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Successfully implement the mission and earn a cool badge as a reward.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="2025-05-27_20-12-19.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/266624iF4B7D41FDC38D057/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-05-27_20-12-19.png" alt="2025-05-27_20-12-19.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;It will highlight your success of combining multiple SAP solutions and showcase your ability to tackle new topics and realize value from it!&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Seamless Integration with SAP Build&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;SAP Build, equipped with Python and Jupyter capabilities, serves as the bridge between raw data and actionable insights. It enables the extraction of event log data from SAP Signavio Process Intelligence, the application of ML algorithms, and the reintegration of enriched data back into the system. This seamless workflow ensures that your process management system evolves from reactive to proactive, continually learning and adapting to new data.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Getting Started&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Embarking on this transformative journey involves a few key steps:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Activate APIs: Enable the OData and Ingestion APIs in SAP Signavio Process Intelligence to facilitate data movement.&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Data Extraction: Utilize SAP Build to extract event log data via the OData API.&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Apply Machine Learning: Develop and train ML models within SAP Build to analyze and predict outcomes based on your data.&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;STRONG&gt;Data Reintegration: Push the enriched, predictive data back into SAP Signavio Process Intelligence through the Ingestion API.&lt;/STRONG&gt;&lt;/STRONG&gt;&lt;P&gt;For a comprehensive, step-by-step guide on implementing this integration, refer to the mission above.&lt;/P&gt;&lt;P&gt;By harnessing the combined power of SAP Signavio Process Intelligence and SAP Build, your organization can transition to a predictive process management paradigm, driving efficiency, foresight, and a competitive edge in your industry.&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/ai-in-action-new-mission-available-to-enhance-sap-signavio-with-machine/ba-p/14112999"/>
    <published>2025-05-27T20:23:26.890000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/curitiba-blog-posts/evento-em-curitiba-re%C3%BAne-sap-e-especialistas-para-discutir-inova%C3%A7%C3%A3o-ia-e/ba-p/14117082</id>
    <title>Evento em Curitiba reÃºne SAP e especialistas para discutir inovaÃ§Ã£o, IA e Reforma TributÃ¡ria no GROW</title>
    <updated>2025-06-03T03:37:54.619000+02:00</updated>
    <author>
      <name>Fabiele</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2053629</uri>
    </author>
    <content>&lt;P&gt;&lt;FONT&gt;&lt;FONT&gt;No prÃ³ximo dia &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;13 de junho&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , Curitiba serÃ¡ palco de um dos encontros mais relevantes do ano para lÃ­deres de tecnologia, finanÃ§as e estratÃ©gia empresarial: o &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;CVA SUMMIT 2025&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; .&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT&gt;&lt;FONT&gt;Realizado na &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;Arena Digital da PUC-PR&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , o evento reunirÃ¡ &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;grandes nomes da SAP&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; e especialistas do mercado para debater o presente e o futuro dos negÃ³cios digitais no Brasil. A programaÃ§Ã£o inclui temas que estÃ£o no centro das decisÃµes das empresas brasileiras, como &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;GROW with SAP&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;InteligÃªncia Artificial aplicada Ã  gestÃ£o&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;plataformas de inovaÃ§Ã£o como o SAP BTP&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , e os &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;impactos da Reforma TributÃ¡ria na gestÃ£o fiscal&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; .&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT&gt;&lt;FONT&gt;Entre os palestrantes confirmados estÃ£o:&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;Eduardo Ferraz&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , Head Brasil do GROW com SAP&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;Christian Geronasso&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , CRO Global de InteligÃªncia Artificial da SAP&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;Arthur ProenÃ§a&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , Consultor de SoluÃ§Ãµes Digitais da SAP BTP&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;JoÃ£o EmÃ­lio&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , Executivo SAP LeanIX e Signavio&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;Luiz Fernando Albertin&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , Gerente Engenheiro de Vendas na Avalara&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT&gt;&lt;FONT&gt;Mais do que um evento, o CVA SUMMIT Ã© uma &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;experiÃªncia imersiva&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; , pensada para fornecer &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;conexÃµes de qualidade&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; entre profissionais que desejam estar Ã  frente das transformaÃ§Ãµes do mercado. Com um ambiente tecnolÃ³gico e inovador, o encontro oferece ainda &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;coffee break, almoÃ§o estratÃ©gico e estacionamento incluÃ­do&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; .&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;â€œTransformaÃ§Ã£o, inovaÃ§Ã£o e estratÃ©gia fiscal em um sÃ³ lugarâ€,&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; esse Ã© o espÃ­rito do CVA SUMMIT 2025. Um convite para &lt;/FONT&gt;&lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;refletir, aprender e se conectar com quem estÃ¡ fazendo a diferenÃ§a na jornada digital das empresas brasileiras&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt; . &lt;/FONT&gt;&lt;/FONT&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;Arena Digital da PUC-PR â€“ Curitiba/PR, dia&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;13 de junho â€“ a partir das 8h30 |&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;FONT&gt;&lt;FONT&gt;Evento exclusivo para lÃ­deres de TI, CFOs, CEOs, Controllers e tomadores de decisÃ£o. INSCREVA-SE:&amp;nbsp;&lt;A href="https://solucoes.cvaconsultoria.com.br/summit-2025-cva" target="_blank" rel="nofollow noopener noreferrer"&gt;https://solucoes.cvaconsultoria.com.br/summit-2025-cva&lt;/A&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/curitiba-blog-posts/evento-em-curitiba-re%C3%BAne-sap-e-especialistas-para-discutir-inova%C3%A7%C3%A3o-ia-e/ba-p/14117082"/>
    <published>2025-06-03T03:37:54.619000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/quickly-deploy-a-streamlit-python-app-to-btp/ba-p/14124259</id>
    <title>Quickly Deploy a Streamlit Python App to BTP</title>
    <updated>2025-06-10T20:12:24.528000+02:00</updated>
    <author>
      <name>Chinmay_Kakatkar</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1892603</uri>
    </author>
    <content>&lt;P&gt;Streamlit is an open-source Python framework that is useful for quickly building and deploying data-centric web apps with dynamic frontends (&lt;A href="https://streamlit.io/" target="_self" rel="nofollow noopener noreferrer"&gt;link to documentation&lt;/A&gt;). A key benefit of using Streamlit is that AI scientists/engineers can create UI-based apps using just Python (a language they tend to be highly familiar with), rather than having to resort to JavaScript, HTML/CSS, etc. Streamlit use cases may include analytics dashboards that leverage Pandas data frames, visualization of geographical maps, and interactive ML services (see many more examples in the Streamlit app gallery &lt;A href="https://streamlit.io/gallery" target="_self" rel="nofollow noopener noreferrer"&gt;here&lt;/A&gt;).&lt;/P&gt;&lt;P&gt;In this blog post, we will look at how to quickly deploy a Streamlit app on BTP, which can be especially useful for productizing company-internal data products. Fortunately, &lt;A href="https://developers.sap.com/tutorials/btp-cf-buildpacks-python-create.html" target="_self" rel="noopener noreferrer"&gt;this&lt;/A&gt; SAP tutorial already describes how to deploy a "Hello World" Python app on BTP using Cloud Foundry, and we will use that tutorial as a basis for rest of this blog post. While that tutorial uses the Flask framework, we only need to make a few small modifications to the code to make it work for Streamlit. &lt;STRONG&gt;As such, in the following, we will assume that you are able to deploy the "Hello World" Flask app from that tutorial without any issues.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;In order to modify the tutorial code to work with Streamlit, perform the following changes:&lt;/P&gt;&lt;P&gt;In &lt;STRONG&gt;server.py&lt;/STRONG&gt;, replace all of the code with:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;import streamlit as st

st.write("Hello world")&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;In &lt;STRONG&gt;requirements.txt&lt;/STRONG&gt;, add the following requirement:&lt;/P&gt;&lt;pre class="lia-code-sample language-yaml"&gt;&lt;code&gt;streamlit&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;In&amp;nbsp;&lt;STRONG&gt;manifest.yml&lt;/STRONG&gt;, change the line describing the command to:&lt;/P&gt;&lt;pre class="lia-code-sample language-yaml"&gt;&lt;code&gt;command: streamlit run server.py --server.port 8080&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Notice that the Streamlit app is exposed on port 8080.&lt;/P&gt;&lt;P&gt;And that's essentially it&amp;nbsp;&lt;span class="lia-unicode-emoji" title=":smiling_face_with_smiling_eyes:"&gt;ğŸ˜Š&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now redeploy the app with &lt;FONT face="courier new,courier"&gt;cf push&lt;/FONT&gt;.&lt;/P&gt;&lt;P&gt;The app should load at the appropriate app url (e.g.,&amp;nbsp;&lt;A href="https://myapp-tired-oribi-it.cfapps.eu12.hana.ondemand.com/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://&amp;lt;some_url_prefix&amp;gt;.cfapps.eu12.hana.ondemand.com/&lt;/A&gt;).&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/quickly-deploy-a-streamlit-python-app-to-btp/ba-p/14124259"/>
    <published>2025-06-10T20:12:24.528000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/explicit-knowledge-representation-and-reasoning-with-knowledge-graphs/ba-p/14124234</id>
    <title>Explicit knowledge representation and reasoning with Knowledge Graphs: introduction &amp; use case</title>
    <updated>2025-06-11T16:31:10.985000+02:00</updated>
    <author>
      <name>cesarecalabria93</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/42191</uri>
    </author>
    <content>&lt;H1 id="toc-hId-1603240804"&gt;Explicit knowledge representation and reasoning with Knowledge Graphs: introduction &amp;amp; use case&lt;/H1&gt;&lt;P&gt;&lt;BR /&gt;In this blog post we will explore how SAP HANA Cloud is further increasing its multi-model capabilities by supporting also RDF-based knowledge graphs and SPARQL querying and we will see a real-world business application of this.&amp;nbsp;We will see how to organize and represent enterprise data in a graph structure with HANA Cloud Knowledge Graph Engine, we will discover how this structure facilitates knowledge representation and reasoning and we will learn how to leverage Knowledge Graphs to retrieve structured data and achieve greater accuracy and explainability in RAG scenarios.&lt;/P&gt;&lt;P&gt;This is a summary of the business use case I presented together with my colleague&amp;nbsp;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/16662"&gt;@merza&lt;/a&gt;&amp;nbsp;&amp;nbsp;in this webinar:&amp;nbsp;&lt;A href="https://partneredge.sap.com/en/library/education/psd/2025/jan/e_oe_te_w_PSD_WEB_00008801.html" target="_blank" rel="noopener noreferrer"&gt;Explicit knowledge representation and reasoning with Knowledge Graphs&lt;/A&gt;.&amp;nbsp;Please, note the mentioned session is part of a series of webinars under the topic of &lt;EM&gt;â€œTalk to Your Business with Generative AIâ€.&lt;/EM&gt; Check the full calendar &lt;A href="https://url.sap/crvdej" target="_blank" rel="noopener nofollow noreferrer"&gt;here&lt;/A&gt; to watch the recordings of past sessions and register for the upcoming ones!&lt;/P&gt;&lt;P&gt;The summary of the session is structured in two parts: this blog post where I introduce RDF-based knowledge graphs and the business use case we used to demonstrate the new capabilities of HANA Cloud, and then a second part with a &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/explicit-knowledge-representation-and-reasoning-with-knowledge-graphs/ba-p/14125040" target="_self"&gt;deep dive&lt;/A&gt;&amp;nbsp;into the proof-of-concept implementation we developed on the business use case.&lt;/P&gt;&lt;P&gt;As we always do in our sessions, we make a proof-of-concept, which I will go into more detail about in the implementation in the&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/explicit-knowledge-representation-and-reasoning-with-knowledge-graphs/ba-p/14125040" target="_self"&gt;second blog post&lt;/A&gt;. This is not a product, itâ€™s just a prototype that we use to illustrate how to implement the services and concepts we talk about and we hope it might not only inspire you but also be of great help as you have access to the working code through the&amp;nbsp;&lt;A href="https://github.com/SAP-samples/btp-generative-ai-hub-use-cases/tree/main/51-Knowledge-Graph-Explicit-knowledge-representation-and-reasoning" target="_blank" rel="noopener nofollow noreferrer"&gt;SAP-Samples repository here&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;To understand the content of this blog post, it would be useful if you are already familiar with some SAP products, especially SAP BTP Platform and SAP HANA Cloud, and if you already have some knowledge of generative AI, data science in general and also a basic knowledge of JavaScript and Python programming languages.&lt;/P&gt;&lt;P&gt;Many thanks to our colleagues in the HANA Cloud Product Management Team for their great support in helping us develop this content: &lt;A href="https://community.sap.com/t5/user/viewprofilepage/user-id/17350" target="_blank"&gt;@mfath&lt;/A&gt;,&amp;nbsp;&lt;A href="https://community.sap.com/t5/user/viewprofilepage/user-id/14106" target="_blank"&gt;@ChristophMorgen&lt;/A&gt;, &lt;A href="https://community.sap.com/t5/user/viewprofilepage/user-id/160939" target="_blank"&gt;@mkemeter&lt;/A&gt;, Stefan Uhrig, Tobias Mindnich!&lt;/P&gt;&lt;H2 id="toc-hId-1535810018"&gt;&lt;BR /&gt;Introduction&lt;/H2&gt;&lt;P&gt;&lt;BR /&gt;The term knowledge graph itself is not a new, it was coined in the 70s of of the previous century and then in 2012 Google introduced its own knowledge graph. But nowadays the interest in knowledge graphs is growing with the rise of generative AI and consequently SAP is now introducing this technology into HANA HANA Cloud database.&lt;/P&gt;&lt;P&gt;But why is the interest in the knowledge graph growing with the rise of generative AI? We can mention several reasons:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;because raw data is not enough and adding meaning and semantics can turn data into actionable knowledge;&lt;/LI&gt;&lt;LI&gt;because machines should understand knowledge. And with knowledge graphs we can enable machines to interpret, reason and act on data;&lt;/LI&gt;&lt;LI&gt;because of the varied and complex business domains, with knowledge graphs we can represent rich interlinked knowledge using graph structures.&lt;/LI&gt;&lt;LI&gt;because hallucinations increase in business domains and structured knowledge helps improving grounding large language models and reduces hallucinations;&lt;/LI&gt;&lt;LI&gt;because we there's a need for reasoning and logic.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;BR /&gt;Letâ€™s introduce briefly what a knowledge graph is.&lt;/P&gt;&lt;H3 id="toc-hId-1468379232"&gt;&lt;BR /&gt;What is a Knowledge Graph&lt;/H3&gt;&lt;P&gt;Todayâ€™s organizations generate massive volumes of data. Yet, without structure and context, that data rarely matures into actionable knowledge that enables informed decision-making and supports intelligent actions based on semantics and reasoning over raw data. This is where knowledge graphs come in.&lt;/P&gt;&lt;P&gt;A &lt;STRONG&gt;knowledge graph (KG)&lt;/STRONG&gt; is a graph-based data model that captures entities (like people, products, places) and their relationships, aiming in making the knowledge understandable by machines. To do so, a formal knowledge representation is needed, where knowledge is broken down into atomic units, aka Facts, each of which is given in the form of triples (subject-predicate-object), as in the following example:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_0-1749628413163.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272933i8F4EB0B28DC2F652/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_0-1749628413163.png" alt="cesarecalabria_0-1749628413163.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;By linking different facts together, they form a knowledge graph:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_1-1749628413164.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272934iFBC3F8E8B4573622/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_1-1749628413164.png" alt="cesarecalabria_1-1749628413164.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This type of representation is not limited to concrete instances like the author Arthur Conan Doyle or the character Sherlock Holmes, but it can be extended to include type semantics or classes like saying that Arthur Conan Doyle is a person and Sherlock Holmes is a fictional character (see image below).&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-06-11 at 17.17.38.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273218i6500277DDA49380E/image-size/large?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-06-11 at 17.17.38.png" alt="Screenshot 2025-06-11 at 17.17.38.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1271865727"&gt;Core technologies behind Knowledge Graphs&lt;/H3&gt;&lt;P&gt;At the core of knowledge graphs are semantic web standards that ensure interoperability, extensibility, and formal meaning. These standards support automated reasoning and complex queries in a machine-understandable way.&lt;/P&gt;&lt;H4 id="toc-hId-1204434941"&gt;Resource Description Framwork (RDF): the building block of graphs&lt;/H4&gt;&lt;P&gt;The &lt;A href="https://www.w3.org/RDF/" target="_blank" rel="noopener nofollow noreferrer"&gt;Resource Description Framework (RDF)&lt;/A&gt; is the core triple-based data model for knowledge graphs. Letâ€™s give an example: based on the previously depicted KG, the resulting facts expressed as triples in the RDF standard would look like as the following:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_3-1749628413171.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272937i0235DDEB3E522B80/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_3-1749628413171.png" alt="cesarecalabria_3-1749628413171.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Note that RDF is a 1-to-1 representation of triples of facts, and each part of the triple is considered a uniquely identified resource referenced by a uniform resource identifier (URI) here abbreviated defining some namespaces.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H4 id="toc-hId-1007921436"&gt;SPARQL: the query language of RDF-based knowledge graphs&lt;/H4&gt;&lt;P&gt;Now that we know how to express data using RDF, let's explore how we can actually use that data by querying a RDF-based knowledge graph.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;SPARQL&lt;/STRONG&gt; is the standard query language for RDF data. It works by matching graph patterns across the dataset. Pattern matching means looking for RDF triples that contain given variables at any arbitrary place (Subject, Property, Object). SPARQL variables are bound to RDF terms and all the variables will appear as columns in the result table by the select statement. For example consider the following example query (where we used resources from the public knowledge base &lt;A href="https://www.dbpedia.org/" target="_blank" rel="noopener nofollow noreferrer"&gt;DBPedia&lt;/A&gt;) and the corresponding result:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_4-1749628413184.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272938iDF939894F856B273/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_4-1749628413184.png" alt="cesarecalabria_4-1749628413184.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;SPARQL supports filtering, aggregation, and even complex query logic. It can also reach out to &lt;STRONG&gt;remote endpoints&lt;/STRONG&gt; via &lt;STRONG&gt;federated queries&lt;/STRONG&gt;, e.g., fetching author birthplaces from DBpedia while querying local product catalogs.&lt;/P&gt;&lt;P&gt;RDF triples allow a simple representation of facts. But list of facts is not enough to make full sense of the data. For this reason we need a formal description of the knowledge as a set of concepts, relationships and constraints. Letâ€™s some of the options available to build a conceptual model for a knowledge graph.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;H4 id="toc-hId-811407931"&gt;RDFS: typing and hierarchies&lt;/H4&gt;&lt;P&gt;One simple option is &lt;A href="https://www.w3.org/TR/rdf11-schema/" target="_blank" rel="noopener nofollow noreferrer"&gt;RDF Schema (RDFS)&lt;/A&gt; that extends RDF by adding basic vocabulary for defining:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Classes (rdfs:Class, rdf:type)&lt;/LI&gt;&lt;LI&gt;Hierarchies (rdfs:subClassOf, rdfs:subPropertyOf)&lt;/LI&gt;&lt;LI&gt;Domains and ranges for properties&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;A simple example is given below:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_5-1749628413185.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272936i6FCF2455A9CCE7E3/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_5-1749628413185.png" alt="cesarecalabria_5-1749628413185.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H4 id="toc-hId-614894426"&gt;OWL: expressive ontologies&lt;/H4&gt;&lt;P&gt;What if more expressivity power is needed to express more sophisticated conditions like cardinality, class disjoints, or equivalence? For that, there's the OWL, the Web Ontology Language, which is designed to represent rich and complex knowledge. The Web Ontology Language (OWL) builds on RDFS to support richer axioms and reasoning rules. With OWL, you can express:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Class equivalence and disjointness&lt;/LI&gt;&lt;LI&gt;Property characteristics (e.g. symmetric, transitive)&lt;/LI&gt;&lt;LI&gt;Restrictions and cardinalities&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This enables reasoning and inference such as in the following example:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_6-1749628413196.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272940i9631E9DA2399F6AA/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_6-1749628413196.png" alt="cesarecalabria_6-1749628413196.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-289298202"&gt;Knowledge Graph applications&lt;/H3&gt;&lt;P&gt;Letâ€™s review quickly the applications of RDF-based knowledge graphs.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Enhanced data integration:&lt;/STRONG&gt; Knowledge graphs can integrate diverse data sources, both structured and unstructured into unified view.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;An example application of that is 360 customer relationship management app because with KG we can link data from various customer touchpoints such as sales, service interactions and marketing campaigns.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Smart search and discovery&lt;/STRONG&gt;: Knowledge graphs enable more accurate and context aware search results.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;So for example, e-commerce platforms can recommend products not just by text match, but products which are contextually related and knowledge graphs connect silent data and surface relevant insights leading to an improved decision support.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Connected siloed data: &lt;/STRONG&gt;for example, a supply chain dashboard can warn you of delays by linking parts from a delayed supplier to active production orders, using semantic links in the graph and establishing clear relationships and rules for data entities.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Logical reasoning to derive new knowledge:&lt;/STRONG&gt; example application of that is fraud detection, because knowledge graphs enable you to connect complex relationships between people, devices and transactions and apply logical rules to spot anomalies.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Semantic understanding of data:&lt;/STRONG&gt; for example legal departments can extract entities from contracts and link them to existing regulations or templates via the knowledge graph.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;GraphRAG:&lt;/STRONG&gt; KG helps grounding large language models on structured data and opens doors for many applications like business aware bots.&lt;/LI&gt;&lt;/UL&gt;&lt;H4 id="toc-hId-221867416"&gt;&lt;BR /&gt;GraphRAG&lt;/H4&gt;&lt;P&gt;GraphRAG is based on the same principle of the well known vector-based RAG retrieval augmented generation (refer to figure below).&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="cesarecalabria_7-1749628413199.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272939iC50E62215F8AC276/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_7-1749628413199.png" alt="cesarecalabria_7-1749628413199.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Retrieval Augmented Generation (RAG) is a framework where a large language model receives external knowledge before generating the answer.&lt;/P&gt;&lt;P&gt;In a GraphRAG scenario, the generative AI app is not sending the question directly to the large language model, but to a specific component (1) that converts the natural language query to a SPARQL query by using the LLM itself (text2SPARQL). This SPARQL query is executed against a triple store (2) where the knowledge is stored in the form of triples to retrieve the needed information. Then finally this information is sent with the original question as additional context to the LLM (3 and 4) which then generate an accurate answer and sends it back to the app. GraphRAG is a technique suitable in particular to ground a LLM on specific business domains and on thei structured data to enhance the accuracy of the LLM answers.&lt;/P&gt;&lt;H2 id="toc-hId-114442830"&gt;&lt;BR /&gt;SAP HANA Cloud Knowledge Graph Engine&lt;/H2&gt;&lt;P&gt;Letâ€™s now see what SAP HANA Cloud offers in terms of RDF-based knowledge graphs (NB: HANA Cloud is alredy supporting since quite some time another category of knowledge graphs, the labeled property graphs. If you are interested, please have a look &lt;A href="https://developers.sap.com/group.hana-aa-graph-overview.html" target="_blank" rel="noopener noreferrer"&gt;here&lt;/A&gt;).&lt;/P&gt;&lt;P&gt;HANA Cloud is supporting RDF-based knowledge graphs with the release of the Knowledge Graph Engine in QRC12025. The Knowledge Graph engine is a high performance graph analytics database system designed to store, manage and query RDF data or triples. So it is a triple store.&lt;/P&gt;&lt;P&gt;Letâ€™s review the core capabilities of the Knowledge Graph Engine (KGE):&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;KGE stores RDF data in a manner that enables efficient retrieval and querying.&lt;/LI&gt;&lt;LI&gt;KGE provides a SPARQL Query Engine that executes all SPARQL query forms and updates (see &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sparql-reference-guide/sap-hana-cloud-sap-hana-database-sparql-reference-guide?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP HANA Database SPARQL Reference Guide&lt;/A&gt;).&lt;/LI&gt;&lt;LI&gt;The main interface to query KGE is provided by a HANA Cloud stored procedure named &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sparql-reference-guide/sparql-execute-stored-procedure?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SPARQL_EXECUTE&lt;/A&gt;.&lt;/LI&gt;&lt;LI&gt;KGE will support RDFS and OWL-based reasoning starting from QRC2.&lt;/LI&gt;&lt;LI&gt;KGE will support RDF data validation with &lt;A href="https://www.w3.org/TR/shacl/" target="_blank" rel="noopener nofollow noreferrer"&gt;SHACL&lt;/A&gt; starting from QRC2.&lt;/LI&gt;&lt;LI&gt;HANA Cloud provides a SQL-to-SPARQL interoperability functionality to federate queries from SQL Engine to Knowledge Graph Engine and viceversa.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;To embed SPARQL queries inside SQL statements, a public table function &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sparql-reference-guide/sparql-table-function?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SPARQL_TABLE&lt;/A&gt; is provided. This function returns an internal table which can be used by the SQL engine before further processing with other SQL objects.&lt;/P&gt;&lt;P&gt;To embed SQL statements inside a SPARQL query, a function SQL_TABLE is provided to federate queries to the corresponding engine. The return results of the SQL statement is&amp;nbsp; converted into a form of graph pattern with SQL projections mapped into variables.&lt;/P&gt;&lt;H3 id="toc-hId--375473682"&gt;&lt;BR /&gt;Consumption&lt;/H3&gt;&lt;P&gt;&lt;BR /&gt;So how can we consume the Knowledge Graph Engine? There are several options:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;the SQL interface within the HANA Database Explorer where you can directly execute the SQL and SPARQL statements;&lt;/LI&gt;&lt;LI&gt;the Python interface by using either &lt;A href="https://pypi.org/project/hdbcli/" target="_blank" rel="noopener nofollow noreferrer"&gt;hdbcli&lt;/A&gt; or &lt;A href="https://pypi.org/project/hana-ml/" target="_blank" rel="noopener nofollow noreferrer"&gt;hana-ml&lt;/A&gt;;&lt;/LI&gt;&lt;LI&gt;the &lt;A href="https://pypi.org/project/langchain-hana/" target="_blank" rel="noopener nofollow noreferrer"&gt;Langchain plugin&lt;/A&gt; update (coming soon) which will enable RDF Graph and SPARQL queries and SPARQL Q&amp;amp;A chain creation as well as support for HANA Cloud vector capabilities.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId--278584180"&gt;&lt;STRONG&gt;Business Use Case: Smart Advisory Companion â€œKnowledge Graph Editionâ€ &lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;&lt;BR /&gt;Now that we have introduced RDF-based knowledge graphs and the HANA Cloud Knowledge Graph Engine, we can see what we can build with this technology.&lt;/P&gt;&lt;P&gt;As mentioned in the beginning, this is a summary of a webinar that is part of a mini series consisting of three appointments. When we conceived this program we envisioned a single business use case that we would have ehnanced it over time with new features.&lt;/P&gt;&lt;P&gt;This is to say that we will make use of the same business use case described &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/grounding-ai-models-in-sap-btp-enhancing-accuracy-and-context/ba-p/14060012" target="_blank"&gt;here&lt;/A&gt; used for the first webinar we delivered in mid March, but this time we will expand the scope with Knowledge Graph technology.&lt;/P&gt;&lt;P&gt;So here we will deal again with a typical customer support team that usually is made of two types of personas with different needs. For example, the technical engineers here represented by John or the support team manager here represented by Mary.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_8-1749628413204.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272941i12D954CBD9A4239E/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_8-1749628413204.png" alt="cesarecalabria_8-1749628413204.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In general, John and the technical engineers take customer incidents and questions, and they try to answer and provide guidance. Mary on the other side is more interested to properly manage the whole team and in ensuring the customer satisfaction and the optimal support processing.&lt;/P&gt;&lt;P&gt;Let's try to recap the use case and the proof of concept we implemented for the first webinar of the program. We imagined the team gets incidents and questions from customers through a CRM system running on SAP HANA Cloud. We imagined that in this CRM system, this team basically collects, stores all the questions, incidents, but also the comments and solutions provided.&lt;/P&gt;&lt;P&gt;We imagined also the involved personas face some issues in their daily working experience. We imagine John struggling with a lot when searching the knowledge base for past cases, and we imagined Mary needs to identify trends to better manage his team and to follow the company priorities.&lt;/P&gt;&lt;P&gt;We addressed these two problems implementing a specific application we named â€œSmart Advisory Companionâ€ that offers several tools to John and Mary in particular to perform smart searches and some analytics for for Mary. In particular, John can run meaningful searches instead of just exact matches, and Mary can get insights from a cluster analysis view of incidents and queries.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_9-1749628413208.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272942iF60189B95E79FB0F/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_9-1749628413208.png" alt="cesarecalabria_9-1749628413208.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;To implement this solution, we basically vectorized the information from the customer questions, inquiries and provided solutions and we stored everything in the HANA Cloud Vector Engine.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;div class="video-embed-center video-embed"&gt;&lt;iframe class="embedly-embed" src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FTA5A5mPWT04%3Ffeature%3Doembed&amp;amp;display_name=YouTube&amp;amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DTA5A5mPWT04&amp;amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FTA5A5mPWT04%2Fhqdefault.jpg&amp;amp;type=text%2Fhtml&amp;amp;schema=youtube" width="200" height="113" scrolling="no" title="kg_demo1_recap" frameborder="0" allow="autoplay; fullscreen; encrypted-media; picture-in-picture;" allowfullscreen="true"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;All this was already very good, but this tool cannot answer properly some questions. For example, letâ€™s imagine John and Mary need to ask a question like this: &lt;EM&gt;â€œtell me the SAP employees who delivered a service of type â€˜BTP technical advisoryâ€™ regarding â€˜multi-tenancyâ€™â€&lt;/EM&gt;.&lt;/P&gt;&lt;P&gt;To answer such a question, it's not enough to leverage the vectorized knowledge available in the HANA Cloud Vector Engine. We need to leverage in some way also the structured data generated by or related to the customer support team activity. But what are the structure data we are talking about? Let me remind you that this this use case was suggested by our daily working experience as BTP Solution architects.&lt;/P&gt;&lt;P&gt;We deal with partners, but it's not so different from interacting with customers. And we have also a sort of CRM system based on a data model in HANA Cloud. So letâ€™s imagine our data model reported in the figure below is the one used by our fictitious customer support team. We have used our relational data for the implementation of the POC associated to this use case.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Jun-11-2025 17-05-44.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273207i3BBDD9FC87E6584B/image-size/large?v=v2&amp;amp;px=999" role="button" title="Jun-11-2025 17-05-44.gif" alt="Jun-11-2025 17-05-44.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Let's have a look closer look to this to this data model. So here you can see we have one main fact table, the service request table, where each new request is tracked and here we collect information about who created the services requested, who is the associated partner and contact person and the associated use case and so on and so forth. Then we have also other tables, for example, the service table where we track all the services requested via a service request and many other dimensions where we collect details about for example, the partners, the countries and regions of the partners or where the services have been delivered, the SAP products covered by the services and the relative industries and LoBâ€™s and so on and so forth.&lt;/P&gt;&lt;P&gt;In the picture below you can see the actual scenario: basically our Smart Advisory Companion needs to be updated to leverage not only the vectorized knowledge base, but also the structured information coming from the relational database.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Jun-09-2025 16-48-10.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273198i2A5B3DB147042486/image-size/large?v=v2&amp;amp;px=999" role="button" title="Jun-09-2025 16-48-10.gif" alt="Jun-09-2025 16-48-10.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;In this scenario we can recognize some new problems for the involved personas here. For example, we can imagine John needs to access quickly the data about submitted requests without browsing the CRM UI or executing complex SQL queries. And on the other hand we imagined Mary needs to access easily the same data in natural language.&lt;/P&gt;&lt;P&gt;How can we enhance then the Smart Advisor advisory companion capabilities to address these new need? We neet to introduce the Knowledge Graph Engine, our triple store. We need to map our relational data model to a custom knowledge graph that we will store and query by means of the Knowledge Graph Engine. We need also to introduce Generative AI Hub because, if we want to allow Mary to interact in natural language with this structured data, we need also to leverage some large language model.&lt;/P&gt;&lt;P&gt;Now let's have a look at the functionalities we added to the original version of our Smart Advisory Companion. We are talking about 3 different modules (refer to image below).&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_2-1749630977626.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272972iD34B958FD97427EC/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_2-1749630977626.png" alt="cesarecalabria_2-1749630977626.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The first one we named Knowledge Graph Discovery is to explore the custom knowledge graph obtained from the customer support team relational data (see demo below).&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;&lt;div class="video-embed-center video-embed"&gt;&lt;iframe class="embedly-embed" src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FkCMqC361Tqk%3Ffeature%3Doembed&amp;amp;display_name=YouTube&amp;amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DkCMqC361Tqk&amp;amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FkCMqC361Tqk%2Fhqdefault.jpg&amp;amp;type=text%2Fhtml&amp;amp;schema=youtube" width="200" height="113" scrolling="no" title="kg_demo2_kg_discovery" frameborder="0" allow="autoplay; fullscreen; encrypted-media; picture-in-picture;" allowfullscreen="true"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/P&gt;&lt;P&gt;Then we have the SPARQL Explorer, another functionality to allow John and all the technical personas to submit SPARQL queries that will be executed against the Knowledge Graph Engine.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;div class="video-embed-center video-embed"&gt;&lt;iframe class="embedly-embed" src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FmhCU1gEWcw4%3Ffeature%3Doembed&amp;amp;display_name=YouTube&amp;amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DmhCU1gEWcw4&amp;amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FmhCU1gEWcw4%2Fhqdefault.jpg&amp;amp;type=text%2Fhtml&amp;amp;schema=youtube" width="200" height="113" scrolling="no" title="kg_demo3_sparql_explorer" frameborder="0" allow="autoplay; fullscreen; encrypted-media; picture-in-picture;" allowfullscreen="true"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Finally, we have the enhanced version of the Advisory Buddy that allows Mary or John to submit queries in natural language, to leverage the interoperability between Knowledge Graph engine and Vector Engine and to consume the new knowledge inferred with Knowledge Graph engine.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;div class="video-embed-center video-embed"&gt;&lt;iframe class="embedly-embed" src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FPQHhrVV_gUU%3Ffeature%3Doembed&amp;amp;display_name=YouTube&amp;amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DPQHhrVV_gUU&amp;amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FPQHhrVV_gUU%2Fhqdefault.jpg&amp;amp;type=text%2Fhtml&amp;amp;schema=youtube" width="200" height="113" scrolling="no" title="kg_demo4_nl2sparql" frameborder="0" allow="autoplay; fullscreen; encrypted-media; picture-in-picture;" allowfullscreen="true"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/P&gt;&lt;P&gt;&lt;div class="video-embed-center video-embed"&gt;&lt;iframe class="embedly-embed" src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FVnNPrPPYQaY%3Ffeature%3Doembed&amp;amp;display_name=YouTube&amp;amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DVnNPrPPYQaY&amp;amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FVnNPrPPYQaY%2Fhqdefault.jpg&amp;amp;type=text%2Fhtml&amp;amp;schema=youtube" width="200" height="113" scrolling="no" title="kg_demo5_nl2sparql_topic" frameborder="0" allow="autoplay; fullscreen; encrypted-media; picture-in-picture;" allowfullscreen="true"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId--475097685"&gt;&lt;STRONG&gt;Architecture&lt;/STRONG&gt;&lt;STRONG&gt;&lt;BR /&gt;&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;Let's now have a look at the solution architecture to achieve the results and to implement all the functionalities seen in the previous demos. Let's start from the architecture we have seen in the original version of the Advisory Buddy poc developed for the webinar we delivered in mid March (see animation below).&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Jun-09-2025 16-53-40.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273199i531F1D91EA568CE5/image-size/large?v=v2&amp;amp;px=999" role="button" title="Jun-09-2025 16-53-40.gif" alt="Jun-09-2025 16-53-40.gif" /&gt;&lt;/span&gt;So here we can recognise an app composed by a Fiori UI5 front end that relies on Python microservices to consume the SAP and a cloud services both for persistency and for the PAL functions needed for Mary for the cluster analysis view.&lt;/P&gt;&lt;P&gt;How does it change to introduce the capabilities we have seen? We need to introduce the Knowledge Graph Engine here, and we need also to introduce Generative AI Hub because we need to access a large language model to convert the query expressed in natural language into a SPARQL query. Of course the Python micro services here need to be updated to consume the new services and we will see later how they are made.&lt;/P&gt;&lt;P data-unlink="true"&gt;If you want to know more about the technical implementation of our prototype, jump to the&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/explicit-knowledge-representation-and-reasoning-with-knowledge-graphs/ba-p/14125040" target="_self"&gt;second blog post&lt;/A&gt;.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/explicit-knowledge-representation-and-reasoning-with-knowledge-graphs/ba-p/14124234"/>
    <published>2025-06-11T16:31:10.985000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/explicit-knowledge-representation-and-reasoning-with-knowledge-graphs/ba-p/14125040</id>
    <title>Explicit knowledge representation and reasoning with Knowledge Graphs: implementation deep dive</title>
    <updated>2025-06-11T16:31:49.637000+02:00</updated>
    <author>
      <name>cesarecalabria93</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/42191</uri>
    </author>
    <content>&lt;H1 id="toc-hId-1603268700"&gt;Explicit knowledge representation and reasoning with Knowledge Graphs: implementation deep dive&lt;/H1&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;In this blog post we will explore how SAP HANA Cloud is further increasing its multi-model capabilities by supporting also RDF-based knowledge graphs and SPARQL querying and we will see a real-world business application of this.&amp;nbsp;We will see how to organize and represent enterprise data in a graph structure with HANA Cloud Knowledge Graph Engine, we will discover how this structure facilitates knowledge representation and reasoning and we will learn how to leverage Knowledge Graphs to retrieve structured data and achieve greater accuracy and explainability in RAG scenarios.&lt;/P&gt;&lt;P&gt;This is a summary of the business use case I presented together with my colleague&amp;nbsp;&lt;A href="https://community.sap.com/t5/user/viewprofilepage/user-id/16662" target="_blank"&gt;@merza&lt;/A&gt;&amp;nbsp;&amp;nbsp;in this webinar:&amp;nbsp;&lt;A href="https://partneredge.sap.com/en/library/education/psd/2025/jan/e_oe_te_w_PSD_WEB_00008801.html" target="_blank" rel="noopener noreferrer"&gt;Explicit knowledge representation and reasoning with Knowledge Graphs&lt;/A&gt;.&amp;nbsp;Please, note the mentioned session is part of a series of webinars under the topic of&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;EM&gt;â€œTalk to Your Business with Generative AIâ€.&lt;/EM&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;Check the full calendar&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://url.sap/crvdej" target="_blank" rel="noopener nofollow noreferrer"&gt;here&lt;/A&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;to watch the recordings of past sessions and register for the upcoming ones!&lt;/P&gt;&lt;P&gt;The session summary is structured in two parts: in this blog post I will dive into the implementation details of the business use case introduced in the&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/explicit-knowledge-representation-and-reasoning-with-knowledge-graphs/ba-p/14124234" target="_self"&gt;first blog post&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;This is not a product, itâ€™s just a prototype that we use to illustrate how to implement the services and concepts we talk about and we hope it might not only inspire you but also be of great help as you have access to the working code through the&amp;nbsp;&lt;A href="https://github.com/SAP-samples/btp-generative-ai-hub-use-cases/tree/main/51-Knowledge-Graph-Explicit-knowledge-representation-and-reasoning" target="_blank" rel="noopener nofollow noreferrer"&gt;SAP-Samples repository here&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;To understand the content of this blog post, it would be useful if you are already familiar with some SAP products, especially SAP BTP Platform and SAP HANA Cloud, and if you already have some knowledge of generative AI, data science in general and also a basic knowledge of JavaScript and Python programming languages.&lt;/P&gt;&lt;H2 id="toc-hId-1535837914"&gt;&amp;nbsp;&lt;/H2&gt;&lt;H2 id="toc-hId-1339324409"&gt;&lt;STRONG&gt;Implementation Deep Dive&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;&lt;BR /&gt;In the next sections I will describe:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;how we developed our custom knowledge graph starting from our relational data model and how we load it into the Knowledge Graph Engine. This is a prerequisite for everything here in this POC in particular, of course for the Knowledge Graph Discovery module that we implemented to explore the RDF knowledge graph.&lt;/LI&gt;&lt;LI&gt;Then we will see how to implement a SPARQL endpoint. This is behind the SPARQL Explorer functionality and allows to submit SPARQL queries against the Knowledge Graph Engine.&lt;/LI&gt;&lt;LI&gt;Then we will see how we enhanced the Advisory Buddy in order to be able to query in natural language the custom knowledge graph we created and to leverage the Knowledge Graph and Vector Engine together.&lt;/LI&gt;&lt;LI&gt;Finally, we will see how it's possible to infer new knowledge with the Knowledge Graph Engine.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_0-1749646302369.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273091i3D17F15C0C6BEAFB/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_0-1749646302369.png" alt="cesarecalabria_0-1749646302369.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Please, refer to &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/explicit-knowledge-representation-and-reasoning-with-knowledge-graphs/ba-p/14124234" target="_self"&gt;previous blog post&lt;/A&gt; for the use case description and the relative architecture.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_0-1749646813914.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273098i555113329A1F8BE6/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_0-1749646813914.png" alt="cesarecalabria_0-1749646813914.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1271893623"&gt;&lt;STRONG&gt;From relational DB to KG&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;&lt;BR /&gt;Let's start from the custom knowledge graph development. So we need to move from our representation with the traditional data structures to a graph representation obtained by leveraging the RDF standard.&lt;/P&gt;&lt;P&gt;There are many ways to build a knowledge graph, but if the starting point is, as in our case, a relational data model in a relational database, this is already of great advantage because the information is already organised in structures and relationships and the relationships and semantics are implicitly available.&lt;/P&gt;&lt;P&gt;So let's see the different steps we followed:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;First of all, we collected as much information, as much information as possible about the relational data model.&lt;/LI&gt;&lt;LI&gt;Then we designed and developed an ontology from the relational data model. As you will see, this is crucial if you want perform text2SPARQL (this is a prerequisite to implement a GraphRAG pipeline) or if you want to infer new knowledge.&lt;/LI&gt;&lt;LI&gt;Another important step is the mapping of relational database content to RDF triples. The final step of course is loading the triples into the triple store, into the HANA Cloud Knowledge Graph Engine.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Let me clarify &amp;nbsp;that in general building an RDF knowledge graph is a tough task and it's it's an open question. There is no one-size-fits-all approach. And in fact, in this section we give only some advises and inputs but then you have to analyse your situation carefully and then identify the best way to proceed.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;1. Project documentation&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;Project documentation is very important and if it is not available, then a preliminary analysis is is required, because we need to list and select all the existing tables and columns. We need to know about the different primary keys and foreign keys, and we need to check the different data types to understand if a conversion is possible and how. And we need also to know about the semantics, the meaning associated to each table and column. Finally we need also to identify those concepts that cannot be expressed in SQL, but that we want to describe in an RDF Knowledge Graph.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;2.&amp;nbsp;Some basic rules for a RDB-&amp;gt;RDF direct mapping:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;each table generates a class;&lt;/LI&gt;&lt;LI&gt;each column generates a property;&lt;/LI&gt;&lt;LI&gt;foreign keys are used to construct further properties and relate the different resources;&lt;/LI&gt;&lt;LI&gt;primary keys can be used to build the URIâ€™s needed to uniquely identify the different resources in the knowledge graph.&lt;/LI&gt;&lt;/UL&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;This is just, I mean a bunch of rules that we used in the following, but if you are interested to know more about the rules of the direct mapping, check the &lt;A href="http://www.w3.org/TR/rdb-direct-mapping/" target="_blank" rel="noopener nofollow noreferrer"&gt;W3C recommendation&lt;/A&gt;.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;3.&amp;nbsp;Ontology development&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;To understand how to use the previous rules to develop an ontology for our custom knowledge graph, let's analyze just a small piece of the ontology we developed.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;In our RDB we have a main fact table â€œservice requestâ€ and another important dimension describing the partners. In our ontology, these two tables became two classes with the same name and the same meaning.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;To model the concept that a service request that can be requested by a partner, we introduced also a specific property named â€œrequestedByâ€.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;To develop our ontology, we leveraged a specific language that offers already a lot of expressivity power. So everything that I have described actually is expressed formally with some lines code (see the example below).&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_0-1749633132008.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272990i9B4ED7DE91FBD543/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_0-1749633132008.png" alt="cesarecalabria_0-1749633132008.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;The first thing that we do here is to define the â€œSAP service requestâ€ class and provide a description for that. We do the same for the â€œSAP Partnerâ€ class. Then we provide a formal expression for the property â€œrequestedByâ€ that is linking the two classes.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;Similar lines of code have to be written to define every class, property, rule, axiom that you need in the ontology. In general in this phase a domain expert is needed, it is difficult to automate the process. So you can do it manually if you know OWL or otherwise you can profit of an open source&amp;nbsp; and visual tool named &lt;A href="https://protege.stanford.edu/software.php#desktop-protege" target="_blank" rel="noopener nofollow noreferrer"&gt;ProtÃ©gÃ©&lt;/A&gt;.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;4. Map DB content to RDF triples&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;Now let's see how we can map all the content of the different tables we have in the relational database. To understand it, we can consider again the example of the â€œservice requestâ€ table. Let's try to convert just the first row of this simplified this table into triples by following the rules that I mentioned before.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Jun-10-2025 16-57-49.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273201iDFA267D8ECE6F965/image-size/large?v=v2&amp;amp;px=999" role="button" title="Jun-10-2025 16-57-49.gif" alt="Jun-10-2025 16-57-49.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Refer to the animation above. The column named â€œIDâ€ here in this table is the the primary key. This can be used to build a unique identifier for the resource. This will be the subject of all the triples we are going to build.&lt;/P&gt;&lt;P&gt;The â€œrequest stateâ€ column becomes a property. The content of the field becomes the object of the corresponding triple. The â€œPartner IDâ€ is a foreign key and it can be used to generate a new property, the â€œrequestedByâ€ property that we have defined conceptually in ontology.&lt;/P&gt;&lt;P&gt;Also in this case the content of the field, the ID identifying the partner, is used here to build another URI that points to an object that is instance of another class, the â€œSAP Partnerâ€ class.&lt;/P&gt;&lt;P&gt;This is just an example, but actually this procedure needs be repeated for all the columns that are in our â€œservice requestâ€ table and also for all the tables in the relational data model. This is the base of a direct mapping and in the end it's an ETL process that you can try to automatize with an ETL pipeline.&lt;/P&gt;&lt;P&gt;There is one simple and open source tool named &lt;A href="https://openrefine.org/" target="_blank" rel="noopener nofollow noreferrer"&gt;OpenRefine&lt;/A&gt; where you can apply this procedure to process your relational data and convert it to RDF triples. You can try it for developing pocâ€™s or for small projects, but it doesnâ€™t allow any automation. Another possibility to implement a direct mapping is using a specific language for converting our relational DP to RDF named &lt;A href="https://www.w3.org/TR/r2rml/" target="_blank" rel="noopener nofollow noreferrer"&gt;R2RML&lt;/A&gt;.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;5. Loading the triples to HANA Cloud Knowledge Graph&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;All the processes we described so far generates triples that need to be loaded into the HANA Cloud triple store. The triples can come as a unique file or distributed over many files as in our case. The Knowledge Graph Engine provides a Python interface that we can use to access the HANA Cloud DB and load the files. Check &lt;A href="https://github.com/SAP-samples/btp-generative-ai-hub-use-cases/blob/main/51-Knowledge-Graph-Explicit-knowledge-representation-and-reasoning/knowledge_graph/notebooks/load_triples_to_kge.ipynb" target="_blank" rel="noopener nofollow noreferrer"&gt;this Jupyter notebook&lt;/A&gt; to see the code.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1075380118"&gt;&lt;STRONG&gt;SPARQL Explorer&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;Now let's move to the SPARQL Explorer and the SPARQL endpoint implementation. This is one of the endpoints that we developed for our POC and it's deployed as all the other ones in Cloud Foundry. The code is very simple here, you can see it in the image below and also directly in our &lt;A href="https://github.com/SAP-samples/btp-generative-ai-hub-use-cases/blob/main/51-Knowledge-Graph-Explicit-knowledge-representation-and-reasoning/backend/app/api.py#L39" target="_blank" rel="noopener nofollow noreferrer"&gt;GitHub repository&lt;/A&gt;. This is a Python micro service and it's a wrapper around the SPARQL_EXECUTE procedure that is available in Knowledge Graph Engine.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_2-1749633132042.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/272989i9088B8DDFF273E9D/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_2-1749633132042.png" alt="cesarecalabria_2-1749633132042.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;If we look at the code, we see that we get the SPARQL query from the body of the request sent to this endpoint. Then we execute the SPARQL query by calling the procedure SPARQL_EXECUTE and we return back the data in CSV file format or JSON format. We can choose the output format, both are supported by Knowledge Graph Engine.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-878866613"&gt;&lt;STRONG&gt;Enhanced Advisory Buddy: querying in natural language&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;&lt;BR /&gt;&lt;/STRONG&gt;Let's see how we implemented the functionality for querying the custom Knowledge Graph in natural language. In the image below you can see the process flow we need to implement to achieve this querying in natural language. So basically, the query is submitted by Mary to our application, our Smart Advisory Companion, and then this question is converted in the backend to a SPARQL query. This is done with the help of a large language model that we access through Generative AI Hub.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_0-1749647418102.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273102iFA79569D7C4CE32C/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_0-1749647418102.png" alt="cesarecalabria_0-1749647418102.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once we have this SPARQL query, this can be executed by means of the SPARQL execute procedure in our Knowledge Graph Engine. The result is returned back to the user.&lt;/P&gt;&lt;P&gt;The key process here is this text to SPARQL conversion that is a prerequisite for implementing a complete GraphRAG pipeline. Here we are missing just the last step where the large language model is used also to generate the final answer in natural language, but we didn't need it for our POC.&lt;/P&gt;&lt;P&gt;In this scenario the large language model is used to perform this text to SPARQL conversion. The large language model probably knows better than us all the rules and syntax of SPARQL, but it doesn't know anything about the custom knowledge graph that we have in the Knowledge Graph Engine.&lt;/P&gt;&lt;P&gt;So in order to perform an accurate text2SPARQL conversion we need to guide the large language model and we need also to provide the KG conceptual model, that is the ontology we have built on top of our KG. In our implementation all the needed information is taken from a specific SQL table stored in HANA Cloud SQL DB at runtime. From this table we take a prompt template and also an example of a good SPARQL query to guide the model in the SPARQL query generation.&lt;/P&gt;&lt;P&gt;Let's understand the most important point, how we provide information about the ontology as additional context to the user prompt to achieve the text2SPARQL conversion. In the SQL table we have stored some SPARQL queries designed to be executed on the KG stored in the Knowledge Graph Engine to retrieve the ontology description. Below you can see one of the SPARQL queries:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_1-1749647472568.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273104iEBEC1D376851B8FE/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_1-1749647472568.png" alt="cesarecalabria_1-1749647472568.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;The one shown is used to retrieve information about all the classes that we have in our ontology along with their descriptions. These descriptions are crucial for the for guiding the large language model. The other query is similar, but it retrieves the information about all the properties.&lt;/P&gt;&lt;P&gt;Now let's have a look at the Python microservice that performs text2SPARQL. Letâ€™s refer to the two images below and letâ€™s go through the different steps:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;So first of all, we retrieve the configurations from the SQL table that I have mentioned before and that we have in HANA Cloud SQL DB.&lt;/LI&gt;&lt;LI&gt;Then we execute the different SPARQL queries to retrieve the information about the ontology.&lt;/LI&gt;&lt;LI&gt;We initialize the model thanks to the Generative AI Hub SDK.&lt;/LI&gt;&lt;LI&gt;We prepare the prompt prompt template, replacing all the paramentes that needs to be replaced.&lt;/LI&gt;&lt;LI&gt;Then we create a chain between this prompt template and the large language model.&lt;/LI&gt;&lt;LI&gt;And finally we are ready to invoke the model to generate the SPARQL query that is returned back and executed against the Knowledge Graph Engine thanks to the procedure SPARQL_EXECUTE procedure.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-06-11 at 15.57.57.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273136i48CB18927F6A9D1C/image-size/large?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-06-11 at 15.57.57.png" alt="Screenshot 2025-06-11 at 15.57.57.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-06-11 at 15.58.21.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273138iA5EF0E47DB6543BD/image-size/large?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-06-11 at 15.58.21.png" alt="Screenshot 2025-06-11 at 15.58.21.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-682353108"&gt;&lt;STRONG&gt;Enhanced Advisory Buddy: KG Engine and Vector Engine&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;&lt;BR /&gt;&lt;/STRONG&gt;Now let's see how we can further improve our advisory body to leverage both the Knowledge Graph Engine and the Vector Engine capabilities.&lt;/P&gt;&lt;P&gt;As explained in the previous demo, we need to introduce also the Vector Engine because we want to answer questions like this: &lt;EM&gt;â€œTell me the SAP employees who delivered a service of type named â€œSAP BTP Technical Advisoryâ€ regarding â€œMulti-tenancyâ€&lt;/EM&gt;.&lt;/P&gt;&lt;P&gt;To do this we need both structured and unstructured data. Letâ€™s refer to the diagram below. We need to retrieve information from structured data stored in the HANA Cloud KG Engine and SQL DB, but we need also to retrieve the information stored as vectors available in the Vector Engine, and for that we need to execute some similarity searches.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_2-1749647695958.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273109iCFDE5E4990C5F12A/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_2-1749647695958.png" alt="cesarecalabria_2-1749647695958.png" /&gt;&lt;/span&gt;Now, the microservice this time should perform two different tasks: identify the topic in the natural language query submitted by Mary and convert part of her request into a SPARQL query. So two different tasks that are performed by the large language model that is accessed with the help of Generative AI Hub.&lt;/P&gt;&lt;P&gt;With this information, the microservice is able to generate a hybrid query. Since we are not interested in letting the LLM generate the entire query, we impose a constraint by providing the final query model, so that the large language model only needs to generate parts of this query.&lt;/P&gt;&lt;P&gt;Letâ€™s have a look at the query template (see animation below). We can recognize an outer part that is SQL-like and an inner part that is SPARQL-like.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Jun-06-2025 15-47-58.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273202iA7D409AD1A0EA19C/image-size/large?v=v2&amp;amp;px=999" role="button" title="Jun-06-2025 15-47-58.gif" alt="Jun-06-2025 15-47-58.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The large language model needs to generate the internal SPARQL query and identify the topic. When the final hybrid query is executed, the internal SPARQL query is executed against the Knowledge Graph Engine using the SPARQL_TABLE function. This is because SPARQL_TABLE returns a SQL table that can be used with all other SQL tables in the HANA Cloud. And that is exactly what we do here: via a join we retrieve the use case short descriptions and their embeddings from another table in the HANA Cloud DB. Then we perform a similarity search comparing the topic identified by the LLM in the Maryâ€™s query and the different short descriptions to find the 5 best matches.&lt;/P&gt;&lt;P&gt;As already mentioned, we have a new task here with respect to the previous implementation involving only the KG Engine: we need to select the delivered services based on the topic. In order to do that we need to guide our large language model also on this task by providing a specific prompt template to extract the topic from Maryâ€™s request in natural language and also the hybrid query template that we have seen previously.&lt;/P&gt;&lt;P&gt;As mentioned, we have a new task compared to the previous implementation that only involved the KG Engine: we need to select the delivered services based on the topic they covered. To do that, we need to guide our large language model in this task as well, providing a specific prompt template to extract the topic from Mary's natural language request and also the hybrid query template we saw earlier. This information is again taken from the same config SQL table that we have created in HANA Cloud DB.&lt;/P&gt;&lt;P&gt;Now let's have a look at the Python microservice that performs this conversion of text to a hybrid query like the one shown before. Letâ€™s refer to code below and letâ€™s go through the different steps:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;We retrieve the needed configurations from the config SQL table.&lt;/LI&gt;&lt;LI&gt;We prepare the prompt template to identify the topic.&lt;/LI&gt;&lt;LI&gt;We create the LLM chain to identify the topic thanks to Langchain and Generative AI Hub SDK.&lt;/LI&gt;&lt;LI&gt;Then we invoke the large language model to identify the topic.&lt;/LI&gt;&lt;LI&gt;We generate the SPARQL query in the very same way described in the previous section.&lt;/LI&gt;&lt;LI&gt;Once we have these two ingredients, we prepare the final hybrid query.&lt;/LI&gt;&lt;LI&gt;We execute the final query on HANA Cloud and we return the result of the execution.&lt;/LI&gt;&lt;/OL&gt;&lt;DIV class=""&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-06-11 at 16.02.10.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273144i430A2BB6689911F8/image-size/large?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-06-11 at 16.02.10.png" alt="Screenshot 2025-06-11 at 16.02.10.png" /&gt;&lt;/span&gt;&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Screenshot 2025-06-11 at 16.02.22.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273146iABBBD24EE747F410/image-size/large?v=v2&amp;amp;px=999" role="button" title="Screenshot 2025-06-11 at 16.02.22.png" alt="Screenshot 2025-06-11 at 16.02.22.png" /&gt;&lt;/span&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;STRONG&gt;Inference with Knowledge Graph Engine (expected in QRC2)&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Now let me cover another important capability of RDF-based knowledge graphs that is probably the real differentiator with respect to the traditional data structures, the possibility to infer new knowledge. This is a festure provided by the RDF standard, and it will be supported in Q2 by HANA Cloud Knowledge Graph Engine.&lt;/P&gt;&lt;P&gt;Let's try to understand what inference is in the context of RDF knowledge graphs. The key feature of an RDF knowledge graph is to make explicit all the available knowledge about a given domain so that this is immediately usable. The usability is closely related to the presence of triples that are served something in the knowledge graph.&lt;/P&gt;&lt;P&gt;It may happen that in the knowledge graph there is still some implicit knowledge that is not immediately immediately usable. This can can happen when the ontology describes more entities, more relationships or logical rules than the facts that are available in form of triples. In this kind of situation, we can try to make this implicit knowledge explicit and usable. To do that, we can use the inference procedure. We can therefore say that inference is the procedure for making implicit knowledge explicit and usable for business action.&lt;/P&gt;&lt;P&gt;But what does this mean in practice? Let's try to understand it in the context of our POC using the custom knowledge graph we developed. So let's start with some known data from our custom knowledge graph. For simplicity, in the following example we will not use the full URI of the objects and we will replace reale names with fictitious ones.&lt;/P&gt;&lt;P&gt;If we look at the animation below, what we know from the facts explicitly asserted in our knowledge graph is that:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;the service request 123 was requested by Hogwarts Solutions;&lt;/LI&gt;&lt;LI&gt;for this service request we have a partner contact that is Emily;&lt;/LI&gt;&lt;LI&gt;the service request consists of a service named â€œtechnical advisoryâ€;&lt;/LI&gt;&lt;LI&gt;Hogwarts Solutions is an SAP partner and Emily is his contact;&lt;/LI&gt;&lt;LI&gt;the technical advisory was delivered by John and John is an SAP employee.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;So these are the known facts that are explicitly given in the KG. Now let's see the questions we can answer with this information. For example, we could ask: "&lt;EM&gt;who was the contact person for the service request 123?&lt;/EM&gt;&amp;nbsp;", the answer is simple because it's stated and it's Emily. Moreover &lt;EM&gt;â€œwho delivered the the technical advisory service?â€&lt;/EM&gt;&amp;nbsp;, this question is also very simple, it was John.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Jun-09-2025 12-54-51.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273203iCF625557E4E42220/image-size/large?v=v2&amp;amp;px=999" role="button" title="Jun-09-2025 12-54-51.gif" alt="Jun-09-2025 12-54-51.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;But if we ask: &lt;EM&gt;â€œwho are the persons involved in service request 123?â€&lt;/EM&gt;, &amp;nbsp;we cannot answer this question because we are missing some concepts and we are missing also the triples, the facts to answer this question. So what can we do?&lt;/P&gt;&lt;P&gt;We can first of all work on the ontology introducing the missing concepts. And in fact, for this purpose, in our ontology we have introduced some hierarchies of classes and properties. We introduced the generic concepts of Organization and Person. Then we declared SAP Organization and SAP Partner subclasses of the class Organization. Similarly SAP Employee or the SAP Partner Contact are subclasses of the class Person. Additionally, we introduced the concept of role-independent involvement. We did this by introducing a property called "Involves" (and its inverse property) and by declaring the existing properties "deliveredBy" or "hasPartnerContact" as special cases of the "Involves" property.&lt;/P&gt;&lt;P&gt;With these additional concepts the ontology contains more information than the facts asserted in the KG. As mentioned, in such a situation, we can make use of the reasoner that is available in the Knowledge Graph engine to make explicit some the implicit knowledge contained in the ontology. So the triples of ontology and the triples corresponding to the known facts become inputs to the reasoner to infer new facts.&lt;/P&gt;&lt;P&gt;What are these these new facts?&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;John and Emily are persons;&lt;/LI&gt;&lt;LI&gt;the technical advisory involved in some way John and Emily;&lt;/LI&gt;&lt;LI&gt;Hogwarts Solutions is a partner, but also an organization.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;We now have everything we need to make our app know that John and Emily were the people involved in the 123 request, regardless of their role and answer correctly the previous question.&lt;/P&gt;&lt;P&gt;What I have described is just an example of inference related to the knowledge regarding a single service request, but in reality we have inferred similar new triples for all service requests tracked in the system. So with this inference procedure, we can then answer more complex queries such as the following: "count the number of people involved in services and service requests, grouping them by service and by organization to which they belong" (refer to image below).&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_0-1749648159403.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273114i32C11B77D046A7EB/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_0-1749648159403.png" alt="cesarecalabria_0-1749648159403.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;We can drop this query natural language in our Enhanced Advisory Buddy where it is converted into a SPARQL query. By inspecting the SPARQL query, we can see that we're performing a specific pattern matching because here we are looking for triples requiring persons involved in a service request or a service and persons that are employed by an organization generically. This is possible because we declared the concepts explicitly in the ontology. But the answer to this question (see image below) is possible because we inferred the missing triples. In the answer we can see that every service request service involves at least one person from the partner and one person from SAP.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="cesarecalabria_1-1749648185317.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273115iEBA3863D7C10B20D/image-size/large?v=v2&amp;amp;px=999" role="button" title="cesarecalabria_1-1749648185317.png" alt="cesarecalabria_1-1749648185317.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;So this is a very important capability of RDF knowledge graphs especially when you have implemented very complex logics in the ontology and you want to deduce new unknown facts from what you already know.&lt;/P&gt;&lt;P&gt;Now let's have a look at how we can run this inference in Knowledge Graph Engine. Letâ€™s refer to the the following animation.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Jun-09-2025 15-53-08.gif" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/273205i029F156C60D6E758/image-size/large?v=v2&amp;amp;px=999" role="button" title="Jun-09-2025 15-53-08.gif" alt="Jun-09-2025 15-53-08.gif" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;There is a specific command for batch inferencing where we need to provide the graphs where the ontology and the facts are stored. Then we can decide if we want to store the inferred new facts into one of the existing graphs or in new one. Finally the command is executed against the Knowledge Graph Engine. In particular, when it is executed, the Knowledge Graph engine scans the specific specified graphs for any of the RDFS or unsupported OWL ontologies and then it generates new triples according to the W3C&amp;nbsp;&lt;A href="https://www.w3.org/TR/owl2-profiles/" target="_blank" rel="noopener nofollow noreferrer"&gt;OWL 2 RL&lt;/A&gt;&amp;nbsp;rules or rules that you can specify in the WHERE close.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-356756884"&gt;&lt;STRONG&gt;Wrap-up and roadmap&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;Let's summarise what we have learnt in this blog post. First of all in SAP HANA Cloud we are introducing a new a new functionality: a triple store, the Knowledge Graph Engine, &amp;nbsp;to store and consume RDF-based knowledge graphs. So we are now supporting the RDF standard and the SPARQL querying.&lt;/P&gt;&lt;P&gt;We are providing tools to ensure the interoperability between SQL and SPARQL with specific procedures and functions. We are also going to support inference with RDF KG &amp;nbsp;and the validation with SHACL in Q2.&lt;/P&gt;&lt;P&gt;The poc we have developed helps us recognize some of the advantages that can be obtained with RDF KS and the Knowledge Graph Engine:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Model (even abstract) concepts from custom business domains;&lt;/LI&gt;&lt;LI&gt;Create a centralised semantic view of the business data (especially when the data sources leverage already the same RDF standard);&lt;/LI&gt;&lt;LI&gt;Implementation of text2SPARQL and GraphRAG pipelines to ground generative on structured data;&lt;/LI&gt;&lt;LI&gt;Benefit from the synergy with other HANA Cloud multi-model capabilities and implement a multi-model RAG pipelines.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Concerning the roadmap for Knowledge Graph Engine, as mentioned, we will have in Q2 the inference and the validation capabilities. We are waiting for the Langchain integration that, for instance, will simplify the implementation of Q&amp;amp;A chains with RDF knowledge graphs. You can check the &lt;A href="https://github.com/SAP/langchain-integration-for-sap-hana-cloud/tree/hana-kg" target="_blank" rel="noopener nofollow noreferrer"&gt;GitHub repo&lt;/A&gt; to be informed about the release. Finally to be always informed about the future HANA Cloud feature, you can check the &lt;A href="https://roadmaps.sap.com/board?PRODUCT=73554900100800002881&amp;amp;BC=6EAE8B28C5D91EDA9A993F47E721E0E5&amp;amp;range=FIRST-LAST#Q2%202025" target="_blank" rel="noopener noreferrer"&gt;official HANA Cloud roadmap&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;As a final note, don't miss the opportunity and register now for the next webinars:&lt;/P&gt;&lt;P&gt;&lt;A href="https://partneredge.sap.com/en/library/education/psd/2025/jan/e_oe_te_w_PSD_WEB_00008804.html" target="_blank" rel="noopener noreferrer"&gt;Amplify Joule's power for your enterprise needs&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Session 1: 1st July&amp;nbsp; 2025, 09:00 AM CET - 11:00 AM CET&lt;/P&gt;&lt;P&gt;Session 2: 2nd July 2025, 10:00 AM EST - 12:00 PM EST&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-160243379"&gt;Additional resources&lt;/H2&gt;&lt;P&gt;â€¢&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/become-an-early-adopter-for-the-knowledge-graph-engine-in-sap-hana-cloud/ba-p/14021136" target="_blank"&gt;Become an Early Adopter for the Knowledge Graph Engine in SAP HANA Cloud&lt;/A&gt;&lt;/P&gt;&lt;P&gt;â€¢&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-knowledge-graph-guide/sap-hana-cloud-sap-hana-database-knowledge-graph-engine-guide?locale=en-US&amp;amp;version=2025_1_QRC" target="_blank" rel="noopener noreferrer"&gt;HANA Cloud KG Engine documentation&lt;/A&gt;&lt;/P&gt;&lt;P&gt;â€¢&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/connecting-the-facts-sap-hana-cloud-s-knowledge-graph-engine-for-business/ba-p/13888597" target="_blank"&gt;Blog Post: Connecting the Facts: SAP HANA Cloudâ€™s Knowledge Graph Engine for Business Context&lt;/A&gt;&lt;/P&gt;&lt;P&gt;â€¢&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;A href="https://open.hpi.de/courses/knowledgegraphs2023" target="_blank" rel="noopener nofollow noreferrer"&gt;Learning: openHPI Knowledge Graphs - Foundations and Applications&lt;/A&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/explicit-knowledge-representation-and-reasoning-with-knowledge-graphs/ba-p/14125040"/>
    <published>2025-06-11T16:31:49.637000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217</id>
    <title>Comprehensive Guide to MLTrack in SAP HANA Cloud: End-to-End Machine Learning Experiment Tracking</title>
    <updated>2025-06-24T07:47:19.397000+02:00</updated>
    <author>
      <name>raymond_yao</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/282718</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1733246985"&gt;&lt;SPAN&gt;Introduction: MLTrack &lt;/SPAN&gt;&lt;/H2&gt;&lt;P class=""&gt;&lt;SPAN&gt;Machine learning experimentation requires robust tracking capabilities to ensure reproducibility, comparison, and auditability of models. SAP HANA Cloud's MLTrack feature provides seamless integration with Predictive Analysis Library (PAL) procedures, enabling automatic logging of critical experiment artifacts. This end-to-end tracking solution captures parameters, datasets, models, metrics, and visualizations in a structured way, transforming how data scientists manage ML workflows. &lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1536733480"&gt;&lt;SPAN&gt;1. Understanding MLTrack Architecture &lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;SPAN&gt;MLTrack organizes experiment data through three core tables in the PAL_ML_TRACK schema: &lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1469302694"&gt;&lt;SPAN&gt;1.1 TRACK_METADATA Table &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The experiment registry storing high-level information: &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Column &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Description &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Example Value &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;TRACK_ID &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Unique experiment identifier &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;"TRACK_TEST" &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;OWNER &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Experiment creator &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;"DEVELOPER_A" &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;STATUS &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Current state (ACTIVE/FINISHED/FAILED) &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;"FINISHED" &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;PROC_NAME &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;PAL procedure used &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;"PAL_UNIFIED_CLASSIFICATION" &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H3 id="toc-hId-1272789189"&gt;&lt;SPAN&gt;1.2 TRACK_LOG Table &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The detailed experiment diary capturing chronological events: &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;SELECT * FROM PAL_ML_TRACK.TRACK_LOG&amp;nbsp;&lt;/P&gt;&lt;P&gt;WHERE EXECUTION_ID = 'TRACK_TEST'&lt;/P&gt;&lt;P&gt;ORDER BY SEQ, EVENT_TIMESTAMP;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;&lt;SPAN&gt;Each record includes: &lt;/SPAN&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;EVENT_KEY&lt;SPAN&gt;: Entity type (Parameter/Dataset/Metric) &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;EVENT_MESSAGE&lt;SPAN&gt;: JSON payload with entity details &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;SEQ&lt;SPAN&gt;: Message sequence number &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Automatic message splitting for payloads &amp;gt; 5000 characters &lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;H3 id="toc-hId-1076275684"&gt;&lt;SPAN&gt;1.3 TRACK_LOG_HEADER Table &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The tagging system for log records: &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;SELECT * FROM PAL_ML_TRACK.TRACK_LOG_HEADER&amp;nbsp;&lt;/P&gt;&lt;P&gt;WHERE EXECUTION_ID = 'TRACK_TEST'&lt;/P&gt;&lt;P&gt;ORDER BY SEQ;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;&lt;SPAN&gt;Enables adding custom key-value pairs to any log entry for enhanced categorization. &lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-750679460"&gt;&lt;SPAN&gt;2. Enabling MLTrack in PAL Procedures &lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;SPAN&gt;Activate tracking by adding these parameters to your PAL call: &lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-683248674"&gt;&lt;SPAN&gt;2.1 Control Parameters &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Parameter &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Type &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Values &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Functionality &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;LOG_ML_TRACK &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;INTEGER &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;0 or 1 &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Master switch for MLTrack &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;LOG_PARAM &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;INTEGER &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;0 or 1 &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Log procedure parameters &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;LOG_DATASET &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;INTEGER &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;0 or 1 &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Log dataset metadata &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;LOG_MODEL_SIGNATURE &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;INTEGER &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;0 or 1 &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Log model input/output schemas &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;LOG_FIGURE &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;INTEGER &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;0 or 1 &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Log visualization data &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H3 id="toc-hId-486735169"&gt;&lt;SPAN&gt;2.2 Identification Parameters &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;INSERT INTO PAL_PARAMETER_TBL VALUES&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; ('LOG_ML_TRACK', 1, NULL, NULL),&lt;/P&gt;&lt;P&gt;&amp;nbsp; ('TRACK_ID', NULL, NULL, 'PLAY_PREDICTION_1'),&lt;/P&gt;&lt;P&gt;&amp;nbsp; ('TRACK_DESCRIPTION', NULL, NULL, 'Golf play decision tree'),&lt;/P&gt;&lt;P&gt;&amp;nbsp; ('DATASET_NAME', NULL, NULL, 'Golf_Play_Dataset'),&lt;/P&gt;&lt;P&gt;&amp;nbsp; ('DATASET_SOURCE', NULL, NULL, 'PAL_GOLF_DATA_TBL');&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H2 id="toc-hId-161138945"&gt;&lt;SPAN&gt;3. Practical Implementation: Classification Example &lt;/SPAN&gt;&lt;/H2&gt;&lt;H3 id="toc-hId-93708159"&gt;&lt;SPAN&gt;3.1 Dataset Setup &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;CREATE COLUMN TABLE PAL_GOLF_DATA (&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; "ID" INTEGER,&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; "OUTLOOK" NVARCHAR(20),&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; "TEMP" DOUBLE,&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; "HUMIDITY" DOUBLE,&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; "WINDY" NVARCHAR(10),&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; "PLAY" NVARCHAR(20)&amp;nbsp; -- Target variable&lt;/P&gt;&lt;P&gt;);&lt;/P&gt;&lt;P&gt;-- Sample data insertion&lt;/P&gt;&lt;P&gt;INSERT INTO PAL_GOLF_DATA VALUES&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; (1, 'Sunny', 75, 70.0, 'No', 'Play'),&lt;/P&gt;&lt;P&gt;&amp;nbsp; (2, 'Rainy', 68, 80.0, 'Yes', 'Do not Play');&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H3 id="toc-hId--178036715"&gt;&lt;SPAN&gt;3.2 Parameter Configuration &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;CREATE COLUMN TABLE PAL_PARAMS (&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; "PARAM_NAME" NVARCHAR(100),&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; "INT_VALUE" INTEGER,&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; "STRING_VALUE" NVARCHAR(100)&lt;/P&gt;&lt;P&gt;);&lt;/P&gt;&lt;P&gt;INSERT INTO PAL_PARAMS VALUES&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; ('FUNCTION', NULL, 'RDT'),&amp;nbsp; -- Random Decision Tree&lt;/P&gt;&lt;P&gt;&amp;nbsp; ('MAX_DEPTH', 10, NULL),&lt;/P&gt;&lt;P&gt;&amp;nbsp; ('LOG_ML_TRACK', 1, NULL),&lt;/P&gt;&lt;P&gt;&amp;nbsp; ('TRACK_ID', NULL, 'GOLF_CLS_EXP_1'),&lt;/P&gt;&lt;P&gt;&amp;nbsp; ('DATASET_SOURCE', NULL, 'PAL_GOLF_DATA');&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H3 id="toc-hId--374550220"&gt;&lt;SPAN&gt;3.3 Execute PAL Procedure with Tracking &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;DO&lt;/P&gt;&lt;P&gt;BEGIN&lt;/P&gt;&lt;P&gt;&amp;nbsp; lt_data = SELECT * FROM PAL_GOLF_DATA;&lt;/P&gt;&lt;P&gt;&amp;nbsp; lt_params = SELECT * FROM PAL_PARAMS;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; CALL _SYS_AFL.PAL_UNIFIED_CLASSIFICATION_TRACK(&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; :lt_data,&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; :lt_params,&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; lt_model, lt_imp, lt_stat, lt_cmatrix&lt;/P&gt;&lt;P&gt;&amp;nbsp; );&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; -- Persist outputs&lt;/P&gt;&lt;P&gt;&amp;nbsp; INSERT INTO ML_MODELS SELECT * FROM :lt_model;&lt;/P&gt;&lt;P&gt;&amp;nbsp; INSERT INTO FEATURE_IMPORTANCE SELECT * FROM :lt_imp;&lt;/P&gt;&lt;P&gt;END;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H2 id="toc-hId--277660718"&gt;&lt;SPAN&gt;4. Accessing Tracked Experiment Data &lt;/SPAN&gt;&lt;/H2&gt;&lt;H3 id="toc-hId--767577230"&gt;&lt;SPAN&gt;4.1 Retrieve Experiment Metadata &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;SELECT * FROM PAL_ML_TRACK.TRACK_METADATA&amp;nbsp;&lt;/P&gt;&lt;P&gt;WHERE TRACK_ID = 'GOLF_CLS_EXP_1';&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="å›¾ç‰‡ 1.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277532iE2B39317CDD7D73F/image-size/large?v=v2&amp;amp;px=999" role="button" title="å›¾ç‰‡ 1.png" alt="å›¾ç‰‡ 1.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId--964090735"&gt;&lt;SPAN&gt;4.2 Analyze Logged Parameters &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;SELECT EVENT_MESSAGE FROM PAL_ML_TRACK.TRACK_LOG&lt;/P&gt;&lt;P&gt;WHERE EXECUTION_ID = 'GOLF_CLS_EXP_1'&lt;/P&gt;&lt;P&gt;&amp;nbsp; AND EVENT_KEY = 'Parameter';&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277535i229FA82ABF14C446/image-size/large?v=v2&amp;amp;px=999" role="button" title="2.png" alt="2.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId--1160604240"&gt;&lt;SPAN&gt;4.3 Extract Model Evaluation Metrics &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;SELECT&lt;BR /&gt;JSON_VALUE(EVENT_MESSAGE, '$.accuracy') AS accuracy,&lt;BR /&gt;JSON_VALUE(EVENT_MESSAGE, '$.f1_score') AS f1&lt;BR /&gt;FROM PAL_ML_TRACK.TRACK_LOG&lt;BR /&gt;WHERE EXECUTION_ID = 'GOLF_CLS_EXP_1'&lt;BR /&gt;AND EVENT_KEY = 'METRIC';&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H2 id="toc-hId--1063714738"&gt;&lt;SPAN&gt;5. Advanced Management: Log Removal &lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;SPAN&gt;Safely remove experiments using hierarchical deletion: &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;DO&lt;/P&gt;&lt;P&gt;BEGIN&lt;/P&gt;&lt;P&gt;&amp;nbsp; DECLARE param_tbl TABLE (&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; PARAM_NAME NVARCHAR(256),&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; STRING_VALUE NVARCHAR(1000)&lt;/P&gt;&lt;P&gt;&amp;nbsp; );&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; DECLARE removed_info TABLE (&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; TRACK_ID NVARCHAR(128),&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; STATUS NVARCHAR(10)&lt;/P&gt;&lt;P&gt;&amp;nbsp; );&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; INSERT INTO param_tbl VALUES&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; ('REMOVE_MODE', '1'),&amp;nbsp; -- Hierarchical removal&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; ('TRACK_ID', 'GOLF_CLS_EXP_1'),&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; ('IS_FORCE', '0');&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; -- Don't remove active tracks&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; CALL _SYS_AFL.PAL_REMOVE_MLTRACK_LOG(:param_tbl, removed_info);&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; SELECT * FROM :removed_info;&amp;nbsp; -- Removal confirmation&lt;/P&gt;&lt;P&gt;END;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="3.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277536i8A4594DA212825C1/image-size/large?v=v2&amp;amp;px=999" role="button" title="3.png" alt="3.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId--1260228243"&gt;&lt;SPAN&gt;6. Python Integration with hana_ml &lt;/SPAN&gt;&lt;/H2&gt;&lt;H3 id="toc-hId--1750144755"&gt;&lt;SPAN&gt;HANA ML Experiment Tracking Example &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;This code demonstrates how to track machine learning experiments using SAP HANA ML's tracking capabilities: &lt;/SPAN&gt;&lt;/P&gt;&lt;H4 id="toc-hId-2054906029"&gt;&lt;SPAN&gt;1. Imports and Initialization &lt;/SPAN&gt;&lt;/H4&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;from hana_ml.artifacts.tracking.tracking import MLExperiments&lt;/P&gt;&lt;P&gt;# Create Unified Classification model using Hybrid Gradient Boosting Trees algorithm&lt;/P&gt;&lt;P&gt;uc = UnifiedClassification(func="hybridgradientboostingtree")&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H4 id="toc-hId-2026576215"&gt;&lt;SPAN&gt;2. Experiment Setup &lt;/SPAN&gt;&lt;/H4&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;# Define unique experiment identifier&lt;/P&gt;&lt;P&gt;experiment_id = "cls_HGBT_0"&lt;/P&gt;&lt;P&gt;# Optional: Delete previous experiment logs (commented out)&lt;/P&gt;&lt;P&gt;# delete_experiment_log(connection_context, experiment_id)&lt;/P&gt;&lt;P&gt;# Initialize experiment tracking object&lt;/P&gt;&lt;P&gt;class_experiment = MLExperiments(&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; connection_context=connection_context,&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; experiment_id=experiment_id,&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; experiment_description="cls fit test HGBT"&lt;/P&gt;&lt;P&gt;)&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H4 id="toc-hId-1830062710"&gt;&lt;SPAN&gt;3. Autologging Configuration &lt;/SPAN&gt;&lt;/H4&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;# Enable automatic logging for model training&lt;/P&gt;&lt;P&gt;class_experiment.autologging(&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; uc,&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; run_name="diabetes_6",&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; dataset_name="diabetes_train",&lt;/P&gt;&lt;P&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; dataset_source="DIABETES_TBL"&lt;/P&gt;&lt;P&gt;)&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H4 id="toc-hId-1633549205"&gt;&lt;SPAN&gt;Key Features Demonstrated: &lt;/SPAN&gt;&lt;/H4&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;MLExperiments Class&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;: Central class for managing experiment metadata and tracking &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;Autologging&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;: Automatically captures: &lt;/SPAN&gt;&lt;OL&gt;&lt;LI&gt;&lt;SPAN&gt;Model parameters &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Dataset information &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Training metadata &lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;Experiment Organization&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;: &lt;/SPAN&gt;&lt;OL&gt;&lt;LI&gt;&lt;SPAN&gt;Unique experiment_id groups related runs &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Custom run_name identifies specific executions &lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;Dataset Tracking&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;: Explicit linkage between model runs and training data sources &lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;H4 id="toc-hId-1437035700"&gt;&lt;SPAN&gt;Reference Implementation Details &lt;/SPAN&gt;&lt;/H4&gt;&lt;P&gt;&lt;SPAN&gt;The underlying MLExperiments class provides these core functions: &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Method &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Purpose &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;autologging()&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Attach tracking metadata to models &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;get_current_tracking_id()&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Retrieve unique ID for the run &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;get_tracking_log_for_current_run()&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Fetch execution logs &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="184"&gt;&lt;P&gt;get_tracking_metadata_for_current_run()&lt;/P&gt;&lt;/TD&gt;&lt;TD width="184"&gt;&lt;P&gt;&lt;SPAN&gt;Retrieve metadata &lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H2 id="toc-hId-1827328209"&gt;&lt;SPAN&gt;7. Visualization and Monitoring &lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;SPAN&gt;The experiment monitor will display all tracked experiments and experiment runs, obtain the status of each run, and capture detailed internal information about each run. &lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1337411697"&gt;&lt;SPAN&gt;Monitor experiments &lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE width="70%"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="100%"&gt;&lt;P&gt;from hana_ml.visualizers.tracking import ExperimentMonitor&lt;/P&gt;&lt;P&gt;experiment_monitor = ExperimentMonitor(connection_context)&lt;/P&gt;&lt;P&gt;experiment_monitor.start()&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="4.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277538i1E88B6DA9C9F99D2/image-size/large?v=v2&amp;amp;px=999" role="button" title="4.png" alt="4.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="5.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277539i4A7AE62E424AF0A7/image-size/large?v=v2&amp;amp;px=999" role="button" title="5.png" alt="5.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1434301199"&gt;&lt;SPAN&gt;Conclusion &lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;SPAN&gt;MLTrack transforms SAP HANA Cloud into a fully traceable MLOps platform, providing: &lt;/SPAN&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;âœ…&lt;/span&gt;Reproducibility of any ML experiment &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;âœ…&lt;/span&gt;Comparability of model versions &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;âœ…&lt;/span&gt;Auditability for compliance requirements &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;âœ…&lt;/span&gt;Visualization of experiment history &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;âœ…&lt;/span&gt;Integration with existing PAL workflows &lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;SPAN&gt;By implementing MLTrack, organizations bridge the gap between experimental machine learning and production-grade MLOps, ensuring every model decision is traceable, explainable, and reproducible. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Related Articles:&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-features-in-sap-hana-cloud-2024-q3/ba-p/13874878" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-features-in-sap-hana-cloud-2024-q3/ba-p/13874878&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/artificial-intelligence-and-machine-learning-blogs/hands-on-tutorial-machine-learning-with-sap-hana-cloud/bc-p/14028202#M604" target="_blank"&gt;https://community.sap.com/t5/artificial-intelligence-and-machine-learning-blogs/hands-on-tutorial-machine-learning-with-sap-hana-cloud/bc-p/14028202#M604&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/model-storage-with-python-machine-learning-client-for-sap-hana/ba-p/13483099" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/model-storage-with-python-machine-learning-client-for-sap-hana/ba-p/13483099&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/hybrid-prediction-with-tabular-and-text-inputs-using-hybrid-gradient/ba-p/13927218" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/hybrid-prediction-with-tabular-and-text-inputs-using-hybrid-gradient/ba-p/13927218&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217"/>
    <published>2025-06-24T07:47:19.397000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/clustering-text-documents-using-constrained-clustering/ba-p/14134157</id>
    <title>Clustering text documents using constrained clustering</title>
    <updated>2025-06-24T09:49:35.514000+02:00</updated>
    <author>
      <name>zhengwang</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/893377</uri>
    </author>
    <content>&lt;P&gt;Clustering is a fundamental technique in data analysis and machine learning, widely used for identifying and grouping similar objects within a dataset based on inherent characteristics or patterns. It involves partitioning data points into distinct subsets known as clusters, where data points within the same cluster are more similar to each other than to those in other clusters. This unsupervised learning approach facilitates data exploration, pattern recognition, and information retrieval across various fields, from market segmentation to image analysis. However, traditional clustering methods operate without prior knowledge about the data, often leading to challenges in achieving meaningful or contextually relevant groupings. This limitation paves the way for constrained clustering, an advanced form of clustering that incorporates domain-specific constraints or prior information to guide the clustering process, ensuring more accurate and meaningful results tailored to specific analytical needs.&lt;/P&gt;&lt;P&gt;We are excited to announce the integration of a newly developed constrained clustering algorithm into &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/sap-hana-cloud-sap-hana-database-predictive-analysis-library-pal" target="_self" rel="noopener noreferrer"&gt;SAP HANA Predictive Analysis Library (PAL)&lt;/A&gt;. In this blog post, we will explore the fundamentals of constrained clustering and demonstrate its application in document clustering.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1604163429"&gt;Constrained clustering&lt;/H1&gt;&lt;P&gt;As data complexity increases, traditional clustering algorithms such as k-means and hierarchical clustering often fall short in capturing the intrinsic structure of the data. Deep clustering addresses these limitations by combining deep learning and clustering techniques to provide powerful representations and facilitate more accurate clustering. This approach serves as an excellent foundation for developing constrained clustering algorithms, which incorporate domain-specific constraints into the clustering process.&lt;/P&gt;&lt;P&gt;Deep Embedded Clustering (DEC) is a framework that leverages deep neural networks to learn low-dimensional representations of data, which are subsequently used for clustering. The key idea behind DEC is to use a deep autoencoder to obtain meaningful embeddings and then refine these embeddings through clustering-oriented learning. The components of DEC contains:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Autoencoder Architecture: An autoencoder is a type of neural network designed to learn efficient codings of input data. It consists of two parts: the encoder, which compresses the data, and the decoder, which reconstructs the data from the compressed representation. In DEC, the encoder is crucial for learning compact, informative representations that can be clustered effectively.&lt;/LI&gt;&lt;LI&gt;Clustering Layer: Once a suitable representation is obtained from the encoder, DEC introduces a clustering layer that refines these representations to better fit a clustering model.&lt;/LI&gt;&lt;LI&gt;Optimization Objective: The DEC framework focuses on minimizing the reconstruction loss of the autoencoder along with a clustering loss that aims to improve clustering accuracy.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Constrained clustering is an extension of traditional clustering paradigms that incorporates domain-specific knowledge into the clustering process through constraints. This approach is particularly beneficial in scenarios where certain data points are known to belong together or certain separations should be maintained. By building on the DEC framework, constrained clustering can effectively leverage deep representations while respecting additional constraints. To integrate constraints into DEC, important modifications include:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Defining Constraints: Constraints can be pairwise, such as must-link constraints (indicating that two data points should be clustered together) and cannot-link constraints (indicating that two data points should belong to different clusters). Constraints can also be triplet constraint by specifying relative similarity relationships among data points, where a given anchor point should be more similar to a designated positive point than to a negative point.&lt;/LI&gt;&lt;LI&gt;Modified Clustering Layer: In the DEC algorithm that accounts for constraints, the clustering layer can be extended to handle these constraints. This involves modifying the clustering loss to not only minimize the disparity within clusters but also satisfy the specified constraints.&lt;/LI&gt;&lt;LI&gt;Optimization with Constraints: The optimization objective of constrained clustering balances between the fidelity of data representation, clustering quality, and adherence to constraints. This involves sophisticated optimization techniques such as alternating optimization to balance these competing aspects effectively.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;In the following section, we will explore the application of constrained clustering in the context of document clustering.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1407649924"&gt;Example&lt;/H1&gt;&lt;P&gt;Document clustering is a crucial process in the realm of natural language processing (NLP) and information retrieval. It involves grouping text documents into clusters, where documents in the same cluster share similar topics or contents. This technique has vast applications in organizing, filtering, and searching information, thus enhancing user experience in navigating vast text archives. The dataset for applying document clustering is the 20 Newsgroups dataset.&lt;/P&gt;&lt;H2 id="toc-hId-1340219138"&gt;Dataset&lt;/H2&gt;&lt;P&gt;The 20 Newsgroups dataset is a benchmark dataset used extensively for text classification and clustering tasks. It comprises approximately 20,000 newsgroup documents, partitioned across 20 different newsgroups, each corresponding to a different topic. This dataset serves as a useful test bed for document clustering due to its diversity in topics and ease of accessibility. These topics range broadly from computer science themes such as "comp.graphics" to recreational or opinion-based themes like "rec.sport.baseball."&lt;/P&gt;&lt;P&gt;Before applying clustering algorithms, documents must be preprocessed to transform the text into a suitable format for analysis. This includes:&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;- Tokenization: Breaking down text into individual words or tokens.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;- Stopwords Removal: Excluding common words that do not contribute to topic differentiation (e.g., "the," "is," "and").&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;- Stemming/Lemmatization: Reducing words to their base or root form (e.g., "running" to "run").&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;- Vectorization: Converting text into numerical vectors using techniques like TF-IDF or &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-embedding" target="_self" rel="noopener noreferrer"&gt;embeddings&lt;/A&gt;. Interested readers can find more information on text embeddings in the topics linked at the bottom of the page.&lt;/P&gt;&lt;P&gt;Once the document data has been vectorized, we can proceed to prepare the constraints information. For 20 Newsgroups datasets that includes target information, we employ a straightforward strategy to automatically generate constraints.&lt;/P&gt;&lt;H2 id="toc-hId-1143705633"&gt;Pairwise constraints&lt;/H2&gt;&lt;P&gt;We randomly select pairs of instances to generate pairwise constraints. To ensure the constraints are transitive, we calculate the transitive closure for all instances that are must-linked. Subsequently, we derive additional constraints from the cannot-link constraints to maintain this property. The resulting constraints are entered into the constraints table. In this table, the first column specifies the type of constraint, with '1' representing a must-link and '-1' representing a cannot-link. The second and third columns contain the IDs of the instance pairs. Here is an example of a pairwise constraint table for illustration:&lt;/P&gt;&lt;TABLE border="1" width="100%"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="33.33333333333333%"&gt;CONSTRAINT_TYPE&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;ID1&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;ID2&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="33.33333333333333%"&gt;1&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;0&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;1&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="33.33333333333333%"&gt;-1&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;1&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;2&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="33.33333333333333%"&gt;-1&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;2&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;3&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H2 id="toc-hId-947192128"&gt;Triplet constraints&lt;/H2&gt;&lt;P&gt;Triplet constraints indicate that instance i is more similar to instance j than to instance k. To emulate human input on these triplet constraints, we randomly choose instances to serve as anchors (i). For each anchor, we then randomly select two instances (j and k) based on their similarity to the anchor. This similarity is determined by calculating the Euclidean distance between the preprocessed embeddings of the instances. The following is an example of generated triplet constraints specifying anchor, positive and nagetive instances:&lt;/P&gt;&lt;TABLE border="1" width="100%"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="33.333333333333336%"&gt;ANCHOR&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;POSITIVE&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;NAGETIVE&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="33.333333333333336%"&gt;1&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;2&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;3&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="33.333333333333336%"&gt;2&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;4&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;5&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="33.333333333333336%"&gt;3&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;6&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;7&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;Once the input data and constraints are prepared, using constrained clustering is as straightforward as employing any other algorithm in the PAL. Below is an annotated code example for your reference.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;--########## COLUMN TABLE CREATION ##########
CREATE LOCAL TEMPORARY COLUMN TABLE #PAL_PARAMETER_TBL ("PARAM_NAME" NVARCHAR (256), "INT_VALUE" INTEGER, "DOUBLE_VALUE" DOUBLE, "STRING_VALUE" NVARCHAR (1000));
CREATE COLUMN TABLE PAL_DCC_PREMODEL_TBL ("ROW_INDEX" INTEGER, "MODEL_CONTENT" NVARCHAR (5000));
CREATE COLUMN TABLE PAL_DCC_RESULT_TBL ("ID" INTEGER, "CLUSTER_ID" INTEGER, "CONFIDENCE" DOUBLE);
CREATE COLUMN TABLE PAL_DCC_MODEL_TBL ("ROW_INDEX" INTEGER, "MODEL_CONTENT" NVARCHAR (5000));
CREATE COLUMN TABLE PAL_DCC_LOG_TBL ("EPOCH" INTEGER, "BATCH" NVARCHAR (256), "VALUE" DOUBLE);
CREATE COLUMN TABLE PAL_DCC_STATISTICS_TBL ("STAT_NAME" NVARCHAR (256), "STAT_VALUE" NVARCHAR (1000), "STAT_VECTOR" REAL_VECTOR);

--########## TABLE INSERTS ##########
-- Assume the data is inserted in the PAL_DCC_DATA_TBL and the constraints are in the PAL_DCC_CONSTRAINTS_TBL table.

--########## PAL_PARAMETER_TBL DATA INSERTION ##########
-- mandatory, number of groups
INSERT INTO #PAL_PARAMETER_TBL VALUES ('GROUP_NUMBER', 4, NULL, NULL);
-- mandatory, type of constraints
INSERT INTO #PAL_PARAMETER_TBL VALUES ('CONSTRAINT_TYPE', 0, NULL, NULL);
-- hidden layer sizes of encoder
INSERT INTO #PAL_PARAMETER_TBL VALUES ('ENCODER_HIDDEN_DIMS', NULL, NULL, '50, 200');
-- dimension of latent space
INSERT INTO #PAL_PARAMETER_TBL VALUES ('EMBEDDING_DIM', 3, NULL, NULL);
-- whether to use normalization
INSERT INTO #PAL_PARAMETER_TBL VALUES ('NORMALIZATION', 1, NULL, NULL);
-- seed for random number generator
INSERT INTO #PAL_PARAMETER_TBL VALUES ('SEED', 1, NULL, NULL);
-- learning rate of pretraining
INSERT INTO #PAL_PARAMETER_TBL VALUES ('PRETRAIN_LEARNING_RATE', NULL, 0.01, NULL);
-- number of pretraining epochs
INSERT INTO #PAL_PARAMETER_TBL VALUES ('PRETRAIN_EPOCHS', 200, NULL, NULL);
-- number of training samples in a batch
INSERT INTO #PAL_PARAMETER_TBL VALUES ('PRETRAIN_BATCH_SIZE', 16, NULL, NULL);
-- ratio of total number of threads that can be used
INSERT INTO #PAL_PARAMETER_TBL VALUES ('THREAD_RATIO', NULL, 1.0, NULL);
-- degree of distorting latent space
INSERT INTO #PAL_PARAMETER_TBL VALUES ('GAMMA', NULL, 0.1, NULL);
-- pairwise, penalty for must-link constraints
INSERT INTO #PAL_PARAMETER_TBL VALUES ('ML_PENALTY', NULL, 0.1, NULL);
-- pairwise, penalty for cannot-link constraints
INSERT INTO #PAL_PARAMETER_TBL VALUES ('CL_PENALTY', NULL, 1.0, NULL);
-- triplet, margin in triplet loss
INSERT INTO #PAL_PARAMETER_TBL VALUES ('THETA', NULL, 0.1, NULL);
-- learning rate
INSERT INTO #PAL_PARAMETER_TBL VALUES ('LEARNING_RATE', NULL, 0.01, NULL);
-- maximum number of training epochs
INSERT INTO #PAL_PARAMETER_TBL VALUES ('MAX_EPOCHS', 100, NULL, NULL);
-- number of training samples in a batch
INSERT INTO #PAL_PARAMETER_TBL VALUES ('BATCH_SIZE', 16, NULL, NULL);
-- frequency of updating target distribution
INSERT INTO #PAL_PARAMETER_TBL VALUES ('UPDATE_INTERVAL', 1, NULL, NULL);
-- pairwise, number of must-link constraints in a batch
INSERT INTO #PAL_PARAMETER_TBL VALUES ('ML_BATCH_SIZE', 16, NULL, NULL);
-- pairwise, number of cannot-link constraints in a batch
INSERT INTO #PAL_PARAMETER_TBL VALUES ('CL_BATCH_SIZE', 16, NULL, NULL);
-- triplet, number of triplet constraints in a batch
INSERT INTO #PAL_PARAMETER_TBL VALUES ('TRIPLET_BATCH_SIZE', 16, NULL, NULL);
-- pairwise, frequency of training with must-link constraints
INSERT INTO #PAL_PARAMETER_TBL VALUES ('ML_UPDATE_INTERVAL', 1, NULL, NULL);
-- pairwise, frequency of training with cannot-link constraints
INSERT INTO #PAL_PARAMETER_TBL VALUES ('CL_UPDATE_INTERVAL', 1, NULL, NULL);
-- triplet, frequency of training with triplet constraints
INSERT INTO #PAL_PARAMETER_TBL VALUES ('TRIPTLET_UPDATE_INTERVAL', 1, NULL, NULL);
-- stopping threshold
INSERT INTO #PAL_PARAMETER_TBL VALUES ('TOLERANCE', NULL, 0.01, NULL);
-- verbosity of log
INSERT INTO #PAL_PARAMETER_TBL VALUES ('VERBOSE', 0, NULL, NULL);

--########## PAL_PIPELINE_EXPLAIN FOR TIME SERIES CALL ##########
DO BEGIN
    lt_data = SELECT * FROM PAL_DCC_DATA_TBL;
    lt_constraints = SELECT * FROM PAL_DCC_CONSTRAINTS_TBL;
    lt_param = SELECT * FROM #PAL_PARAMETER_TBL;
    lt_premodel = SELECT * FROM PAL_DCC_PREMODEL_TBL;
    CALL _SYS_AFL.PAL_CONSTRAINED_CLUSTERING(:lt_data, :lt_constraints, :lt_param, :lt_premodel, lt_result, lt_model, lt_log, lt_statistics);
    INSERT INTO PAL_DCC_RESULT_TBL SELECT * FROM :lt_result;
    INSERT INTO PAL_DCC_MODEL_TBL SELECT * FROM :lt_model;
    INSERT INTO PAL_DCC_LOG_TBL SELECT * FROM :lt_log;
    INSERT INTO PAL_DCC_STATISTICS_TBL SELECT * FROM :lt_statistics;
END;

--########## SELECT * TABLES ##########
SELECT * FROM PAL_DCC_RESULT_TBL;
SELECT * FROM PAL_DCC_MODEL_TBL;
SELECT * FROM PAL_DCC_LOG_TBL;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;You can view the clustering results, model, and training log in the output tables. Below are illustrative snapshots of the output tables.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Constrained_Clustering_Result_1.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277498i9510105082DE9845/image-size/large?v=v2&amp;amp;px=999" role="button" title="Constrained_Clustering_Result_1.png" alt="Constrained_Clustering_Result_1.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The result table presents the assigned cluster ID for each instance and includes a third column that indicates the soft label or probabilities.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Constrained_Clustering_Result_2.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277500i82E93A1B56D768C8/image-size/large?v=v2&amp;amp;px=999" role="button" title="Constrained_Clustering_Result_2.png" alt="Constrained_Clustering_Result_2.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The model table documents crucial training information and the weights for the trained neural networks.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Constrained_Clustering_Result_3.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/277501i11D381250D19B38D/image-size/large?v=v2&amp;amp;px=999" role="button" title="Constrained_Clustering_Result_3.png" alt="Constrained_Clustering_Result_3.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The entire training process can be monitored through the log table, which contains loss values for each training iteration. Additionally, the verbosity of the log can be adjusted using the VERBOSE parameter.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-621595904"&gt;Summary&lt;/H1&gt;&lt;P&gt;Deep clustering provides a robust framework that pushes the boundaries of unsupervised learning through the integration of deep learning. By extending DEC to incorporate constraints, we show a variant that combines the strengths of deep representations with domain-specific knowledge, enhancing clustering applicability in complex real-world problems.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Recent topics on HANA machine learning:&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/hybrid-prediction-with-tabular-and-text-inputs-using-hybrid-gradient/ba-p/13927218" target="_self"&gt;Hybrid Prediction with Tabular and Text Inputs using Hybrid Gradient Boosting Trees&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/dimensionality-reduction-of-text-embeddings-for-hybrid-prediction-data/ba-p/14025126" target="_self"&gt;Dimensionality Reduction of Text Embeddings for Hybrid Prediction Data&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/text-embedding-service-in-sap-hana-cloud-predictive-analysis-library-pal/ba-p/14025121" target="_self"&gt;Text Embedding Service in SAP HANA Cloud Predictive Analysis Library (PAL)&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/document-clustering-using-kmeans-and-text-embeddings/ba-p/14025111" target="_self"&gt;Document Clustering using KMeans and Text Embeddings&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-text-analysis-in-sap-hana-cloud-predictive-analysis-library-pal/ba-p/14025117" target="_self"&gt;New Text Analysis in SAP HANA Cloud Predictive Analysis Library (PAL)&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-information-retrieval-techniques-in-sap-hana-cloud-using-bm25-and-anns/ba-p/13958729" target="_self"&gt;New Information Retrieval Techniques in SAP HANA Cloud using BM25 and ANNS for Advanced Text Mining&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/text-chunking-an-exciting-new-nlp-function-in-sap-hana-cloud/ba-p/13958766" target="_self"&gt;Text Chunking â€“ An Exciting New NLP Function in SAP HANA Cloud&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/exploring-ml-explainability-in-sap-hana-pal-automl/ba-p/13958883" target="_self"&gt;Exploring ML Explainability in SAP HANA PAL - AutoML&lt;/A&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/clustering-text-documents-using-constrained-clustering/ba-p/14134157"/>
    <published>2025-06-24T09:49:35.514000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/the-rise-of-intelligent-tax-how-ai-is-transforming-tax-operations-and/ba-p/14135774</id>
    <title>The Rise of Intelligent Tax: How AI is Transforming Tax Operations and Compliance</title>
    <updated>2025-06-24T15:40:52.524000+02:00</updated>
    <author>
      <name>Avnish_Goyal</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/775580</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;Artificial Intelligence (AI)&lt;/STRONG&gt; has moved beyond the realm of science fiction and is now actively shaping our everyday lives. Whether itâ€™s recommending what we buy online, helping self-driving cars avoid traffic, or identifying fraud in banking, AI is making industries work faster, smarter, and more efficiently. At its foundation, AI allows machines to analyze data, learn from it, and make decisions. AI is automating tasks that previously relied heavily on human effort.&lt;/P&gt;&lt;P&gt;Even the complex and cautious world of taxation is undergoing a digital transformation, thanks to AI. Tax functions within organizations have traditionally faced challenges like overwhelming regulations, repetitive processes, and frequent legislative updates. Today, AI is helping these teams simplify workflows, boost compliance, minimize errors, and generate insights quickly and accurately.&lt;/P&gt;&lt;P&gt;Here are a few practical ways AI is being used in the tax domain:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Automating routine processes:&lt;/STRONG&gt; AI handles time-consuming tasks such as invoice matching, tax code validation, exemption certificate tracking, and return preparation, freeing tax professionals to focus on more strategic work.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Intelligent tax classification:&lt;/STRONG&gt; AI tools accurately categorize goods and services into the right tax brackets, which enhances compliance and reduces costly mistakes.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Finding tax credits&lt;/STRONG&gt;: Businesses can uncover overlooked opportunities like VAT reclaims or R&amp;amp;D credits through AI-powered data analysis.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Ensuring real-time compliance:&lt;/STRONG&gt; AI continuously monitors transactions and flags non-compliance, helping companies stay up to date with evolving tax laws across regions.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Practical implementations are already happening. For instance, SAP Concur, in collaboration with AI companies like Bluedot, uses machine learning to automate VAT recovery on business travel expenses, a task that used to be manual and error-prone. Similarly, platforms like Vertex and Thomson Reuters OneSource are leveraging AI to apply tax rules accurately, organize tax data, categorize products and GL accounts, manage certificates, and maintain global tax compliance effortlessly.&lt;/P&gt;&lt;P&gt;Governments are also embracing AI to enhance public tax services and enforcement efforts:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;AI-powered chatbots&lt;/STRONG&gt; are helping taxpayers complete returns, get guidance, and understand forms in multiple languages.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Fraud detection&lt;/STRONG&gt; tools powered by AI can analyze behavioral patterns and catch irregularities in filings that might signal tax evasion, something human auditors could miss.&lt;/LI&gt;&lt;LI&gt;Countries including Singapore, South Korea, France, and the UK are already using AI in areas like &lt;STRONG&gt;document processing, risk assessment, and taxpayer support&lt;/STRONG&gt;.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;However, integrating AI into tax operations does come with challenges:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Data security:&lt;/STRONG&gt; Since tax data is highly sensitive, AI systems must meet strict privacy standards.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Bias and fairnes&lt;/STRONG&gt;s: AI decisions are only as good as the data theyâ€™re trained on. Flawed or biased inputs can lead to inaccurate results.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Lack of transparency:&lt;/STRONG&gt; Some AI systems work in a â€œblack boxâ€ manner, making decisions without easily explainable logic, which raises accountability concerns.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Skills gap:&lt;/STRONG&gt; As AI becomes a core part of tax operations, tax professionals need upskilling in technology and data to make the most of these tools.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Despite these challenges, the benefits of AI in tax are substantial. Itâ€™s not just about doing the same work faster. Itâ€™s about transforming how tax functions operate and contribute to business success. With AI, tax teams can:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Produce insights faster to support better decision-making&lt;/LI&gt;&lt;LI&gt;Monitor tax compliance globally in real time&lt;/LI&gt;&lt;LI&gt;Cut operational costs while improving accuracy&lt;/LI&gt;&lt;LI&gt;Align tax strategies with broader goals like ESG compliance and digital transformation&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;And this is just the start. As AI continues to evolve especially when paired with innovations like quantum computing and blockchain, we can expect even more advanced solutions that revolutionize tax management and governance.&lt;/P&gt;&lt;P&gt;For a deeper dive into this topic, I invite you to read my detailed paper:&lt;/P&gt;&lt;P&gt;â€œThe Impact of Artificial Intelligence on Taxation: The Role of AI and Key Use Casesâ€. This research paper explores the evolution of AI in taxation, practical examples, benefits, and key risks. It's free to read and download and is a great resource for anyone interested in the future of tax.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;ğŸ”—&lt;/span&gt; &lt;A href="https://www.researchgate.net/publication/391997676_The_Impact_of_Artificial_Intelligence_on_Taxation_The_Role_of_AI_and_Key_Use_Cases" target="_blank" rel="nofollow noopener noreferrer"&gt;Click here to access the full paper&lt;/A&gt;&lt;/P&gt;&lt;P&gt;In conclusion, AI is no longer a "nice to have" in the world of taxâ€”itâ€™s becoming essential. For organizations and tax professionals ready to adapt, AI opens the door to smarter, faster, and more agile tax functions. The future of tax is not just digital, itâ€™s intelligent.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/the-rise-of-intelligent-tax-how-ai-is-transforming-tax-operations-and/ba-p/14135774"/>
    <published>2025-06-24T15:40:52.524000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-and-ai-features-in-sap-hana-cloud-2025-q2/ba-p/14136079</id>
    <title>New Machine Learning and AI features in SAP HANA Cloud 2025 Q2</title>
    <updated>2025-06-24T21:40:03.946000+02:00</updated>
    <author>
      <name>ChristophMorgen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14106</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;With the &lt;STRONG&gt;SAP HANA Cloud 2025 Q2 release&lt;/STRONG&gt;, several &lt;STRONG&gt;new embedded Machine Learning / AI functions&lt;/STRONG&gt;&amp;nbsp;have been released with the SAP HANA Cloud Predictive Analysis Library (PAL) and the Automated Predictive Library (APL). &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Key new capabilities to be highlighted include &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;A &lt;STRONG&gt;new text embedding model version&lt;/STRONG&gt;, covering more languages and short-text embedding scenarios,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;more &lt;STRONG&gt;tabular AI functions&lt;/STRONG&gt; enhanced to support&amp;nbsp;&lt;STRONG&gt;vector data processing&lt;/STRONG&gt; like &lt;STRONG&gt;AutoML&lt;/STRONG&gt;, &lt;STRONG&gt;k-nearest neighbors&lt;/STRONG&gt; (k-NN),&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;outlier detection using &lt;STRONG&gt;isolation forest&lt;/STRONG&gt; supporting &lt;STRONG&gt;outlier explainability &lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;machine learning &lt;STRONG&gt;experiment tracking&lt;/STRONG&gt; and &lt;STRONG&gt;task scheduling&lt;/STRONG&gt; capabilities&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;STRONG&gt;data drift analysis&lt;/STRONG&gt; using the &lt;STRONG&gt;Automated Predictive Library&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;An enhancement summary is available in the Whatâ€™s new document for &lt;A href="https://help.sap.com/whats-new/2495b34492334456a49084831c2bea4e?Category=Predictive+Analysis+Library&amp;amp;Valid_as_Of=2025-06-01:2025-06-30&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP HANA Cloud database 2025.14 (QRC 2/2025)&lt;/A&gt;.&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1733304833"&gt;&lt;SPAN&gt;Text processing, text embedding and vector processing using ML functions&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text tokenization&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-tokenize" target="_blank" rel="noopener noreferrer"&gt;text tokenization &lt;/A&gt;function has been released, allowing to &lt;STRONG&gt;split text into tokens&lt;/STRONG&gt;, a fundamental preparation step in natural language processing (NLP) like text analysis, and many other downstream text processing tasks like text embedding or vector similarity search. The new function support key tokenization capabilities like&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;removal of common stopwords (e.g., "the", "and", "is").&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;filtering out purely numeric and alphanumeric tokens&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;specifications of characters or symbols that should always be kept or removed &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;controls for stemming, language detection.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_0-1750792982539.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/278450iC65F3B44B14FB758/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_0-1750792982539.png" alt="ChristophMorgen_0-1750792982539.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text embedding &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new &lt;STRONG&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/no-content-for-file-textembedding-md?" target="_blank" rel="noopener noreferrer"&gt;text embedding&lt;/A&gt;&lt;/STRONG&gt; model version (&lt;/SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-embedding-model?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP_GXY.20250407&lt;/A&gt;&lt;SPAN&gt;) is made available, which has been fine-tuned based on a roberta-base-encoder model and more training data for improved retrieval accuracy, short text scenarios and extend multi-lingual &amp;amp; cross-lingual retrieval scenarios. New additional languages supported include Chinese (CH), Japanese (JP) and Italian (IT). The default token length for embedding functions has been increase to 512.&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Extended embedding vector processing by Machine Learning functions&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Unlocking the semantic understanding of your text data stored in SAP HANA Cloud, for use cases like similarity search, however moreover for machine learning scenarios like &amp;nbsp;document/text- classification and â€“clustering, and more has now been extended to even more PAL Machine Learning functions&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;K-nearest neighbor models (&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/knn-knn-f2440c6" target="_blank" rel="noopener noreferrer"&gt;K-NN&lt;/A&gt;) for classification/regression/similarity search&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/random-decision-trees-random-decision-trees-9ad576a" target="_blank" rel="noopener noreferrer"&gt;Random Decision Trees&lt;/A&gt;&lt;/SPAN&gt; &lt;SPAN&gt;for classification/regression models &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/automl-automl?" target="_blank" rel="noopener noreferrer"&gt;AutoML&lt;/A&gt; &lt;/SPAN&gt;scenarios for classification, regression and times series&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;including the fit, prediction, scoring, and pipeline procedures&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;support with all pipeline operators (algorithms), except for the Imputer and&lt;BR /&gt;&amp;nbsp;ImputeTS-operators&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_1-1750792982549.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/278449iA91EDCE14A4D9CEF/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_1-1750792982549.png" alt="ChristophMorgen_1-1750792982549.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1536791328"&gt;&lt;SPAN&gt;Machine Learning function enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Outlier detection enhancements using Isolation Forests&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The &lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/isolation-forest-isolation-forest-11345d9" target="_blank" rel="noopener noreferrer"&gt;Isolation Forest &lt;/A&gt;&amp;nbsp;function for &lt;STRONG&gt;outlier detection&lt;/STRONG&gt; has been enhanced with &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;support categorial columns as features in outlier models&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;a new massive outlier detection function for parallel analysis of multiple data subsets&lt;BR /&gt;(PAL_MASSIVE_ISOLATION_FOREST)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;a new outlier explanation method based on Shapley values (PAL_ISOLATION_FOREST_EXPLAIN)&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;providing local explanations for the predicted outlier classification,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;describing the contribution of each feature to the predicted classification,&lt;BR /&gt;based on a Tree-SHAP explainer model,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;options to configure the explanation function by setting contamination level (proportion of outliers), scope (explanations for outliers only or all predictions), top K contributions (set k number of features in explanations)&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&lt;EM&gt;Isolation Forest&lt;/EM&gt; is a strong and &lt;EM&gt;trending function for outlier detection&lt;/EM&gt;, which can be applied on any data for outlier analysis inside the database, hence especially suitable also for use cases where data shall not leave the system or is too big to be copied out for analysis like use cases for &lt;STRONG&gt;detecting outliers on your financial accounting&lt;/STRONG&gt;, like the &lt;STRONG&gt;universal journal data&lt;/STRONG&gt; (ACDOCA).&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_2-1750792982556.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/278448i1C259DFB5755E343/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_2-1750792982556.png" alt="ChristophMorgen_2-1750792982556.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Constraint Clustering&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/constrained-clustering" target="_blank" rel="noopener noreferrer"&gt;constraint clustering &lt;/A&gt;function is introduced, an advanced form of clustering that &lt;STRONG&gt;incorporates domain-specific constraints or prior information&lt;/STRONG&gt; to &lt;EM&gt;guide the clustering process&lt;/EM&gt;, ensuring more accurate and meaningful results tailored to specific analytical needs. Traditional clustering methods are mostly limited and cannot include prior knowledge about the data, often leading to challenges in achieving meaningful or contextually relevant groupings. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Prior contexts can be included in the clustering process as &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Pairwise constraints: Must-link / Must-Not-link constraints of data points to be / not in the same cluster&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Triplet Constraints: With an anchor instance (a), a positive instance (p), and a negative instance (n), the constraint shows that instance a is more similar to p than to n.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;A detailed introduction to the new function is given in the following blog post &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/clustering-text-documents-using-constrained-clustering/ba-p/14134157" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/clustering-text-documents-using-constrained-clustering/ba-p/14134157&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Further enhanced machine learning algorithms for Tabular AI scenarios&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The recently implemented &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/multi-task-multilayer-perceptron?" target="_blank" rel="noopener noreferrer"&gt;Multi-task MLP&lt;/A&gt; (&lt;STRONG&gt;multi-layer perceptron&lt;/STRONG&gt;) &lt;STRONG&gt;neural network&lt;/STRONG&gt; function, unlocking predictions for &lt;STRONG&gt;multiple targets / labels using a single model&lt;/STRONG&gt;, has now been enhanced with an improved built-in &lt;STRONG&gt;model evaluation and parameter search&lt;/STRONG&gt; interface, providing faster approach and productivity to achieve even better prediction outcomes.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The new optimization can be leveraged by calling the function directly or via its use within the Unified Classification/Regression functions and supports to search and select the following optimal neural network model parameter values&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;LEARNING_RATE, EMBEDDED_NUM, RESIDUAL_NUM, DROPOUT_PROB, HIDDEN_LAYER_SIZE, HIDDEN_LAYER_ACTIVE_FUNC, OPTIMIZER&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;In the domain of &lt;STRONG&gt;time series analysis and forecasting,&lt;/STRONG&gt; the &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/arima-arima-dbd52a1" target="_blank" rel="noopener noreferrer"&gt;ARIMA&lt;/A&gt; forecasting function now supports to keep context of the time horizon index and interval&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Trained ARIMA model keeps track of the final time index value and the determined index interval&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Subsequently,&amp;nbsp;ARIMA_PREDICT&amp;nbsp;will use this information to output forecast values with a continuous index&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1340277823"&gt;&lt;SPAN&gt;Machine Learning experiment tracking and task scheduling&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Experiment tracking and monitoring for PAL ML models&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Machine learning &lt;STRONG&gt;experimentation&lt;/STRONG&gt; requires robust &lt;STRONG&gt;tracking capabilities&lt;/STRONG&gt; to ensure reproducibility, comparison, and auditability of models. SAP HANA Cloud's new &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/pal-track?q=PAL_REMOVE_MLTRACK_LOG&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;ML tracking&lt;/A&gt; feature provides seamless integration with Predictive Analysis Library (PAL) procedures, enabling &lt;STRONG&gt;automatic logging of critical experiment artifacts&lt;/STRONG&gt;. This end-to-end tracking solution captures &lt;EM&gt;parameters, datasets, models, metrics, and visualizations&lt;/EM&gt; in a structured way, transforming how data scientists manage ML workflows.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The new execution &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/pal-track?q=PAL_REMOVE_MLTRACK_LOG&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;tracking of PAL &lt;/A&gt;procedure supports&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;use with al Unified Regression/Classification-, Pipeline-fit/score procedures&amp;nbsp;(with new interfaces suffix&amp;nbsp; â€œ_TRACKâ€ suffix)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;tracking of content including: Parameters, Dataset Metadata, Model Signature, Metrics(including Variable Importance), Figures(discrete and continuous), etc.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;management of tracking data in a built-in schema PAL_ML_TRACK and tables for metadata, log and header information&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;procedure parameters activate the tracking like LOG_ML_TRACK, TRACK_ID, etc.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;A more detailed introduction is provided in the following blog post &lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Task scheduling for PAL procedures&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new PAL &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/calling-pal-with-schedule?q=PAL_REMOVE_MLTRACK_LOG&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;task scheduling&lt;/A&gt; &lt;/SPAN&gt;allows you to run SQLScript procedures (calling PAL procedures) by the SAP HANA Cloud schedular asynchronously (&lt;SPAN&gt;cron-based).&lt;/SPAN&gt; The targeted SQLScript (PAL) procedure calls get mapped to a define task with task ID, task descriptions, owner, etc. A task can be scheduled to executed, a job is the instance of scheduled task.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;The built-in schema PAL_SCHEDULED_EXECUTION provides tables for storage of task definition/metadata, relationships, procedures parameters, TASK_SCHEDULE_JOB, task (operation) log&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;The actual job execution information is provided within the System views SCHEDULE_JOBS, M_SCHEDULE_JOBS&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;New PAL procedures are provided for task creation (AFLPAL_CREATE_TASK_PROC)&lt;BR /&gt;and removal, scheduled job creation for a task (AFLPAL_CREATE_TASK_SCHEDULE_PROC), altering, pausing, resuming and removing task jobs&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The python ML client adds additional interfaces and methods to leverage the new capabilities easily by experts developing HANA ML scenarios.&lt;/P&gt;&lt;H2 id="toc-hId-1143764318"&gt;&lt;SPAN&gt;Data Drift detector with the Automated Predictive Library (APL)&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;The new data drift detector in the APL helps you spot changes or deviations between a given dataset and a reference. Reference data could be a version in the past, or a particular segment of customers or employees, or an expected distribution (e.g. Benford). Use cases of data comparison are:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;This year employee survey results versus last year results by country&lt;/LI&gt;&lt;LI&gt;Machine learning inference dataset versus training dataset&lt;/LI&gt;&lt;LI&gt;Male staff versus female staff&lt;/LI&gt;&lt;LI&gt;Payment amounts by legal entity versus the Benfordâ€™s law to find potential fraud&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This feature from APL (Automated Predictive Library) is available for both Python and SQL. For more details see blog post on the&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/hana-ml-data-drift-detector/ba-p/14148518" target="_blank"&gt;HANA ML Data Drift Detector&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_0-1752234591748.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/285456i75A1F6A79758D3C3/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_0-1752234591748.png" alt="ChristophMorgen_0-1752234591748.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-947250813"&gt;&lt;SPAN&gt;Python ML client (hana-ml) enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;EM&gt;The full list of new methods and enhancements with hana_ml 2.25&amp;nbsp; is summarized in the &lt;/EM&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/doc/cd94b08fe2e041c2ba778374572ddba9/2025_2_QRC/en-US/change_log.html" target="_blank" rel="noopener noreferrer"&gt;&lt;EM&gt;changelog for hana-ml 2.25&lt;/EM&gt;&lt;/A&gt; &lt;/SPAN&gt;&lt;EM&gt;as part of the documentation. The key enhancements in this release include&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text and vector processing enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;New embedding model version SAP_GXY.20250407&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Classification / regression function enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Use of Multi-task MLP with UnifiedClassification | Regression&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;Benefit from unified interface capabilities like score-function, resampling/parameter search and optimization, model-report, â€¦&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;HGBT regressor with Linear Tree trend extrapolation&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;AutoML and pipeline modeling improvements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Faster random search with hyperband optimization support&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Progress monitor enhancements for fine-tuning and random search &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;HANA ML experiment tracking and task schedule execution&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Experiment tracking and experiment monitor UI (&lt;/SPAN&gt;detailed introduction is provided in the referenced &lt;A title="comprehensive-guide-to-mltrack-in-sap-hana-cloud" href="https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217" target="_self"&gt;blog post&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Enhanced PAL task schedule and job schedule execution UI&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;You can find an examples notebook illustrating the highlighted feature enhancements &lt;SPAN&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/pal/notebooks/25QRC02_2.25.ipynb" target="_blank" rel="noopener nofollow noreferrer"&gt;here 25QRC02_2.25.ipynb&lt;/A&gt;.&amp;nbsp; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-and-ai-features-in-sap-hana-cloud-2025-q2/ba-p/14136079"/>
    <published>2025-06-24T21:40:03.946000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/the-ai-adoption-journey-detour-into-o-net-codes/ba-p/14142036</id>
    <title>The AI Adoption Journey- Detour into O*NET Codes</title>
    <updated>2025-07-01T23:17:47.598000+02:00</updated>
    <author>
      <name>Amreen_Honeycutt</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1836792</uri>
    </author>
    <content>&lt;P&gt;Hello everyone!&lt;BR /&gt;&lt;BR /&gt;I am sure I am not alone in having read the release notes about Machine Learning and FG Base AI features, coming across the â€œ&lt;EM&gt;Recommend O*NET Code for Job Classification&lt;/EM&gt;â€ and furrowed my brow.&lt;BR /&gt;Like many of you, Iâ€™m sure, you may have brushed it off as a common enough use case for some customers to need it, or maybe even accepting that it may be industry specific.&lt;BR /&gt;But my curiosity got the better of me- so this week I will be taking you through a little detour journey to understand what O*NET codes are, why theyâ€™re Important, and how Fieldglass uses them with our existing machine learning capabilities!&lt;BR /&gt;&lt;BR /&gt;&lt;BR /&gt;So- &lt;STRONG&gt;What are O*NET codes&lt;/STRONG&gt;? A quick search tells me that they are part of something called an &lt;U&gt;O*NET system&lt;/U&gt;, and they are used to classify and provide descriptions for various occupations.&lt;BR /&gt;That makes sense, but what why would that be important to me? In workforce management, a connector to this platform can play a significant part in helping a business match job titles in their company or industry with more broad occupational information.&lt;BR /&gt;T&lt;U&gt;he O*NET Resource Center is actually a database developed by the U.S Department of Labor&lt;/U&gt;- this means that the titles and codes that are in this database, can function as a standardized measure to help widen the range a business can cover when acquiring or cultivating a pool of talent!&lt;BR /&gt;&lt;BR /&gt;Join me as we discover more about how FG can use AI to leverage this database, and how FG customers can best benefit from it!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/the-ai-adoption-journey-detour-into-o-net-codes/ba-p/14142036"/>
    <published>2025-07-01T23:17:47.598000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/hana-ml-data-drift-detector/ba-p/14148518</id>
    <title>HANA ML Data Drift Detector</title>
    <updated>2025-07-10T17:08:13.870000+02:00</updated>
    <author>
      <name>marc_daniau</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/187920</uri>
    </author>
    <content>&lt;P&gt;The release of HANA ML 2.23 includes a new function called: APL data drift detector. This drift detector helps you spot changes or deviations between a given dataset and a reference. Reference data could be a version in the past, or a particular segment of customers or employees, or an expected distribution (e.g. Benford). Use cases of data comparison are:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;This year employee survey results versus last year results by country&lt;/LI&gt;&lt;LI&gt;Machine learning inference dataset versus training dataset&lt;/LI&gt;&lt;LI&gt;Male staff versus female staff&lt;/LI&gt;&lt;LI&gt;Payment amounts by legal entity versus the Benfordâ€™s law to find potential fraud&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This feature from APL (Automated Predictive Library) is available for both Python and SQL.&lt;/P&gt;&lt;P&gt;The rest of this blog will walk you through a scenario with code snippets in Python as well as SQL that you can reuse and adapt to your own case.&lt;/P&gt;&lt;P&gt;We chose to work with Olympics athletes and results data. The dataset contains summer and winter games since 1896. We want to make a comparison over time.&lt;/P&gt;&lt;P&gt;First, we connect to the SAP HANA database using a Python notebook.&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;DB_Host='host'  
DB_Port='port_number'
DB_User='user_name'
DB_Password='user_password'

from hana_ml import dataframe as hd
conn = hd.ConnectionContext(address = DB_Host, port = DB_Port, 
                            user = DB_User, password = DB_Password, 
                            encrypt = 'true', sslValidateCertificate = 'false' )
conn.connection.isconnected()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The reference dataframe comprises the Olympic games before 1970 â€¦&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport" 
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;lt;= 1970  
order by "Id"
"""
hdf_ref= hd.DataFrame(conn, sql_cmd)
hdf_ref.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_Ref.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284591i95E55218053F1DBE/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_Ref.png" alt="Data_Ref.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-left" style="text-align : left;"&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;â€¦ and the comparison dataframe, after 1970:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport"
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;gt; 1970 
order by "Id"
"""
hdf_new= hd.DataFrame(conn, sql_cmd)
hdf_new.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_New.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284593i5A0C2A7E6A164C02/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_New.png" alt="Data_New.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The code to run the comparison is the following:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;from hana_ml.algorithms.apl.drift_detector import DriftDetector
apl_model = DriftDetector()
results = apl_model.fit_detect(hdf_ref, hdf_new, build_report=True)
print(results.collect())&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Deviation_Over_time.png" style="width: 200px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284595iD85393F245D82537/image-size/small?v=v2&amp;amp;px=200" role="button" title="Deviation_Over_time.png" alt="Deviation_Over_time.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;All the variables appearing here have a deviation indicator over 0.95. This threshold can be changed with the syntax below:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;results = apl_model.fit_detect(hdf_ref, hdf_new, threshold=0.80)&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Here is a report putting the two datasets side by side with their counts (aka weight) by category; the most changing categories (top 10 here) appear first:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;df = apl_model.get_debrief_report('Deviation_CategoryFrequencies').head(10).deselect(['Oid','Category Order']).collect()
format_dict = {
    'Ref Weight': '{:,.0f}', 'New Weight': '{:,.0f}', 'Change': '{:,.0f}', 
    'Ref % Weight': '{:.1f}', 'New % Weight': '{:.1f}', '% Change': '{:.1f}', 'Abs % Change': '{:.1f}'
}
df.style.format(format_dict).hide(axis='index')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Top_Changing.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284599iAD21273F45BCE584/image-size/large?v=v2&amp;amp;px=999" role="button" title="Top_Changing.png" alt="Top_Changing.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;KxMissing is a special category created by APL when finding empty or null values. With far less missing values on athletesâ€™ height and weight, we see that data quality is getting better overtime.&lt;/P&gt;&lt;P&gt;More women are participating to the Olympic games after 1970. The male % change value mirrors the female % change value. The same remark applies to summer and winter seasons.&lt;/P&gt;&lt;P&gt;The following code brings the data drift results as charts:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;apl_model.generate_notebook_iframe_report()
# apl_model.generate_html_report('drift_olympics')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="HTML_Report.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284610i88BD0F5CB087BFE5/image-size/large?v=v2&amp;amp;px=999" role="button" title="HTML_Report.png" alt="HTML_Report.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;After comparing athletes across all types of sports, letâ€™s compare them by sport. For that we must provide the drift detector with two dataframes sorted by Sport:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;## Reference Dataset
sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport" 
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;lt;= 1970  
order by "Sport", "Id"
"""
hdf_ref= hd.DataFrame(conn, sql_cmd)
hdf_ref.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_Ref-By_Sport.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284614i904817BDECD46EDB/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_Ref-By_Sport.png" alt="Data_Ref-By_Sport.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;## Dataset for comparison
sql_cmd =  """ 
select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport" 
from "APL_SAMPLES"."OLYMPICS" 
where "Year" &amp;gt; 1970  
order by "Sport", "Id"
"""
hdf_new= hd.DataFrame(conn, sql_cmd)
hdf_new.head(5).collect()&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data_New-By_Sport.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284615iA1B4FC007FBA9463/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Data_New-By_Sport.png" alt="Data_New-By_Sport.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;You specify the segment for drift detection the same way as for segmented forecasting, regression or classification scenarios:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;col_segment= 'Sport'    
from hana_ml.algorithms.apl.drift_detector import DriftDetector
apl_model = DriftDetector(segment_column_name= col_segment, max_tasks= 4)
results = apl_model.fit_detect(hdf_ref, hdf_new, threshold=0.95)
print(results.sort(["Segment","Variable"]).collect())&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The deviating variables appear for each sport:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Deviation_Over_time-By_Sport.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284619iEDD5AE5373CE1C3B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Deviation_Over_time-By_Sport.png" alt="Deviation_Over_time-By_Sport.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;We check if there are segments with status â€˜Failedâ€™:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;my_filter = "KEY in ('AplTaskStatus') and VALUE ='Failed'"
df = apl_model.get_summary().filter(my_filter).select('OID').collect()
failed_segments = df['OID'].tolist()
print('Preview of failed segments')
print(failed_segments[:5])&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Failed_Segments.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284621iAC4A5C8B2A51FC6B/image-size/large?v=v2&amp;amp;px=999" role="button" title="Failed_Segments.png" alt="Failed_Segments.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The log contains the cause of failure:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;df = apl_model.get_fit_operation_log().filter("LEVEL = 0").select('OID','ORIGIN','MESSAGE').head(5).collect()
df.columns = [col_segment, 'Cause', 'Error']
df.style.hide(axis='index')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Cause_Of_Failure.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/284622iAC753A3C7B57F4AE/image-size/large?v=v2&amp;amp;px=999" role="button" title="Cause_Of_Failure.png" alt="Cause_Of_Failure.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;These sports were introduced after 1970. Thus, there is no reference data to compare against.&lt;/P&gt;&lt;P&gt;To obtain the Data Drift report, you must provide a segment value as in the example below:&lt;/P&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;seg_value = "Swimming"
apl_model.build_report(segment_name=seg_value)
apl_model.generate_notebook_iframe_report()
#apl_model.generate_html_report('Sport_Report')&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;We are nearing the end of this post, and you have not yet seen how to run a comparison with the SQL interface. Here is the syntax for calling the new APL function COMPARE_DATA from a SQL script:&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;drop view DATASET_1;
create view DATASET_1 as (
 select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport"
 from "APL_SAMPLES"."OLYMPICS" 
 where "Year" &amp;lt;= 1970  
 order by "Sport", "Id"
);

drop view DATASET_2;
create view DATASET_2 as (
 select "Height", "Weight", "Age", "Medal", "Gender", "Season", "Country", "Sport"
 from "APL_SAMPLES"."OLYMPICS" 
 where "Year" &amp;gt; 1970  
 order by "Sport", "Id"
);

DO BEGIN
    declare header "SAP_PA_APL"."sap.pa.apl.base::BASE.T.FUNCTION_HEADER";
    declare config "SAP_PA_APL"."sap.pa.apl.base::BASE.T.OPERATION_CONFIG_EXTENDED";   
    declare var_desc "SAP_PA_APL"."sap.pa.apl.base::BASE.T.VARIABLE_DESC_OID";      
    declare var_role "SAP_PA_APL"."sap.pa.apl.base::BASE.T.VARIABLE_ROLES_WITH_COMPOSITES_OID";      
    declare out_log   "SAP_PA_APL"."sap.pa.apl.base::BASE.T.OPERATION_LOG";             
    declare out_summary  "SAP_PA_APL"."sap.pa.apl.base::BASE.T.SUMMARY";   
    declare out_metric   "SAP_PA_APL"."sap.pa.apl.base::BASE.T.DEBRIEF_METRIC_OID";      
    declare out_property "SAP_PA_APL"."sap.pa.apl.base::BASE.T.DEBRIEF_PROPERTY_OID";
 
    :header.insert(('Oid', 'Before-After 1970'));

    :config.insert(('APL/SegmentColumnName', 'Sport',null)); 

	:var_desc.insert((0,'Height','number','continuous',0,0,null,null,null,null));
	:var_desc.insert((1,'Weight','number','continuous',0,0,null,null,null,null));
	:var_desc.insert((2,'Age','integer','continuous',0,0,null,null,null,null));
    :var_desc.insert((3,'Medal','string','nominal',0,0,null,null,null,null));
	:var_desc.insert((4,'Gender','string','nominal',0,0,null,null,null,null));
	:var_desc.insert((5,'Season','string','nominal',0,0,null,null,null,null));
	:var_desc.insert((6,'Country','string','nominal',0,0,null,null,null,null));
	
	"SAP_PA_APL"."sap.pa.apl.base::COMPARE_DATA" (
	:header, :config, :var_desc, :var_role,'USER_APL','DATASET_1', 'USER_APL','DATASET_2', 
	out_log, out_summary, out_metric, out_property );
 
 	select value as "Status", count(*) as "Nb of Segments" from :out_summary where key = 'AplTaskStatus' group by value;
	select OID as "Sport", message as "Error" from :out_log where level=0;
	 	
    select * from SAP_PA_APL."sap.pa.apl.debrief.report::Deviation_ByVariable"(:out_property,:out_metric, Deviation_Threshold =&amp;gt; 0.9);
    select * from SAP_PA_APL."sap.pa.apl.debrief.report::Deviation_ByCategory"(:out_property,:out_metric, Deviation_Threshold =&amp;gt; 0.9); 
    select * from SAP_PA_APL."sap.pa.apl.debrief.report::Deviation_CategoryFrequencies"(:out_property,:out_metric) order by "Abs % Change" desc;
END;

-- Cases where a comparison is not possible
select "Sport" from "DATASET_1" minus select "Sport" from "DATASET_2"; -- Sports that have been removed 
select "Sport" from "DATASET_2" minus select "Sport" from "DATASET_1"; -- New Sports&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The APL drift detector supports also a 2-step approach to address the cases where you have a changing dataset that needs to be compared on a regular basis (e.g. every week or every month) to a fixed reference. The samples below illustrate how it works with Python:&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/apl/notebooks/63a_Data_Drift-Learn_and_Report.ipynb" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 1 notebook&lt;/A&gt;&amp;nbsp; &amp;nbsp;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/apl/notebooks/63b_Data_Drift-Detect_and_Report.ipynb" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 2 notebook&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;and with SQL:&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/APL-SQL/63a_Data_Drift-Learn_and_Report.sql" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 1 script&lt;/A&gt;&amp;nbsp; &amp;nbsp;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/APL-SQL/63b_Data_Drift-Detect_and_Report.sql" target="_self" rel="nofollow noopener noreferrer"&gt;Data Drift Step 2 script&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Happy data drift detection with APL.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/viewer/p/apl" target="_self" rel="noopener noreferrer"&gt;To know more about APL&lt;/A&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/hana-ml-data-drift-detector/ba-p/14148518"/>
    <published>2025-07-10T17:08:13.870000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/sap-community-leaders-finder/juhi-kulshreshtha/ba-p/14151799</id>
    <title>Juhi Kulshreshtha</title>
    <updated>2025-07-14T17:58:37.251000+02:00</updated>
    <author>
      <name>StephanieMarley</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/109</uri>
    </author>
    <content>&lt;P&gt;&lt;A href="https://community.sap.com/t5/user/viewprofilepage/user-id/39604" target="_self"&gt;Juhi&lt;/A&gt;&amp;nbsp;&lt;SPAN&gt;{juhik2003}&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;FONT face="tahoma,arial,helvetica,sans-serif"&gt;India&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="tahoma,arial,helvetica,sans-serif"&gt;SAP Mentor since 2025&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="tahoma,arial,helvetica,sans-serif"&gt;Follow Juhi in &lt;A href="https://www.linkedin.com/in/juhi-kulshreshtha-aba8486/" target="_self" rel="nofollow noopener noreferrer"&gt;LinkedIn&lt;/A&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="juhi.png" style="width: 200px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/286427iC81223CED51715EA/image-size/small?v=v2&amp;amp;px=200" role="button" title="juhi.png" alt="juhi.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Juhi is a Senior SAP Professional with more than 20 years of experience in implementation, operations and support of business technology in various areas of SAP. In her current role, she is leading SAP BTP Practice in her organisation and is responsible for growing SAP BTP Competencies. She is responsible for making sure that the BTP developments are aligned with the Best Practices recommended by SAP. Also to make sure that BTP teams leverage the finest methodologies and reference architectures. Her role also includes evangelizing about the â€˜Art of Possibleâ€™ in BTP within the organisation and to clients. Her current areas of focus also include Custom AI/ML solutions, GenAI and Business AI in SAP. Her latest area of interest is BDC and how to leverage BDC to gain business insights. She believes in constant learning and upskilling and encourages her teams to stay updated with latest skills and tools.&lt;/P&gt;&lt;P&gt;She is an active member of SAP Community and an avid blogger. She has participated as a speaker in multiple SAP Inside Track Events in India, Podcasts and Virtual Roundtables during the last 2 years. She is an SAP BTP evangelist and loves to share her knowledge about BTP and AI/ML.&lt;/P&gt;&lt;P&gt;&lt;FONT face="tahoma,arial,helvetica,sans-serif"&gt;&lt;STRONG&gt;Topics of interest:&amp;nbsp;&lt;/STRONG&gt;&lt;/FONT&gt;BTP, AI/ML, GenAI, BDC&lt;/P&gt;&lt;P&gt;&lt;FONT face="tahoma,arial,helvetica,sans-serif"&gt;&lt;STRONG&gt;Juhi, what inspired you to become an SAP Mentor?&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="tahoma,arial,helvetica,sans-serif"&gt;&lt;STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="handshake .png" style="width: 68px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/52491i8E9D2FFB3C7BC293/image-dimensions/68x68?v=v2" width="68" height="68" role="button" title="handshake .png" alt="handshake .png" /&gt;&lt;/span&gt;&lt;/STRONG&gt;&lt;/FONT&gt;After working for over 20 years in SAP areas, I have encountered numerous challenges and questions raised by clients, analysts, and developers who implement SAP solutions. My teams and I have often provided innovative solutions to these issues. However, without a broader platform to share this knowledge, much of this valuable experience has remained within our organizations.&lt;/P&gt;&lt;P&gt;I am also inspired by the other SAP Mentors and the significant value they contribute to the SAP ecosystem.&lt;/P&gt;&lt;P&gt;As an SAP Mentor, I would like to share knowledge and learn from othersâ€™ experiences in this ecosystem. It is a fantastic platform for the cross-pollination of ideas and innovative outcomes. I would be delighted if I could improve the life of even a single developer or client through this process and give back to the wonderful SAP community.&lt;/P&gt;&lt;P&gt;&lt;FONT face="tahoma,arial,helvetica,sans-serif"&gt;&lt;STRONG&gt;What advice would like to share with other SAP community members?&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="tahoma,arial,helvetica,sans-serif"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="298874_collaborate_blue (1).png" style="width: 65px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/52495i64D82195EFF8CCB9/image-dimensions/65x65?v=v2" width="65" height="65" role="button" title="298874_collaborate_blue (1).png" alt="298874_collaborate_blue (1).png" /&gt;&lt;/span&gt;&lt;/FONT&gt;My advice to other SAP Community members is to always be curious about learning new technologies in SAP. Ask yourself: Why am I implementing a particular SAP technology? Am I able to bring value to the table and provide a great experience for my stakeholders? What kind of impact is my code making ? &amp;nbsp;You will find that these questions are the triggers where your real learning journey will start. And thatâ€™s how I started mine.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/sap-community-leaders-finder/juhi-kulshreshtha/ba-p/14151799"/>
    <published>2025-07-14T17:58:37.251000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/using-python-in-sap-business-application-studio-my-notes/ba-p/14155516</id>
    <title>Using Python in SAP Business Application Studio â€“ my notes</title>
    <updated>2025-07-18T13:55:15.744000+02:00</updated>
    <author>
      <name>Vitaliy-R</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/183</uri>
    </author>
    <content>&lt;P&gt;The &lt;STRONG&gt;Python Tools extension&lt;/STRONG&gt;, which enhances the Python coding experience, was introduced in SAP Business Application Studio (referred to as "BAS" below) exactly two years ago. Here are my notes from using it.&lt;/P&gt;&lt;P&gt;This post is not a tutorial or a comprehensive guide to best practices. Itâ€™s a collection of personal notes, which I hope you find helpful when working with Python in BAS. The &lt;STRONG&gt;focus here is on&lt;/STRONG&gt; &lt;STRONG&gt;running Python code in BAS&lt;/STRONG&gt;, not on deploying to SAP BTP runtimes like Cloud Foundry (CF) or Kyma. This is when you are usually working on &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/quot-getting-started-with-machine-learning-using-sap-hana-quot-as-a-new-sap/ba-p/13574098" target="_self"&gt;Machine Learning&lt;/A&gt; or AI projects in BAS,&amp;nbsp;like during SAP CodeJams.&lt;/P&gt;&lt;P&gt;I assume you're not an absolute beginner with SAP Business Application Studioâ€”or at least you're familiar with Visual Studio Code.&lt;/P&gt;&lt;P&gt;For the examples in this post, Iâ€™ll be using the SAP Business Application Studio available in the SAP BTP Trial environment.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1606043981"&gt;Python runtime&lt;/H1&gt;&lt;P&gt;In SAP Business Application Studio, the dev space includes a system-level Python 3 binary at &lt;FONT face="terminal,monaco" color="#000080"&gt;/bin/python3&lt;/FONT&gt;, which is primarily intended for OS-level scripts and tooling. This version is tied to the base container image and is only updated when the image itself is refreshed.&lt;/P&gt;&lt;H3 id="toc-hId-1667695914"&gt;Managing Python versions&lt;/H3&gt;&lt;P&gt;For application development, developers typically use user-managed Python runtimes. Since &lt;A href="https://help.sap.com/docs/bas/sap-business-application-studio/2024-what-s-new-for-sap-business-application-studio?locale=en-US" target="_blank" rel="noopener noreferrer"&gt;January 2024&lt;/A&gt;, you can select the Python version with which you want to work.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752787857188.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288194i63734250F432B502/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1752787857188.png" alt="VitaliyR_0-1752787857188.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;SAP Business Application Studio uses &lt;A href="https://asdf-vm.com/guide/introduction.html" target="_self" rel="nofollow noopener noreferrer"&gt;asdf&lt;/A&gt; to allow you to select which runtime versions to install and use for developing your application. You can check this in the BAS terminal with &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf current python&lt;/FONT&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752826029935.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288476i3AA3E4CCAB7C035F/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1752826029935.png" alt="VitaliyR_0-1752826029935.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;By default, SAP Business Application Studio provides only one officially supported Python version.&lt;/P&gt;&lt;P&gt;If you need another version of Python, you can install it with&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;FONT face="terminal,monaco" color="#000080"&gt;asdf install python &amp;lt;version&amp;gt;&lt;/FONT&gt;. If you want the latest minor version, then use&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;FONT face="terminal,monaco" color="#000080"&gt;latest:&lt;/FONT&gt;, like&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;FONT face="terminal,monaco" color="#000080"&gt;asdf install python latest:3.12&lt;/FONT&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;in the case of the 3.12 version of Python.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1752826587342.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288479i3F1AFA339D0457AC/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_1-1752826587342.png" alt="VitaliyR_1-1752826587342.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;At the time of writing this post, the &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf&lt;/FONT&gt;&amp;nbsp;version used in BAS is 0.12.0. This version uses the &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf global&lt;/FONT&gt;&amp;nbsp;and &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf local&lt;/FONT&gt;&amp;nbsp;commands to set the actual runtime version. If you refer to the &lt;A href="https://asdf-vm.com/manage/commands.html" target="_self" rel="nofollow noopener noreferrer"&gt;asdf documentation&lt;/A&gt;, these commands have been replaced with &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf set&lt;/FONT&gt;, so don't get confused.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_4-1752832090379.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288513i2594100CA73554EA/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_4-1752832090379.png" alt="VitaliyR_4-1752832090379.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1471182409"&gt;Runtime management from the command palette&lt;/H3&gt;&lt;P&gt;You can also install different versions from the command palette. Select &lt;STRONG&gt;&amp;gt; Runtime: Install&lt;/STRONG&gt;,&amp;nbsp;then Python, and the version you want to install. To set the default version of Python for execution, use the command &lt;STRONG&gt;&amp;gt; Runtime: Set Default&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_3-1752831488109.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288507iF7D44FFABFDAC454/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_3-1752831488109.png" alt="VitaliyR_3-1752831488109.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://help.sap.com/docs/bas/sap-business-application-studio/runtime-version-management" target="_blank" rel="noopener noreferrer"&gt;These commands&lt;/A&gt; are provided by the built-in &lt;STRONG&gt;BAS Framework&lt;/STRONG&gt; extension.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_2-1752831268028.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288505i52FE94C88EEC6711/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_2-1752831268028.png" alt="VitaliyR_2-1752831268028.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1274668904"&gt;You can now run your Python programs in BAS...&lt;/H3&gt;&lt;P&gt;...using a version of Python accordingly to your requirements.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752833019314.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288533iF1F4C8ABA0F83A9D/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_0-1752833019314.png" alt="VitaliyR_0-1752833019314.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-819989961"&gt;Design-time&lt;/H1&gt;&lt;P&gt;Being a &lt;STRONG&gt;fork of Visual Studio Code - Open Source ("&lt;A href="https://github.com/microsoft/vscode" target="_self" rel="nofollow noopener noreferrer"&gt;Code - OSS&lt;/A&gt;")&lt;/STRONG&gt;â€”SAP Business Application Studio provides basic support for Python files and Jupyter notebooks out of the box.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752835179123.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288559i5DC7A0BAB2529980/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_0-1752835179123.png" alt="VitaliyR_0-1752835179123.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-881641894"&gt;BAS additional extension "&lt;SPAN&gt;Python Tools&lt;/SPAN&gt;"&lt;/H3&gt;&lt;P&gt;To improve your Python coding experience, SAP Business Application Studio provides an additional extension called "&lt;SPAN&gt;Python Tools&lt;/SPAN&gt;". This extension includes IntelliSense, formatting, linting, and debugging support for Python files and Jupyter notebooks.&lt;/P&gt;&lt;P&gt;To add "Python Tools" to your BAS dev space, go to the configuration of a stopped or a newly created dev space, and select &lt;STRONG&gt;Python Tools&lt;/STRONG&gt; from&amp;nbsp;&lt;STRONG&gt;Additional SAP Extensions&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1752833807354.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288542i4B3C4AE1B211B686/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1752833807354.png" alt="VitaliyR_1-1752833807354.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Upon activation, you should see additional extensions listed now as built-in in BAS.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1752835746649.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288580i881221FC5560023D/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1752835746649.png" alt="VitaliyR_1-1752835746649.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Note&lt;SPAN&gt;&amp;nbsp;that BAS installs its extensions from &lt;A href="https://open-vsx.org/" target="_self" rel="nofollow noopener noreferrer"&gt;Open VSX&lt;/A&gt;, an open-source registry for VS Code extensions.&amp;nbsp;&lt;A href="https://github.com/Microsoft/vscode-python" target="_blank" rel="noopener nofollow noreferrer"&gt;VS Code's Python extension&lt;/A&gt;&amp;nbsp;is available&lt;/SPAN&gt;&amp;nbsp;at:&amp;nbsp;&lt;A href="https://open-vsx.org/extension/ms-python/python" target="_blank" rel="noopener nofollow noreferrer"&gt;https://open-vsx.org/extension/ms-python/python&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;You can see Python extensions in the file system:&lt;/P&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;ls -lad /extbin/local/openvscode-server/extensions/ms-py*&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_2-1752837415019.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288590iAD09D0AB5EF7209B/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_2-1752837415019.png" alt="VitaliyR_2-1752837415019.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;These are extensions selected and integrated by the BAS product team at SAP.&lt;/P&gt;&lt;H3 id="toc-hId-685128389"&gt;Additional notes:&lt;/H3&gt;&lt;P&gt;You can install other versions of the same extensions directly from&amp;nbsp;&lt;A href="https://open-vsx.org/," target="_blank" rel="noopener nofollow noreferrer"&gt;https://open-vsx.org/,&lt;/A&gt;&amp;nbsp;but there is no guarantee that they have been tested and will properly work with BAS. First of all, the extension version installed directly from the marketplace should be compatible with the version of SAP Business Application Studio (or the "Codeâ€”OSS" to be more precise).&lt;/P&gt;&lt;P&gt;For example, at the time of writing this post, the version of the Python extension at the VSX marketplace is 2025.04...&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1752844419611.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288649i9D1EA9993790B188/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1752844419611.png" alt="VitaliyR_0-1752844419611.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;which is compatible with version&amp;nbsp;1.94.0 of Code-OSS and therefore BAS:&amp;nbsp;&lt;A href="https://github.com/microsoft/vscode-python/blob/v2025.4.0/package.json#L50" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/microsoft/vscode-python/blob/v2025.4.0/package.json#L50&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P class="lia-align-center" style="text-align: center;"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="VitaliyR_1-1752844619669.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288650i4AACB703E4B1AB99/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_1-1752844619669.png" alt="VitaliyR_1-1752844619669.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-488614884"&gt;Usage of the Python extension in BAS&lt;/H3&gt;&lt;P&gt;Upon installation of the Python extension in BAS, you can:&lt;/P&gt;&lt;P&gt;1/ Execute Python extension's commands from the palette:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_3-1752839390743.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288612iE7D273E2ECA1213B/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_3-1752839390743.png" alt="VitaliyR_3-1752839390743.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;2/ Trigger an execution of a program from the editor:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_4-1752839526904.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288613i6971D9697275CE7D/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_4-1752839526904.png" alt="VitaliyR_4-1752839526904.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;...which you can configure by editing the&amp;nbsp;&lt;FONT face="terminal,monaco" color="#000080"&gt;python.terminal&lt;/FONT&gt;&amp;nbsp;settings:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_0-1753218387860.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/290009i4BCA41DCB5E93013/image-size/medium?v=v2&amp;amp;px=400" role="button" title="VitaliyR_0-1753218387860.png" alt="VitaliyR_0-1753218387860.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;3/ modify its &lt;FONT face="terminal,monaco" color="#000080"&gt;@ext:ms-python.python&lt;/FONT&gt;&amp;nbsp;settings:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_5-1752839680256.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/288616i88C848EA078DDAA6/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_5-1752839680256.png" alt="VitaliyR_5-1752839680256.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-33935941"&gt;Python virtual environments&lt;/H1&gt;&lt;P&gt;To run your code, you usually need additional Python packages, such as the&amp;nbsp;&lt;A href="https://pypi.org/project/hana-ml/" target="_blank" rel="noopener nofollow noreferrer"&gt;Python machine learning client for SAP HANA (hana-ml)&lt;/A&gt;&amp;nbsp;or &lt;A href="https://pypi.org/project/sap-ai-sdk-gen/" target="_self" rel="nofollow noopener noreferrer"&gt;SAP Cloud SDK for AI (Python)&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;If you have experience with Python, then you already know all the advantages of using virtual environments. Although you can think of BAS devspace as an isolated project development environment, there is a good reason to use Python virtual environments there, as I already explained in&amp;nbsp;&lt;A class="" href="https://community.sap.com/t5/technology-blog-posts-by-sap/persisting-python-environment-when-using-jupyter-notebooks-in-sap-business/ba-p/13549863" target="_self"&gt;Persisting Python environment in SAP Business Application Studio&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;An additional reason to use a virtual environment is if you plan to test or run your project using different versions of Python managed by &lt;FONT face="terminal,monaco" color="#000080"&gt;asdf&lt;/FONT&gt;. Each of the installed versions of Python will use their own location to store packages:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="VitaliyR_1-1753198029018.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/289900iDF172F958DDDAA5B/image-size/large?v=v2&amp;amp;px=999" role="button" title="VitaliyR_1-1753198029018.png" alt="VitaliyR_1-1753198029018.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId--162577564"&gt;Stay tuned for a separate post on the topic of using Jupyter notebooks.&lt;/H1&gt;&lt;P&gt;Please share your tips using Python in SAP Business Application Studio!&lt;/P&gt;&lt;P&gt;------&lt;/P&gt;&lt;P&gt;-Vitaliy, aka&amp;nbsp;&lt;A href="https://bsky.app/profile/sygyzmundovych.bsky.social" target="_self" rel="nofollow noopener noreferrer"&gt;@Sygyzmundovych&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/using-python-in-sap-business-application-studio-my-notes/ba-p/14155516"/>
    <published>2025-07-18T13:55:15.744000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/sap-joule-for-beginners-everything-you-need-to-know-all-at-one-stop/ba-p/14160885</id>
    <title>SAP Joule for Beginners: Everything You Need to Know - All at one stop!</title>
    <updated>2025-07-26T07:38:02.640000+02:00</updated>
    <author>
      <name>rajarajeswari_kaliyaperum</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/654809</uri>
    </author>
    <content>&lt;H4 id="toc-hId-1332914048" id="toc-hId-1994069803"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;This blog is for anyone in the SAP domain â€” from consultants to architects â€” who is curious about SAP Joule and wants to understand how it works. You're in the right place!&lt;/FONT&gt;&lt;/H4&gt;&lt;PRE&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#999999"&gt;Disclaimer: This blog is based on publicly available information as of 24th July 2025, along with my personal interpretation. Sources of all referenced information, where available, are quoted in the REFERENCE section of this blog.&lt;/FONT&gt;&lt;/PRE&gt;&lt;H4 id="toc-hId-1797556298"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT color="#800080"&gt;Topics covered in this blog are:&lt;/FONT&gt;&lt;/FONT&gt;&lt;/H4&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT color="#800080"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="37.png" style="width: 481px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291777i28093FAF830C717A/image-size/large?v=v2&amp;amp;px=999" role="button" title="37.png" alt="37.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;H4 id="toc-hId-1601042793"&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;Welcome to the world of SAP Joule! Let's decode it into chunks!&amp;nbsp;&lt;/FONT&gt;&lt;/H4&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="2.png" style="width: 200px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/290644iE8FF85A840D68163/image-size/small?v=v2&amp;amp;px=200" role="button" title="2.png" alt="2.png" /&gt;&lt;/span&gt;&lt;FONT color="#800080"&gt;"&lt;EM&gt;How can I help you?&amp;nbsp;&lt;/EM&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#800080"&gt;&lt;EM&gt;Talk to me naturally. For example, 'What are my task for today?&lt;/EM&gt;"&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;This is how Joule greets you in first place!&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT color="#800080"&gt;Joule&lt;/FONT&gt; â€” a name derived from the unit of energy â€” is here to energize our business processes, save valuable time, and simplify even the most tedious tasks resulting in greater efficiency and a noticeable uplift in the quality of our work.&lt;/FONT&gt;&lt;/P&gt;&lt;H4 id="toc-hId-1404529288"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000080"&gt;SECTION 1: Understanding key terminologies and concepts:&lt;/FONT&gt;&lt;/H4&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Letâ€™s cover some basic artificial intelligence terms before diving deeper into Joule for better understanding.&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT color="#800080"&gt;&lt;FONT face="arial black,avant garde"&gt;Artificial intelligence (AI)&lt;/FONT&gt;&lt;/FONT&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt; is a technology that mimics human reasoning and behavior, enabling machines to make decisions on their own. By processing large volumes of data, AI can understand speech, identify patterns and trends, solve problems proactively, and forecast future outcomes.&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL class="lia-list-style-type-square"&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde" color="#800080"&gt;GenAI&lt;/FONT&gt; also known as generative AI is a model where it can create new content which can either be text, image, audio and video based on the existing content that it already has.&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde" color="#800080"&gt;LLM &lt;/FONT&gt;(Large language Model) is the specific model (like&amp;nbsp;GPT, PaLM, LLaMA) that powers the text generation part of GenAI. It is a type of artificial intelligence model that is trained to understand and generate human-like language. It's designed to read, summarize, translate, predict, or generate text based on the input it receives. Eg, When we ask ChatGPT a question, it's an LLM that's interpreting our text and generating a relevant, natural-sounding response.&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde" color="#800080"&gt;AI copilot&lt;/FONT&gt; is a virtual assistant that helps business application users complete tasks more easily through a conversational interface. It uses generative AI to understand requests, take actions, and offer insights from business data. AI Copilots use LLMs to understand natural language and assist users in real time.The answer that is provided to the user is limited to training data against LLMs.&amp;nbsp;&lt;/FONT&gt;&lt;FONT color="#000000"&gt;"Large"&lt;/FONT&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt; refers to the massive amount of data and the billions of parameters the model is trained on.&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="5.png" style="width: 200px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/290771i09EC5D3ADCFD2CB2/image-size/small?v=v2&amp;amp;px=200" role="button" title="5.png" alt="5.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde" color="#800080"&gt;Retrieval-Augmented Generation (RAG): &lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;In SAP world, customer specific data cannot be used to train the LLMs. And hence we need a better way to retrieve the desired outcomes without breaching the customer's data privacy. This is where RAG comes into picture. It&lt;/FONT&gt;&lt;/FONT&gt;&amp;nbsp;is used to generate more relevant answers to an SAP user's question without actually training the Large Language Model (LLM). This is done through Document Grounding. As a part of preparation of RAG, it provided with SAP and customer specific documents such as HR policies, manuals, and SOPs that may be useful for answering SAP user queries. These documents are then chunked into smaller parts and are then embedded into dense, continuous vectorsâ€”known as &lt;FONT color="#800080"&gt;embeddings&lt;/FONT&gt;â€”which represent the data in a high-dimensional space. These embeddings are then stored in the &lt;FONT color="#800080"&gt;HANA Vector Database&lt;/FONT&gt; for retrieval based on the user's query. This information is passed to the LLM as prompts during runtime rather than getting it trained.&amp;nbsp;The LLM uses this prompt to generate a response in real time. Thus, LLMs are not trained against customer data. Rather, they get Grounded against customer specific data.&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde" color="#800080"&gt;HANA Vector Database&lt;/FONT&gt; enables the storage, indexing, and searching of unstructured data like vector embeddings (numerical representations of text, documents, or images). This allows AI systems to retrieve and interpret information based on semantic meaning, not just keywords.&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="8.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/290829i3D3BA62A80454FE0/image-size/large?v=v2&amp;amp;px=999" role="button" title="8.png" alt="8.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="simsun,hei" color="#999999"&gt;Image source:&amp;nbsp;&lt;A href="https://www.youtube.com/watch?v=Uiv29xYlXvQ" target="_blank" rel="noopener nofollow noreferrer"&gt;https://www.youtube.com/watch?v=Uiv29xYlXvQ&lt;/A&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="7.png" style="width: 200px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/290831i03D7EB8DEE7D62E9/image-size/small?v=v2&amp;amp;px=200" role="button" title="7.png" alt="7.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;For example, company policy documents are broken into chunks and converted into multi-dimensional vectors (numerical coordinates that represent the meaning of text) using an AI model. These vectors, along with metadata, are stored in the SAP HANA Vector Database to enable semantic search, so RAG can retrieve relevant content for the LLM to generate accurate natural language responses. For instance, when a user asks about their company's paternity leave policy, the system converts the question into a vector, searches for the most relevant policy content using the HANA Vector Database, and then uses an LLM to generate a clear answer based on that information.&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H4 id="toc-hId-1208015783"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#003366"&gt;SECTION 2: What is SAP Joule and what are its use cases in the SAP world&lt;/FONT&gt;&lt;/H4&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde" color="#800080"&gt;SAP Joule&lt;/FONT&gt; is an AI copilot from SAP. Powered by SAP BTP (Business Technology Platform), it serves as a virtual assistant that leverages generative AI to understand and respond to user requests within SAP systems.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Before diving deeper, Let's understand some of the use cases of SAP Joule. Below are some of the end-user prompts that can be sent to Joule, where it responds appropriately using natural language processing.&amp;nbsp;&lt;/FONT&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;These examples are sourced from SAP's official Joule product pages.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="9.png" style="width: 842px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291179i9BAE05099D26C3BA/image-dimensions/842x687?v=v2" width="842" height="687" role="button" title="9.png" alt="9.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT face="simsun,hei" color="#000000"&gt;Image source: &lt;A href="https://www.sap.com/india/products/artificial-intelligence/ai-assistant.html#agility-for-all" target="_blank" rel="noopener noreferrer"&gt;https://www.sap.com/india/products/artificial-intelligence/ai-assistant.html#agility-for-all&lt;/A&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;Why Joule?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Joule is SAP domain-specific and is integrated with SAPâ€™s suite of products, ensuring seamless interaction and data exchange across the SAP portfolio. It is also a responsible AI solution, with a strong emphasis on industry-specific regulations and standards. As a result, Joule is a more &lt;FONT color="#800080"&gt;Relevant, Reliable, and Responsible&lt;/FONT&gt; AI copilot for SAP.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="29.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291766iF2B2C5B2A3C80068/image-size/medium?v=v2&amp;amp;px=400" role="button" title="29.png" alt="29.png" /&gt;&lt;/span&gt;As specified earlier, the LLMs in Joule are not actually trained to respond to SAP user queries. Instead, Joule use document grounding through RAGe (&lt;FONT color="#800080"&gt;Retrieval-Augmented Generation for enterprise&lt;/FONT&gt;) for unstructured data, and the SAP Knowledge Graph for structured data, enabling it to provide more comprehensive responses by referencing business documents from both SAP and third-party repositories , while LLMs are used to add natural language rather than the actual context in the response that is sent to user by Joule. That is, &lt;FONT color="#800080"&gt;Grounding&lt;/FONT&gt; uses a customerâ€™s own knowledge sources (e.g., travel policies, enablement content, service manuals, FAQs, etc.) to supplement the capabilities of Large language models (LLMs). This gives Joule a unique understanding of SAP data and processes, allowing it to respond more reliably than any other AI copilot.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Joule is seamlessly integrated into various SAP cloud solutions to help users work more efficiently across different business functions, such as:&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;SAP S/4HANA Cloud&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;SAP S/4HANA Cloud, private edition&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;SAP SuccessFactors&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;SAP Ariba&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;SAP Sales Cloud&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;SAP Customer Experience solutions&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;SAP Concur&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;SAP ABAP Cloud&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#800080"&gt;However, it is worth noting that Joule is not available for on-premise solutions.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Thus the main advantages of SAP Joule include:&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Enhanced decision-making&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Accelerated end-to-end business processes&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Personalized UI with inherited user authorizations&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Advanced analytics&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Contextual awareness&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Ability to meet diverse business needs&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;Business application supported by SAP Joule:&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;SAP Joule runs on the AI Foundation of SAP BTP (Business Technology Platform) and supports a wide range of business application such as Finance, Procurement, Supply Chain, Human Resources, Sales and Services, Marketing and E-Commerce, Development, and Consulting.&amp;nbsp; Apart from some of the use cases described before, a&amp;nbsp;detailed list of business use cases are available through URL =&amp;gt; &lt;A href="https://www.sap.com/india/products/artificial-intelligence/ai-assistant.html#agility-for-all" target="_blank" rel="noopener noreferrer"&gt;https://www.sap.com/india/products/artificial-intelligence/use-cases.html&lt;/A&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="10.png" style="width: 830px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291177iC66F90E0C8C3410A/image-dimensions/830x106?v=v2" width="830" height="106" role="button" title="10.png" alt="10.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;Joule's interaction pattern:&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="15.png" style="width: 834px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291288i0F7D2880DE9045C2/image-dimensions/834x340?v=v2" width="834" height="340" role="button" title="15.png" alt="15.png" /&gt;&lt;/span&gt;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="simsun,hei" color="#999999"&gt;Image source:&amp;nbsp;&lt;/FONT&gt;&lt;A href="https://www.sap.com/india/products/artificial-intelligence/ai-assistant.html" target="_blank" rel="noopener noreferrer"&gt;&lt;FONT face="simsun,hei" color="#999999"&gt;https://www.sap.com/india/products/artificial-intelligence/ai-assistant.htm&lt;/FONT&gt;l&lt;/A&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Joule's interaction pattern can vary from:&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT color="#800080"&gt;Informational&lt;/FONT&gt;:&amp;nbsp;The Joule provides answers to factual questions (e.g. "What are the key rules for a team outing?")&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT color="#800080"&gt;Navigational&lt;/FONT&gt;:&amp;nbsp;The Joule guides users through a multi-step process or an internal journey, like approving a request or changing organizational data. (e.g. â€œWhere in the app do I send a promotion request?â€)&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT color="#800080"&gt;Transactional&lt;/FONT&gt;:&amp;nbsp;The Joule engages in task completion workflows, e.g. reviewing and updating position details (job title, department, cost center), then confirming by saying â€œDoneâ€. It also supports user edits and next steps before finalizing.&amp;nbsp;(e.g.&amp;nbsp;â€œUpdate the position title to Sustainability Supply Chain Consultant â€” ready to submit?â€)&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT color="#800080"&gt;Analytical&lt;/FONT&gt;:&amp;nbsp;The Joule offers data insights, metrics, and visual analytics, such as attrition trends vs. hiring rates charted by quarter. It helps users interpret numbers and trends. (e.g.â€œWhat was our quarterly attrition rate in 2024?â€)&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;H4 id="toc-hId-1011502278"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#003366"&gt;SECTION 3: Joule architecture&lt;/FONT&gt;&lt;/H4&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="24.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291681i0B358B504AD06487/image-size/medium?v=v2&amp;amp;px=400" role="button" title="24.png" alt="24.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;FONT face="simsun,hei" color="#000000"&gt;Image source: &lt;A href="https://learning.sap.com/learning-journeys/provisioning-and-implementing-joule" target="_self" rel="noopener noreferrer"&gt;Joule learning journey&lt;/A&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Joule architecture consists of key components which work together to respond to a user's question.&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;&lt;FONT face="arial black,avant garde"&gt;Scenario Catalog&lt;/FONT&gt;&lt;/FONT&gt;&lt;FONT color="#000000"&gt;:&lt;/FONT&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&amp;nbsp;The Scenario Catalog holds information about all the available scenarios, functions, and skills in SAP cloud applications. In helps to distinguish between different user questions and guides Joule to understand the request and connect it to the right action or system or workflow. This acts like a blueprint that maps user queries to the appropriate actions, destinations, or logic within SAP systems. For example, if a user query is "&lt;EM&gt;Retrieves the current leave balance for a given employee&lt;/EM&gt;", then this gets mapped as below:&lt;/FONT&gt;&lt;OL class="lia-list-style-type-lower-roman"&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Scenario: 'Get_Employee_Leave_Balance' &lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Business application : Human Resource&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;'leave balance': Employee ID, leave Type and Date Range.&lt;/FONT&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde"&gt;Knowledge Catalog:&lt;/FONT&gt;&amp;nbsp;&lt;SPAN&gt;This contains&amp;nbsp;&lt;/SPAN&gt;SAP-knowledge&lt;SPAN&gt;&amp;nbsp;as well as the&amp;nbsp;&lt;/SPAN&gt;customer-owned knowledge&lt;SPAN&gt;.&amp;nbsp;&lt;/SPAN&gt;It is a collection of documents and content sources (often unstructured or semi-structured) that are made available to Joule for question-answering using RAG (Retrieval-Augmented Generation) techniques. It supports Joule in answering open-ended, natural language questions that arenâ€™t directly tied to structured data or APIs. For example, it can have a company's HR policies (e.g., leave, travel, benefits), Finance guidelines (e.g., expense reimbursement rules) and so on. These documents are chunked and vectorized using embeddings in HANA vector database as specified earlier.&amp;nbsp;When a user asks a related question, Joule retrieves relevant chunks and sends them to the LLM to generate a grounded answer.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde"&gt;User Context:&amp;nbsp;&lt;/FONT&gt;This helps joule to contextualize a user's question. This includes information about the SAP cloud applications the user is currently using, along with any additional SAP applications the customer has licensed and activated for use with Joule. Joule also recognizes the userâ€™s roles and permissions, ensuring they can access only the information or perform the actions they are authorized to within the SAP cloud environment. Additionally, Joule takes into account the userâ€™s chat history and context to provide most relevant and accurate responses to user queries. To put in other words, a user will be able to view or perform any tasks only if they are authorized to do so based on their existing authorization.&amp;nbsp;&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde"&gt;Document Grounding:&lt;/FONT&gt;&amp;nbsp;Large Language Models (LLMs) are generally capable of understanding prompts and generating human-like responses. However, they often lack the context and specificity needed for business scenarios. To address this, Joule uses a technique called &lt;EM&gt;document gro&lt;/EM&gt;&lt;EM&gt;unding&lt;/EM&gt;. This allows Joule to generate more accurate and relevant responses by referencing business documents stored in SAP and third-party repositories.&amp;nbsp;As part of document grounding, customers can upload their own content (such as HR policies, travel policies, service manuals, etc.). When an end user asks a question, Joule searches these documents for relevant information and returns a concise, natural-language response, including the source references. This ensures the answers are grounded in the customer's own structured and unstructured data, making them more trustworthy and context-aware.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde"&gt;&amp;nbsp;Grounding&lt;STRONG&gt;: &lt;/STRONG&gt;&lt;/FONT&gt;This&amp;nbsp;is the process of combining generative LLMs with advanced information retrieval techniques to enhance the accuracy and relevance of responsesâ€”without the need to train or fine-tune the model on company-specific data. It leverages a customerâ€™s internal knowledge sources (e.g., policies, FAQs, training material) to supplement the LLMâ€™s existing knowledge. This improves the modelâ€™s reliability and ensures that responses reflect the customerâ€™s unique business context.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial black,avant garde"&gt;Retrieval-Augmented Generation (RAG):&lt;/FONT&gt; RAG&amp;nbsp;is used to generate more relevant answers to an SAP user's question without actually training the Large Language Model (LLM).&amp;nbsp;As part of the RAG, Document Grounding is performed. In this step, RAG is provided with relevant documents such as HR policies, manuals, and SOPs that may be useful for answering SAP user queries. These documents are chunked into smaller parts and then embedded into dense, continuous vectorsâ€”known as &lt;FONT color="#800080"&gt;embeddings&lt;/FONT&gt;â€”which represent the data in a high-dimensional space. These embeddings are then stored in the HANA Vector Database for retrieval based on the user's query.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&amp;nbsp;&lt;FONT face="arial black,avant garde"&gt;HANA Vector Database:&lt;/FONT&gt; It enables the storage, indexing, and searching of unstructured data like vector embeddings (numerical representations of text, documents, or images). This allows AI systems to retrieve and interpret information based on semantic meaning, not just keywords.&amp;nbsp;For example, company policy documents are broken into chunks and converted into multi-dimensional vectors (numerical coordinates that represent the meaning of text) using an AI model. These vectors, along with metadata, are stored in the SAP HANA Vector Database to enable semantic search, so RAG can retrieve relevant content for the LLM to generate accurate natural language responses. When a user asks about their leave balance, the system converts the question into a vector, searches for the most relevant policy content using the HANA Vector Database, and then uses an LLM to generate a clear answer based on that information.&lt;span class="lia-inline-image-display-wrapper lia-image-align-right" image-alt="27.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291720i783996A8E5F98AFF/image-size/large?v=v2&amp;amp;px=999" role="button" title="27.png" alt="27.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&amp;nbsp;&lt;FONT face="arial black,avant garde"&gt;Knowledge Graph:&lt;/FONT&gt; This graph is a&amp;nbsp;semantic network that connects entities (like customers, products, orders, employees, etc.) and defines how they are related. This helps Joule go beyond keyword matching or document lookup. It actually lets Joule "&lt;U&gt;understand&lt;/U&gt;" business context and structure.&amp;nbsp;&amp;nbsp;Joule uses the graph to understand how different entities are linked (e.g., â€œEmployee X belongs to Department Yâ€ or â€œInvoice A is tied to Purchase Order Bâ€). With this, Joule disambiguate questions and provide more accurate answers.&amp;nbsp; It also e&lt;SPAN&gt;nables &lt;/SPAN&gt;logical inferences&lt;SPAN&gt;, like&amp;nbsp;&lt;/SPAN&gt;â€œShow me all open invoices for suppliers in Germanyâ€, â€œList products related to a delayed shipmentâ€ etc.&amp;nbsp;Even if the data is spread across multiple systems, the graph can link them together efficiently.&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="28.png" style="width: 861px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291770iAD504DCD2BA843C5/image-dimensions/861x247?v=v2" width="861" height="247" role="button" title="28.png" alt="28.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT face="simsun,hei" color="#999999"&gt;Image sources:&amp;nbsp;&lt;A href="https://www.youtube.com/watch?v=6vG_amAshTk&amp;amp;list=LL&amp;amp;index=4&amp;amp;t=589s" target="_self" rel="nofollow noopener noreferrer"&gt;Knowledge Graph or Vector Databaseâ€¦ Which is Better? and&amp;nbsp;&amp;nbsp;&lt;/A&gt;&lt;A href="https://www.youtube.com/watch?v=knDDGYHnnSI&amp;amp;list=LL&amp;amp;index=1" target="_self" rel="nofollow noopener noreferrer"&gt;GraphRAG: The Marriage of Knowledge Graphs and RAG: Emil Eifrem&lt;/A&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;EM&gt;NOTE:&amp;nbsp;&lt;SPAN&gt;While &lt;/SPAN&gt;RAG&lt;SPAN&gt; brings in document-based context and &lt;/SPAN&gt;vector search&lt;SPAN&gt; finds the right text chunks, the &lt;/SPAN&gt;Knowledge Graph brings in structure and relationship-based logic&lt;SPAN&gt;.&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;Eg: RAG may find a document about a purchase policy, but the Knowledge Graph helps determine which department owns that policy and who can approve it.&lt;/SPAN&gt;&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;Does LLM gets trained with SAP's data?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;When SAPâ€™s AI assistant Joule interacts with a Large Language Model (LLM), it doesnâ€™t send data for storage or training. Instead, it shares information only briefly, as part of a prompt during runtime. The LLM uses this prompt to generate a response in real time, but it doesnâ€™t remember or learn from what it receives. Thus, LLMs are not trained against customer data.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;Joule's orchestration layer:&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="26.png" style="width: 882px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291687i58871CEC9669DD1B/image-size/large?v=v2&amp;amp;px=999" role="button" title="26.png" alt="26.png" /&gt;&lt;/span&gt;&lt;FONT face="simsun,hei" color="#999999"&gt;Image source:&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;FONT face="simsun,hei" color="#999999"&gt;&lt;A href="https://www.youtube.com/watch?v=m0BMI2v-REY" target="_self" rel="nofollow noopener noreferrer"&gt;Examining how to onboard and extend Joule | AI105&lt;/A&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Steps involved within Joule for processing user query:&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;User submits query in natural language via Joule client in SAP cloud apps&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;The prompt is sent to the Dialogue Management system, which manages the conversation flow and understands the user's intent.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000000"&gt;The Retrieval-Augmented Generation (RAG) service forms a semantic vector search query based on the user input.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;This query is executed against a Vector Database where document embeddings are stored. The relevant document extracts are retrieved.&amp;nbsp;These embeddings were created earlier from company-specific or SAP documents using document grounding&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;The retrieved document snippets are passed along with the original prompt to a Large Language Model. The LLM uses the relevant extracts to ground its response (ensuring the response is based on actual documents, not hallucinations).&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;The LLM generates a natural-language answer, grounded in the retrieved documents.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;The final answer is displayed to the user with source links and supporting documents attached.-&amp;gt;Example: A link to a company travel policy PDF is shown under â€œSource Documentâ€.&lt;/FONT&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;For more information, refer to &lt;A href="https://learning.sap.com/learning-journeys/provisioning-and-implementing-joule" target="_self" rel="noopener noreferrer"&gt;Provisioning and Implementing Joule learning journey&lt;/A&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;Deep dive into SAP Joule possible workflow to respond to any user prompt&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;Below is a scenario which is explained in SAP joule product page specified below where a sales manager who is logged into SAP Sales Cloud, sees that there is an upcoming meeting with a customer called MDT. She takes help of joules to get below information.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="simsun,hei" color="#999999"&gt;Please do watch the video below which depicts Joule in action before proceeding further.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="simsun,hei" color="#999999"&gt;&lt;A href="https://www.sap.com/assetdetail/2024/05/946160f3-be7e-0010-bca6-c68f7e60039b.html" target="_self" rel="noopener noreferrer"&gt;Introducing Joule - The AI copilot that truly understands your business&lt;/A&gt;&lt;/FONT&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="30.png" style="width: 644px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291746i95065A8624AE1821/image-size/large?v=v2&amp;amp;px=999" role="button" title="30.png" alt="30.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#0000FF"&gt;&lt;FONT color="#000000"&gt;USE CASE 1: Ask Joule to provide details about this customer so that she can be prepared or the meeting.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#FF0000"&gt;&lt;FONT color="#999999"&gt;CAUTION !&lt;/FONT&gt; &lt;FONT color="#999999"&gt;The below flow is only for illustration purpose as of how Joule MIGHT respond based on my assumptions. It must be used only for understanding purpose.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#0000FF"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="34.png" style="width: 853px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291772iF768B32792781004/image-size/large?v=v2&amp;amp;px=999" role="button" title="34.png" alt="34.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;USE CASE 2: She also asks Joules to extract the customer requirement by pasting the email in Joule prompt&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#0000FF"&gt;Workflow of use case 2:&amp;nbsp;&lt;/FONT&gt;&lt;FONT color="#0000FF"&gt;&amp;nbsp;&lt;FONT color="#000000"&gt;T&lt;/FONT&gt;&lt;/FONT&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#0000FF"&gt;&lt;FONT color="#000000"&gt;he user shares&amp;nbsp;a business email requesting a product recommendation for an industrial robot. This is a semi-structured prompt. Joule extracts the requirements from this text, matches it to product data, and provides a recommendation with pricing, configuration, and confidence level.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#FF0000"&gt;&lt;FONT color="#999999"&gt;CAUTION !&lt;/FONT&gt; &lt;FONT color="#999999"&gt;The below flow is only for illustration purpose as of how Joule MIGHT respond based on my assumptions.It must be used only for understanding purpose.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#FF0000"&gt;&lt;FONT color="#999999"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="35.png" style="width: 854px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291773iCA76ED186B4095E8/image-size/large?v=v2&amp;amp;px=999" role="button" title="35.png" alt="35.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;USE CASE 3: User asks Joule about the expense limit for business meals in Germany&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;EM&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="31.png" style="width: 542px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291774i45C7655404DA150B/image-size/large?v=v2&amp;amp;px=999" role="button" title="31.png" alt="31.png" /&gt;&lt;/span&gt;&lt;/EM&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#0000FF"&gt;Workflow of use case 3:&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#FF0000"&gt;&lt;FONT color="#999999"&gt;CAUTION !&lt;/FONT&gt; &lt;FONT color="#999999"&gt;The below flow is only for illustration purpose as of how Joule MIGHT respond based on my assumptions.It must be used only for understanding purpose.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#FF0000"&gt;&lt;FONT color="#999999"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="36.png" style="width: 850px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291775iD1A7039DD7778FBE/image-size/large?v=v2&amp;amp;px=999" role="button" title="36.png" alt="36.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;We can infer that most of the structured user queries are predominantly handled by SAP Knowledge graph while unstructured queries are handled through RAG which in turn works with HANA Vector Database.&lt;/FONT&gt;&lt;/P&gt;&lt;H3 id="toc-hId-685906054"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000080"&gt;SECTION 4: Joule packages and pricing: Base and premium&lt;/FONT&gt;&lt;/H3&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Joules comes in 2 different packages for consumption:&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#800080"&gt;Joule Base (No additional cost involved)&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#800080"&gt;Joule Premium&lt;/FONT&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;STRONG&gt;&lt;FONT color="#0000FF"&gt;A. SAP Joule Base package:&amp;nbsp;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#000000"&gt;Joule Base package is available as supplement to all eligible SAP cloud subscriptions&amp;nbsp;at no additional cost. As a prerequisite customer m&lt;/FONT&gt;ust have an active subscription to a supported SAP cloud product (e.g., SAP SuccessFactors).&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde"&gt;Current entitlements:&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#800080"&gt;Joule for developers, ABAP AI capabilities:&lt;/FONT&gt; To accelerate ABAP development with Joule&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#800080"&gt;Joule with SAP Fieldglass solutions:&lt;/FONT&gt;&amp;nbsp;Enhance efficiencies across hiring processes with AI&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#800080"&gt;Joule with SAP LeanIX:&lt;/FONT&gt;&amp;nbsp;Search and navigate to the right information through natural language queries.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#800080"&gt;Joule with SAP S/4HANA Cloud Private Edition:&lt;/FONT&gt;&amp;nbsp;Streamline the informational, navigational, and transactional tasks.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#800080"&gt;Joule with SAP S/4HANA Cloud Public Edition:&lt;/FONT&gt;&amp;nbsp;Streamline the informational, navigational, and transactional tasks.&lt;/FONT&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde"&gt;Features:&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Provides access to a base set of Jouleâ€™s AI functions.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Supports navigation, information retrieval, and basic task assistance within SAP cloud solutions.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Unlimited usage under a flat fee model.&lt;/FONT&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Joule is a central service and hence customer must choose&amp;nbsp;the SAP BTP global account to attach Joule to in case of base package.&amp;nbsp;&amp;nbsp;&lt;FONT color="#999999"&gt;For more information on this regard, please refer to links below.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#999999"&gt;&lt;A href="https://discovery-center.cloud.sap/ai-catalog/?searchValue=joule%20base" target="_blank" rel="noopener nofollow noreferrer"&gt;AI Catalog - Joule Base&lt;/A&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#999999"&gt;&lt;A href="https://www.sap.com/products/artificial-intelligence/joule-base-entitlement.html" target="_self" rel="noopener noreferrer"&gt;SAP Joule Base Entitlement&lt;/A&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;STRONG&gt;&lt;FONT color="#0000FF"&gt;B. SAP Joule Premium package:&amp;nbsp;&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Joule Premium enhances the Joule Base with domain-specific and agentic AI features. It is available as a paid add-on through AI Units.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT face="arial black,avant garde"&gt;Premium Packages by Business applications&lt;/FONT&gt;(as on date 25th July 25):&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;SPAN&gt;&lt;FONT color="#800080"&gt;Joule Premium for financial management:&lt;/FONT&gt; D&lt;/SPAN&gt;elivers deep financial insights and smart summarizations tailored for finance users. It brings in agent-driven capabilities that cover both transactional and analytical needs â€” helping finance teams make better, faster decisions.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#800080"&gt;Joule Premium for spend management:&lt;/FONT&gt; With features like Category Segmentation and Statement of Work (SOW) Description Generation, Joule Premium supports procurement and finance functions in improving efficiency and streamlining sourcing processes.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#800080"&gt;Joule Premium for supply chain management:&lt;/FONT&gt; Enhances supply chain visibility with intelligent tools such as Equipment Insights and ESG Report Generation â€” boosting transparency and operational awareness across logistics and asset-heavy processes.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&amp;nbsp;&lt;FONT color="#800080"&gt;Joule Premium for human capital management:&lt;/FONT&gt; HR teams can benefit from AI-Assisted Writing, Interview Feedback Insights, and other intelligent capabilities that help improve talent processes, communications, and candidate engagement.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#800080"&gt;Joule Premium for customer experience:&lt;/FONT&gt; Designed to enhance customer engagement, Joule Premium in CX includes innovative features like Image Generation and Lead Booster to drive personalized interactions and improved conversions.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#800080"&gt;SAP Joule for Consultants:&lt;/FONT&gt; SAP Joule empowers consultants with expert-level AI guidance, helping them accelerate SAP cloud deployments and ensure higher implementation quality and productivity.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#800080"&gt;Joule for Developers:&lt;/FONT&gt; Joule acts as a real-time AI assistant for SAP developers, offering on-the-fly explanations of development objects, quick answers to dev-related queries, and seamless learning support.&lt;/FONT&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;U&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;Costing involved with Premium packages: &lt;/FONT&gt;&lt;STRONG&gt;&lt;FONT color="#800080"&gt;AI Units&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/U&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;SAP Joules premium packages can be bought from the &lt;FONT color="#800080"&gt;AI Catalog of Discovery center&lt;/FONT&gt;.&amp;nbsp;&lt;/FONT&gt;&lt;SPAN&gt;URL:&lt;/SPAN&gt;&lt;A href="https://discovery-center.cloud.sap/ai-catalog" target="_self" rel="nofollow noopener noreferrer"&gt;https://discovery-center.cloud.sap/ai-catalog&lt;/A&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;These are priced based on &lt;STRONG&gt;AI Units&lt;/STRONG&gt;, which serve as a virtual currency that can be used across all SAP cloud products and lines of business through a shared AI Unit pool. AI Units are calculated based on predefined business metrics (e.g., transactions, pages, users, expenses), with each metric having its own conversion rate (e.g., 1 transaction = X AI Units).&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Purchasing premium licenses typically includes a fixed number of Joule messages per year (e.g., RISE with SAP S/4HANA Cloud Premium includes approximately 2,500 messages). A single message refers to one user ask and the corresponding Joule response. Any usage beyond the included quota will consume additional AI Units.&lt;/FONT&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;SAP provides an &lt;A href="https://discovery-center.cloud.sap/aiestimatorhelp" target="_self" rel="nofollow noopener noreferrer"&gt;AI Unit Estimator Tool&lt;/A&gt; to help estimate AI Unit requirements based on selected capabilities and transaction volume. A quote can be requested directly through the estimator.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Below is a sample screenshot from the Discovery Center showing how to search for the package. It also displays the list of functionalities available under 'Joule Premium for Human Capital Management'.&amp;nbsp;To purchase a specific functionality within this package, click on the corresponding tile to view its estimate and understand the pricing.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="13.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291283i8497977091BC409D/image-size/large?v=v2&amp;amp;px=999" role="button" title="13.png" alt="13.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;H3 id="toc-hId-489392549"&gt;&lt;FONT color="#000080"&gt;SECTION 5: Joule functionalities that is targeted at technology consultants&lt;/FONT&gt;&lt;/H3&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#000000"&gt;Two of the Joule premium that can help technology consultants are&amp;nbsp;&lt;/FONT&gt;Joule for Consultants and&amp;nbsp;Joule for developers.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;U&gt;&lt;STRONG&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#0000FF"&gt;A.&amp;nbsp;Joule for Consultants:&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/U&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;SAP Joule for Consultants is a conversational AI solution that speeds up SAP cloud transformations by providing expert guidance drawn from SAPâ€™s most extensive and carefully curated knowledge base.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;Key uses:&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;It is designed to reduce substantial amount of search time.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&amp;nbsp;It helps to interpret custom code faster.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;It avoids rework and helps with improving the quality of work.&lt;/FONT&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;To enable Joule for Consultant kick start using the mission&amp;nbsp;&lt;A href="https://discovery-center.cloud.sap/missiondetail/4633/4922/" target="_self" rel="nofollow noopener noreferrer"&gt;Enable SAP Joule for Consultants&lt;/A&gt;&amp;nbsp;.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="16.png" style="width: 825px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291301i7A9BD79A7B7475CB/image-dimensions/825x487?v=v2" width="825" height="487" role="button" title="16.png" alt="16.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Some of the use cases of this product as described in SAP product page at URL&amp;nbsp;&lt;A href="https://www.sap.com/india/products/artificial-intelligence/ai-assistant/sap-consulting-capability.html" target="_self" rel="noopener noreferrer"&gt;SAP Joule for Consultants&lt;/A&gt;&amp;nbsp;are:&lt;/FONT&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="17.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291311iF36A88EACB349A90/image-size/large?v=v2&amp;amp;px=999" role="button" title="17.png" alt="17.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#0000FF"&gt;&lt;U&gt;&lt;STRONG&gt;B.&amp;nbsp;Joule for Developers:&lt;/STRONG&gt;&lt;/U&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Joule for developers is part of SAP's Build portfolio. The primary objective of SAP Build is to enable citizen developers (business or end users) to build applications, processes, and business websites through visual drag-and-drop elements. It also helps professional developers accelerate development by generating data models, services, UI components, sample data, and business logic using Joule prompts.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT color="#999999"&gt;NOTE: Joule with SAP Build is available as part of trial account or free tier. Upcoming SAP build details will have links to exercises that can be tried out with &lt;A href="https://www.sap.com/india/products/technology-platform/process-automation/trial.html" target="_self" rel="noopener noreferrer"&gt;SAP BTP trial account&lt;/A&gt;.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000000"&gt;Key components of SAP Build are:&lt;/FONT&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#993366"&gt;&lt;FONT color="#3366FF"&gt;SAP Build Apps:&lt;/FONT&gt;&amp;nbsp;&lt;/FONT&gt;SAP Build Apps helps both business users and developers quickly create and customize applications using low-code, AI assistance, and reusable modulesâ€”ensuring fast, collaborative development across SAP and non-SAP systems.&lt;/FONT&gt;&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#3366FF"&gt;SAP Build Code&lt;/FONT&gt;: SAP Build Code is a powerful generative AIâ€“based code development environment for professional developers, offering end-to-end support for Java and JavaScript, AI-assisted coding with Joule, and a streamlined experience for collaborative SAP development across both expert and citizen developers. It provides a&amp;nbsp;turnkey environment for coding, testing, integrations, and application lifecycle management.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#3366FF"&gt;SAP Build Process Automation:&lt;/FONT&gt; SAP Build Process Automation lets both business users and developers automate workflows without coding, using drag-and-drop tools, AI, and pre-built contentâ€”boosting productivity, enabling collaboration, and running securely on SAP Business Technology Platform.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#3366FF"&gt;SAP Build Work Zone:&lt;/FONT&gt; SAP Build Work Zone is a user-friendly platform that brings together apps, tools, and content in one place to help employees work smarter and stay informed by building digital workspaces &amp;amp; sites.&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;FONT color="#3366FF"&gt;SAP Build Content Catalog:&lt;/FONT&gt; Prebuilt business content &amp;amp; templates that can be reused during application build.&lt;/FONT&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="18.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291436iF9917EA948D477C5/image-size/large?v=v2&amp;amp;px=999" role="button" title="18.png" alt="18.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000080"&gt;&lt;FONT color="#000000"&gt;&lt;FONT face="arial black,avant garde"&gt;A. Joule and SAP Build Code:&lt;/FONT&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000080"&gt;&lt;FONT color="#000000"&gt;Below screen shot depicts how Joule is able to generate data sets, sample data, logic and so on using AI.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000080"&gt;&lt;FONT color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="19.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291644iC4294ABEDD4B7FE2/image-size/large?v=v2&amp;amp;px=999" role="button" title="19.png" alt="19.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000080"&gt;&lt;FONT color="#000000"&gt;For more information check the learning journey and git hub for sample application creation detailed steps.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://trials.cfapps.eu10-004.hana.ondemand.com/learning-journey/BT-Build_code" target="_self" rel="nofollow noopener noreferrer"&gt;SAP Build Learning Journey&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://github.com/SAP-samples/build-code-connect-2024/tree/main/Customer_Loyalty_Program" target="_self" rel="nofollow noopener noreferrer"&gt;Customer_Loyalty_Program&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000080"&gt;&lt;FONT color="#000000"&gt;B. Joule and SAP Build Process automation:&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial, helvetica, sans-serif" color="#000000"&gt;Below screen shots indicate how joule can be used for SAP Build process automation.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial, helvetica, sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="20.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291652i852A87EA14772CB3/image-size/large?v=v2&amp;amp;px=999" role="button" title="20.png" alt="20.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial, helvetica, sans-serif" color="#000000"&gt;For more information, refer to below link:&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://learning.sap.com/learning-journeys/develop-and-automate-with-sap-build/automating-processes-with-sap-build-automation" target="_self" rel="noopener noreferrer"&gt;Creating a sample application with SAP Build Process Automation&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000080"&gt;&lt;FONT color="#000000"&gt;C. SAP Build Work Zone:&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial, helvetica, sans-serif" color="#000000"&gt;Below screen shots depicts how a business site can be created using drag and drop options with built in icons and buttons.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial, helvetica, sans-serif" color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="21.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291678iD41AC718109EE642/image-size/large?v=v2&amp;amp;px=999" role="button" title="21.png" alt="21.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="22.png" style="width: 778px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291679i3135A3118C002B50/image-size/large?v=v2&amp;amp;px=999" role="button" title="22.png" alt="22.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000080"&gt;&lt;FONT color="#000000"&gt;Follow below tutorial to create business websites.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P class=""&gt;&lt;A href="https://developers.sap.com/mission.workzone-workshop.html" target="_self" rel="noopener noreferrer"&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;Create Your First Workspace in SAP Build Work Zone, advanced edition Workshop&lt;/FONT&gt;&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial black,avant garde" color="#000080"&gt;&lt;FONT color="#000000"&gt;D. SAP Build App:&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000080"&gt;&lt;FONT color="#000000"&gt;Below screen shot shows how a citizen developers (Business or end users) can build a Mobile front-end application through drag and drop options within 20 mins.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000080"&gt;&lt;FONT color="#000000"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="23.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/291680i93B513691A3C7861/image-size/large?v=v2&amp;amp;px=999" role="button" title="23.png" alt="23.png" /&gt;&lt;/span&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000080"&gt;&lt;FONT color="#000000"&gt;For more details as of how to build this app, check the below link.&lt;/FONT&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://learning.sap.com/learning-journeys/develop-and-automate-with-sap-build/creating-a-first-application-with-sap-build-apps" target="_self" rel="noopener noreferrer"&gt;Creating a sample application with SAP Build Apps:&lt;/A&gt;&lt;/P&gt;&lt;H3 id="toc-hId-292879044"&gt;&lt;FONT color="#000080"&gt;SECTION 6: Other important links and references&lt;/FONT&gt;&lt;/H3&gt;&lt;OL&gt;&lt;LI&gt;&lt;FONT color="#000080"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;A href="https://community.sap.com/t5/enterprise-resource-planning-blog-posts-by-sap/joule-for-sap-s-4hana-cloud-private-edition-a-comprehensive-setup-guide/ba-p/13786453" target="_self"&gt;Joule for SAP S/4HANA Cloud Private Edition - A Comprehensive Setup Guide&lt;/A&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000080"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;A href="https://discovery-center.cloud.sap/missiondetail/4452/4738/" target="_self" rel="nofollow noopener noreferrer"&gt;Activate Joule with SAP S/4HANA Cloud Public Edition&lt;/A&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000080"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;A href="https://discovery-center.cloud.sap/missiondetail/4451/4737/" target="_self" rel="nofollow noopener noreferrer"&gt;Activate Joule for SAP SuccessFactors&lt;/A&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000080"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;A href="https://www.youtube.com/watch?v=Uiv29xYlXvQ" target="_self" rel="nofollow noopener noreferrer"&gt;Improve RAG performance with Knowledge Graphs, Generative AI Hub and SAP BTP&lt;/A&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT color="#000080"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;&lt;A href="https://learning.sap.com/learning-journeys/provisioning-and-implementing-joule" target="_self" rel="noopener noreferrer"&gt;Provisioning and Implementing Joule&lt;/A&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A title="GraphRAG: The Marriage of Knowledge Graphs and RAG: Emil Eifrem" href="https://www.youtube.com/watch?v=knDDGYHnnSI" target="_self" rel="nofollow noopener noreferrer"&gt;&lt;FONT color="#000080"&gt;&lt;FONT color="#000080"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;FONT face="arial,helvetica,sans-serif"&gt;G&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/FONT&gt;raphRAG: The Marriage of Knowledge Graphs and RAG: Emil Eifrem&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://www.youtube.com/watch?v=6vG_amAshTk&amp;amp;list=LL&amp;amp;index=3&amp;amp;t=589s" target="_self" rel="nofollow noopener noreferrer"&gt;Knowledge Graph or Vector Databaseâ€¦ Which is Better?&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#000000"&gt;&lt;A href="https://learning.sap.com/learning-journeys/provisioning-and-implementing-joule" target="_self" rel="noopener noreferrer"&gt;Joule's learning journey&lt;/A&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;H5 id="toc-hId-354530977"&gt;&lt;FONT color="#993366"&gt;&lt;SPAN&gt;Thus, Joule is DECODED!&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/H5&gt;&lt;H5 id="toc-hId--762185349"&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#993366"&gt;&lt;SPAN&gt;Thanks for making until here! Hope I was able to help!&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/H5&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#808080"&gt;Rajarajeswari Kaliyaperumal&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="arial,helvetica,sans-serif" color="#808080"&gt;Author of&amp;nbsp;the book 'SAP HANA 2.0 Installation and Administration A Practical Guide'&lt;/FONT&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;FONT color="#999999"&gt;&lt;FONT face="simsun,hei"&gt;Available now in&lt;/FONT&gt;&lt;FONT face="simsun,hei"&gt;&amp;nbsp;&lt;A href="https://a.co/d/0HIWp24" target="_self" rel="nofollow noopener noreferrer"&gt;Amazon US&lt;/A&gt;,&lt;A href="https://amzn.in/d/7kSqOQk" target="_self" rel="nofollow noopener noreferrer"&gt;Amazon India,&amp;nbsp;&lt;/A&gt;&lt;A href="https://a.co/d/23fBSNk" target="_self" rel="nofollow noopener noreferrer"&gt;Amazon Mexico&amp;nbsp;&lt;/A&gt;&amp;nbsp;and&amp;nbsp;&lt;A href="https://a.co/d/eEccyGp" target="_self" rel="nofollow noopener noreferrer"&gt;Amazon Brazil&lt;/A&gt;&amp;nbsp;&lt;/FONT&gt;&lt;/FONT&gt;&lt;/DIV&gt;&lt;/DIV&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/sap-joule-for-beginners-everything-you-need-to-know-all-at-one-stop/ba-p/14160885"/>
    <published>2025-07-26T07:38:02.640000+02:00</published>
  </entry>
</feed>
