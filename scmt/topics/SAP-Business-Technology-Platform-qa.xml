<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/SAP-Business-Technology-Platform-qa.xml</id>
  <title>SAP Community - SAP Business Technology Platform</title>
  <updated>2025-09-29T17:00:51.600219+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/SAP Business Technology Platform/pd-p/73555000100700000172" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>SAP Business Technology Platform Q&amp;A in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/honecomb-mta-scan-error-path-workspace-source-our-app-our-app-target-our/qaq-p/14215995</id>
    <title>honecomb mta-scan error: path /workspace/source-our-app/our-app/target/our-app-1.0.0.jar/ not exists</title>
    <updated>2025-09-12T18:17:01.293000+02:00</updated>
    <author>
      <name>Sonali_Gandhare71</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1998666</uri>
    </author>
    <content>&lt;P&gt;Hello Team,&lt;BR /&gt;We have CodeQL(2.21.4) tool configured in github-&amp;gt;Repo-&amp;gt;Security-&amp;gt;Code Scanning.&lt;/P&gt;&lt;P&gt;In honeycomb, we have MTA-SCAN pipeline setup and we can run the scan from honeycomb.&lt;/P&gt;&lt;P&gt;Earlier the scan was running fine but recently its failing.&lt;/P&gt;&lt;P&gt;Its forming below command:&lt;BR /&gt;codeql database create /workspace/source-our-app/our-app/target/our-app-1.0.0.jar/codeqldb --source-root /workspace/source-our-app/our-app/target/our-app-1.0.0.jar --threads=0 --overwrite --language=java-kotlin --command='mvn package -DskipTests=true'&lt;BR /&gt;&lt;BR /&gt;and this command failing with error:&lt;BR /&gt;Path /workspace/source-our-app/our-app/target/our-app-1.0.0.jar does not exists.&lt;/P&gt;&lt;P&gt;CodeQL creates workspace path in previous step as : /workspace/source-our-app&lt;/P&gt;&lt;P&gt;and then it is appending our-app/target/our-app-1.0.0.jar in next step in create command.&lt;/P&gt;&lt;P&gt;This our-app/target/our-app-1.0.0.jar path is configured in mta.yml.&lt;/P&gt;&lt;P&gt;If we modify mta.yml to change path to '.' mta-scan works but deployment to btp will fail.&lt;/P&gt;&lt;P&gt;So any workaround or fix for this issue.&lt;/P&gt;&lt;P&gt;How can we fix path for create command without modifying path in mta.yml.&lt;/P&gt;&lt;P&gt;Any other settings required in github in our repo ?&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/honecomb-mta-scan-error-path-workspace-source-our-app-our-app-target-our/qaq-p/14215995"/>
    <published>2025-09-12T18:17:01.293000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-handle-cross-global-account-subscriptions-and-customer-managed-hana/qaq-p/14218979</id>
    <title>How to Handle Cross-Global Account Subscriptions and Customer-Managed HANA in CAP SaaS?</title>
    <updated>2025-09-16T17:54:13.141000+02:00</updated>
    <author>
      <name>MoudhafferAzizi</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2119453</uri>
    </author>
    <content>&lt;P&gt;A SaaS solution built using &lt;STRONG&gt;SAP CAP (Node.js)&lt;/STRONG&gt; with &lt;STRONG&gt;MTX-enabled multitenancy&lt;/STRONG&gt; is currently running in production with several subscribed tenants (subaccounts under the same global account).&lt;/P&gt;&lt;P&gt;The solution is deployed as an MTA in a &lt;STRONG&gt;provider subaccount&lt;/STRONG&gt;, while each customer has a &lt;STRONG&gt;dedicated subscriber subaccount&lt;/STRONG&gt; to consume the application.&lt;/P&gt;&lt;H3 id="toc-hId-1889237892"&gt;HANA setup&lt;/H3&gt;&lt;P&gt;At the moment, I use a &lt;STRONG&gt;shared HANA Cloud database&lt;/STRONG&gt;. The &lt;STRONG&gt;MTX sidecar&lt;/STRONG&gt; creates a Service Manager HDI container for each tenant, and together with the CDS framework, it handles multitenancy properly.&lt;/P&gt;&lt;H3 id="toc-hId-1692724387"&gt;Customer concern&lt;/H3&gt;&lt;P&gt;One customer raised &lt;STRONG&gt;data privacy concerns&lt;/STRONG&gt;, since the solution connects to their &lt;STRONG&gt;S/4HANA system&lt;/STRONG&gt; (via Cloud Connector) and stores data in &lt;STRONG&gt;our HANA Cloud&lt;/STRONG&gt;.&lt;/P&gt;&lt;H3 id="toc-hId-1496210882"&gt;My questions&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;Part 1:&lt;/STRONG&gt; Is it possible for a customer to subscribe to the SaaS application from a &lt;STRONG&gt;subaccount in a different global account&lt;/STRONG&gt; (not the same global account as the provider subaccount)? I am particularly thinking about potential &lt;STRONG&gt;XSUAA-related challenges&lt;/STRONG&gt; here.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Part 2:&lt;/STRONG&gt; Is it possible to support a &lt;STRONG&gt;‚Äúbring your own HANA‚Äù (BYO HANA)&lt;/STRONG&gt; model, where the CDS framework would connect to a &lt;STRONG&gt;customer-managed HANA instance&lt;/STRONG&gt; instead of the shared one?&lt;/P&gt;&lt;P&gt;I understand this may be a stretch given the current state of CAP applications, but I‚Äôd appreciate any insights into what &lt;STRONG&gt;SAP offers in terms of architectural possibilities and limitations&lt;/STRONG&gt; in this area.&lt;BR /&gt;&lt;BR /&gt;Thank you !&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-handle-cross-global-account-subscriptions-and-customer-managed-hana/qaq-p/14218979"/>
    <published>2025-09-16T17:54:13.141000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-integration-suite-unavailable-in-marketplace-after-adding-it-in/qaq-p/14219529</id>
    <title>SAP Integration Suite unavailable in marketplace after adding it in entitlements in KSA-sa30 region</title>
    <updated>2025-09-17T08:19:42.023000+02:00</updated>
    <author>
      <name>I766318</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2180879</uri>
    </author>
    <content/>
    <link href="https://community.sap.com/t5/technology-q-a/sap-integration-suite-unavailable-in-marketplace-after-adding-it-in/qaq-p/14219529"/>
    <published>2025-09-17T08:19:42.023000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/cap-how-to-update-association-of-remote-entity-without-duplicating-entries/qaq-p/14220394</id>
    <title>CAP - How to Update Association of Remote Entity without Duplicating Entries in Local DB ?</title>
    <updated>2025-09-17T18:36:24.204000+02:00</updated>
    <author>
      <name>DavidBrodmann</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/168790</uri>
    </author>
    <content>&lt;P&gt;Dear Reader,&amp;nbsp;&lt;/P&gt;&lt;P&gt;I have a question about how to deal with remote associations when updating their values from my local CAP application.&lt;/P&gt;&lt;P&gt;Imagine having a schema like this:&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;entity Products : cuid {
    name  : String;
    price : Integer;
    order : Association to Orders;
    /*
    totalQuantiy : type of order.TotalQuantity;
    startDate    : type of order.MfgOrderPlannedStartDate;
    endDate      : type of order.MfgOrderPlannedEndDate;
    */
}

entity Orders                      as
    projection on API_PRODUCTION_ORDER_2_SRV {
        key ManufacturingOrder,
            TotalQuantity,
            MfgOrderPlannedStartDate,
            MfgOrderPlannedEndDate,
    }&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;My local CAP application has a Fiori-Eelements frontend and displays all the fields of "Products" in an object page and I dynamically add associated fields to "TotalQuantity", "StartDate" and "EndDate" from remote entity "Orders". So when I am reading my "Products" I expand the read to the remote entity with my custom handler, everything is fine.&amp;nbsp;&lt;/P&gt;&lt;P&gt;But what if I want to update certain elements, like&amp;nbsp;"TotalQuantity", "StartDate" and "EndDate" from the remote entity?&lt;BR /&gt;My Entity "Products" is draft enabled, but changes in the fields "TotalQuantity", "StartDate" and "EndDate" of the association are not triggering any "PUSH" or "UPDATE" event in the backend.&amp;nbsp;&lt;/P&gt;&lt;P&gt;The problem is, I don't want to persistently add the fields&amp;nbsp;"TotalQuantity", "StartDate" and "EndDate" to the entity "Products", that is why I added them in /* */.&lt;BR /&gt;I tried making them virtual or computed fields, but then they are also read-only for the Fiori frontend and no event is triggered when changing them. New values are also not delivered to the backend on "save" button in the frontend.&amp;nbsp;&lt;/P&gt;&lt;P&gt;So the question for me remains, is it only possible to send draft values from the frontend to the backend on persistently saved elements ?&lt;BR /&gt;or is there another way I am missing, to somehow allow me to change the values in the fields&amp;nbsp;"TotalQuantity", "StartDate" and "EndDate" and receive the new values in the backend, so I can update the remote entity ?&lt;/P&gt;&lt;P&gt;I hope i explained the problem somehow understandable, otherwise feel free to tell me so I can update &lt;span class="lia-unicode-emoji" title=":slightly_smiling_face:"&gt;üôÇ&lt;/span&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;thanks for your time, greetings&lt;/P&gt;&lt;P&gt;David&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/cap-how-to-update-association-of-remote-entity-without-duplicating-entries/qaq-p/14220394"/>
    <published>2025-09-17T18:36:24.204000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/trail-account-integration-suite-subscription-failed/qaq-p/14221167</id>
    <title>Trail account integration suite subscription failed</title>
    <updated>2025-09-18T12:45:32.758000+02:00</updated>
    <author>
      <name>JhansiRani</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1465185</uri>
    </author>
    <content>Hi Experts , In SAP CPI Trail account while subscribing Integration suite it is failing due to couldn't subscribe. Please any one faced this issue let me know solution. **Error: Couldn't subscribe to Integration Suite. Try again. If the problem persists, please post a question to SAP Community.** Best Regards, Jhansi</content>
    <link href="https://community.sap.com/t5/technology-q-a/trail-account-integration-suite-subscription-failed/qaq-p/14221167"/>
    <published>2025-09-18T12:45:32.758000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/delta-sync-issue-in-ssam-2505-with-basic-authentication/qaq-p/14221607</id>
    <title>Delta Sync Issue in SSAM 2505 with Basic Authentication</title>
    <updated>2025-09-18T17:21:37.595000+02:00</updated>
    <author>
      <name>sushma1001</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1517124</uri>
    </author>
    <content>&lt;P&gt;Hi Experts,&lt;/P&gt;&lt;P&gt;We are setting up a new development application using SAP Service and Asset Manager (SSAM) 2505 with Basic Authentication. During testing, we noticed that delta sync is not working consistently.&lt;/P&gt;&lt;P&gt;Some mobile users are receiving the latest backend changes through delta sync, while others are not. This is causing data mismatches across devices.&lt;/P&gt;&lt;P&gt;Has anyone faced similar issues with delta sync when using Basic Authentication? Any suggestions or insights would be helpful.&lt;/P&gt;&lt;P&gt;Thank you in advance!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/delta-sync-issue-in-ssam-2505-with-basic-authentication/qaq-p/14221607"/>
    <published>2025-09-18T17:21:37.595000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-use-bdwreferencerequest-in-inside-a-sap-integration-suite-iflow-for/qaq-p/14221778</id>
    <title>How to use bdwreferencerequest_in inside a SAP Integration suite iflow for POST operation</title>
    <updated>2025-09-18T21:48:58.979000+02:00</updated>
    <author>
      <name>amitpathak</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/138357</uri>
    </author>
    <content>&lt;P&gt;Hi,&lt;/P&gt;&lt;P&gt;I have a requirement to create a billing document based on input SalesOrderID. This has to be done inside AP Integration suite (BTP).I looked through various options including oData v4 which does not allows this:&lt;/P&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;SPAN&gt;"message": &lt;SPAN&gt;"Creating operations are disabled for entity '$SRVD_A2X#API_BILLINGDOCUMENT~A_BILLINGDOCUMENT_2'",&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;SPAN&gt;So I narrowed down to &lt;EM&gt;SOAP API&lt;/EM&gt;,&amp;nbsp;&lt;STRONG&gt;bdwreferencerequest_in&lt;/STRONG&gt;. However my integration suite is failing at this POST step with unclear error message. Can someone please explain what should be the URL, required configurations and sample payload for this request.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://api.sap.com/api/BDWREFERENCEREQUEST_IN/overview" target="_blank" rel="noopener noreferrer"&gt;https://api.sap.com/api/BDWREFERENCEREQUEST_IN/overview&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;#SAP BTP&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Integration+Suite/pd-p/73554900100800003241" class="lia-product-mention" data-product="23-1"&gt;SAP Integration Suite&lt;/a&gt;&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-use-bdwreferencerequest-in-inside-a-sap-integration-suite-iflow-for/qaq-p/14221778"/>
    <published>2025-09-18T21:48:58.979000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/support-for-16kb-page-compatibility-in-appgyver-which-google-is-requiring/qaq-p/14221816</id>
    <title>Support for 16KB page compatibility in AppGyver, which Google is requiring</title>
    <updated>2025-09-18T23:09:08.091000+02:00</updated>
    <author>
      <name>portfolioz</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1768137</uri>
    </author>
    <content>&lt;PRE&gt;&lt;SPAN&gt;The Google Play Console has now required all Android apps to support 16KB pages by November 1, 2025, and has stated that apps will need to be recompiled to ensure continuous updates. Failure to meet this requirement may result in the app being suspended from the platform.

Since we use AppGyver (no-code) to develop our apps, we don't have direct access to the build settings. Therefore, it is essential that, at the time of creation, the app is generated in compliance with this technical requirement, that is, with support for 16KB pages.

In light of this, I am requesting guidance and support from SAP to ensure that, when editing or creating new apps in AppGyver, the generated build package complies with the new Google Play Console requirements.

Thank you in advance for your attention and I look forward to hearing from you with instructions on how to proceed in this case. If possible, please send me the links where I can ask for help, since the build generated in AppGyver is done using no-code, without the possibility of manual adjustments, and must already be compiled in the version requested by Google.

Project ID: P2006971219
Contact email: &lt;A href="mailto:portfoliozx@gmail.com" target="_blank" rel="noopener nofollow noreferrer"&gt;portfoliozx@gmail.com&lt;/A&gt;

Sincerely,
Vianeis Rodrigues Pereira.&lt;/SPAN&gt;&lt;/PRE&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/support-for-16kb-page-compatibility-in-appgyver-which-google-is-requiring/qaq-p/14221816"/>
    <published>2025-09-18T23:09:08.091000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/power-designer-reverse-engeneering-postgresql-using-script-file/qaq-p/14225557</id>
    <title>Power Designer - Reverse Engeneering Postgresql using script file</title>
    <updated>2025-09-23T13:16:51.344000+02:00</updated>
    <author>
      <name>Ulrich_Ruppel</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2255972</uri>
    </author>
    <content>&lt;P&gt;Hi,&lt;/P&gt;&lt;P&gt;Reverse Engeneering Postgresql using script file leads to the Tables and views defined in the pg_dump.sql file. But: All indexes and foreign key relationships are not in the PDM generated.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Using the same script file and creating a Postgres database and do the reverse engeneering against this new DB will generate these important informations.&lt;/P&gt;&lt;P&gt;Have you experienced the same issue? is there a fix for that problem known?&lt;/P&gt;&lt;P&gt;Thanks&lt;/P&gt;&lt;P&gt;Ulrich&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/power-designer-reverse-engeneering-postgresql-using-script-file/qaq-p/14225557"/>
    <published>2025-09-23T13:16:51.344000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-download-libsapcrypto-dll/qaq-p/14226753</id>
    <title>How to download libsapcrypto.dll</title>
    <updated>2025-09-24T12:36:30.965000+02:00</updated>
    <author>
      <name>vijayakumarm</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2256223</uri>
    </author>
    <content>&lt;P&gt;I need a guidance to download this&amp;nbsp;libsapcrypto.dll .&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-download-libsapcrypto-dll/qaq-p/14226753"/>
    <published>2025-09-24T12:36:30.965000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/unable-to-subscribe-to-sap-build-process-automation/qaq-p/14227810</id>
    <title>unable to subscribe to SAP build process automation</title>
    <updated>2025-09-25T13:29:56.589000+02:00</updated>
    <author>
      <name>sri_s471</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2256462</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;Hi ,&lt;/SPAN&gt;&lt;BR /&gt;&lt;SPAN&gt;I have been trying to subscribe to SAP Build process automation, but I am getting subscription failed error, I have also checked for BPA boosters, but its not available in my account.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="sri_s471_0-1758799639884.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/319820i65491018B3AD5DF3/image-size/medium?v=v2&amp;amp;px=400" role="button" title="sri_s471_0-1758799639884.png" alt="sri_s471_0-1758799639884.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="sri_s471_2-1758799686856.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/319822i5B6738DAF5FC7FBD/image-size/medium?v=v2&amp;amp;px=400" role="button" title="sri_s471_2-1758799686856.png" alt="sri_s471_2-1758799686856.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Build+Process+Automation/pd-p/73554900100800003832" class="lia-product-mention" data-product="1213-1"&gt;SAP Build Process Automation&lt;/a&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/unable-to-subscribe-to-sap-build-process-automation/qaq-p/14227810"/>
    <published>2025-09-25T13:29:56.589000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/cap-bookshop-fiori-example-quot-error-cannot-find-module-capire-bookshop/qaq-p/14228739</id>
    <title>CAP bookshop (Fiori) example: "Error: Cannot find module '@capire/bookshop/package.json'"</title>
    <updated>2025-09-26T11:57:40.877000+02:00</updated>
    <author>
      <name>jens_glander</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/188695</uri>
    </author>
    <content>&lt;P&gt;Hi,&lt;/P&gt;&lt;P&gt;I'm trying to get the CAP bookshop (Fiori) example running and run into&amp;nbsp;"Error: Cannot find module '@capire/bookshop/package.json'"&lt;/P&gt;&lt;P&gt;Steps I executed described in [1].&lt;/P&gt;&lt;P&gt;Thanks for any help here.&lt;/P&gt;&lt;P&gt;[1] Steps which resulted in an issue "Error: Cannot find module '@capire/bookshop/package.json'"&lt;/P&gt;&lt;P&gt;1. setup done as described here: &lt;A href="https://cap.cloud.sap/docs/get-started/#setup" target="_blank" rel="nofollow noopener noreferrer"&gt;https://cap.cloud.sap/docs/get-started/#setup&lt;/A&gt;&lt;BR /&gt;2. git clone &lt;A href="https://github.com/capire/bookstore" target="_blank" rel="nofollow noopener noreferrer"&gt;https://github.com/capire/bookstore&lt;/A&gt;&lt;BR /&gt;3. cds watch bookstore&lt;/P&gt;&lt;P&gt;Result details (console output)&lt;/P&gt;&lt;P&gt;&lt;EM&gt;$&amp;gt; cds watch bookstore&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;cd bookstore&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;cds serve all --with-mocks --in-memory?&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;( live reload enabled for browsers )&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;___________________________&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;[cds] - bootstrapping from { file: 'bookstore/server.js' }&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;&lt;span class="lia-unicode-emoji" title=":exclamation_mark:"&gt;‚ùó&lt;/span&gt;Ô∏è ERROR on server start: &lt;span class="lia-unicode-emoji" title=":exclamation_mark:"&gt;‚ùó&lt;/span&gt;Ô∏è&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;Error: Cannot find module '@capire/bookshop/package.json'&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;Require stack:&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;- /Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/node_modules/@sap/cds/server.js&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;- /Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/node_modules/@sap/cds/lib/index.js&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;- /Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/lib/cds.js&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;- /Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/lib/watch/watched.js&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;at Module._resolveFilename (node:internal/modules/cjs/loader:1212:15)&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;at Function.resolve (node:internal/modules/helpers:193:19)&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;at Object.from (/Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/node_modules/@sap/cds/server.js:115:60)&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;at cds.&amp;lt;anonymous&amp;gt; (/Users/d032153/dev/tmp/bookstore/srv/mashup.js:6:28)&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;at Object.onceWrapper (node:events:639:26)&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;at cds.emit (node:events:536:35)&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;at cds.emit (/Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/node_modules/@sap/cds/lib/index.js:31:23)&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;at cds_server (/Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/node_modules/@sap/cds/server.js:41:7)&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;at Object.serve (/Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/node_modules/@sap/cds/bin/serve.js:196:24)&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;at async Object.exec (/Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/bin/cds.js:99:16) {&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;code: 'MODULE_NOT_FOUND',&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;requireStack: [&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;'/Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/node_modules/@sap/cds/server.js',&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;'/Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/node_modules/@sap/cds/lib/index.js',&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;'/Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/lib/cds.js',&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;'/Users/d032153/.nvm/versions/node/v20.19.0/lib/node_modules/@sap/cds-dk/lib/watch/watched.js'&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;]&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;}&lt;/EM&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/cap-bookshop-fiori-example-quot-error-cannot-find-module-capire-bookshop/qaq-p/14228739"/>
    <published>2025-09-26T11:57:40.877000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/1-500-faster-abap-cloud-api-with-just-gzip/qaq-p/14229207</id>
    <title>1,500√ó Faster: ABAP Cloud API with ‚ÄúJust‚Äù Gzip</title>
    <updated>2025-09-26T16:36:17.362000+02:00</updated>
    <author>
      <name>natanael1</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1557162</uri>
    </author>
    <content>&lt;H3 id="toc-hId-1890184258"&gt;The 3-hours to 7-Second Story&lt;/H3&gt;&lt;P&gt;We had a weekly data integration form ABAP in Cloud, via an OData service, that took about &lt;STRONG&gt;3 hours&lt;/STRONG&gt;(10800 seconds) and nearly &lt;STRONG&gt;600 requests&lt;/STRONG&gt; to finish. After a small redesign, the same data now arrives in &lt;STRONG&gt;~7 seconds(instead of 10800 seconds)&lt;/STRONG&gt; using just &lt;STRONG&gt;3 requests&lt;/STRONG&gt;. So a dramatic x1500 reduction. No new servers, no fancy tools, just smarter packaging of the data, but of course with some drawback.&lt;/P&gt;&lt;P&gt;The full PDF paper, and code is available in this GitHub repo:&amp;nbsp;&lt;A href="https://github.com/legonmarian/abap-btp-api-optimization" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/legonmarian/abap-btp-api-optimization&lt;/A&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1693670753"&gt;Quick Context&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Where:&lt;/STRONG&gt; ABAP in Cloud on SAP BTP.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;What:&lt;/STRONG&gt; A big, flat table (around 3 million rows) needed once a week.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Old approach: &lt;/STRONG&gt;OData service exposing this table, called 600 times,&amp;nbsp;5,000 rows per call ‚Üí slow and expensive, the extraction workflow took ~3 hours&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Constraint:&lt;/STRONG&gt; We can‚Äôt stream chunks; each response is built on the server, then sent.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Goal:&lt;/STRONG&gt; Deliver everything fast, simple, and cheap for both sides.&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1497157248"&gt;The Simple Change&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;Goal:&lt;/STRONG&gt; make a big weekly export feel like a single, quick download. No fancy infra, no special client libraries.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Why not OData for this job&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;OData shines for interactive reads: $filter, $expand, small pages, typed entities.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Our use case was the opposite: &lt;STRONG&gt;one flat dataset, all of it, as fast as possible&lt;/STRONG&gt;.&lt;/LI&gt;&lt;LI&gt;With OData we‚Äôd still pay the cost of many small pages and per-entity overhead the client didn‚Äôt need.&lt;/LI&gt;&lt;LI&gt;Most consumers wanted a simple file-like payload they could ingest with generic tools.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Why a plain HTTP service instead&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;A plain GET endpoint gives us &lt;STRONG&gt;full control over the wire format&lt;/STRONG&gt; (JSON/CSV), headers, and compression.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;It‚Äôs easier for any consumer to adopt (curl, Python, Node, SAP or non-SAP).&lt;/LI&gt;&lt;LI&gt;We can define a &lt;STRONG&gt;predictable paging contract&lt;/STRONG&gt; (e.g., offset/count) and let the client fetch pages in parallel.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Why ‚Äújust HTTP‚Äù still wasn‚Äôt enough&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;In ABAP Cloud, we don‚Äôt stream chunked responses; the server assembles the response first, then sends it.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;If we na√Øvely send a huge JSON array, the &lt;STRONG&gt;payload is too big&lt;/STRONG&gt; and &lt;STRONG&gt;too slow&lt;/STRONG&gt;.&lt;/LI&gt;&lt;LI&gt;If we keep tiny pages, we fix size but suffer &lt;STRONG&gt;hundreds of roundtrips&lt;/STRONG&gt;.&lt;/LI&gt;&lt;LI&gt;Conclusion: we needed to &lt;STRONG&gt;keep HTTP simple but make each response compact and each request count&lt;/STRONG&gt;.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;What we explored&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Formats:&lt;/STRONG&gt; JSON vs CSV vs newline-delimited JSON. CSV is smaller raw, but‚Ä¶&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Serialization:&lt;/STRONG&gt; /ui2/cl_json, XCO, and CALL TRANSFORMATION for speed and stability.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Compression:&lt;/STRONG&gt; no compression vs gzip; single gzip member vs multiple members inside one response.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Delivery patterns:&lt;/STRONG&gt; direct download vs staging to storage; server-side streaming ideas (ruled out).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Paging shapes:&lt;/STRONG&gt; many small pages vs a few big pages; client parallelism vs server complexity.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;What we landed on (the pattern)&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Keep JSON&lt;/STRONG&gt; for compatibility, but &lt;STRONG&gt;generate it fast&lt;/STRONG&gt; (use the fastest serializer available to you).&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Compress every response&lt;/STRONG&gt; and signal it with Content-Encoding: gzip. One &lt;STRONG&gt;single gzip member&lt;/STRONG&gt; per response so common clients auto-decompress reliably.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Use coarse paging&lt;/STRONG&gt; (few big pages) to cut roundtrips. Expose simple params (e.g., offset and count) and a ‚Äúcount only‚Äù helper so clients can plan pages.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Let clients parallelize&lt;/STRONG&gt; safely: stable ordering, idempotent reads, and clear retry rules.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Stay boring on the protocol:&lt;/STRONG&gt; plain HTTP GET, clear headers, predictable JSON shape. No streaming tricks, no custom encodings that break tools.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Why this works?&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;We &lt;STRONG&gt;remove protocol overhead&lt;/STRONG&gt; we don‚Äôt need (OData features) and &lt;STRONG&gt;add the two things we do need&lt;/STRONG&gt; for bulk: fast serialization + compression.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Coarse pages shift the bottleneck from ‚Äútoo many calls‚Äù to ‚Äúa few efficient transfers‚Äù.&lt;/LI&gt;&lt;LI&gt;Gzip neutralizes JSON‚Äôs key overhead, so we keep a &lt;STRONG&gt;friendly format&lt;/STRONG&gt; without paying a size penalty.&lt;/LI&gt;&lt;LI&gt;The approach is &lt;STRONG&gt;portable and observable&lt;/STRONG&gt;: easy to test locally, easy to monitor in production, and easy for partners to adopt.&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1300643743"&gt;Before vs After&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;TL;DR:&lt;/STRONG&gt; We didn‚Äôt change the data, only the delivery: coarse pages, fast JSON, and gzip over a plain HTTP contract.&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;P&gt;Dimension Before (many small pages) After (few big pages + gzip) Why it matters&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD&gt;Dataset&lt;/TD&gt;&lt;TD&gt;~3,000,000 rows (flat, ~12 columns)&lt;/TD&gt;&lt;TD&gt;Same&lt;/TD&gt;&lt;TD&gt;Same data, new delivery.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Page size&lt;/TD&gt;&lt;TD&gt;5,000 rows/page&lt;/TD&gt;&lt;TD&gt;~1,000,000 rows/page (tunable)&lt;/TD&gt;&lt;TD&gt;Fewer roundtrips, less latency.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Number of requests&lt;/TD&gt;&lt;TD&gt;~593&lt;/TD&gt;&lt;TD&gt;3&lt;/TD&gt;&lt;TD&gt;Network overhead drops dramatically.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;End-to-end time&lt;/TD&gt;&lt;TD&gt;~3 hours (sequential pulls)&lt;/TD&gt;&lt;TD&gt;~6-7 seconds (3 parallel pulls)&lt;/TD&gt;&lt;TD&gt;Parallelizable, near ‚Äúsingle download‚Äù feel.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Format on the wire&lt;/TD&gt;&lt;TD&gt;JSON (uncompressed)&lt;/TD&gt;&lt;TD&gt;JSON (gzipped)&lt;/TD&gt;&lt;TD&gt;Keep JSON for compatibility; shrink it with gzip.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Total transfer&lt;/TD&gt;&lt;TD&gt;~0.6 GB&lt;/TD&gt;&lt;TD&gt;~9 MB&lt;/TD&gt;&lt;TD&gt;Bandwidth and cost fall off a cliff.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Payload per page&lt;/TD&gt;&lt;TD&gt;~1.15 MB per 5k rows (raw)&lt;/TD&gt;&lt;TD&gt;~3 MB per 1M rows (gzipped)&lt;/TD&gt;&lt;TD&gt;Gzip beats key overhead; size scales well.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Serialization&lt;/TD&gt;&lt;TD&gt;Generic JSON serializer&lt;/TD&gt;&lt;TD&gt;Fast serializer (CALL TRANSFORMATION)&lt;/TD&gt;&lt;TD&gt;Server can build big pages quickly.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Protocol&lt;/TD&gt;&lt;TD&gt;OData-style paging&lt;/TD&gt;&lt;TD&gt;Plain HTTP GET with offset/count&lt;/TD&gt;&lt;TD&gt;Simple contract any client can call.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Compression&lt;/TD&gt;&lt;TD&gt;None&lt;/TD&gt;&lt;TD&gt;Content-Encoding: gzip (single member)&lt;/TD&gt;&lt;TD&gt;Works out-of-the-box with common tools/SDKs.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Client pattern&lt;/TD&gt;&lt;TD&gt;Sequential loop&lt;/TD&gt;&lt;TD&gt;Fetch pages in parallel, then merge&lt;/TD&gt;&lt;TD&gt;Easy speed-up without server tricks.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Retry model&lt;/TD&gt;&lt;TD&gt;Many small retries&lt;/TD&gt;&lt;TD&gt;Few coarse, idempotent retries&lt;/TD&gt;&lt;TD&gt;Fewer moving parts, simpler error handling.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Server behavior&lt;/TD&gt;&lt;TD&gt;Build JSON, send raw&lt;/TD&gt;&lt;TD&gt;Build JSON ‚Üí gzip ‚Üí send single member&lt;/TD&gt;&lt;TD&gt;Reliable auto-decompression on client side.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Limits to watch&lt;/TD&gt;&lt;TD&gt;Too many roundtrips; egress cost&lt;/TD&gt;&lt;TD&gt;Client RAM per page; choose page size wisely&lt;/TD&gt;&lt;TD&gt;Balance page size vs client capacity.&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H3 id="toc-hId-1104130238"&gt;How to reproduce this in three simple steps&lt;/H3&gt;&lt;BLOCKQUOTE&gt;&lt;P&gt;Heads-up: in here I will refer to an Appendix, you can find it in the detailed PDF paper about the optimization, the paper and some code is available on GitHub&lt;/P&gt;&lt;/BLOCKQUOTE&gt;&lt;HR /&gt;&lt;H4 id="toc-hId-1036699452"&gt;Step 1. Define a tiny HTTP contract&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Endpoint:&lt;/STRONG&gt; GET /entity?offset=‚Ä¶&amp;amp;count=‚Ä¶&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Helper:&lt;/STRONG&gt; GET /entity?get_only_count=true returns a small pagination object with totals and suggested pages, for example:&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;PRE&gt;{
  "number_of_records": 2496434,
  "batch_size": { "maximum": 1500000, "recommended": 1000000 },
  "recommended_pages": [
    "/entity?offset=0&amp;amp;count=1000000",
    "/entity?offset=1000000&amp;amp;count=1000000",
    "/entity?offset=2000000&amp;amp;count=1000000"
  ]
}&lt;/PRE&gt;&lt;P&gt;This keeps clients simple and lets them plan parallel pulls.&lt;/P&gt;&lt;HR /&gt;&lt;H4 id="toc-hId-840185947"&gt;Step 2. Build one big page, serialize fast, and gzip it on the server&lt;/H4&gt;&lt;P&gt;&lt;STRONG&gt;a) Fast JSON generation with CALL TRANSFORMATION&lt;/STRONG&gt;&lt;BR /&gt;Appendix C shows the lean serializer that won your benchmarks:&lt;/P&gt;&lt;PRE&gt;METHOD convert_json_transformation.
  DATA(lo_writer) = cl_sxml_string_writer‚áícreate( type = if_sxml‚áíco_xt_json ).
  CALL TRANSFORMATION id
    SOURCE itab = data
    RESULT XML lo_writer.
  string = lo_writer-&amp;gt;get_output( ).
ENDMETHOD.&lt;/PRE&gt;&lt;P&gt;Use this to turn your internal table into JSON quickly.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;b) Minimal HTTP handler that serves one gzipped page&lt;/STRONG&gt;&lt;BR /&gt;Appendix I demonstrates the pattern: set headers, read a deterministic slice, serialize, gzip once, send bytes.&lt;/P&gt;&lt;PRE&gt;METHOD gzip_json_single_page.
  response-&amp;gt;set_status( 200 ).
  response-&amp;gt;set_content_type( 'application/gzip' ).
  response-&amp;gt;set_header_field(
    i_name = 'Content-Disposition'
    i_value = |attachment; filename="data_subset.gz"| ).
  response-&amp;gt;set_compression(
    options = if_web_http_response‚áíco_compress_none ).
  response-&amp;gt;set_header_field(
    i_name = 'Content-Encoding'
    i_value = |deflate| ).

  SELECT column_1, column_2, ... , column_12
    FROM dbtable
    ORDER BY column_2
    INTO TABLE @DATA(page)
    UP TO @page_size ROWS.

  cl_abap_gzip‚áícompress_binary(
    EXPORTING raw_in = convert_json_transformation( page )
    IMPORTING gzip_out = DATA(gzip) ).

  response-&amp;gt;set_binary( gzip ).
ENDMETHOD.&lt;/PRE&gt;&lt;P&gt;&lt;STRONG&gt;c) Where the handler is wired&lt;/STRONG&gt;&lt;BR /&gt;Appendix F shows the entry point choosing which implementation to run:&lt;/P&gt;&lt;PRE&gt;METHOD if_http_service_extension~handle_request.
  " choose one of these
  gzip_json_single_page( CHANGING request = request response = response ).
  " only for demonstration
  "gzip_csv_single_page( CHANGING request = request response = response ).
  " only for demonstration
  "gzip_csv_multiple_pages( CHANGING request = request response = response ).
ENDMETHOD.&lt;/PRE&gt;&lt;P&gt;Keep it simple in production and call the JSON + single-member gzip method.&lt;/P&gt;&lt;HR /&gt;&lt;H4 id="toc-hId-643672442"&gt;Step 3. Let the client pull a few big pages in parallel&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Ask get_only_count first to get total and recommended pages.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Fire 2‚Äì4 page requests in parallel, then merge locally.&lt;/LI&gt;&lt;LI&gt;Most clients auto-decompress when Content-Encoding is set, which is exactly why the server returns a single gzip response.&lt;/LI&gt;&lt;/UL&gt;&lt;HR /&gt;&lt;H4 id="toc-hId-447158937"&gt;Optional: CSV variant from the appendix&lt;/H4&gt;&lt;P&gt;If you ever need CSV, Appendix H shows the single-page CSV + gzip flow. The JSON path above stayed as our final choice because gzip erases most of JSON‚Äôs key overhead while keeping tooling friendly.&lt;/P&gt;&lt;H3 id="toc-hId-121562713"&gt;When to use this pattern and when not to&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;Use it when&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;You need to deliver a large, flat dataset fast, usually for batch or analytics.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Your consumers are happy with a plain HTTP GET that returns JSON.&lt;/LI&gt;&lt;LI&gt;You can sort by a unique key and read stable slices with offset and count.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Think twice when&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Consumers need rich OData features&lt;/STRONG&gt; like server-side filtering and $expand. You will be giving those up and implementing only what you need in plain HTTP.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Clients cannot hold the decompressed page in memory.&lt;/STRONG&gt; A 1,000,000 row page is roughly a few hundred MB once decompressed, so plan for that on the client side.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;You require true streaming.&lt;/STRONG&gt; ABAP ICF in the cloud does not support HTTP/1.1 chunked transfer, so streaming is out of scope here.&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId--150182161"&gt;Gotchas to avoid&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Do not concatenate multiple gzip members&lt;/STRONG&gt; in one HTTP response if you expect tools like Postman to auto-decompress. Many clients only unpack the first member. Prefer one contiguous gzip stream per response.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Set the right headers.&lt;/STRONG&gt; Send Content-Encoding: gzip for the single member response. If you build a multi-member payload, clients may not decode it automatically, which is why your final solution avoided that.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Keep ordering stable.&lt;/STRONG&gt; Always ORDER BY a unique key to make pages deterministic and retries idempotent. (Your examples order by a key column before slicing.)&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Pick a page size both sides can hold.&lt;/STRONG&gt; You found that 1,000,000 rows per page hits a good balance. Results and size scale with total rows, not so much with page count.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Stick to one gzip pass per response.&lt;/STRONG&gt; Compress after you generate JSON for the page, not per record or per mini-chunk inside the same response. It keeps clients simple.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;For the full PDF paper, and code please check this GitHub repo:&amp;nbsp;&lt;A href="https://github.com/legonmarian/abap-btp-api-optimization" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/legonmarian/abap-btp-api-optimization&lt;/A&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/1-500-faster-abap-cloud-api-with-just-gzip/qaq-p/14229207"/>
    <published>2025-09-26T16:36:17.362000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/cap-vue-based-bookshop-sample-deploy-to-cloud-foundry-failed/qaq-p/14229305</id>
    <title>CAP (vue based) bookshop sample: Deploy to Cloud Foundry failed</title>
    <updated>2025-09-26T18:07:18.497000+02:00</updated>
    <author>
      <name>jens_glander</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/188695</uri>
    </author>
    <content>&lt;P&gt;Steps I followed:&lt;/P&gt;&lt;P&gt;Deploy to Cloud Foundry&lt;BR /&gt;&lt;A href="https://cap.cloud.sap/docs/guides/deployment/to-cf" target="_blank" rel="nofollow noopener noreferrer"&gt;https://cap.cloud.sap/docs/guides/deployment/to-cf&lt;/A&gt;&lt;/P&gt;&lt;P&gt;1. Prerequisites executed as described in section: &lt;A href="https://cap.cloud.sap/docs/guides/deployment/to-cf#prerequisites" target="_blank" rel="nofollow noopener noreferrer"&gt;https://cap.cloud.sap/docs/guides/deployment/to-cf#prerequisites&lt;/A&gt; ; sample code used from &lt;A href="https://github.com/capire/bookshop.git" target="_blank" rel="nofollow noopener noreferrer"&gt;https://github.com/capire/bookshop.git&lt;/A&gt;&lt;BR /&gt;2. Mandatory steps (1.-5.) executed as described in section 'Prepare for Production': &lt;A href="https://cap.cloud.sap/docs/guides/deployment/to-cf#prepare-for-production" target="_blank" rel="nofollow noopener noreferrer"&gt;https://cap.cloud.sap/docs/guides/deployment/to-cf#prepare-for-production&lt;/A&gt;&lt;BR /&gt;3. In 'Build and Deploy' 'cds up' command failed with the following output (entire output in [1])&lt;/P&gt;&lt;P&gt;&lt;EM&gt;...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:42:07] INFO executing the "npm run build" command...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm error Missing script: "build"&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm error&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm error To see a list of scripts, run:&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm error npm run&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm error A complete log of this run can be found in: /Users/d032153/.npm/_logs/2025-09-26T15_42_07_555Z-debug-0.log&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:42:07] ERROR could not build the "bookshopvue" module: could not execute the "npm run build" command: exit status 1&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;make: *** [bookshopvue] Error 1&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:42:07] ERROR could not build the MTA project: could not execute the "make -f Makefile_20250926174144.mta p=cf mtar=mta.tar strict=true mode= t=\"gen\"" command: exit status 2&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;Error: could not build the MTA project: could not execute the "make -f Makefile_20250926174144.mta p=cf mtar=mta.tar strict=true mode= t=\"gen\"" command: exit status 2&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;Command failed: mbt build -t gen --mtar mta.tar&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;...&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;Any idea what went wrong here?&lt;/P&gt;&lt;P&gt;Thank you!&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;[1]'cds up': detailed output&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;$: ~/dev/tmp/bookshop cds up&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm i --package-lock-only --prefix /Users/d032153/dev/tmp/bookshop/app/vue&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;up to date, audited 1 package in 385ms&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;found 0 vulnerabilities&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm i --package-lock-only --prefix .deploy/app-router&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;up to date, audited 214 packages in 6s&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;24 packages are looking for funding&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;run `npm fund` for details&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;found 0 vulnerabilities&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;mbt build -t gen --mtar mta.tar&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:44] INFO Cloud MTA Build Tool version 1.2.34&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:44] INFO generating the "Makefile_20250926174144.mta" file...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:44] INFO done&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:44] INFO executing the "make -f Makefile_20250926174144.mta p=cf mtar=mta.tar strict=true mode= t=\"gen\"" command...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:44] INFO validating the MTA project&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:44] INFO running the "before-all" build...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:44] INFO executing the "npm ci" command...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;added 290 packages, and audited 291 packages in 3s&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;27 packages are looking for funding&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;run `npm fund` for details&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;found 0 vulnerabilities&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:47] INFO executing the "npx cds build --production" command...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;.building project with {&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;versions: { cds: '9.3.1', compiler: '6.3.6', dk: '9.3.2' },&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;target: 'gen',&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;tasks: [&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;{ src: 'db', for: 'hana', options: { model: [ 'db', 'srv', 'app', '@sap/cds/srv/outbox' ] } },&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;{ src: 'srv', for: 'nodejs', options: { model: [ 'db', 'srv', 'app', '@sap/cds/srv/outbox' ] } }&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;]&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;}&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;.done &amp;gt; wrote output to:&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/init.js&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/package.json&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/.hdiconfig&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/.hdiconfig&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/.hdinamespace&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/AdminService.Authors.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/AdminService.Books.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/AdminService.Books_texts.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/AdminService.Currencies.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/AdminService.Currencies_texts.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/AdminService.Genres.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/AdminService.Genres_texts.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/CatalogService.Books.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/CatalogService.Books_texts.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/CatalogService.Currencies.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/CatalogService.Currencies_texts.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/CatalogService.Genres.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/CatalogService.Genres_texts.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/CatalogService.ListOfBooks.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/cds.outbox.Messages.hdbtable&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/data/sap.capire.bookshop-Authors.csv&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/data/sap.capire.bookshop-Authors.hdbtabledata&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/data/sap.capire.bookshop-Books.csv&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/data/sap.capire.bookshop-Books.hdbtabledata&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/data/sap.capire.bookshop-Books.texts.csv&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/data/sap.capire.bookshop-Books.texts.hdbtabledata&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/data/sap.capire.bookshop-Genres.csv&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/data/sap.capire.bookshop-Genres.hdbtabledata&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/localized.AdminService.Books.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;gen/db/src/gen/localized.AdminService.Currencies.hdbview&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;... 25 more. Run with DEBUG=build to show all files.&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;build completed in 1767 ms&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:49] INFO validating the MTA project&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:49] INFO building the "bookshop-srv" module...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:49] INFO executing the "npm clean-install --production" command...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm warn config production Use `--omit=dev` instead.&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;added 88 packages, and audited 89 packages in 797ms&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;15 packages are looking for funding&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;run `npm fund` for details&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;found 0 vulnerabilities&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:50] INFO the build results of the "bookshop-srv" module will be packaged and saved in the "gen/.bookshop_mta_build_tmp/bookshop-srv" folder&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:51] INFO finished building the "bookshop-srv" module&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:51] INFO building the "bookshop-db-deployer" module...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:51] INFO executing the "npm install --production" command...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm warn config production Use `--omit=dev` instead.&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;.&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;added 28 packages, and audited 29 packages in 1s&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;3 packages are looking for funding&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;run `npm fund` for details&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;found 0 vulnerabilities&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:53] INFO the build results of the "bookshop-db-deployer" module will be packaged and saved in the "gen/.bookshop_mta_build_tmp/bookshop-db-deployer" folder&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:53] INFO finished building the "bookshop-db-deployer" module&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:53] INFO building the "bookshop" module...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:53] INFO executing the "npm install --production" command...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm warn config production Use `--omit=dev` instead.&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;.&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;added 213 packages, and audited 214 packages in 1s&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;24 packages are looking for funding&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;run `npm fund` for details&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;found 0 vulnerabilities&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:41:54] INFO the build results of the "bookshop" module will be packaged and saved in the "gen/.bookshop_mta_build_tmp/bookshop" folder&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:42:07] INFO finished building the "bookshop" module&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:42:07] INFO building the "bookshopvue" module...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:42:07] INFO executing the "npm ci" command...&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;up to date, audited 1 package in 260ms&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;found 0 vulnerabilities&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:42:07] INFO executing the "npm run build" command...&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm error Missing script: "build"&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm error&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm error To see a list of scripts, run:&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm error npm run&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;npm error A complete log of this run can be found in: /Users/d032153/.npm/_logs/2025-09-26T15_42_07_555Z-debug-0.log&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:42:07] ERROR could not build the "bookshopvue" module: could not execute the "npm run build" command: exit status 1&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;make: *** [bookshopvue] Error 1&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;[2025-09-26 17:42:07] ERROR could not build the MTA project: could not execute the "make -f Makefile_20250926174144.mta p=cf mtar=mta.tar strict=true mode= t=\"gen\"" command: exit status 2&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;Error: could not build the MTA project: could not execute the "make -f Makefile_20250926174144.mta p=cf mtar=mta.tar strict=true mode= t=\"gen\"" command: exit status 2&lt;/EM&gt;&lt;BR /&gt;&lt;EM&gt;Command failed: mbt build -t gen --mtar mta.tar&lt;/EM&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/cap-vue-based-bookshop-sample-deploy-to-cloud-foundry-failed/qaq-p/14229305"/>
    <published>2025-09-26T18:07:18.497000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/c-wzadm-2404-exam-sap-build-work-zone-guidance-for-preparing-sap-certified/qaq-p/14229389</id>
    <title>C_WZADM_2404 Exam (SAP Build Work Zone) - Guidance for Preparing SAP Certified Associate</title>
    <updated>2025-09-26T20:59:50.316000+02:00</updated>
    <author>
      <name>martin3321</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2252854</uri>
    </author>
    <content>&lt;P&gt;Hi everyone,&lt;/P&gt;&lt;P&gt;I‚Äôm planning to take the SAP Certified Associate ‚Äì SAP Build Work Zone Implementation and Administration (C_WZADM_2404) exam. I‚Äôve reviewed the Learning Journey and the exam topics like Solution Architecture, Extensibility, Integration, and Overview, but I‚Äôm still unsure how to structure my preparation effectively.&lt;/P&gt;&lt;P&gt;For those who have already taken this certification:&lt;/P&gt;&lt;P&gt;Which areas did you find the most challenging?&lt;/P&gt;&lt;P&gt;Are the official Learning Journey and practice materials enough, or should I look into additional resources?&lt;/P&gt;&lt;P&gt;Any tips on managing time during the 60 questions / 2-hour exam?&lt;/P&gt;&lt;P&gt;Appreciate any insights or personal experiences you can share.&lt;/P&gt;&lt;P&gt;Thanks in advance!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/c-wzadm-2404-exam-sap-build-work-zone-guidance-for-preparing-sap-certified/qaq-p/14229389"/>
    <published>2025-09-26T20:59:50.316000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/btp-cis-provisioning-job-fail-with-error/qaq-p/14229569</id>
    <title>BTP CIS Provisioning Job fail with error</title>
    <updated>2025-09-27T16:52:47.042000+02:00</updated>
    <author>
      <name>Venkat53</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1750718</uri>
    </author>
    <content>&lt;P&gt;Hi Everyone,&lt;BR /&gt;When I scheduled the provisioning job in Cloud identity services with IAS as source data(reads Users and Groups) and BTP Subaccount as Target system. The Provisioning Job fail with the attached error, Could you suggest how to resolve the issue.&lt;BR /&gt;&lt;BR /&gt;I've attached the source system transformation&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Venkat53_0-1758984546949.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320721i64904425F4334BE4/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Venkat53_0-1758984546949.png" alt="Venkat53_0-1758984546949.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/btp-cis-provisioning-job-fail-with-error/qaq-p/14229569"/>
    <published>2025-09-27T16:52:47.042000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/roadmap-for-joule-studio/qaq-p/14229654</id>
    <title>Roadmap for Joule studio</title>
    <updated>2025-09-27T23:29:32.790000+02:00</updated>
    <author>
      <name>rimjhim_agrawal</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2256795</uri>
    </author>
    <content>&lt;P&gt;Can anyone explain the roadmap for Joule studio?&lt;/P&gt;&lt;P&gt;IT is unclear to me as what is available and what is yet to be implemented in Joule Studio.&lt;/P&gt;&lt;P&gt;Is AI agent available?&lt;/P&gt;&lt;P&gt;Can Joule Studio be integrated to S4HANA private cloud?&lt;/P&gt;&lt;P&gt;Can Joule Studio be integrated to on premise system?&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/roadmap-for-joule-studio/qaq-p/14229654"/>
    <published>2025-09-27T23:29:32.790000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/cannot-receive-sms-verification-code-for-sap-trial-account-in-china/qaq-p/14229780</id>
    <title>Cannot receive SMS verification code for SAP Trial account in China</title>
    <updated>2025-09-28T17:26:05.945000+02:00</updated>
    <author>
      <name>huzhinan</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2256838</uri>
    </author>
    <content>&lt;P&gt;Hello SAP Community, I am currently stuck in the final step of creating my SAP Trial account and would appreciate any help from the community. Issue: After entering my mobile number for verification, I consistently get the error message: "We cannot send you a code. Please check your phone number and try again." I do not receive the SMS code at all. What I have already tried/troubleshooted: To solve this, I have already taken the following steps, but without success: Correct Format: I ensured my number is in the correct international format: (e.g., +8613811122233), without any dashes or spaces. Different Browsers: I tried using different browsers (Chrome, Edge) and also in incognito/private mode. Cleared Cache: I cleared my browser cache and cookies.&lt;/P&gt;&lt;P&gt;#&lt;A href="https://account.hanatrial.ondemand.com/trial/#/home/tria" target="_blank" rel="nofollow noopener noreferrer"&gt;https://account.hanatrial.ondemand.com/trial/#/home/tria&lt;/A&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/cannot-receive-sms-verification-code-for-sap-trial-account-in-china/qaq-p/14229780"/>
    <published>2025-09-28T17:26:05.945000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/does-sap-s-4hana-public-cloud-support-ocr-based-invoice-document-capture/qaq-p/14229911</id>
    <title>Does SAP S/4HANA Public Cloud Support OCR-based Invoice Document Capture Without  Ariba Central?</title>
    <updated>2025-09-29T06:22:40.160000+02:00</updated>
    <author>
      <name>byd</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1424802</uri>
    </author>
    <content>&lt;P&gt;Hello SAP Community,&lt;/P&gt;&lt;P&gt;I have a question regarding invoice processing capabilities in SAP S/4HANA Public Cloud.&lt;/P&gt;&lt;P&gt;Does SAP S/4HANA Public Cloud have a built-in feature to scan and capture supplier invoices (PDF or paper format) using OCR technology and import them as documents into the system?&lt;/P&gt;&lt;P&gt;I'm aware that integrating with SAP Ariba Central Invoice Management is one option for this functionality. However, I'm wondering if this can be achieved using SAP S/4HANA Public Cloud as a standalone solution, without requiring additional Ariba licensing.&lt;/P&gt;&lt;P&gt;Any insights or guidance would be greatly appreciated.&lt;/P&gt;&lt;P&gt;Thank you in advance for your help!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/does-sap-s-4hana-public-cloud-support-ocr-based-invoice-document-capture/qaq-p/14229911"/>
    <published>2025-09-29T06:22:40.160000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/vibe-coding-with-mcp-servers-amp-sap-ai-core-toward-quot-coding-by/qaq-p/14230581</id>
    <title>Vibe Coding with MCP Servers &amp; SAP AI Core: Toward "Coding by Conversation"</title>
    <updated>2025-09-29T15:36:36.701000+02:00</updated>
    <author>
      <name>Ankur_Kumar1</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/171016</uri>
    </author>
    <content>&lt;P&gt;Over the past few months, I‚Äôve explored &lt;STRONG&gt;&lt;EM&gt;vibe coding&lt;/EM&gt;&lt;/STRONG&gt; ‚Äî a workflow where you prompt the AI, it generates code, and you iterate. Fast and interactive, yes ‚Äî but in enterprise projects, context and governance are critical. Without them, hallucinations and mismatched code structures quickly emerge.&lt;/P&gt;&lt;P&gt;This is where &lt;STRONG&gt;MCP servers (Model Context Protocol)&lt;/STRONG&gt; and &lt;STRONG&gt;SAP AI Core&lt;/STRONG&gt; become essential. Tools like fiori server and cap server allow AI assistants to understand your CDS models, Fiori metadata, and application structure ‚Äî enabling contextual, reliable code generation.&lt;/P&gt;&lt;P&gt;In this blog, we‚Äôll explore the architecture, practical usage, and enterprise best practices that make AI-assisted coding robust and production-ready.&lt;/P&gt;&lt;H2 id="toc-hId-1761760066"&gt;What is Vibe Coding?&lt;/H2&gt;&lt;P&gt;Vibe coding is a transformative approach to software development ‚Äî essentially, &lt;STRONG&gt;&lt;EM&gt;coding by conversation&lt;/EM&gt;.&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;You describe requirements in natural language.&lt;/LI&gt;&lt;LI&gt;The AI assistant interprets your intent and proposes code patches, scaffolding, or tests.&lt;/LI&gt;&lt;LI&gt;You review, refine, and approve the generated output.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The power of vibe coding lies in freeing developers from repetitive boilerplate tasks, allowing them to focus on high-value work like architecture, user experience, and business logic.&lt;/P&gt;&lt;P&gt;SAP‚Äôs reference architecture for vibe coding with &lt;STRONG&gt;Cline + SAP AI Core&lt;/STRONG&gt; demonstrates how AI-assisted development can be safe, repeatable, and fully aligned with enterprise standards ‚Äî turning AI from a helper into a structured development partner.&lt;/P&gt;&lt;H2 id="toc-hId-1565246561"&gt;Core Principles from the SAP Architecture&lt;/H2&gt;&lt;P&gt;From the reference architecture, five principles stand out:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Prompt-Driven Development&lt;/STRONG&gt; ‚Äì Express features in natural language, and let the system automatically generate the initial scaffolding.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Context Engineering&lt;/STRONG&gt; ‚Äì Supply LLMs with only the necessary structural context, such as APIs, CDS models, or MCP metadata.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;AI-Assisted Test-First Approach&lt;/STRONG&gt; ‚Äì Begin by generating tests, then guide the AI to produce code that fulfills those requirements.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Human-in-the-Loop Governance&lt;/STRONG&gt; ‚Äì Developers retain responsibility for ensuring compliance, performance, and security.&lt;/LI&gt;&lt;/OL&gt;&lt;H2 id="toc-hId-1368733056"&gt;Introducing MCP Servers&lt;/H2&gt;&lt;P&gt;MCP (Model Context Protocol) acts as the &lt;STRONG&gt;bridge between your project and the AI assistant&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;MCP (Model Context Protocol) is designed to act as a powerful bridge between your project and the AI assistant, ensuring that development is not just driven by prompts but also grounded in real project context. Instead of leaving the AI to guess or hallucinate about how your application is structured, MCP Servers provide it with a deep, contextual understanding of your project.&lt;/P&gt;&lt;P&gt;They expose key elements such as metadata, annotations, models, services, entities, relationships, and queries. This allows the AI to reason intelligently about your project‚Äôs architecture, whether it‚Äôs related to the user interface, the underlying data definitions, or the service layer.&lt;/P&gt;&lt;P&gt;With MCP servers running, your AI assistant doesn‚Äôt hallucinate blindly ‚Äî it &lt;EM&gt;knows&lt;/EM&gt; your project structure.&lt;/P&gt;&lt;H2 id="toc-hId-1172219551"&gt;Architecture in Action: Cline + SAP AI Core + MCP&lt;/H2&gt;&lt;P&gt;Here‚Äôs how the pieces fit:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Cline&lt;/STRONG&gt; ‚ÄìYour coding agent inside the IDE, mediating prompts, code diffs, and project changes.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;SAP AI Core&lt;/STRONG&gt; ‚Äì Hosts the foundation models (Claude, OpenAI, Gemini) in a governed, enterprise-ready environment.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;MCP Servers&lt;/STRONG&gt; ‚Äì mcp server expose structured context:&lt;BR /&gt;&lt;UL&gt;&lt;LI&gt;UI annotations, metadata, and manifest structure&lt;/LI&gt;&lt;LI&gt;Style guides and constraints&lt;/LI&gt;&lt;LI&gt;CDS entities and services&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;Workflow&lt;/STRONG&gt;:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;You prompt: ‚ÄúCreate a ListReport for SalesOrder with a status field.‚Äù&lt;/LI&gt;&lt;LI&gt;AI (via MCP) inspects CDS models and annotations.&lt;/LI&gt;&lt;LI&gt;AI generates the CDS extension, Fiori annotations, and manifest changes.&lt;/LI&gt;&lt;LI&gt;You review, test, and deploy.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This architecture transforms AI coding from a ‚Äútoy experiment‚Äù into a repeatable, enterprise-grade engineering practice.&lt;/P&gt;&lt;H3 id="toc-hId-1104788765"&gt;How to Get SAP AI Core Credentials&lt;/H3&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Access SAP BTP Cockpit&lt;/STRONG&gt;: Go to your SAP BTP subaccount&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Navigate to AI Core&lt;/STRONG&gt;: Services ‚Üí Instances and Subscriptions ‚Üí AI Core&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Create Service Key&lt;/STRONG&gt;:&lt;UL&gt;&lt;LI&gt;Go to your AI Core service instance&lt;/LI&gt;&lt;LI&gt;Create a new service key&lt;/LI&gt;&lt;LI&gt;Copy the credentials (clientid, clientsecret, url, serviceurls)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Configure Authentication URL&lt;/STRONG&gt;: Usually follows pattern&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;CODE&gt;https://{subdomain}.authentication.{region}.hana.ondemand.com/oauth/token&lt;/CODE&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Set Base URL&lt;/STRONG&gt;: Typically&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;CODE&gt;&lt;A href="https://api.ai.ml.hana.ondemand.com" target="_blank" rel="noopener nofollow noreferrer"&gt;https://api.ai.ml.hana.ondemand.com&lt;/A&gt;&lt;/CODE&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;(check your service key for the exact URL)&lt;/LI&gt;&lt;/OL&gt;&lt;pre class="lia-code-sample language-python"&gt;&lt;code&gt;SAP_AI_CORE_CLIENT_ID=your-client-id
SAP_AI_CORE_CLIENT_SECRET=your-client-secret
SAP_AI_CORE_AUTH_URL=https://your-subdomain.authentication.sap.hana.ondemand.com/oauth/token
SAP_AI_CORE_BASE_URL=https://base-ai-core-url
SAP_AI_CORE_RESOURCE_GROUP=your-resource-group&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Refer to the screenshot below, which shows how we subscribed to the SAP AI Launchpad application to deploy our model according to the use case. We also created an SAP AI Core instance to obtain the necessary key details required for configuration in the Cline client.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ankur_Kumar1_5-1759141820101.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/321107i940D7C6A1E9FCC47/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Ankur_Kumar1_5-1759141820101.png" alt="Ankur_Kumar1_5-1759141820101.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-908275260"&gt;&lt;STRONG&gt;Cline Configuration&lt;/STRONG&gt;&lt;/H3&gt;&lt;OL class=""&gt;&lt;LI&gt;Install the Cline extension in VS Code&lt;/LI&gt;&lt;LI&gt;Open Cline settings&lt;/LI&gt;&lt;LI&gt;Configure these fields:&lt;/LI&gt;&lt;UL class=""&gt;&lt;LI&gt;&lt;STRONG&gt;API Provider&lt;/STRONG&gt;: Select "SAP AI Core"&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Client ID&lt;/STRONG&gt;:&amp;nbsp;.clientid&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Client Secret&lt;/STRONG&gt;:&amp;nbsp;.clientsecret&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Base URL&lt;/STRONG&gt;:&amp;nbsp;.serviceurls.AI_API_URL&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Auth URL&lt;/STRONG&gt;:&amp;nbsp;.url&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;AI Core Resource Group&lt;/STRONG&gt;: Extract UUID from&amp;nbsp;.appname&amp;nbsp;(first part before the&amp;nbsp;!)&lt;/LI&gt;&lt;/UL&gt;&lt;/OL&gt;&lt;P class=""&gt;&lt;SPAN class=""&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/SPAN&gt;4. Test with a simple query to make sure it works&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ankur_Kumar1_3-1759141491137.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/321105iC6D60BFC68733EC5/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Ankur_Kumar1_3-1759141491137.png" alt="Ankur_Kumar1_3-1759141491137.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;DIV class=""&gt;&lt;H3 id="toc-hId-711761755"&gt;Add Server Configurations&lt;/H3&gt;&lt;/DIV&gt;&lt;P&gt;To enable AI-assisted coding with full context, add the following server configurations to your &lt;CODE&gt;cline_mcp_settings.json&lt;/CODE&gt; file. This configuration allows Cline to connect to the MCP servers that expose structured information about your project, including CDS models, Fiori metadata, manifest files, and coding style constraints. By providing these settings, you ensure that the AI assistant can:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Understand project structure:&lt;/STRONG&gt; MCP servers give the AI visibility into your CDS entities, services, and UI annotations, allowing it to generate code that aligns with your existing models.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Follow enterprise standards:&lt;/STRONG&gt; Style guides, naming conventions, and other constraints are passed through MCP servers, ensuring that generated code adheres to your organization‚Äôs best practices.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Generate context-aware code:&lt;/STRONG&gt; Instead of generic snippets, the AI can create extensions, annotations, or manifests that fit seamlessly into your project.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Improve efficiency and reduce errors:&lt;/STRONG&gt; By providing a structured context, the AI minimizes mismatches and hallucinations, letting developers focus on architecture, business logic, and user experience rather than repetitive boilerplate.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;With the server configurations in place, Cline can interact with MCP servers in real time, making AI-assisted coding a safe, reliable, and enterprise-ready process.&lt;/P&gt;&lt;pre class="lia-code-sample language-yaml"&gt;&lt;code&gt;{
  "mcpServers": {
    "cds-mcp": {
      "command": "cds-mcp",
      "args": [],
      "env": {},
    }
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;H2 id="toc-hId-386165531"&gt;Set Guardrails with Cline Rules (How-To)&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;Purpose:&lt;/STRONG&gt; Provide persistent, project-level guidance ‚Äî covering scope, coding style, documentation standards, and more ‚Äî that‚Äôs always active in your workspace.&lt;/P&gt;&lt;P&gt;Cline Rules act as a continuous, automated advisor for your development team. By defining guardrails, you ensure that AI-assisted coding adheres to enterprise standards and project-specific conventions. This prevents inconsistent implementations, reduces technical debt, and maintains code quality across the team.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Create a Rule File&lt;BR /&gt;&lt;OL&gt;&lt;LI&gt;In &lt;STRONG&gt;Cline‚Äôs Rules tab&lt;/STRONG&gt;, click &lt;STRONG&gt;‚Äú+‚Äù&lt;/STRONG&gt; or use the command: &lt;CODE&gt;/newrule&lt;/CODE&gt;.&lt;/LI&gt;&lt;LI&gt;Save as a single file: &lt;CODE&gt;.clinerules&lt;/CODE&gt; at the repo root, &lt;STRONG&gt;or&lt;/STRONG&gt; use a folder-based setup &lt;CODE&gt;.clinerules/&lt;/CODE&gt; for multiple rules.&lt;/LI&gt;&lt;/OL&gt;&lt;/LI&gt;&lt;LI&gt;Recommended Folder Structure&lt;/LI&gt;&lt;/OL&gt;&lt;pre class="lia-code-sample language-bash"&gt;&lt;code&gt;your-project/
‚îú‚îÄ‚îÄ .clinerules/
‚îÇ   ‚îú‚îÄ‚îÄ 01-project.md      
‚îÇ   ‚îú‚îÄ‚îÄ 02-coding.md
‚îÇ   ‚îî‚îÄ‚îÄ 03-documentation.md  
‚îú‚îÄ‚îÄ docs/&lt;/code&gt;&lt;/pre&gt;&lt;UL&gt;&lt;LI&gt;Each file addresses a specific aspect of project guidance: project scope, coding standards, and documentation expectations.&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-189652026"&gt;Example Prompt Flow&lt;/H2&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;You: "Initialise an empty SAP CAP application in this folder."
AI: The empty CAP application has been successfully initialised in the current folder&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-json"&gt;&lt;code&gt;You: "Generate an entities sales and sales order items"
AI: The entities is successfully created.&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Result:&lt;/STRONG&gt; you stay focused on implementing business logic and refining the user experience, while the AI assistant handles all the scaffolding, boilerplate, and repetitive code generation.&lt;/P&gt;&lt;P&gt;Open the Cline application and start the conversation with the above commands ‚Äî this is where vibe coding truly comes alive, as your AI assistant (powered by MCP servers and SAP AI Core) begins generating context-aware code that you review, refine, and evolve into enterprise-ready solutions.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ankur_Kumar1_4-1759141624011.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/321106i96F558A3B5912FD6/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Ankur_Kumar1_4-1759141624011.png" alt="Ankur_Kumar1_4-1759141624011.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once you select the &lt;EM&gt;Plan&lt;/EM&gt; and submit the prompt, Cline (with MCP servers in the loop) interprets your intent, fetches the right CAP/Fiori context, and proposes structured code changes that you can review and refine into a production-ready solution.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ankur_Kumar1_2-1759141463291.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/321103iD7D961B01826892B/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Ankur_Kumar1_2-1759141463291.png" alt="Ankur_Kumar1_2-1759141463291.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;You will now see a fully scaffolded CAP (Cloud Application Programming) application generated ‚Äî with entities, services, and annotations created automatically based on your prompt, thanks to the MCP servers providing structured context to the AI assistant.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Ankur_Kumar1_0-1759141394076.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/321100iCD7C39D1198DDC36/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Ankur_Kumar1_0-1759141394076.png" alt="Ankur_Kumar1_0-1759141394076.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-122221240"&gt;Benefits &amp;amp; Caution&lt;/H3&gt;&lt;H3 id="toc-hId--149523634"&gt;Benefits&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Faster Prototyping and Scaffolding&lt;/STRONG&gt; ‚Äì Quickly generate CAP entities, Fiori views, and annotations without manual boilerplate work.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Reduced Hallucinations&lt;/STRONG&gt; ‚Äì Structured context from MCP servers ensures AI proposals are relevant and accurate.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Freed Mental Bandwidth&lt;/STRONG&gt; ‚Äì Focus on UX, domain logic, and performance optimization, while AI handles repetitive scaffolding.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Aligned with SAP Standards &amp;amp; Governance&lt;/STRONG&gt; ‚Äì Generated code respects enterprise best practices and architectural guidelines.&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId--346037139"&gt;Caution&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;MCP Servers Are Evolving&lt;/STRONG&gt; ‚Äì Always review AI-generated code before deployment.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Complex Business Logic Needs Oversight&lt;/STRONG&gt; ‚Äì Human expertise is essential for transactional integrity, security, and edge-case handling.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Prompt Precision Matters&lt;/STRONG&gt; ‚Äì Well-crafted prompts yield better, more reliable results.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Governance Remains Your Responsibility&lt;/STRONG&gt; ‚Äì Testing, security, and compliance cannot be fully delegated to AI.&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId--542550644"&gt;Conclusion&lt;/H3&gt;&lt;P&gt;Vibe coding isn‚Äôt just about writing code faster ‚Äî it‚Äôs about reimagining how we build enterprise software. By combining AI assistants, SAP AI Core, and MCP servers, we provide AI the context it needs to act as a true development partner.&lt;/P&gt;&lt;P&gt;This approach lets developers move beyond boilerplate work and focus on what matters most: architecture, business logic, user experience, and innovation&lt;/P&gt;&lt;P&gt;Human expertise remains essential. Governance, compliance, performance tuning, and creativity stay firmly in the developer‚Äôs hands. But with vibe coding, tedious and repetitive tasks are no longer blockers ‚Äî they‚Äôre delegated.&lt;/P&gt;&lt;P&gt;As these patterns mature, this may be remembered as the moment enterprise development evolved from ‚Äúwriting code‚Äù to ‚Äúdesigning conversations.‚Äù The future of coding in SAP isn‚Äôt just AI-assisted ‚Äî it‚Äôs context-aware, collaborative, and human-centered.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/vibe-coding-with-mcp-servers-amp-sap-ai-core-toward-quot-coding-by/qaq-p/14230581"/>
    <published>2025-09-29T15:36:36.701000+02:00</published>
  </entry>
</feed>
