<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/SAP-HANA-Cloud-blog-posts.xml</id>
  <title>SAP Community - SAP HANA Cloud</title>
  <updated>2026-01-11T00:01:36.855174+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/SAP HANA Cloud/pd-p/73554900100800002881" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>SAP HANA Cloud blog posts in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/the-architect-s-blueprint-unifying-commerce-for-business-growth/ba-p/14271301</id>
    <title>üí° The Architect's Blueprint: Unifying Commerce for Business Growth</title>
    <updated>2025-11-17T17:46:15.412000+01:00</updated>
    <author>
      <name>raghavendra_desu</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/477476</uri>
    </author>
    <content>&lt;P class="lia-align-left" style="text-align : left;"&gt;&lt;SPAN&gt;Our primary mission is to solve the endemic problem of &lt;/SPAN&gt;&lt;STRONG&gt;fragmented customer experiences&lt;/STRONG&gt;&lt;SPAN&gt;. When disparate systems‚Äîsales, inventory, and marketing‚Äîoperate in silos, we lose sight of the customer, resulting in wasted budget and missed opportunities. This blueprint outlines the strategic use of the SAP technology stack to achieve true &lt;/SPAN&gt;&lt;STRONG&gt;Unified Commerce&lt;/STRONG&gt;&lt;SPAN&gt;, providing value not just to the business, but also clear direction for our technical teams.&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1765481771"&gt;1. The Foundation: Customer Identity and Trust&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;Business Problem:&lt;/STRONG&gt; We can't personalize experiences or comply with global privacy regulations without a single, reliable customer record.&lt;/P&gt;&lt;H3 id="toc-hId-1698050985"&gt;&lt;STRONG&gt;Component: SAP Customer Data Cloud (CDC)&lt;/STRONG&gt;&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Architectural Role:&lt;/STRONG&gt; This is our &lt;STRONG&gt;Identity and Trust Hub&lt;/STRONG&gt;. It must be the authoritative &lt;STRONG&gt;System of Record&lt;/STRONG&gt; for customer identity and consent.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Developer Focus:&lt;/STRONG&gt; CDC performs &lt;STRONG&gt;Profile Unification&lt;/STRONG&gt;, aggregating data across all channels into one golden record. It manages mandatory &lt;STRONG&gt;Consent Management Platform (CMP)&lt;/STRONG&gt; functions, ensuring that all data activation is compliant.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Integration Strategy:&lt;/STRONG&gt; A crucial, high-priority &lt;STRONG&gt;Profile Sync&lt;/STRONG&gt; pipeline sends unified, consented customer profiles and real-time behavioral data directly to &lt;STRONG&gt;SAP Emarsys&lt;/STRONG&gt; for activation. This is the bedrock of our personalization strategy.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;HR /&gt;&lt;H2 id="toc-hId-1372454761"&gt;2. The Front Door: Experience and Transaction&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;Business Problem:&lt;/STRONG&gt; Customers demand instant, seamless experiences across all touchpoints with flexible, reliable payment options.&lt;/P&gt;&lt;H3 id="toc-hId-1305023975"&gt;&lt;STRONG&gt;Component: SAP Commerce Cloud&lt;/STRONG&gt;&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Architectural Role:&lt;/STRONG&gt; The &lt;STRONG&gt;API-First Front Office&lt;/STRONG&gt;. It's responsible for the user experience, product catalog, and pricing. The built-in AI features enable natural language shopping queries, improving conversion rates.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Payment Strategy (OPF):&lt;/STRONG&gt; We mandate the use of the &lt;STRONG&gt;Open Payment Framework (OPF)&lt;/STRONG&gt;.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;The Value:&lt;/STRONG&gt; The OPF serves as a standardized adapter layer, abstracting sensitive payment logic away from the core. This allows our teams to integrate seamlessly with various &lt;STRONG&gt;Third-Party Payment Providers (PSPs)&lt;/STRONG&gt; for flexible payment options, while minimizing &lt;STRONG&gt;PCI compliance&lt;/STRONG&gt; scope on the Commerce platform itself.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;HR /&gt;&lt;H2 id="toc-hId-979427751"&gt;3. The Digital Core and Integration Strategy&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;Business Problem:&lt;/STRONG&gt; The customer experience fails if the back office is not reliable (e.g., incorrect inventory). We need resilient, real-time connectivity between sales and fulfillment.&lt;/P&gt;&lt;H3 id="toc-hId-911996965"&gt;&lt;STRONG&gt;Core Components: SAP S/4HANA &amp;amp; SAP Business Technology Platform (BTP)&lt;/STRONG&gt;&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;SAP S/4HANA (The Digital Core):&lt;/STRONG&gt; This is the transactional back-end, handling &lt;STRONG&gt;Order Fulfillment&lt;/STRONG&gt;, &lt;STRONG&gt;Logistics&lt;/STRONG&gt;, and &lt;STRONG&gt;Inventory&lt;/STRONG&gt;. Its real-time architecture is vital for providing accurate inventory checks to Commerce.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;SAP BTP Integration Suite:&lt;/STRONG&gt; This is the &lt;STRONG&gt;Architectural Glue and Integration Layer&lt;/STRONG&gt;.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Developer Focus:&lt;/STRONG&gt; All cross-system data exchange is managed here using &lt;STRONG&gt;iFlows&lt;/STRONG&gt;. This enforces the &lt;STRONG&gt;Clean Core Principle&lt;/STRONG&gt;‚Äîwe do not modify core S/4HANA code for integration.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Key Integration:&lt;/STRONG&gt; The high-volume &lt;STRONG&gt;Order Sync&lt;/STRONG&gt; (Commerce to S/4HANA) is orchestrated through the Integration Suite, ensuring reliable, guaranteed delivery and a unified order history.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;HR /&gt;&lt;H2 id="toc-hId-586400741"&gt;4. The Intelligence Layer: Activation and Personalization&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;Business Problem:&lt;/STRONG&gt; Marketing spend must be targeted, relevant, and based on the most accurate customer profile to maximize Customer Lifetime Value (CLV).&lt;/P&gt;&lt;H3 id="toc-hId-518969955"&gt;&lt;STRONG&gt;Component: SAP Emarsys Marketing &amp;amp; Campaign Management&lt;/STRONG&gt;&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Architectural Role:&lt;/STRONG&gt; The &lt;STRONG&gt;Unified Activation Platform&lt;/STRONG&gt;. It consolidates all campaign planning, email execution, and personalization into a single system.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Developer/Architect Focus:&lt;/STRONG&gt; Emarsys receives the high-fidelity, consented profiles from CDC. It serves as the orchestration engine for multi-wave, AI-powered campaigns, utilizing &lt;STRONG&gt;real-time triggers&lt;/STRONG&gt; based on customer behavior.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;HR /&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="raghavendra_desu_0-1763397286020.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/342009i3C850B3CBDE5F40C/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="raghavendra_desu_0-1763397286020.png" alt="raghavendra_desu_0-1763397286020.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;HR /&gt;&lt;H2 id="toc-hId-193373731"&gt;&lt;span class="lia-unicode-emoji" title=":direct_hit:"&gt;üéØ&lt;/span&gt; Conclusion: Strategic Mandates for Technical Teams&lt;/H2&gt;&lt;P&gt;This blueprint provides the stability and scalability required for business growth. For the developer and architect community, the mandate is clear:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Enforce the Clean Core:&lt;/STRONG&gt; All integrations &lt;STRONG&gt;must&lt;/STRONG&gt; run through the &lt;STRONG&gt;SAP BTP Integration Suite&lt;/STRONG&gt;.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Profile Consistency:&lt;/STRONG&gt; Ensure all systems read and write customer identity and consent data via &lt;STRONG&gt;SAP CDC&lt;/STRONG&gt;.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Future-Proof Payments:&lt;/STRONG&gt; Utilize the &lt;STRONG&gt;OPF&lt;/STRONG&gt; in Commerce to ensure a flexible, compliant payment architecture.&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Following this structure ensures we deliver not just a functional solution, but a scalable, maintainable enterprise architecture.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/the-architect-s-blueprint-unifying-commerce-for-business-growth/ba-p/14271301"/>
    <published>2025-11-17T17:46:15.412000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-members/create-a-cap-application-with-sap-hana-cloud-from-scratch-and-deploy-to/ba-p/14270378</id>
    <title>Create a CAP Application with SAP HANA Cloud from Scratch and Deploy to Cloud Foundry in SAP BTP</title>
    <updated>2025-11-19T12:24:37.057000+01:00</updated>
    <author>
      <name>MaheshSirsat1708</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1495997</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;Create a CAP Application with SAP HANA Cloud from Scratch and Deploy to Cloud Foundry&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This guide walks you through the complete lifecycle of building a CAP (Cloud Application Programming) application, connecting it to SAP HANA Cloud, and deploying it to SAP BTP Cloud Foundry.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;1.Create SAP BTP Trial Account &lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;You need a trial account to access Cloud Foundry, SAP HANA Cloud, and all BAS development tools.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;2. Subscribe to SAP Business Application Studio (BAS)&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;If not subscribed:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Go to &lt;STRONG&gt;SAP BTP Cockpit ‚Üí Instances and Subscriptions&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Subscribe to &lt;STRONG&gt;Business Application Studio&lt;/STRONG&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;3. Create CAP Project Skeleton (Using Template Wizard)&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Open BAS and press:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Ctrl + Shift + P ‚Üí Template Wizard&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_0-1763211188026.png" style="width: 715px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341554i3993176A4F10ACB7/image-dimensions/715x268?v=v2" width="715" height="268" role="button" title="MaheshSirsat1708_0-1763211188026.png" alt="MaheshSirsat1708_0-1763211188026.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Then follow these steps:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;3.1 Select Template&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Select: &lt;STRONG&gt;CAP Project Generator&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Click &lt;STRONG&gt;Next&lt;/STRONG&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_1-1763211188035.png" style="width: 792px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341556i63819F2D42A2C78B/image-dimensions/792x305?v=v2" width="792" height="305" role="button" title="MaheshSirsat1708_1-1763211188035.png" alt="MaheshSirsat1708_1-1763211188035.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;3.2 Provide Project Details&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Project Name&lt;/STRONG&gt; ‚Üí Any name of your choice&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Choose Database&lt;/STRONG&gt; ‚Üí SQLite (default)&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Choose Deployment Target&lt;/STRONG&gt; ‚Üí Cloud Foundry&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Note:&lt;/STRONG&gt;&lt;BR /&gt;Do &lt;STRONG&gt;not&lt;/STRONG&gt; select SAP HANA Cloud here.&lt;BR /&gt;We first deploy the application with SQLite, then add HANA later from terminal.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_2-1763211188038.png" style="width: 808px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341555i2438C022DD442EE1/image-dimensions/808x400?v=v2" width="808" height="400" role="button" title="MaheshSirsat1708_2-1763211188038.png" alt="MaheshSirsat1708_2-1763211188038.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;3.3 Choose Runtime Capabilities&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Select these productive services:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;XSUAA&lt;/LI&gt;&lt;LI&gt;SAP BTP Connectivity Service&lt;/LI&gt;&lt;LI&gt;SAP BTP Destination Service&lt;/LI&gt;&lt;LI&gt;SAP BTP Application Router&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Click &lt;STRONG&gt;Finish&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_3-1763211188042.png" style="width: 832px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341558i637385D60D1DCAAB/image-dimensions/832x557?v=v2" width="832" height="557" role="button" title="MaheshSirsat1708_3-1763211188042.png" alt="MaheshSirsat1708_3-1763211188042.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This creates the complete folder structure including:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;/db&lt;/LI&gt;&lt;LI&gt;/srv&lt;/LI&gt;&lt;LI&gt;/app&lt;/LI&gt;&lt;LI&gt;mta.yaml&lt;/LI&gt;&lt;LI&gt;Security and deployment artifacts&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_4-1763211188044.png" style="width: 626px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341557iE62AF70D55D19C84/image-dimensions/626x462/is-moderation-mode/true?v=v2" width="626" height="462" role="button" title="MaheshSirsat1708_4-1763211188044.png" alt="MaheshSirsat1708_4-1763211188044.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;4. Modify MTA Configuration&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Cloud Foundry sometimes fails when resource names contain dynamic interpolation (org/space).&lt;/P&gt;&lt;P&gt;Removing them ensures deployment simplicity.&lt;/P&gt;&lt;P&gt;Open mta.yaml and remove:&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;-${org}-${space}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;from all resource names.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_5-1763211188053.png" style="width: 805px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341559i627892299805720D/image-dimensions/805x668?v=v2" width="805" height="668" role="button" title="MaheshSirsat1708_5-1763211188053.png" alt="MaheshSirsat1708_5-1763211188053.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;5. Create a Sample CAP Model&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;5.1 Define Database Schema&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Open /db/schema.cds:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_6-1763211188054.png" style="width: 792px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341560iB9DB9D0EC9B90F71/image-dimensions/792x310?v=v2" width="792" height="310" role="button" title="MaheshSirsat1708_6-1763211188054.png" alt="MaheshSirsat1708_6-1763211188054.png" /&gt;&lt;/span&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;5.2 Create Service Definition&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Open /srv/service.cds:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_7-1763211188057.png" style="width: 800px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341561i963DB326381F59F6/image-dimensions/800x378?v=v2" width="800" height="378" role="button" title="MaheshSirsat1708_7-1763211188057.png" alt="MaheshSirsat1708_7-1763211188057.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now, you have a simple end-to-end data + service model to validate local and cloud deployment.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;6. Test the CAP Application Locally&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;cds w&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Now, CAP runs using &lt;STRONG&gt;SQLite&lt;/STRONG&gt;, allowing quick testing without any external services.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_8-1763211188059.png" style="width: 819px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341562iB233AC76E44A3D8E/image-dimensions/819x172?v=v2" width="819" height="172" role="button" title="MaheshSirsat1708_8-1763211188059.png" alt="MaheshSirsat1708_8-1763211188059.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_9-1763211188063.png" style="width: 840px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341565iCF7BF7CEF9F8EC06/image-dimensions/840x401?v=v2" width="840" height="401" role="button" title="MaheshSirsat1708_9-1763211188063.png" alt="MaheshSirsat1708_9-1763211188063.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;STRONG&gt;7. Deploy the CAP Application (SQLite Mode)&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Right-click &lt;STRONG&gt;mta.yaml ‚Üí Build MTA Project&lt;/STRONG&gt;&lt;/LI&gt;&lt;UL&gt;&lt;LI&gt;Or use:&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;/OL&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;mbt build&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 2. Login to Cloud Foundry&lt;BR /&gt;&lt;STRONG&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;Ctrl + Shift + P ‚Üí CF Login&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_10-1763211188066.png" style="width: 796px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341563iD4221ED927318F5B/image-dimensions/796x545?v=v2" width="796" height="545" role="button" title="MaheshSirsat1708_10-1763211188066.png" alt="MaheshSirsat1708_10-1763211188066.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;3. Deploy the generated .mtar&lt;/P&gt;&lt;OL&gt;&lt;UL&gt;&lt;LI&gt;Right-click .mtar ‚Üí &lt;STRONG&gt;Deploy MTA Archive&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Or use:&lt;/LI&gt;&lt;LI&gt;cf deploy yourfile.mtar&lt;/LI&gt;&lt;/UL&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_11-1763211188068.png" style="width: 808px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341564iD79AE9B0405CBAD7/image-dimensions/808x521?v=v2" width="808" height="521" role="button" title="MaheshSirsat1708_11-1763211188068.png" alt="MaheshSirsat1708_11-1763211188068.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Your CAP app runs in Cloud Foundry with SQLite.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_12-1763211188071.png" style="width: 804px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341567iD0A5D438A28F1971/image-dimensions/804x374?v=v2" width="804" height="374" role="button" title="MaheshSirsat1708_12-1763211188071.png" alt="MaheshSirsat1708_12-1763211188071.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_13-1763211188078.png" style="width: 815px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341569i7384482A1FF44144/image-dimensions/815x446?v=v2" width="815" height="446" role="button" title="MaheshSirsat1708_13-1763211188078.png" alt="MaheshSirsat1708_13-1763211188078.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Next, we will connect it to real SAP HANA Cloud&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;8. Create SAP HANA Cloud Instance&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Go to:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;SAP BTP Cockpit ‚Üí Instances &amp;amp; Subscriptions ‚Üí Create&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Choose:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Service:&lt;/STRONG&gt; SAP HANA Cloud&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Plan:&lt;/STRONG&gt; hana&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Environment:&lt;/STRONG&gt; Cloud Foundry&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Instance Name:&lt;/STRONG&gt; hanaDB&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Set the DB &lt;STRONG&gt;administrator password&lt;/STRONG&gt; ‚Üí required for Data Explorer.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_37-1763212044767.png" style="width: 812px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341616i73CF9005761D119B/image-dimensions/812x483/is-moderation-mode/true?v=v2" width="812" height="483" role="button" title="MaheshSirsat1708_37-1763212044767.png" alt="MaheshSirsat1708_37-1763212044767.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;And press on Create instance.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_38-1763212044776.png" style="width: 829px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341615i85BC894E78731A9A/image-dimensions/829x114/is-moderation-mode/true?v=v2" width="829" height="114" role="button" title="MaheshSirsat1708_38-1763212044776.png" alt="MaheshSirsat1708_38-1763212044776.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;It will take estimated 10-15min&lt;/P&gt;&lt;P&gt;It creates the actual HANA database where CAP HDI containers will be deployed.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;9. Subscribe to SAP HANA Cloud Tools&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Without this subscription, you cannot access the DB instance UI.&lt;/P&gt;&lt;P&gt;Go to:&lt;BR /&gt;&lt;STRONG&gt;Instances &amp;amp; Subscriptions ‚Üí Subscribe ‚Üí SAP HANA Cloud Tools&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_39-1763212044789.png" style="width: 820px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341617iFE4DE6127FC661D3/image-dimensions/820x525/is-moderation-mode/true?v=v2" width="820" height="525" role="button" title="MaheshSirsat1708_39-1763212044789.png" alt="MaheshSirsat1708_39-1763212044789.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Assign Roles&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Under &lt;STRONG&gt;Users&lt;/STRONG&gt;, assign all required HANA Cloud roles.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_40-1763212044792.png" style="width: 805px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341618i1C6579B51E0F2CAF/image-dimensions/805x246/is-moderation-mode/true?v=v2" width="805" height="246" role="button" title="MaheshSirsat1708_40-1763212044792.png" alt="MaheshSirsat1708_40-1763212044792.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Sign out ‚Üí Sign in again.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;10. Open SAP HANA Data Explorer&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Click the HANA instance ‚Üí &lt;STRONG&gt;Open SAP HANA Database Explorer&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_41-1763212044799.png" style="width: 808px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341620iF3871331C45792B7/image-dimensions/808x322/is-moderation-mode/true?v=v2" width="808" height="322" role="button" title="MaheshSirsat1708_41-1763212044799.png" alt="MaheshSirsat1708_41-1763212044799.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_42-1763212044805.png" style="width: 828px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341619i711B3D612C721832/image-dimensions/828x379/is-moderation-mode/true?v=v2" width="828" height="379" role="button" title="MaheshSirsat1708_42-1763212044805.png" alt="MaheshSirsat1708_42-1763212044805.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;First login:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Username: &lt;STRONG&gt;DBADMIN&lt;/STRONG&gt; (or the username shown under "Administrator")&lt;/LI&gt;&lt;LI&gt;Password: the one you entered during instance creation&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_43-1763212044807.png" style="width: 764px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341621iE24EF3F18E293978/image-dimensions/764x449/is-moderation-mode/true?v=v2" width="764" height="449" role="button" title="MaheshSirsat1708_43-1763212044807.png" alt="MaheshSirsat1708_43-1763212044807.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;If you forgot your DB username&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Open:&lt;BR /&gt;&lt;STRONG&gt;SAP HANA Cloud Administration ‚Üí Overview&lt;/STRONG&gt;&lt;BR /&gt;Your administrator username will be displayed there.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_44-1763212044810.png" style="width: 816px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341623iC7A2A9964208518C/image-dimensions/816x504/is-moderation-mode/true?v=v2" width="816" height="504" role="button" title="MaheshSirsat1708_44-1763212044810.png" alt="MaheshSirsat1708_44-1763212044810.png" /&gt;&lt;/span&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Now, You have direct access to schemas, HDI containers, and database objects.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;11. Open HDI Container Section in SAP HANA Database Explorer&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Inside SAP HANA Database Explorer:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Click the &lt;STRONG&gt;‚Äú+‚Äù&lt;/STRONG&gt; icon&lt;/LI&gt;&lt;LI&gt;Choose &lt;STRONG&gt;Cloud Foundry&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Log in to your CF environment&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_45-1763212044812.png" style="width: 767px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341622iEBCF5AC922B047CC/image-dimensions/767x706/is-moderation-mode/true?v=v2" width="767" height="706" role="button" title="MaheshSirsat1708_45-1763212044812.png" alt="MaheshSirsat1708_45-1763212044812.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;From the list ‚Üí choose &lt;STRONG&gt;Instance Type: HDI Container&lt;/STRONG&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_46-1763212044815.png" style="width: 786px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341627i735E91669E2E8C74/image-dimensions/786x511/is-moderation-mode/true?v=v2" width="786" height="511" role="button" title="MaheshSirsat1708_46-1763212044815.png" alt="MaheshSirsat1708_46-1763212044815.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;At this stage, your CAP HDI container will &lt;STRONG&gt;NOT appear yet&lt;/STRONG&gt;, because we have not created it.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;12. Add HANA Support to CAP Application&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Run the following commands in BAS terminal:&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;cds add hana
npm i&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;What these commands do&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;cds add hana&lt;/STRONG&gt;&lt;/LI&gt;&lt;UL&gt;&lt;LI&gt;Generates HANA-specific configuration&lt;/LI&gt;&lt;LI&gt;Creates HDI deployment artifacts&lt;/LI&gt;&lt;LI&gt;Prepares the project to run on SAP HANA instead of SQLite&lt;/LI&gt;&lt;/UL&gt;&lt;LI&gt;&lt;STRONG&gt;npm i&lt;/STRONG&gt;&lt;/LI&gt;&lt;UL&gt;&lt;LI&gt;Installs additional dependencies required for HANA runtime&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_47-1763212044816.png" style="width: 833px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341625i0DA1BD19BA26CE08/image-dimensions/833x202/is-moderation-mode/true?v=v2" width="833" height="202" role="button" title="MaheshSirsat1708_47-1763212044816.png" alt="MaheshSirsat1708_47-1763212044816.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now, your project is ready to connect and deploy models to an HDI container.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;13. Update package.json for HANA Deployment&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;Open package.json ‚Üí under "cds.requires" add:&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;"db": {
  "kind": "hana"
}&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_48-1763212044818.png" style="width: 815px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341626iF364C6679F6D6414/image-dimensions/815x316/is-moderation-mode/true?v=v2" width="815" height="316" role="button" title="MaheshSirsat1708_48-1763212044818.png" alt="MaheshSirsat1708_48-1763212044818.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This tells CAP to use SAP HANA as the primary database in production.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;14. Bind the CAP Project to Your HANA Instance&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;In &lt;STRONG&gt;BAS ‚Üí Cloud Foundry view&lt;/STRONG&gt;:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Select your CAP app&lt;/LI&gt;&lt;LI&gt;Choose &lt;STRONG&gt;Bind to Service&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Pick your HANA DB instance hanaDB&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;This automatically creates a &lt;STRONG&gt;.env&lt;/STRONG&gt; file containing:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;HDI container name&lt;/LI&gt;&lt;LI&gt;Credentials&lt;/LI&gt;&lt;LI&gt;Database URLs&lt;/LI&gt;&lt;LI&gt;Service keys&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_49-1763212044820.png" style="width: 480px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341629i303D208D68C33D62/image-dimensions/480x604/is-moderation-mode/true?v=v2" width="480" height="604" role="button" title="MaheshSirsat1708_49-1763212044820.png" alt="MaheshSirsat1708_49-1763212044820.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Why we are doing this&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;CAP needs this information to connect to SAP HANA for:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Local ‚Äúcds watch‚Äù&lt;/LI&gt;&lt;LI&gt;Production deployment&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Your project is now fully connected to SAP HANA Cloud.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;15. Build Your CAP Project for Production&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Run:&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;cds build ‚Äìproduction&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_50-1763212044821.png" style="width: 771px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341630i80ED612A714344DE/image-dimensions/771x447/is-moderation-mode/true?v=v2" width="771" height="447" role="button" title="MaheshSirsat1708_50-1763212044821.png" alt="MaheshSirsat1708_50-1763212044821.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;HANA Cloud can now deploy your database schema properly.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;16. Deploy to SAP HANA Cloud&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Run:&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;cds deploy --production&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_51-1763212044822.png" style="width: 797px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341628i64A2B07207BD2D25/image-dimensions/797x462/is-moderation-mode/true?v=v2" width="797" height="462" role="button" title="MaheshSirsat1708_51-1763212044822.png" alt="MaheshSirsat1708_51-1763212044822.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Creates HDI container&lt;/LI&gt;&lt;LI&gt;Deploys CDS schema into HANA tables&lt;/LI&gt;&lt;LI&gt;Activates views, indexes, constraints&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Your CAP application now uses SAP HANA Cloud as its primary DB.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;17. Rebuild and Deploy the Entire CAP Application&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Again perform:&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;mbt build&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Then deploy:&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;cf deploy &amp;lt;yourfile&amp;gt;.mtar&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_52-1763212044825.png" style="width: 812px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341632i2892B1A34996DD82/image-dimensions/812x485/is-moderation-mode/true?v=v2" width="812" height="485" role="button" title="MaheshSirsat1708_52-1763212044825.png" alt="MaheshSirsat1708_52-1763212044825.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_53-1763212044828.png" style="width: 807px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341631iCB3A317D6F3CBA92/image-dimensions/807x228/is-moderation-mode/true?v=v2" width="807" height="228" role="button" title="MaheshSirsat1708_53-1763212044828.png" alt="MaheshSirsat1708_53-1763212044828.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Our complete application (service + database) is deployed on Cloud Foundry using HANA.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;18. Verify Schema Deployment in SAP HANA Cloud&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Open &lt;STRONG&gt;SAP HANA Data Explorer&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Click &lt;STRONG&gt;+&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Select &lt;STRONG&gt;Instance Type = HDI&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Choose your CAP application HDI container&amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_54-1763212044831.png" style="width: 828px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341633i7DF0070B4CBBD556/image-dimensions/828x480/is-moderation-mode/true?v=v2" width="828" height="480" role="button" title="MaheshSirsat1708_54-1763212044831.png" alt="MaheshSirsat1708_54-1763212044831.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 5. Expand &lt;STRONG&gt;Tables&lt;/STRONG&gt; and &lt;STRONG&gt;Views&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_55-1763212044834.png" style="width: 841px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341635iC35710D77B6F877C/image-dimensions/841x295/is-moderation-mode/true?v=v2" width="841" height="295" role="button" title="MaheshSirsat1708_55-1763212044834.png" alt="MaheshSirsat1708_55-1763212044834.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;You can verify that:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Tables are created&lt;/LI&gt;&lt;LI&gt;Data model is deployed correctly&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;19. Running CAP Application Locally Using HANA Cloud&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;If you want to run locally via HANA:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Ensure .env exists&lt;/LI&gt;&lt;LI&gt;Rebind HDI container if needed&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_56-1763212044838.png" style="width: 798px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341636iC4C945CEB2F45A6D/image-dimensions/798x411/is-moderation-mode/true?v=v2" width="798" height="411" role="button" title="MaheshSirsat1708_56-1763212044838.png" alt="MaheshSirsat1708_56-1763212044838.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_57-1763212044841.png" style="width: 840px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341634i9CB213FBF63425CB/image-dimensions/840x439/is-moderation-mode/true?v=v2" width="840" height="439" role="button" title="MaheshSirsat1708_57-1763212044841.png" alt="MaheshSirsat1708_57-1763212044841.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Run:&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/LI&gt;&lt;/OL&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;cds w&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Successful connection check&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;If logs show:&lt;/P&gt;&lt;P&gt;Connected to SAP HANA Cloud (hanaDB) . Then your HDI container is successfully connected.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_58-1763212044855.png" style="width: 794px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341638i8EA67CF9A2C2E3E0/image-dimensions/794x374/is-moderation-mode/true?v=v2" width="794" height="374" role="button" title="MaheshSirsat1708_58-1763212044855.png" alt="MaheshSirsat1708_58-1763212044855.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;20. Validate Deployment Using Postman&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MaheshSirsat1708_59-1763212044858.png" style="width: 822px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/341637iFD481AA8AF732F48/image-dimensions/822x257/is-moderation-mode/true?v=v2" width="822" height="257" role="button" title="MaheshSirsat1708_59-1763212044858.png" alt="MaheshSirsat1708_59-1763212044858.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;This confirms:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Service is running&lt;/LI&gt;&lt;LI&gt;HANA DB is connected&lt;/LI&gt;&lt;LI&gt;Deployment is successful end-to-end&lt;/LI&gt;&lt;/UL&gt;&lt;H1 id="toc-hId-1636369485"&gt;&lt;STRONG&gt;Conclusion&lt;/STRONG&gt;&lt;/H1&gt;&lt;P&gt;&lt;STRONG&gt;In this blog, we have completed the following activities:&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Created a new CAP application using the BAS template wizard.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Performed an initial deployment using SQLite to verify application behavior.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Provisioned a SAP HANA Cloud instance and assigned all required role collections.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Enabled HANA support in the CAP project and generated HDI-related artifacts.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Bound the project to the HANA instance to establish secure database connectivity.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Built CDS artifacts for production and deployed them into the HDI container.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Rebuilt and deployed the full MTA application to SAP BTP Cloud Foundry using HANA as the primary database.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;Verified successful deployment through SAP HANA Database Explorer and API testing.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-members/create-a-cap-application-with-sap-hana-cloud-from-scratch-and-deploy-to/ba-p/14270378"/>
    <published>2025-11-19T12:24:37.057000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/how-ai-solutions-can-align-with-sap-s-clean-core-principles/ba-p/14278920</id>
    <title>How AI Solutions Can Align with SAP‚Äôs Clean Core Principles</title>
    <updated>2025-11-27T11:24:00.361000+01:00</updated>
    <author>
      <name>Shubhojit-Sarkar</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1959363</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;‚ÄúClean core‚Äù&lt;/STRONG&gt; and &lt;STRONG&gt;‚ÄúArtificial Intelligence‚Äù&lt;/STRONG&gt; are often discussed in isolation. Clean core is positioned to reduce technical debt and keep SAP S/4HANA upgradeable, while AI is usually associated with new workloads, additional components, and non-SAP technologies such as Python.&lt;/P&gt;&lt;P&gt;This separation leads to a common misconception: that AI solutions, especially those implemented in Python or using external models, are incompatible with a clean core strategy.&lt;/P&gt;&lt;P&gt;In practice, AI and clean core are closely aligned. SAP‚Äôs own definition of an ERP clean core emphasizes standardization, modern extensibility, and the ability to leverage reliable data and AI innovations on top of a stable core. When designed correctly, AI solutions can fully comply with clean core principles and in many cases help to realize the intended benefits of the strategy.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;SAP Clean Core Strategy&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;SAP describes an ERP clean core strategy as a set of guiding principles to keep business critical systems agile, cost-effective, and ready to adopt innovation. Key elements include:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Reduction of historically grown complexity&lt;/STRONG&gt; and custom code in the core ERP system.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Standardization of processes&lt;/STRONG&gt; by staying close to SAP best practices.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Use of modern extensibility options&lt;/STRONG&gt;, particularly side-by-side extensions on SAP Business Technology Platform (SAP BTP).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;API- first and event-driven integration&lt;/STRONG&gt;, rather than direct database access.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Cloud readiness and continuous innovation&lt;/STRONG&gt;, including the ability to exploit AI capabilities.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Clean core does not prohibit custom logic or non-ABAP technology. It defines where that logic should run (outside the S/4 core) and how it should integrate (through released, supported interfaces).&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Principles Relevant for AI Solutions&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;For AI initiatives, the following clean core principles are particularly relevant:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Decoupled innovation: &lt;/STRONG&gt;AI workloads should run outside the S/4HANA core, typically on SAP BTP, and consume data via published APIs or data services.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Use of official extensibility models: &lt;/STRONG&gt;Extensions should follow the models described in SAP‚Äôs clean core and extensibility guidance, including in-app extensions, developer extensibility (ABAP Cloud), and side-by-side extensions.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;API-first and event-driven patterns: &lt;/STRONG&gt;AI components should use official APIs and events to interact with core applications, rather than relying on direct table access or modifications.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Governed data access: &lt;/STRONG&gt;Data for AI models should be accessed through governed layers such as SAP HANA Cloud or SAP Datasphere, which preserve security, compliance and lineage.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;If an AI architecture respects these principles, it is aligned with the clean core strategy, regardless of the programming language or specific AI framework used.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Clean-Core Compliant AI Architecture Patterns&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Side-by-Side AI on SAP BTP&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;SAP‚Äôs &lt;STRONG&gt;‚ÄúGenerative AI on SAP BTP‚Äù &lt;/STRONG&gt;reference architecture explicitly positions SAP BTP as the platform for AI workloads, with S/4HANA and other SAP cloud solutions used as systems of record.&lt;/P&gt;&lt;P&gt;In a side-by-side pattern:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;SAP S/4HANA&lt;/STRONG&gt;&lt;/LI&gt;&lt;UL&gt;&lt;LI&gt;Hosts standard business processes and transactional data.&lt;/LI&gt;&lt;LI&gt;Exposes business functionality via released OData/REST APIs and events.&lt;/LI&gt;&lt;/UL&gt;&lt;LI&gt;&lt;STRONG&gt;SAP BTP (AI and application layer)&lt;/STRONG&gt;&lt;/LI&gt;&lt;UL&gt;&lt;LI&gt;Runs AI workloads using SAP AI Core and SAP AI Launchpad, where models and pipelines can be implemented in Python or other languages.&lt;/LI&gt;&lt;LI&gt;Uses SAP Generative AI Hub for LLM access, prompt orchestration, retrieval-augmented generation (RAG), and agentic scenarios.&lt;/LI&gt;&lt;/UL&gt;&lt;LI&gt;&lt;STRONG&gt;Integration&lt;/STRONG&gt;&lt;/LI&gt;&lt;UL&gt;&lt;LI&gt;Uses SAP Integration Suite, API Management and/or Event Mesh to connect AI components with S/4HANA through supported interfaces.&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="ShubhojitSarkar_0-1764238704361.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/345876i48EBD332B6ACCDB9/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="ShubhojitSarkar_0-1764238704361.png" alt="ShubhojitSarkar_0-1764238704361.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-60px" style="padding-left : 60px;"&gt;&lt;FONT size="2"&gt;AI workloads remain in the BTP extension layer, while SAP S/4HANA stays as the clean, standard core accessed via published APIs.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;This pattern adheres to clean core because all custom AI logic and orchestration stay outside the S/4HANA core, while S/4HANA is accessed only via documented integration points.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;AI Enabled Data Layer with SAP HANA Cloud&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;SAP has started using the term &lt;STRONG&gt;‚ÄúAI enabled clean core with SAP HANA Cloud‚Äù&lt;/STRONG&gt;, referring to architectures where S/4HANA remains the core ERP and SAP HANA Cloud provides an intelligent data layer for analytics and AI-driven applications.&lt;/P&gt;&lt;P&gt;Key characteristics:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Operational data is exposed or replicated from S/4HANA to SAP HANA Cloud or SAP Datasphere in a governed way.&lt;/LI&gt;&lt;LI&gt;AI models (classical ML or generative) are trained and executed against this data layer.&lt;/LI&gt;&lt;LI&gt;AI outputs are surfaced in side-by-side applications or written back into S/4HANA via APIs and standard extension points.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The core ERP remains clean and standard. AI driven logic is implemented in the surrounding data and application layers, which aligns with SAP‚Äôs stated goal of ‚Äúincreasing the pace of innovation and leveraging business value through reliable data and AI innovations‚Äù without compromising the core.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Programming Language and Clean Core Compliance&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;A frequent objection is that AI solutions are implemented in Python or with non-SAP frameworks and therefore cannot be reconciled with clean core.&lt;/P&gt;&lt;P&gt;From SAP‚Äôs standpoint, this is not correct. The clean core strategy focuses on minimizing custom code inside the core and using side-by-side extensions on SAP BTP to build new applications and innovations.&lt;/P&gt;&lt;P&gt;SAP‚Äôs own extensibility guidance explicitly acknowledges BTP side-by-side extensions implemented in ABAP Cloud, Java, Node.js and other languages. AI services developed in Python and deployed on SAP AI Core or container runtimes on BTP fall into exactly the same category.&lt;/P&gt;&lt;P&gt;Clean core compliance therefore depends on:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;The location of the code (outside S/4HANA vs. in-core modifications).&lt;/LI&gt;&lt;LI&gt;The integration pattern (released APIs and events vs. direct table access).&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;It does not depend on whether the AI logic is written in ABAP, Python, Java or another language.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="ShubhojitSarkar_3-1764238774408.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/345877i2528BA834437251A/image-size/medium/is-moderation-mode/true?v=v2&amp;amp;px=400" role="button" title="ShubhojitSarkar_3-1764238774408.png" alt="ShubhojitSarkar_3-1764238774408.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-120px" style="padding-left : 120px;"&gt;&lt;FONT size="2"&gt;AI solutions built on SAP BTP and SAP HANA Cloud surrounding a clean SAP S/4HANA core, with integration strictly via APIs and events.&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;SAP‚Äôs clean core strategy is often misunderstood as a constraint on innovation. It provides the architectural discipline required to adopt AI at scale without compromising the stability and upgradeability of SAP S/4HANA.&lt;/P&gt;&lt;P&gt;By:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;keeping AI workloads on SAP BTP and SAP HANA Cloud,&lt;/LI&gt;&lt;LI&gt;integrating through released APIs and events, and&lt;/LI&gt;&lt;LI&gt;applying SAP‚Äôs extensibility guidance consistently,&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;organizations can build advanced AI solutions that are fully aligned with clean core principles. The question is not whether AI is compatible with clean core, but whether AI architectures are designed to follow the same patterns that SAP itself recommends for any modern extension.&lt;/P&gt;&lt;P&gt;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+AI+Core/pd-p/73554900100800003641" class="lia-product-mention" data-product="405-1"&gt;SAP AI Core&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+S%25252F4HANA/pd-p/73554900100800000266" class="lia-product-mention" data-product="799-1"&gt;SAP S/4HANA&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+HANA+Cloud/pd-p/73554900100800002881" class="lia-product-mention" data-product="22-1"&gt;SAP HANA Cloud&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Business+Technology+Platform/pd-p/73555000100700000172" class="lia-product-mention" data-product="1215-1"&gt;SAP Business Technology Platform&lt;/a&gt;&amp;nbsp;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Event+Mesh/pd-p/73554900100800000765" class="lia-product-mention" data-product="594-1"&gt;SAP Event Mesh&lt;/a&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/how-ai-solutions-can-align-with-sap-s-clean-core-principles/ba-p/14278920"/>
    <published>2025-11-27T11:24:00.361000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/crm-and-cx-blog-posts-by-sap/using-cap-custom-services-for-sap-sales-amp-service-cloud-v2-esm/ba-p/14281406</id>
    <title>Using CAP = Custom Services for SAP Sales &amp; Service Cloud v2 + ESM</title>
    <updated>2025-12-01T20:08:46.325000+01:00</updated>
    <author>
      <name>Yogananda</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/75</uri>
    </author>
    <content>&lt;P&gt;In today‚Äôs digital landscape, businesses need flexibility to extend standard solutions with custom logic and services. SAP Sales &amp;amp; Service Cloud v2 provides this capability through &lt;STRONG&gt;Custom Services&lt;/STRONG&gt;, and the &lt;STRONG&gt;SAP Cloud Application Programming Model (CAP)&lt;/STRONG&gt; makes it easier to build and deploy these services on &lt;STRONG&gt;SAP Business Technology Platform (BTP)&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-01_20-09-46.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347249i51AC1F87C3388B70/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-01_20-09-46.png" alt="2025-12-01_20-09-46.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This blog walks you through &lt;STRONG&gt;9 essential steps&lt;/STRONG&gt; to create and integrate custom services for SAP Sales &amp;amp; Service Cloud v2 + ESM.&lt;/P&gt;&lt;H3 id="toc-hId-1895488977"&gt;&lt;STRONG&gt;&lt;FONT color="#800080"&gt;High Level Process flow for designing Custom Services&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="diagram (2).png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347225i62EF57A91A35DFE7/image-size/large?v=v2&amp;amp;px=999" role="button" title="diagram (2).png" alt="diagram (2).png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1698975472"&gt;&lt;FONT color="#FF00FF"&gt;Step 1 :&amp;nbsp; Prepare CAP development to your Business Need&lt;/FONT&gt;&lt;/H3&gt;&lt;P&gt;Based on the customer business requirements, you can design, develop the CAP service model..&amp;nbsp;&lt;/P&gt;&lt;P&gt;Kindly refer&amp;nbsp;&lt;A href="https://help.sap.com/docs/CX_CNS_ESM/f1437ed0c63b464983503b1a1dc6af8a/760adeb672fb42229873e45a6bb379a7.html" target="_self" rel="noopener noreferrer"&gt;&lt;FONT color="#FF0000"&gt;Supported and Unsupported&amp;nbsp;&lt;/FONT&gt;&lt;/A&gt;functionalities for Custom Services.&lt;/P&gt;&lt;H3 id="toc-hId-1502461967"&gt;&lt;FONT color="#FF00FF"&gt;Step 2: Deploy to BTP&lt;/FONT&gt;&lt;/H3&gt;&lt;P&gt;once the BTP deployment is successful, ensure your CAP Service is working fine with your credentials and test it out with CRUD methods are functional.&lt;/P&gt;&lt;H3 id="toc-hId-1305948462"&gt;&lt;FONT color="#FF00FF"&gt;Step 3 : Create a Communication System&lt;/FONT&gt;&lt;/H3&gt;&lt;P&gt;In &lt;STRONG&gt;SAP Sales &amp;amp; Service Cloud v2 + ESM&lt;/STRONG&gt;, create a communication system to connect with your CAP deployed service:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Navigate to &lt;STRONG&gt;System Settings ‚Üí Communication Systems&lt;/STRONG&gt;.&lt;/LI&gt;&lt;LI&gt;Add a new system and provide:&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;System ID&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Host URL&lt;/STRONG&gt; (your CAP service endpoint deployed in BTP)&lt;/LI&gt;&lt;LI&gt;Authentication details (OAuth or Basic)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-03_10-07-23.png" style="width: 398px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347870i80143E141F9BDF9B/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-03_10-07-23.png" alt="2025-12-03_10-07-23.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1109434957"&gt;&lt;FONT color="#FF00FF"&gt;Step 4 : Create a Custom Services&lt;/FONT&gt;&lt;/H3&gt;&lt;P class=""&gt;You can create up to 30 custom services in total, with the following limits:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;A maximum of&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;30 mashup-based&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;custom services.&lt;/LI&gt;&lt;LI&gt;A maximum of&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;15 entity-based&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;custom services.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;Navigate to&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;User Menu&lt;/SPAN&gt;&amp;nbsp;-&amp;nbsp;&lt;SPAN class=""&gt;Settings&lt;/SPAN&gt;&amp;nbsp;-&amp;nbsp;&lt;SPAN class=""&gt;All Settings&lt;/SPAN&gt;&amp;nbsp;-&amp;nbsp;&lt;SPAN class=""&gt;Extensibility&lt;/SPAN&gt;&amp;nbsp;-&amp;nbsp;&lt;SPAN class=""&gt;Custom Services&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-01_19-08-25.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347234iC0AF0DE621D80038/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-01_19-08-25.png" alt="2025-12-01_19-08-25.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-912921452"&gt;&lt;FONT color="#FF00FF"&gt;Step 5 : Prepare CAP File Conversion&lt;/FONT&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;Run the following command in (your IDE where CAP is developed) the CLI to convert it to JSON:&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;FONT color="#808080"&gt;cds -2 json &amp;lt;service.cds file path&amp;gt; &amp;gt;output.json&lt;/FONT&gt;&lt;BR /&gt;upload the json as shown in the UI&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-01_19-42-07.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347240iADE3E006D5F9F0A7/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-01_19-42-07.png" alt="2025-12-01_19-42-07.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-716407947"&gt;&lt;FONT color="#FF00FF"&gt;Step 6 : Upload a File Converted&lt;/FONT&gt;&lt;/H3&gt;&lt;P&gt;Upload the file converted from above step and upload as shown in below screen&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-01_19-43-29.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347239i63E9829188A47F46/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-01_19-43-29.png" alt="2025-12-01_19-43-29.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-519894442"&gt;&lt;FONT color="#FF00FF"&gt;Step 7 : Configure Host with assigning Communication System&lt;/FONT&gt;&lt;/H3&gt;&lt;P&gt;Link your CAP service endpoint with the communication system created earlier:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Go to &lt;STRONG&gt;Communication Arrangements&lt;/STRONG&gt; in SAP Sales &amp;amp; Service Cloud.&lt;/LI&gt;&lt;LI&gt;Assign the communication system and specify the service URL.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-01_19-06-14.png" style="width: 403px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347229iEF4DF7020A733849/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-01_19-06-14.png" alt="2025-12-01_19-06-14.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-323380937"&gt;&lt;FONT color="#FF00FF"&gt;Step 8 : Design the App&lt;/FONT&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN class=""&gt;On the&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN class=""&gt;UI View&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;screen, choose&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN class=""&gt;ÓÅò&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN class=""&gt;(Create)&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;available on the top-right corner of the screen.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-01_19-10-36.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347233iE2188F3734EF5F18/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-01_19-10-36.png" alt="2025-12-01_19-10-36.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Select the required UI view pattern for your custom service&amp;nbsp;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-01_19-11-52.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347232i251791A5709767D5/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-01_19-11-52.png" alt="2025-12-01_19-11-52.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId-126867432"&gt;&lt;FONT color="#FF00FF"&gt;Step 9 : Assign the Business Role to the Custom Services&lt;/FONT&gt;&lt;/H3&gt;&lt;P&gt;Finally, ensure proper authorization:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Navigate to &lt;STRONG&gt;Business Roles&lt;/STRONG&gt; in SAP Sales &amp;amp; Service Cloud.&lt;/LI&gt;&lt;LI&gt;Assign your custom service to the relevant role so users can access it.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-01_19-33-55.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347235i5669903AC8761DE1/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-01_19-33-55.png" alt="2025-12-01_19-33-55.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Search the custom services and assign the Business Role&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-01_19-37-29.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347237i9AFC46FD94F788FB/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-01_19-37-29.png" alt="2025-12-01_19-37-29.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H3 id="toc-hId--144877442"&gt;&lt;STRONG&gt;Finally look of Custom Services (Displayed in Menu&amp;nbsp; as Workcenter)&lt;/STRONG&gt;&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="2025-12-02_12-37-50.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/347446iFCAA202A3F868175/image-size/large?v=v2&amp;amp;px=999" role="button" title="2025-12-02_12-37-50.png" alt="2025-12-02_12-37-50.png" /&gt;&lt;/span&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;H3 id="toc-hId--341390947"&gt;&amp;nbsp;&lt;/H3&gt;&lt;H3 id="toc-hId--537904452"&gt;&lt;STRONG&gt;Best Practices&lt;/STRONG&gt;&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;Use &lt;STRONG&gt;OAuth 2.0&lt;/STRONG&gt; for secure communication.&lt;/LI&gt;&lt;LI&gt;Keep CAP services modular for easy maintenance.&lt;/LI&gt;&lt;LI&gt;Test locally before deploying to BTP.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;SAP Help Documentation for &lt;A href="https://help.sap.com/docs/CX_CNS_ESM/f1437ed0c63b464983503b1a1dc6af8a/7cb6b3e19b984d6c9d7f16d0f387e6b0.html" target="_self" rel="noopener noreferrer"&gt;Custom Services&lt;/A&gt;&lt;/P&gt;&lt;H3 id="toc-hId--734417957"&gt;&lt;A href="https://help.sap.com/docs/CX_CNS_ESM/f1437ed0c63b464983503b1a1dc6af8a/760adeb672fb42229873e45a6bb379a7.html" target="_self" rel="noopener noreferrer"&gt;&lt;FONT color="#FF0000"&gt;Supported and Unsupported&lt;/FONT&gt;&lt;/A&gt; CAP Services to Custom Services for SAP Sales &amp;amp; Service Cloud v2&amp;nbsp;&lt;/H3&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/crm-and-cx-blog-posts-by-sap/using-cap-custom-services-for-sap-sales-amp-service-cloud-v2-esm/ba-p/14281406"/>
    <published>2025-12-01T20:08:46.325000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/data-and-analytics-learning-group-blog-posts/what-is-hana-calculation-view-modeling-and-is-it-for-me/ba-p/14283984</id>
    <title>What is HANA Calculation View Modeling and is it for me?</title>
    <updated>2025-12-04T16:06:26.835000+01:00</updated>
    <author>
      <name>jan_zwickel</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/239612</uri>
    </author>
    <content>&lt;P&gt;SAP HANA Calculation View modeling was introduced with the launch of SAP HANA back in 2010 and has become one of the most popular and sought-after skills in SAP Analytics. If you are wondering if this topic is for you, and you would like a brief description of what is it and what can be achieved, then read on.&lt;/P&gt;&lt;P&gt;SAP HANA Calculation View modeling is your tool of choice for modeling analytic scenarios with SAP HANA Cloud. It allows preprocessing and preparation of your data to harvest them in analytic clients. With calculation views you implement your business logic using an intuitive graphical interface.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Graphical Calculation View Editor" style="width: 940px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/348538iF18D1DEB425E42A0/image-size/large?v=v2&amp;amp;px=999" role="button" title="jan_zwickel_0-1764857192280.png" alt="Graphical Calculation View Editor" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;Graphical Calculation View Editor&lt;/span&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;By the close integration of calculation views into SAP HANA you leverage the full potential of the performance of SAP HANA using several pruning and many more techniques.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Some Performance Optimization Options" style="width: 940px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/348539i561B0F0A1B9FE994/image-size/large?v=v2&amp;amp;px=999" role="button" title="jan_zwickel_1-1764857286355.png" alt="Some Performance Optimization Options" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;Some Performance Optimization Options&lt;/span&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Being fully integrated into SAP HANA development tooling you benefit from enterprise ready lifecycle management.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Integrated Version Control" style="width: 266px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/348540i46A719175EB07C2C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="jan_zwickel_2-1764857339178.png" alt="Integrated Version Control" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;Integrated Version Control&lt;/span&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Similarly, you can count on enterprise ready features such as multi-language support.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Support of Multiple Languages" style="width: 940px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/348541i6F68B86128608D8B/image-size/large?v=v2&amp;amp;px=999" role="button" title="jan_zwickel_3-1764857406780.png" alt="Support of Multiple Languages" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;Support of Multiple Languages&lt;/span&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;SAP is working on deepening the bidirectional integration with SAP Business Data Cloud (BDC) so that calculation views seamlessly integrate into BDC modeling while at the same time opening the venue to integrate BDC data products into HANA Cloud via calculation views.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Reporting on calculation views is pretty flexible. You can use SQL statements, SQL based tools, or you can build on the SAP ecosystem around SAP Cloud Analytics. This gives you the free choice around analytic clients. Calculation views automatically generate metadata during their deployment so that analytic clients know how to best access, display, and analyze the data. For example, information about expected prompts or type of data and their meaning are available as metadata.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-analytics-catalog-bimc-views-reference/sap-hana-cloud-sap-hana-analytics-catalog-bimc-views-reference" target="_self" rel="noopener noreferrer"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Documentation about Meta Data" style="width: 940px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/348542i3D2D9DF58B23E02C/image-size/large?v=v2&amp;amp;px=999" role="button" title="jan_zwickel_4-1764857466635.png" alt="Documentation about Meta Data" /&gt;&lt;span class="lia-inline-image-caption" onclick="event.preventDefault();"&gt;Documentation about Meta Data&lt;/span&gt;&lt;/span&gt;&lt;/A&gt;&lt;/P&gt;&lt;P&gt;The graphical building blocks of calculation views make it easy to extend your logic and to visualize the implemented logic to your stakeholders.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Imagine you are asked to provide up to date sales data every morning. Instead of handcrafting a SQL statement you create a calculation view that combines the relevant technical tables in joins. This way you neither have to hand over a SQL statement nor do you need to assume that the stakeholder understands your SQL statement. Instead you point your stakeholder to the created calculation view. By enriching the calculation view with semantically meaningful data, e.g., business partner data you ensure that the report is grounded in a meaningful context.&lt;/P&gt;&lt;P&gt;Calculation view modeling has developed from the on-premise SAP HANA Studio tooling via the on premise browser based SAP Web IDE for HANA to the cloud tooling SAP Business Application Studio. It is embedded into the SAP Build Code environment to make sure that you can integrate it with all the other BTP development options.&lt;/P&gt;&lt;H3 id="toc-hId-1895553610"&gt;Target User&lt;/H3&gt;&lt;P&gt;HANA calculation views are the first stop if you want to encode your technical knowledge about data and tables into an easy to consume model. You can integrate data from different sources either directly with calculation views using the remote capabilities of SAP HANA Cloud or you integrate your calculation views into SAP Business Data Cloud (BDC) to leverage the ecosystem of BDC with its enhanced capabilities to enrich calculation views with additional business semantics. If you are a data expert with a familiarity to databases, calculation views are your tool of choice to leverage database performance techniques while creating semantically meaningful units of reporting. Whether your purpose is to analyse large data sets or your purpose is to provide meaningful analytic reports - calculation views are your choice: Calculation views provide an easy and flexible way to build up complex scenarios in a structured manner and keep the scenarios easily adaptable and maintainable to bring the required agility into your development process.&lt;/P&gt;&lt;P&gt;Got interested? Read about new innovations around calculation views by visiting the blog on &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-calculation-view-modeling-features-in-sap-hana-cloud/ba-p/13525370" target="_self"&gt;new calculation view features&lt;/A&gt;&lt;/P&gt;&lt;P&gt;Visit the &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/faq-modeling-hana-calculation-views-in-sap-business-application-studio-and/ba-p/13442663" target="_self"&gt;FAQ blog&lt;/A&gt; for frequently asked questions&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/data-and-analytics-learning-group-blog-posts/what-is-hana-calculation-view-modeling-and-is-it-for-me/ba-p/14283984"/>
    <published>2025-12-04T16:06:26.835000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/data-and-analytics-learning-group-blog-posts/how-to-learn-and-get-certified-with-sap-hana-calculation-view-modeling/ba-p/14284671</id>
    <title>How to Learn and Get Certified with SAP HANA Calculation View Modeling</title>
    <updated>2025-12-05T15:20:00.177000+01:00</updated>
    <author>
      <name>AlainViguie</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/160453</uri>
    </author>
    <content>&lt;P&gt;SAP HANA Cloud, and SAP HANA Platform (on-premise) is a very popular solution for data management, with its powerful in-memory technology and a data model that fits a variety of data categories, including spatial, graph, unstructured data, and many more.&lt;/P&gt;&lt;P&gt;Calculation Views are the recommended approach to reporting efficiently on SAP HANA data using models that you design with a graphical user interface. To get an introduction to SAP HANA Calculation Views, read &lt;A href="https://community.sap.com/t5/data-and-analytics-learning-group-blog-posts/what-is-hana-calculation-view-modeling-and-is-it-for-me/ba-p/14283984" target="_blank"&gt;Jan ZWICKEL‚Äôs blog&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;So how can you become proficient in SAP HANA Calculation Views modeling?&lt;/P&gt;&lt;P&gt;Calculation View Modeling belongs to the role &lt;STRONG&gt;Data Engineer - SAP HANA&lt;/STRONG&gt;. In addition to Calculation View Modeling, this role also involves knowledge of SAP HANA Data Provisioning using technologies such as SAP HANA Smart Data Access (SDA) and SAP HANA Smart Data Integration (SDI).&lt;/P&gt;&lt;P&gt;The following diagram shows the Data Engineer role responsibilities compared with the Data Analyst/Data Scientist role.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="SNAG_20251205_113352.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/348932iE8F8EFFE3EDB5E2F/image-size/large?v=v2&amp;amp;px=999" role="button" title="SNAG_20251205_113352.png" alt="SNAG_20251205_113352.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H4 id="toc-hId-2024663203"&gt;&lt;STRONG&gt;&amp;nbsp;SAP HANA Cloud or SAP HANA Platform (On-Premise)?&lt;/STRONG&gt;&lt;/H4&gt;&lt;P&gt;As you might know already, SAP HANA Cloud is the technology on which SAP invests heavily, so most of the innovation is made in the cloud version, so that is where you should start if you are a beginner so that you are learning the latest features. But we also maintain a curriculum for SAP HANA On-Premise.&lt;/P&gt;&lt;P&gt;Let's checkout the course offerings:&lt;/P&gt;&lt;TABLE border="1" width="100%"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="25%"&gt;&lt;STRONG&gt;SAP HANA Cloud&amp;nbsp;&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="25%"&gt;&lt;STRONG&gt;SAP HANA On-Premise&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="50%"&gt;&lt;STRONG&gt;Course Purpose&lt;/STRONG&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="25%"&gt;&lt;A title="HC300 - Developing Data Models in SAP HANA" href="https://learning.sap.com/courses/developing-data-models-with-sap-hana-cloud" target="_blank" rel="noopener noreferrer"&gt;HC300 - Developing Data Models in SAP HANA Cloud&lt;/A&gt;&lt;/TD&gt;&lt;TD width="25%"&gt;&lt;A title="HA300 - SAP HANA Modeling" href="https://training.sap.com/course/ha300" target="_blank" rel="noopener noreferrer"&gt;HA300 - SAP HANA Modeling&lt;/A&gt;&lt;/TD&gt;&lt;TD width="50%"&gt;Cover SAP HANA Calculation Views with a comprehensive course that also covers the practical aspects of the HDI Deployment Infrastructure (accessing external data, etc.)&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;&lt;A title="HAHC55 - Provisioning Data to SAP HANA" href="https://learning.sap.com/courses/provisioning-data-to-sap-hana-cloud" target="_blank" rel="noopener noreferrer"&gt;HAHC55 - Provisioning Data to SAP HANA&lt;/A&gt;&lt;/TD&gt;&lt;TD&gt;&lt;A title="HAHC55 - Provisioning Data to SAP HANA" href="https://learning.sap.com/courses/provisioning-data-to-sap-hana-cloud" target="_blank" rel="noopener noreferrer"&gt;HAHC55 - Provisioning Data to SAP HANA&lt;/A&gt;&lt;/TD&gt;&lt;TD&gt;Discuss native provisioning techniques of SAP HANA (Cloud and On-Premise), and covers virtualization, data replication and data transformation&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;These courses offer solid, theoretical knowledge, illustrations, and are complemented by demos by an instructor (HA300 instructor-led training) or recorded demos (HA300 self-study, HC300 and HAHC55).&lt;/P&gt;&lt;H4 id="toc-hId-1828149698"&gt;What if I want to practice?&lt;/H4&gt;&lt;P&gt;Here again, we have you covered!&lt;/P&gt;&lt;P&gt;The HA300 course is offered as an instructor-led training where you can work through lots of exercises on a provided SAP system. The HC300 and HAHC55 courses have fully configured SAP Practice Systems available, where you can quickly spin-up your own system, or access an existing system (depending on type of course and role) where you can practice a using the similar exercises that we have in the instructor-lead class. To access SAP Practice Systems you need a subscription to the SAP learning portal : learning.sap.com).&lt;/P&gt;&lt;P&gt;Note:&amp;nbsp; for a course such as HC300, your system is generally accessible a couple of minutes after you enrolled.&lt;/P&gt;&lt;P&gt;Want to learn how to access practice systems? Just click below:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;A title="HC300 - Developing Data Models with SAP HANA Cloud" href="https://learning.sap.com/practice-systems/sap-hana-cloud-modeling" target="_blank" rel="noopener noreferrer"&gt;HC300 - Developing Data Models with SAP HANA Cloud&lt;/A&gt;&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;H4 id="toc-hId-1631636193"&gt;Live Sessions&lt;/H4&gt;&lt;P&gt;In addition to courses and practice systems, the SAP Learning portal offers live sessions that are useful to go keep learning, ask questions, deepen your knowledge on specific topics. These sessions are delivered by subject-matter-experts (SMEs), either from SAP Training, SAP Partners or other experts at SAP such as Product Managers.&lt;/P&gt;&lt;P&gt;The sessions come under five categories:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Get Started&lt;/LI&gt;&lt;LI&gt;Expert Deep Dive&lt;/LI&gt;&lt;LI&gt;What's New&lt;/LI&gt;&lt;LI&gt;Get Certified&lt;/LI&gt;&lt;LI&gt;Stay Certified&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Some of the live sessions are available for free, some require a subscription. This is visible in the example below:&lt;/P&gt;&lt;P&gt;&lt;A title="SAP HANA Cloud Live Session catalog sample on SAP Learning" href="https://learning.sap.com/search?query=live+session+SAP+HANA+Cloud&amp;amp;page=1&amp;amp;access=free&amp;amp;access=subscription" target="_blank" rel="noopener noreferrer"&gt;SAP HANA Cloud Live Session catalog sample on SAP Learning&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;H4 id="toc-hId-1435122688"&gt;So, ready for the big jump?&lt;/H4&gt;&lt;P&gt;When you feel prepared enough, it's time to take the certification exam.&lt;/P&gt;&lt;P&gt;On this topic, there is some news. SAP is moving its certification model towards practice-based exams which will replace traditional theoretical/knowledge-based exams (multi-choice questions), starting January 1st 2026. Some pilot exams are already available since the beginning of November 2025.&lt;/P&gt;&lt;P&gt;To conclude, we are looking forward to getting your feedback on these resources aimed at getting your level higher in the area of SAP HANA Cloud modeling. Please feel free to use this new community and connect with us and other learners. Also let us know about topics you would like to have covered in future live sessions, so that we can make our content even more suited to your needs.&lt;/P&gt;&lt;P&gt;Happy learning with SAP!&lt;BR /&gt;Alain&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/data-and-analytics-learning-group-blog-posts/how-to-learn-and-get-certified-with-sap-hana-calculation-view-modeling/ba-p/14284671"/>
    <published>2025-12-05T15:20:00.177000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/sap-for-utilities-blog-posts/sap-utilities-roadmap-2026-onwards/ba-p/14285848</id>
    <title>SAP Utilities Roadmap 2026 Onwards</title>
    <updated>2025-12-08T13:13:03.136000+01:00</updated>
    <author>
      <name>holger_schweinfurth</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/196182</uri>
    </author>
    <content>&lt;P&gt;The utilities industry will continue to play a key role in SAP‚Äôs strategy and product development. It is therefore important for us to keep customers, partners, and the entire SAP Utilities ecosystem informed about our planned innovations.&lt;/P&gt;&lt;P&gt;As in previous years, we have created a matrix outlining the relevant industry topics and their corresponding innovations. This matrix represents a selection of the most important innovations and does not claim to be exhaustive.&lt;/P&gt;&lt;P&gt;Additional innovations may be added over time, and delivery timelines remain subject to change. Following a high-level overview of the highlights, we provide detailed information for each topic. For nearly all innovations, a &lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST#Q4%202025" target="_self" rel="noopener noreferrer"&gt;link&lt;/A&gt; to the SAP Roadmap Explorer is included for further details.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Utilities Roadmap 2026 v01.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/348614i17776515516E695F/image-size/large?v=v2&amp;amp;px=999" role="button" title="Utilities Roadmap 2026 v01.png" alt="Utilities Roadmap 2026 v01.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="EAM Final.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349637i933FA6C793EB74AC/image-size/large?v=v2&amp;amp;px=999" role="button" title="EAM Final.png" alt="EAM Final.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;SAP Asset Performance Management:&lt;UL&gt;&lt;LI&gt;Assessments for consequence classification of industrial system functions (&lt;A href="https://roadmaps.sap.com/board?range=CURRENT-LAST&amp;amp;PRODUCT=73555000100800003351#Q2%202026;INNO=000D3ABE772D1FD0AEDA1B7FEE8A5D75" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;AI-automated visual asset condition monitoring (&lt;A href="https://roadmaps.sap.com/board?range=CURRENT-LAST&amp;amp;PRODUCT=73555000100800003351#Q2%202026;INNO=DB9C27ACB50C1FE086C8B80EA1BF0A8A" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;SAP S/4HANA Private Cloud:&lt;UL&gt;&lt;LI&gt;Graphical view for setting relationships between operations of one or multiple maintenance orders (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=42F2E964F4E71EDAA6A0DD317C2CC0E5#Q4%202025;INNO=B9314318771A1FD080F1C62C141C151C" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Joule-based AI agents to propose optimized maintenance event for an asset to minimize operational disruptions (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=42F2E964F4E71EDAA6A0DD317C2CC0E5#Q4%202025;INNO=6DF54C88F6211FE080ED0966547721DF" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Support for the new Permit to Work (PTW) solution (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=42F2E964F4E71EDAA6A0DD317C2CC0E5#Q2%202026;INNO=E3015BA1031B1EEFB79DB2E51D9DAC06" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;SAP Field Service Management:&lt;UL&gt;&lt;LI&gt;Management of measurement points on activity level (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=73554900100800002022#Q1%202026;INNO=000D3AAC9DD21FD098CA48288D7E95E4" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Dependencies between activities (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=73554900100800002022#Q2%202026;INNO=000D3ABE796A1FE0A6961BCD0EAD9ED3" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Tool schedule visualization&amp;nbsp;(&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=73554900100800002022#Q2%202026;INNO=000D3AAADBCE1FE098CA86D20E446CDA" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Linear assets on the service map (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=73554900100800002022#Q4%202025;INNO=000D3ABE772D1FD0A7A4AC18ADB3FC53" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Selection of multiple work orders through a lasso operation (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=73554900100800002022#Q4%202025;INNO=6961C60767D51EDF99ABC5BBB3B6E686" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Timesheet management in the partner portal (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=73554900100800002022#Q4%202025;INNO=000D3ABE796A1EEC96866FF8BB3AA855" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;SAP Service &amp;amp; Asset Manager:&lt;UL&gt;&lt;LI&gt;AI Assisted execution with Joule mobile client (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=73555000100800000639#Q4%202025;INNO=E3015BA1031B1EDFB99DAD4194CC399A" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Service assignment rescheduling support for field service technicians (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=73555000100800000639#Q4%202025;INNO=000D3AAC9DD21FD099E4321F65EC160E" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Esri map improvements with breadcrumbing and draw-to-search capabilities (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=73555000100800000639#;INNO=000D3ABE772D1FD0A7AD36A296E39C57" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Support for the new Permit to Work (PTW) solution (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=73555000100800000639#;INNO=E3015BA1031B1EEFB79DB2E51D9DAC06" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Service assignment rescheduling support for field service technicians (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=42F2E964F4E71EDAA6A0DD317C2CC0E5#Q4%202025;INNO=000D3AAC9DD21FD099E4321F65EC160E" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;Business Network for Asset Collaboration:&lt;UL&gt;&lt;LI&gt;Integration of digital inspection checklists to support sharing with service providers (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=42F2E964F4E71EDAA6A0DD317C2CC0E5#Q4%202025;INNO=BBCA6C615B4F1EDF93A8FBE10A9AC2D2" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Modeling, sharing, and ERP system integration of failure catalogs and codes with causes and effects (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST&amp;amp;PRODUCT=42F2E964F4E71EDAA6A0DD317C2CC0E5#Q2%202026;INNO=252EF753CFDE1EEDA0BA5AF7927C869B" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="M2C Final.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349639i6761DCB78B91976D/image-size/large?v=v2&amp;amp;px=999" role="button" title="M2C Final.png" alt="M2C Final.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;SAP S/4HANA Utilities - Overall Topics:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Utilities Data Products (Master Data) (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800004851&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE772D1FD0908F2720D5DD7797" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Archiving of installations and premises and deletion of unused device information records (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73554900100800000266&amp;amp;BP=40F2E9281A631ED8B4D3C2EC3DF660E2&amp;amp;BP=40F2E9281A631ED8B4D3C2EC3DF920E2&amp;amp;BP=40F2E9281A631ED8B4D3C2EC3DFAA0E2&amp;amp;range=FIRST-LAST#;INNO=EBB49452EF911EDDB4C223EA913E66C5" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Enterprise search for utilities master data (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800004663&amp;amp;range=CURRENT-LAST#;INNO=09840EBB9A121EDFBAA83020F693A6E1" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Continuous Influence (&lt;A href="https://influence.sap.com/sap/ino/#/campaign/3504" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;SAP S/4HANA Utilities - Metering:&lt;UL&gt;&lt;LI&gt;Graphical display of utilities interval data (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800004663&amp;amp;range=CURRENT-LAST#;INNO=E9C7B9C258B21EDFACC6DA99F8BF99F3" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;More flexible completeness check for profile values (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800004663&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE772D1FD0ABB544D3CA71DCEC" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Data Products and CDS views for energy settlement master data (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800004663&amp;amp;q=provisioning&amp;amp;range=CURRENT-LAST#;INNO=DB9C27ACB50C1FE08CB2D39B09B768BC" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Archiving of connection objects, device locations and devices (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73554900100800000266&amp;amp;range=CURRENT-LAST#;INNO=01DD7775C9D61FE08ACAC2274064FA3E" target="_blank" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;SAP S/4HANA Utilities - Market Process Management:&lt;UL&gt;&lt;LI&gt;Utilities Data Products (Market Communication: process document header) (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800004663&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE772D1FD0ABE78C30AD5DFD00" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Utilities Data Products (Market Communication: transfer document header) (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800004663&amp;amp;range=CURRENT-LAST#;INNO=000D3AAADBCE1FE0ABE7BF07528C952B" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;SAP S/4HANA Utilities - Contract Accounting:&lt;UL&gt;&lt;LI&gt;SAP Fiori app for displaying the FI-CA document flow (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73554900100800000266&amp;amp;range=CURRENT-LAST#;INNO=DD6CA1697F461EEEB3F5801A1D9E5C11" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Dispute resolution for missing payments (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800004663&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE796A1FE08FFD1F1AD493ECE3" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Dispute resolution agent for incorrect credits (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800004663&amp;amp;range=CURRENT-LAST#;INNO=000D3AAADBCE1FE08FFD4B8744FA2AB9" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Dispute resolution agent for missing credits (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800004663&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE796A1FE08FFD3362B2BB4CE3" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;SAP Fiori app ‚ÄúManage Contract Accounts‚Äù (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73554900100800000266&amp;amp;range=CURRENT-LAST#;INNO=000D3AAADBCE1FE0A7A2166DAA5D93A0" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;OData v4 API for contract accounts (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73554900100800000266&amp;amp;range=CURRENT-LAST#;INNO=000D3AA914A11FD0A7A265EA6D65D05C" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="CX Final.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349640i53033148EA0F5FF1/image-size/large?v=v2&amp;amp;px=999" role="button" title="CX Final.png" alt="CX Final.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Customer Data Cloud:&lt;UL&gt;&lt;LI&gt;Support for step-up authentication (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;PRODUCT=73555000100800001231&amp;amp;range=CURRENT-LAST#;INNO=4B1ACEFEF2C91EDEB6C147C7BE1B8841" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Consent attributes connections ‚Äì definition and maintenance of user-consent data (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;PRODUCT=73555000100800001231&amp;amp;range=CURRENT-LAST#;INNO=000D3AAADBCE1EDD86FA4AEA9C02A294" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Ability to collect consent that is provided on behalf of a third party (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;PRODUCT=73555000100800001231&amp;amp;range=CURRENT-LAST#;INNO=13FDA4A615C31EEEBCD1A3E442A7AEF6" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&amp;nbsp;Emarsys:&lt;UL&gt;&lt;LI&gt;AI-assisted campaign translator (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;PRODUCT=73554900100800003661&amp;amp;range=CURRENT-LAST#;INNO=000D3AAC9DD21FD0AEC58D2E1FAA9AE1" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;CX AI Toolkit:&lt;UL&gt;&lt;LI&gt;Shopping agent: related accessories based on product relationships (general availability) (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;PRODUCT=73554900100800005363&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE772D1FD0B1E0BC966CA47E00" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;Commerce:&lt;UL&gt;&lt;LI&gt;Integration with SAP Omnichannel Promotion Pricing to display promotion recommendations on the product details page (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800001224&amp;amp;range=CURRENT-LAST#;INNO=7FECA36531611EEEA2A17E3162CFCF25" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;CPQ:&lt;UL&gt;&lt;LI&gt;Conversational AI support for quote handling (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800001601&amp;amp;INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST#;INNO=000D3AAC9DD21FD0A9BB1920F01339F1" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Integration with SAP Subscription Billing for a smooth quote-to-cash experience (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800001601&amp;amp;INDUSTRY=UTILITY&amp;amp;range=CURRENT-LAST#;INNO=000D3AAADBCE1FE0AD968CBBCDAE5563" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;Sales Cloud:&lt;UL&gt;&lt;LI&gt;Promotion management (sales) (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800003822&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE796A1FD0AF97E10C7436404D" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Maintaining marketing attributes for accounts, contacts, products, and registered products (sales) (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800003822&amp;amp;range=CURRENT-LAST#;INNO=000D3AA914A11FD0AF863C0DD35F57AC" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;Service Cloud:&lt;UL&gt;&lt;LI&gt;Case priority prediction (service) (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800003641&amp;amp;range=CURRENT-LAST#;INNO=3D6CE42858DD1EEFA1D753B773B73EB4" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Case routing based on skills (service) (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800003641&amp;amp;range=CURRENT-LAST#;INNO=0734A76C5EE41EEEA3BCB34B0084E390" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;Sales and Service Cloud:&lt;UL&gt;&lt;LI&gt;Additional features to support attachment search and management (sales and service) (&lt;A href="https://roadmaps.sap.com/board?INDUSTRY=UTILITY&amp;amp;PRODUCT=73555000100800003641&amp;amp;PRODUCT=73555000100800003823&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE796A1FD0ADCA78EE714A6012" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Navigation to Custom UIs from a Mashup (sales and service) (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800003641&amp;amp;range=CURRENT-LAST#;INNO=000D3AAC9DD21FD0A3C9E21602A298BE" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Machine translation for notes (sales and service) (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800003641&amp;amp;range=CURRENT-LAST#;INNO=000D3AAC9DD21FD0AD9F0C581D0BFA97" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Home page AI capability for creating KPI cards (sales and service) (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800003641&amp;amp;range=CURRENT-LAST#;INNO=000D3AAC9DD21FD0AD981A89513E9A96" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Energy Transition Final.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349641i6808D3AD1058ECCD/image-size/large?v=v2&amp;amp;px=999" role="button" title="Energy Transition Final.png" alt="Energy Transition Final.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Distributed Energy Resources:&lt;UL&gt;&lt;LI&gt;Enabling validation checks of instances through an API (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800003351&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE772D1FD0AEDA1B7FEE8A5D75" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Analytics for Long-Running Processes (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800003351&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE772D1FD0AEDA1B7FEE8A5D75" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Lightweight process for updating active measurement concept instances (&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73555000100800003351&amp;amp;range=CURRENT-LAST#;INNO=000D3ABE772D1FD0AEDA1B7FEE8A5D75" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;Green Ledger:&lt;UL&gt;&lt;LI&gt;Finance Intelligence: SAP Green Ledger (&lt;A href="https://roadmaps.sap.com/board?q=green%2520ledger&amp;amp;range=FIRST-LAST#;INNO=DB9C27ACB50C1FD086F75D40F2432DD2" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Connecting to several tenants of SAP Sustainability Footprint Management (&lt;A href="https://roadmaps.sap.com/board?q=green%2520ledger&amp;amp;range=FIRST-LAST#;INNO=BBCA6C615B4F1EDF93B68CE9356CE2DC" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Accounting for carbon allowances (CBAM) in a carbon journal (&lt;A href="https://roadmaps.sap.com/board?q=green%2520ledger&amp;amp;range=FIRST-LAST#;INNO=C1C672F971EE1EEEA99A86D4FC7BE51F" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;Sustainability Footprint Management:&lt;UL&gt;&lt;LI&gt;Retrieving carbon flows from SAP Sustainability Footprint Management and posting them as allocations (&lt;A href="https://roadmaps.sap.com/board?q=Sustainability%2520Footprint%2520Management&amp;amp;range=FIRST-LAST#;INNO=EB212B94E01C1EEFA9E075527921B32A" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Connecting to several tenants of SAP Sustainability Footprint Management (&lt;A href="https://roadmaps.sap.com/board?q=Sustainability%2520Footprint%2520Management&amp;amp;range=FIRST-LAST#;INNO=BBCA6C615B4F1EDF93B68CE9356CE2DC" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Supplier footprint integration with data exchange standards (&lt;A href="https://roadmaps.sap.com/board?q=SDX&amp;amp;range=FIRST-LAST#;INNO=000D3ABE796A1FE097B2B8D37F48149A" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&amp;nbsp;Sustainability Control Tower:&lt;UL&gt;&lt;LI&gt;Cloud ERP Intelligence &amp;amp; Finance Intelligence: SAP Sustainability Control Tower (&lt;A href="https://roadmaps.sap.com/board?q=sustainability%2520control%2520tower&amp;amp;range=FIRST-LAST#;INNO=1D57231EA3FF1FD086F753000E86CEA9" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;LI&gt;Data product for carbon journal entry (&lt;A href="https://roadmaps.sap.com/board?q=sustainability%2520control%2520tower&amp;amp;range=FIRST-LAST#;INNO=000D3ABE796A1FD0ADAB0A768E7AE00A" target="_self" rel="noopener noreferrer"&gt;Details&lt;/A&gt;)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/sap-for-utilities-blog-posts/sap-utilities-roadmap-2026-onwards/ba-p/14285848"/>
    <published>2025-12-08T13:13:03.136000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/sap-btp-weekly-edici%C3%B3n-de-cierre-2025/ba-p/14290629</id>
    <title>ü§ñ SAP BTP Weekly¬†| Edici√≥n de cierre 2025</title>
    <updated>2025-12-15T15:18:30.762000+01:00</updated>
    <author>
      <name>FedericoTokman</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/150724</uri>
    </author>
    <content>&lt;P class=""&gt;Cierro el √∫ltimo newsletter del a√±o con una mirada clara: CIOs acelerando con foco, CFOs pidiendo impacto medible, arquitectos cuidando el core y consultores redefiniendo su rol. En estas l√≠neas repaso c√≥mo SAP BTP, Joule y Business Data Cloud dejaron de ser promesa en 2025 y empiezan a sentar las bases de c√≥mo vamos a trabajar, decidir e innovar en 2026.&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="ember201" id="toc-hId-1896384694"&gt;&lt;span class="lia-unicode-emoji" title=":keycap_1:"&gt;1Ô∏è‚É£&lt;/span&gt; Joule for Developers: IA para acelerar la adopci√≥n sin perder control del c√≥digo&lt;/H3&gt;&lt;P class=""&gt;SAP potencia a los desarrolladores con Joule for Developers, integrado en el ciclo de desarrollo para acelerar tareas repetitivas. La IA ayuda a generar y adaptar c√≥digo dentro del contexto de SAP BTP sin perder est√°ndares de calidad. Esto no reemplaza la l√≥gica de dise√±o, pero reduce el tiempo en tareas t√©cnicas b√°sicas. Impulsa la adopci√≥n de IA en entornos empresariales con pr√°cticas seguras. El foco es mantener clean core mientras se ampl√≠a la productividad.&lt;/P&gt;&lt;P class=""&gt;Seg√∫n SAP, esta capacidad est√° pensada para que los developers no solo codifiquen m√°s r√°pido, sino con mayor confianza y alineados al est√°ndar de la empresa. La ventaja principal es eliminar fricci√≥n en actividades tediosas y permitir que el equipo se concentre en l√≥gica de negocio. El desaf√≠o es integrar estas asistencias en pipelines existentes sin perder gobernanza.&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;üîó&lt;/span&gt; &lt;A class="" href="https://news.sap.com/latinamerica/2025/11/sap-empodera-a-los-desarrolladores-para-acelerar-la-adopcion-de-la-ia-en-el-mundo-empresarial/" target="_self" rel="noopener noreferrer"&gt;https://news.sap.com/latinamerica/2025/11/sap-empodera-a-los-desarrolladores-para-acelerar-la-adopcion-de-la-ia-en-el-mundo-empresarial/&lt;/A&gt;&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="ember205" id="toc-hId-1699871189"&gt;&lt;span class="lia-unicode-emoji" title=":keycap_2:"&gt;2Ô∏è‚É£&lt;/span&gt; Joule for Consultants: acelerando entregas y calidad de proyectos SAP&lt;/H3&gt;&lt;P class=""&gt;SAP Joule for Consultants ya est√° disponible y dise√±ado para asistir a consultores en transformaciones SAP a gran escala con gu√≠a inteligente y contexto experto.&lt;/P&gt;&lt;P class=""&gt;¬∑&amp;nbsp;Reduce tiempo de b√∫squeda de documentaci√≥n, interpretaci√≥n de c√≥digo y adopci√≥n de mejores pr√°cticas, apoyado en una base de conocimiento profundamente curada por SAP.&lt;/P&gt;&lt;P class=""&gt;¬∑&amp;nbsp;Puede acelerar la ejecuci√≥n de proyectos hasta ~14 % y disminuir iteraciones de dise√±o y retrabajo.&lt;/P&gt;&lt;P class=""&gt;¬∑&amp;nbsp;&amp;nbsp;La integraci√≥n con herramientas como Microsoft 365 Copilot ofrece un flujo fluido entre contextos.&lt;/P&gt;&lt;P class=""&gt;Esto permite que los consultores se concentren m√°s en decisiones de negocio que en tareas repetitivas.&lt;/P&gt;&lt;P class=""&gt;Un caso concreto viene de grandes firmas de consultor√≠a que est√°n adoptando Joule for Consultants para mejorar tiempos de entrega y calidad del servicio a clientes: por ejemplo, Deloitte anunci√≥ que la soluci√≥n les permite acceder r√°pidamente a pr√°cticas l√≠deres y contenido SAP exclusivo, liberando tiempo para actividades de mayor impacto estrat√©gico en SAP Engage y proyectos de transformaci√≥n integral.&lt;/P&gt;&lt;P class=""&gt;M√°s all√° de m√©tricas de tiempo ahorrado, el impacto real se ve en mejor alineaci√≥n entre dise√±o t√©cnico y necesidades del cliente, reduciendo rework y elevando la confianza en decisiones durante el ciclo del proyecto. El reto para muchas organizaciones ser√° definir m√©tricas claras de impacto (KPIs) que puedan medir estos beneficios en cada entrega.&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;üîó&lt;/span&gt; &lt;A class="" href="https://www.sap.com/latinamerica/products/artificial-intelligence/ai-assistant/sap-consulting-capability.html" target="_self" rel="noopener noreferrer"&gt;https://www.sap.com/latinamerica/products/artificial-intelligence/ai-assistant/sap-consulting-capability.html&lt;/A&gt;&lt;/P&gt;&lt;HR /&gt;&lt;P class=""&gt;&lt;STRONG&gt;&lt;span class="lia-unicode-emoji" title=":keycap_3:"&gt;3Ô∏è‚É£&lt;/span&gt; Joule Studio: agentes de IA que ejecutan procesos, no solo tareas&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;Joule Studio permite crear agentes de IA en SAP Build. Los agentes ejecutan workflows con contexto de negocio. No es solo RPA, es automatizaci√≥n inteligente. Se reduce c√≥digo y tiempo de dise√±o. La gobernanza se vuelve cr√≠tica.&lt;/P&gt;&lt;P class=""&gt;Imaginar un agente que gestione excepciones de facturaci√≥n o approvals complejos ya no es ciencia ficci√≥n. El desaf√≠o real es definir l√≠mites, auditor√≠a y ‚Äúhuman-in-the-loop‚Äù. La ventaja es eficiencia; el riesgo, cajas negras operativas.&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;üîó&lt;/span&gt; &lt;A class="" href="https://www.sap.com/products/artificial-intelligence/joule-studio.html" target="_self" rel="noopener noreferrer"&gt;https://www.sap.com/products/artificial-intelligence/joule-studio.html&lt;/A&gt;&lt;/P&gt;&lt;HR /&gt;&lt;P class=""&gt;&lt;STRONG&gt;&lt;span class="lia-unicode-emoji" title=":keycap_4:"&gt;4Ô∏è‚É£&lt;/span&gt; Nuevos skills SAP: del funcional t√©cnico al ‚ÄúAI-enabled consultant‚Äù&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;La llegada de Joule cambia los perfiles SAP. Menos foco en ejecuci√≥n manual. M√°s foco en dise√±o, validaci√≥n y gobierno. Los skills t√©cnicos se combinan con negocio. La capacitaci√≥n se vuelve estrat√©gica.&lt;/P&gt;&lt;P class=""&gt;Saber configurar ya no alcanza. Entender procesos, datos e IA ser√° diferencial. SAP impulsa nuevas certificaciones, pero el reto est√° en reconvertir talento existente. Ventaja: perfiles m√°s completos. Riesgo: brecha de skills si no se act√∫a a tiempo.&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;üîó&lt;/span&gt; &lt;A class="" href="https://training.sap.com/" target="_self" rel="noopener noreferrer"&gt;https://training.sap.com&lt;/A&gt;&lt;/P&gt;&lt;HR /&gt;&lt;P class=""&gt;&lt;STRONG&gt;&lt;span class="lia-unicode-emoji" title=":keycap_5:"&gt;5Ô∏è‚É£&lt;/span&gt; SAP BDC Connect + Microsoft Fabric: datos SAP donde el negocio ya trabaja&lt;/STRONG&gt;&lt;/P&gt;&lt;P class=""&gt;SAP anunci√≥ Business Data Cloud Connect para Microsoft Fabric, extendiendo la integraci√≥n de BDC con la plataforma de datos de Microsoft. Esto habilita acceso bi-direccional sin copia de datos entre BDC y Microsoft Fabric OneLake, preservando contexto sem√°ntico. Los equipos pueden usar SAP data products directamente en Fabric para analytics, AI y BI. Potencia herramientas como Power BI, Copilot Studio y agentes de IA dentro del ecosistema Microsoft. El enfoque acelera insights y reduce la fricci√≥n de replicar datos.&lt;/P&gt;&lt;P class=""&gt;En la pr√°ctica, esto significa que los datos SAP ya gobernados en BDC pueden ser usados en vivo en herramientas cotidianas del negocio (Power BI, Excel, Teams) sin mover o duplicar la informaci√≥n. La ventaja es una sola fuente de verdad que impulsa tanto AI generativa como anal√≠tica avanzada. El reto principal est√° en coordinar roles y seguridad entre plataformas diferentes, especialmente en organizaciones grandes donde existen m√∫ltiples silos y pol√≠ticas de acceso.&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;üîó&lt;/span&gt; &lt;A class="" href="https://news.sap.com/2025/11/sap-bdc-connect-for-microsoft-fabric-business-insights-ai-innovation/" target="_self" rel="noopener noreferrer"&gt;https://news.sap.com/2025/11/sap-bdc-connect-for-microsoft-fabric-business-insights-ai-innovation/&lt;/A&gt;&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="ember226" id="toc-hId-1503357684"&gt;&lt;span class="lia-unicode-emoji" title=":keycap_6:"&gt;6Ô∏è‚É£&lt;/span&gt; IA + Datos nativos: SAP HANA Cloud, agentic memory y cero-copias con Snowflake&lt;/H3&gt;&lt;P class=""&gt;SAP HANA Cloud se consolida como la base de datos &lt;EM&gt;AI-native&lt;/EM&gt; con Model Context Protocol (MCP) disponible en GA, permitiendo a agentes IA navegar relaciones complejas de datos. Los knowledge graphs autom√°ticos agilizan la generaci√≥n de modelos sem√°nticos del negocio sin semanas de esfuerzo manual (Q1 2026). La incorporaci√≥n de agentic memory permite a agentes de IA aprender de interacciones pasadas para decisiones m√°s inteligentes. SAP BDC se integra con Snowflake como extensi√≥n para habilitar datos sem√°nticamente ricos con zero-copy, preservando contexto y gobernanza. Esto impulsa una visi√≥n donde datos empresariales e IA coexisten con escalabilidad y menor duplicaci√≥n.&lt;/P&gt;&lt;P class=""&gt;Hacia fines de 2025 SAP reporta cientos de casos de uso de Business AI con impacto medible en valor de negocio. MCP en HANA Cloud permite que agentes IA entiendan estructuras m√°s all√° de filas y columnas, abarcando relaciones complejas y b√∫squedas sem√°nticas. La generaci√≥n autom√°tica de knowledge graphs y la memoria &lt;EM&gt;agentic&lt;/EM&gt; reducen tiempo de preparaci√≥n y elevan la inteligencia contextual de los agentes.&lt;/P&gt;&lt;P class=""&gt;Por otro lado, la integraci√≥n de SAP BDC con Snowflake habilita &lt;EM&gt;zero-copy data sharing&lt;/EM&gt;, reduciendo silos y costos de replicaci√≥n sin perder gobernanza. Esto abre modelos h√≠bridos donde SAP conserva el contexto sem√°ntico y Snowflake aporta escala e innovaci√≥n para anal√≠tica y AI.&lt;/P&gt;&lt;P class=""&gt;&lt;span class="lia-unicode-emoji" title=":link:"&gt;üîó&lt;/span&gt; &lt;A class="" href="https://news.sap.com/2025/11/business-ai-innovation-unveiled-at-sap-teched/" target="_self" rel="noopener noreferrer"&gt;https://news.sap.com/2025/11/business-ai-innovation-unveiled-at-sap-teched/&lt;/A&gt;&lt;/P&gt;&lt;HR /&gt;&lt;H3 id="ember231" id="toc-hId-1306844179"&gt;&lt;span class="lia-unicode-emoji" title=":keycap_7:"&gt;7Ô∏è‚É£&lt;/span&gt; Reflexi√≥n de fin de a√±o: de experimentar con IA a redise√±ar la empresa para 2026&lt;/H3&gt;&lt;P class=""&gt;2025 fue el a√±o donde SAP dej√≥ claro que la IA empresarial ya es real. Joule pas√≥ de asistente a agente, y los datos dejaron de ser solo reporting. BTP, BDC y HANA Cloud se alinearon en una visi√≥n coherente. La conversaci√≥n cambi√≥ de ‚Äúqu√© probar‚Äù a ‚Äúqu√© escalar‚Äù. El foco ahora est√° en impacto, no en hype.&lt;/P&gt;&lt;P class=""&gt;Mirando todo lo anunciado este a√±o, Joule en sus distintas formas, Business Data Cloud conectando ecosistemas como Microsoft Fabric y Snowflake, HANA Cloud volvi√©ndose &lt;EM&gt;AI-native&lt;/EM&gt;, creo que 2026 no va a tratar de sumar m√°s tecnolog√≠a, sino de tomar decisiones m√°s valientes. Las organizaciones que lleguen a 2026 con datos gobernados, skills preparados y una visi√≥n clara de d√≥nde usar IA tendr√°n una ventaja enorme. Las que sigan en pilotos aislados van a sentir que ‚Äúllegaron tarde‚Äù, aunque la tecnolog√≠a est√© ah√≠. SAP puso las piezas sobre la mesa; ahora el desaf√≠o es cultural, organizacional y estrat√©gico.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/sap-btp-weekly-edici%C3%B3n-de-cierre-2025/ba-p/14290629"/>
    <published>2025-12-15T15:18:30.762000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934</id>
    <title>Data masking, data scrambling and data anonymization in Business Data Cloud with SAP Datasphere</title>
    <updated>2025-12-18T09:57:28.944000+01:00</updated>
    <author>
      <name>Herve_DeLatte</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/258050</uri>
    </author>
    <content>&lt;P&gt;&lt;ul =""&gt;&lt;li style="list-style-type:none; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId-1637536972"&gt;Introduction&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId-1244509962"&gt;1 - Generalities&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId-1177079176"&gt;1.1 - Data masking&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId-784052166"&gt;1.2 - Data scrambling&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:30px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId-716621380"&gt;1.2.1 - Create function&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:30px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId-520107875"&gt;1.2.2 - Expose table data&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:30px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId-323594370"&gt;1.2.3 - Create a view&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:30px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId-127080865"&gt;1.2.4 - Import the view into Datasphere&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId-148738998"&gt;1.3 - Data anonymization&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId-245628500"&gt;2 - Standardization&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId--244288012"&gt;2.1 - Parameters table&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId--637315022"&gt;2.2 - SQL Procedures&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:30px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId--1127231534"&gt;2.2.1 - Procedure EXEC_VIEWS_CREATOR_CREATE_STATMT&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:30px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId--1323745039"&gt;2.2.2 - Procedure EXEC_VIEWS_CREATOR&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:30px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId--1520258544"&gt;2.2.3 - Procedure EXEC_ALL_VIEWS_CREATOR&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:15px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId--1423369042"&gt;2.3 - Task Chain&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:30px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId--1913285554"&gt;2.3.1 - Grant permissions&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:30px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId--1941615368"&gt;2.3.2 - Create a task chain&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:30px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId--2138128873"&gt;2.3.3 - Test&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:none; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934#toc-hId--2140863374"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-1637536972"&gt;Introduction&lt;/H1&gt;&lt;P&gt;This blog post was inspired from:&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/how-data-anonymization-in-sap-hana-secure-generative-ai-applications/ba-p/13636987" target="_self"&gt;How Data Anonymization in SAP HANA secure Generative AI applications through SAP Datasphere&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Here you will find a description of generalities about:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;masking, scrambling and anonymization features&lt;/LI&gt;&lt;LI&gt;how to automate the creation of views with data masking, data scrambling and data anonymization and the possibility to activate/deactivate some features in the target views.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+Datasphere/pd-p/73555000100800002141" class="lia-product-mention" data-product="16-1"&gt;SAP Datasphere&lt;/a&gt;&amp;nbsp;contains a lot of features. Some are accessible directly via its user interface and others are accessible via Open SQL Schema (see &lt;A href="https://help.sap.com/docs/SAP_DATASPHERE/be5967d099974c69b77f4549425ca4c0/3de55a78a4614deda589633baea28645.html?locale=en-US&amp;amp;version=LATEST" target="_blank" rel="noopener noreferrer"&gt;SAP Datasphere help&lt;/A&gt;&amp;nbsp;site).&amp;nbsp;Open SQL Schema gives you access to the underlying &lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+HANA+Cloud/pd-p/73554900100800002881" class="lia-product-mention" data-product="22-1"&gt;SAP HANA Cloud&lt;/a&gt;&amp;nbsp;database, and extends the capacities offered via Datasphere's UI.&lt;/P&gt;&lt;P&gt;In this blog, we use a Datasphere space called &lt;FONT face="courier new,courier"&gt;DEMO&lt;/FONT&gt;&amp;nbsp;with the database user&amp;nbsp;&lt;FONT face="courier new,courier"&gt;DEMO#USER_ANONYMIZE&lt;/FONT&gt;.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="DEMO DB User Creation.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351575i4C2ACC91B29494C2/image-size/large?v=v2&amp;amp;px=999" role="button" title="DEMO DB User Creation.png" alt="DEMO DB User Creation.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;We will use a&amp;nbsp;&lt;/SPAN&gt;Datasphere&amp;nbsp;&lt;SPAN&gt;local table &lt;FONT face="courier new,courier"&gt;SALARY&lt;/FONT&gt; as an example dataset where we would like to:&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;mask the &lt;FONT face="courier new,courier"&gt;CREDIT_CARD&lt;/FONT&gt; column and rename the column to &lt;FONT face="courier new,courier"&gt;CREDIT_CARD_MASKED&lt;/FONT&gt;,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;scramble the &lt;FONT face="courier new,courier"&gt;NAME&lt;/FONT&gt; column&amp;nbsp;and rename the column to &lt;FONT face="courier new,courier"&gt;NAME_SCRAMBLED&lt;/FONT&gt;,&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;anonymize the &lt;FONT face="courier new,courier"&gt;SALARY&lt;/FONT&gt; column and rename the column to &lt;FONT face="courier new,courier"&gt;SALARY_ANONYMIZED&lt;/FONT&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="SALARY Columns.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351283i6242D012655A62A9/image-size/large?v=v2&amp;amp;px=999" role="button" title="SALARY Columns.png" alt="SALARY Columns.png" /&gt;&lt;/span&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Note&lt;/STRONG&gt;: &lt;FONT face="courier new,courier"&gt;SALARY&lt;/FONT&gt; column data type is Double.&lt;/P&gt;&lt;P&gt;Save the content below to import a sample dataset into the SALARY local table.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;"ID","NAME","GENDER","CITY","SALARY","CREDIT_CARD"
"1","Paul McCartney","M","Levallois","1002.32","1111-1111-1111-1111"
"2","Martin Solveig","M","Munich","3218.21","2222-2222-2222-2222"
"3","Nils Lofgren","M","Nice","1398.32","3333-3333-3333-3333"
"4","Annika","F","Munich","2053.23","4444-4444-4444-4444"&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Import SALARY data.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351865i6107DF711145688D/image-size/large?v=v2&amp;amp;px=999" role="button" title="Import SALARY data.png" alt="Import SALARY data.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H1 id="toc-hId-1441023467"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H1 id="toc-hId-1244509962"&gt;1 - Generalities&lt;/H1&gt;&lt;H2 id="toc-hId-1177079176"&gt;1.1 - Data masking&lt;/H2&gt;&lt;P&gt;Data masking is a feature implemented into &lt;a href="https://community.sap.com/t5/c-khhcw49343/SAP+HANA+Cloud/pd-p/73554900100800002881" class="lia-product-mention" data-product="22-2"&gt;SAP HANA Cloud&lt;/a&gt;&amp;nbsp;(see &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-security-guide/data-masking?locale=en-US&amp;amp;version=LATEST" target="_self" rel="noopener noreferrer"&gt;Data Masking&lt;/A&gt;).&lt;BR /&gt;In this blog, we will not use privileges to manage masking, but simply use calculated SQL expressions when defining views where some columns should be masked.&lt;/P&gt;&lt;P&gt;To mask the content of the &lt;FONT face="courier new,courier"&gt;NAME&lt;/FONT&gt; column, we can just use the following SQL Statement into an SQL view object in Datasphere :&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;SELECT "ID",
   "NAME",
   CITY,
   GENDER,
   SALARY,
   LEFT(CREDIT_CARD, 4) || '-XXXX-XXXX-' || RIGHT(CREDIT_CARD, 4) AS CREDIT_CARD_MASKED
FROM SALARY&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The content displayed by the view is:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="V_SALARY_CC_MASKED.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351655iD3D504E6C4823BB6/image-size/large?v=v2&amp;amp;px=999" role="button" title="V_SALARY_CC_MASKED.png" alt="V_SALARY_CC_MASKED.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H1 id="toc-hId-851482952"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H2 id="toc-hId-784052166"&gt;&lt;SPAN&gt;1.2 - Data scrambling&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;To scramble characters in a string, a function needs to be created in the Open SQL Schema&amp;nbsp;&lt;FONT face="courier new,courier"&gt;DEMO#USER_ANONYMIZE&lt;/FONT&gt;&amp;nbsp;(the one automatically created by Datasphere when creating the database user). To connect to this schema, SAP HANA Database Explorer can be started from the space management window:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Launch Database Explorer.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351580iDB952D6B923642D5/image-size/large?v=v2&amp;amp;px=999" role="button" title="Launch Database Explorer.png" alt="Launch Database Explorer.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-716621380"&gt;1.2.1 - Create function&lt;/H3&gt;&lt;P&gt;Once in data Database explorer, the function &lt;FONT face="courier new,courier"&gt;SCRAMBLE_STRING&lt;/FONT&gt; can be created:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Create Function Scramble_String.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351583iF7E5CF43236F0453/image-size/large?v=v2&amp;amp;px=999" role="button" title="Create Function Scramble_String.png" alt="Create Function Scramble_String.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Copy/Paste the following code:&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE FUNCTION SCRAMBLE_STRING (IN input NVARCHAR(500))
RETURNS scrambled NVARCHAR(500)
LANGUAGE SQLSCRIPT
AS
BEGIN
    DECLARE len INT = LENGTH(:input);
    DECLARE temp NVARCHAR(500) = :input;
    DECLARE result NVARCHAR(500) = '';
    DECLARE pos INT;
 
    WHILE LENGTH(:temp) &amp;gt; 0 DO
        pos := CEIL(RAND() * LENGTH(:temp));  -- Pick random position
        result := result || SUBSTRING(:temp, :pos, 1); -- Append character
        temp := REPLACE(:temp, SUBSTRING(:temp, :pos, 1), ''); -- Remove picked char
    END WHILE;
 
    scrambled := result;
  END&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-520107875"&gt;1.2.2 - Expose table data&lt;/H3&gt;&lt;P&gt;&lt;FONT color="#000000"&gt;&lt;SPAN&gt;Since Datasphere local tables cannot be directly exposed, i&lt;/SPAN&gt;n order to be able to read the content of the &lt;FONT face="courier new,courier"&gt;SALARY&lt;/FONT&gt; table when using an Open SQL Schema, a view &lt;FONT face="courier new,courier"&gt;V_SALARY&lt;/FONT&gt; needs to be created &lt;U&gt;in Datasphere using the Data Builder&lt;/U&gt;:&lt;/FONT&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;SELECT "ID",
	"NAME",
	"GENDER",
	"CITY",
	"SALARY",
	"CREDIT_CARD"
FROM "SALARY"&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-323594370"&gt;1.2.3 - Create a view&lt;/H3&gt;&lt;P&gt;A view &lt;FONT face="courier new,courier"&gt;V_SALARY_SCRAMBLED&lt;/FONT&gt; can now be created using &lt;U&gt;Database Explorer&lt;/U&gt; to scramble the column &lt;FONT face="courier new,courier"&gt;NAME&lt;/FONT&gt; from the&amp;nbsp; &lt;FONT face="courier new,courier"&gt;V_SALARY&lt;/FONT&gt; view (the call to INITCAP function was just added to format names):&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE VIEW "V_SALARY_NAME_SCRAMBLED" AS
(SELECT 
	"ID" AS "ID",
	INITCAP(SCRAMBLE_STRING("NAME")) AS NAME_SCRAMBLED,
	GENDER AS GENDER,
	CITY AS CITY,
	SALARY,
	CREDIT_CARD
FROM DEMO.V_SALARY);&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-127080865"&gt;1.2.4 - Import the view into Datasphere&lt;/H3&gt;&lt;P&gt;You can now import the view to create a Datasphere local table: start the process to create a dummy Datasphere view, select the Sources tab in the source browser, then click on the schema name and Drag and Drop of the View name to the text area. This triggers the table import, click on Import an Deploy, then close the New SQL View object (no need to save it, click on Discard):&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Import SQL view.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351658i85EC9777942532D4/image-size/large?v=v2&amp;amp;px=999" role="button" title="Import SQL view.png" alt="Import SQL view.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Now, the view "DEMO#USER_ANONYMIZE".V_SALARY_SCRAMBLED can be opened and used in Datasphere:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="View V_SALARY_SCRAMBLED.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351659iE710662A31B47AE0/image-size/large?v=v2&amp;amp;px=999" role="button" title="View V_SALARY_SCRAMBLED.png" alt="View V_SALARY_SCRAMBLED.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-148738998"&gt;1.3 - Data anonymization&lt;/H2&gt;&lt;P&gt;The&amp;nbsp;&lt;A href="https://help.sap.com/docs/SAP_HANA_PLATFORM/1d2f0ecc83b34dbf9aa5d08a48be2377/a66e8541c4004f048630f8a55f67ad37.html?version=LATEST&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP HANA Data Anonymization Guide&lt;/A&gt; explains how to anonymize data. In this blog, we will not focus on the technique used to anonymize data, but rather on sample syntax used to anonymize data. The following SQL code creates a view with the anonymized SALARY column (the view with anonymization will be effective after the REFRESH command):&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE VIEW "V_SALARY_SALARY_ANONYMIZED" AS
(SELECT 
	"ID",
	"NAME",
	GENDER,
	CITY,
	SALARY AS SALARY_ANONYMIZED,
	CREDIT_CARD
FROM DEMO.V_SALARY)
WITH ANONYMIZATION(
	ALGORITHM 'DIFFERENTIAL_PRIVACY'
	PARAMETERS '{"data_change_strategy": "qualified"}'
	COLUMN "ID" PARAMETERS '{"is_sequence": true}'
	COLUMN "SALARY_ANONYMIZED" PARAMETERS '{"is_sensitive":true, "epsilon":0.1, "sensitivity":2000}'
);
REFRESH VIEW "V_SALARY_SALARY_ANONYMIZED" ANONYMIZATION;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The &lt;FONT face="courier new,courier"&gt;V_SALARY_SALARY_ANONYMIZED&lt;/FONT&gt; view can now be imported into Datasphere (see&amp;nbsp;&lt;A href="#toc-hId-127080865" target="_self" rel="nofollow noopener noreferrer"&gt;1.2.4 - Import the view into Datasphere&lt;/A&gt;)&lt;/P&gt;&lt;H1 id="toc-hId-245628500"&gt;2 - Standardization&lt;/H1&gt;&lt;P&gt;We've seen above that Open SQL Schema is powerful to create features not implemented in the Datasphere UI but accessible using SQL.&lt;/P&gt;&lt;P&gt;The standardization will allow the SAP Datasphere users to easily activate/deactivate masking, scrambling and anonymization for columns.&lt;BR /&gt;A Datasphere local table (VIEWS_CREATOR_PARAMETERS) will contain the views definitions and a custom SQL procedure (&lt;FONT face="courier new,courier"&gt;EXEC_VIEWS_CREATOR&lt;/FONT&gt;) will read its content to create the views based on the stored definitions. Then a Task Chain will be created to call the procedure from Datasphere.&lt;/P&gt;&lt;H2 id="toc-hId--244288012"&gt;2.1 - Parameters table&lt;/H2&gt;&lt;DIV&gt;The table "&lt;FONT face="courier new,courier"&gt;VIEWS_CREATOR_PARAMETERS&lt;/FONT&gt;" will have the following columns:&lt;/DIV&gt;&lt;UL&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;TARGET_VIEW&lt;/FONT&gt;": name of the view that will be created in the Open SQL Schema&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;CONFIGURATION&lt;/FONT&gt;": characteristic of the target view. Contains the field name of the unmasked, scrambled anonymized field&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;SEQ&lt;/FONT&gt;": optional sequence number used to order the list of the view fields&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;VALUE&lt;/FONT&gt;": value related to the "&lt;FONT face="courier new,courier"&gt;CONFIGURATION&lt;/FONT&gt;". When "&lt;FONT face="courier new,courier"&gt;CONFIGURATION&lt;/FONT&gt;" is a field name, it contains an expression (or NULL when the field doesn't need to be changed in the target view)&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;CREATE&lt;/FONT&gt;": 'YES' when the target field needs to be created in the target table&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;RENAME_TO&lt;/FONT&gt;": target field name when "&lt;FONT face="courier new,courier"&gt;CONFIGURATION&lt;/FONT&gt;" field name needs to be changed&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;ACTIVATE&lt;/FONT&gt;": 'YES' when the target field "&lt;FONT face="courier new,courier"&gt;VALUE&lt;/FONT&gt;" needs to be used (when it doesn't start with the keyword 'PARAMETERS'). Otherwise the field name stored in "&lt;FONT face="courier new,courier"&gt;CONFIGURATION&lt;/FONT&gt;" is used.&lt;/LI&gt;&lt;/UL&gt;&lt;DIV&gt;&lt;FONT face="courier new,courier"&gt;CONFIGURATION&lt;/FONT&gt; contains one of the following keywords:&lt;/DIV&gt;&lt;UL&gt;&lt;LI&gt;'#EXECUTE#': define the behavior of the procedure that will create the target view. When "VALUE" contains the value:&lt;UL class="lia-list-style-type-circle"&gt;&lt;LI&gt;&lt;SPAN&gt;'YES': it creates in the "&lt;FONT face="courier new,courier"&gt;TARGET_VIEW&lt;/FONT&gt;" view the fields with the 'CREATE' value set to 'YES'&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;'ALL': it ignores the value of the "&lt;FONT face="courier new,courier"&gt;ACTIVATE&lt;/FONT&gt;" field ; all the fields with the 'CREATE' value set to 'YES' will be created with the expression stored in "&lt;FONT face="courier new,courier"&gt;CONFIGURATION&lt;/FONT&gt;"&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;'RESET': if ignore the value of the "&lt;FONT face="courier new,courier"&gt;ACTIVATE&lt;/FONT&gt;" field ; all the fields with the 'CREATE' value set to 'YES' will be created with their original definition stored in "&lt;FONT face="courier new,courier"&gt;VALUE&lt;/FONT&gt;"&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;'#SOURCE_NAME#': when used, then "&lt;FONT face="courier new,courier"&gt;VALUE"&lt;/FONT&gt; contains the name of the table/view used to create the target view&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;'#ANONYMIZATION_TYPE#': when used, then VALUE contains the expression used for anonymization (see &lt;A href="https://help.sap.com/docs/SAP_HANA_PLATFORM/1d2f0ecc83b34dbf9aa5d08a48be2377/a66e8541c4004f048630f8a55f67ad37.html?locale=en-US&amp;amp;state=PRODUCTION&amp;amp;version=LATEST" target="_self" rel="noopener noreferrer"&gt;SAP HANA Data Anonymization Guide&lt;/A&gt;)&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="VIEWS_CREATOR_PARAMETERS.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351736i48145BBD989BB77D/image-size/large?v=v2&amp;amp;px=999" role="button" title="VIEWS_CREATOR_PARAMETERS.png" alt="VIEWS_CREATOR_PARAMETERS.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;TABLE width="859px"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="119.91px"&gt;&lt;STRONG&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;TARGET_VIEW&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="163.806px"&gt;&lt;STRONG&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;CONFIGURATION&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="40px"&gt;&lt;STRONG&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;SEQ&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="285.389px"&gt;&lt;STRONG&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;VALUE&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="61.9097px"&gt;&lt;STRONG&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;CREATE&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="121.153px"&gt;&lt;STRONG&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;RENAME_TO&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="65.9444px"&gt;&lt;STRONG&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;ACTIVATE&lt;/FONT&gt;&lt;/STRONG&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="119.91px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;V_SALARY_DERIVED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="163.806px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;#EXECUTE#&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="40px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="285.389px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;ALL&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="61.9097px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="121.153px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="65.9444px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="119.91px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;V_SALARY_DERIVED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="163.806px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;#ANONYMIZATION_TYPE#&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="40px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="285.389px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;WITH ANONYMIZATION (ALGORITHM 'DIFFERENTIAL_PRIVACY' PARAMETERS '{"data_change_strategy": "qualified"}'&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="61.9097px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="121.153px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="65.9444px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="119.91px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;V_SALARY_DERIVED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="163.806px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;#SOURCE_NAME#&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="40px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="285.389px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;V_SALARY&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="61.9097px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="121.153px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="65.9444px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="119.91px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;V_SALARY_DERIVED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="163.806px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;ID&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="40px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;1&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="285.389px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;PARAMETERS '{"is_sequence": true}'&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="61.9097px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;YES&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="121.153px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="65.9444px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;YES&lt;/FONT&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="119.91px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;V_SALARY_DERIVED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="163.806px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;NAME&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="40px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;2&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="285.389px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;INITCAP(SCRAMBLE_STRING(NAME))&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="61.9097px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;YES&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="121.153px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;NAME_SCRAMBLED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="65.9444px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;YES&lt;/FONT&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="119.91px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;V_SALARY_DERIVED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="163.806px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;GENDER&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="40px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;3&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="285.389px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;MAP(GENDER,'M','Mr','F','Ms','')&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="61.9097px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;YES&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="121.153px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="65.9444px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="119.91px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;V_SALARY_DERIVED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="163.806px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;CITY&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="40px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;4&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="285.389px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;CITY&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="61.9097px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="121.153px"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="65.9444px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;YES&lt;/FONT&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="119.91px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;V_SALARY_DERIVED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="163.806px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;SALARY&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="40px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;5&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="285.389px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;PARAMETERS '{"is_sensitive":true, "epsilon":0.1, "sensitivity":2000}'&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="61.9097px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;YES&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="121.153px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;SALARY_ANONYMIZED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="65.9444px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;YES&lt;/FONT&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="119.91px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;V_SALARY_DERIVED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="163.806px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;CREDIT_CARD&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="40px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;6&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="285.389px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;LEFT(CREDIT_CARD,4) || '-XXXX-XXXX-' || RIGHT(CREDIT_CARD,4)&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="61.9097px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;YES&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="121.153px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;CREDIT_CARD_MASKED&lt;/FONT&gt;&lt;/TD&gt;&lt;TD width="65.9444px"&gt;&lt;FONT size="1 2 3 4 5 6 7"&gt;YES&lt;/FONT&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;In the previous screenshot, the view &lt;FONT face="courier new,courier"&gt;V_SALARY_DERIVED&lt;/FONT&gt; will have the following fields and properties:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;ID&lt;/FONT&gt;" will remain unchanged&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;NAME&lt;/FONT&gt;" will be scrambled and renamed to "&lt;FONT face="courier new,courier"&gt;NAME_SCRAMBLED&lt;/FONT&gt;"&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;GENDER&lt;/FONT&gt;" will appear not changed in the target view&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;CITY&lt;/FONT&gt;" will not appear in the target view&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;SALARY&lt;/FONT&gt;" will be anonymized and renamed to "&lt;FONT face="courier new,courier"&gt;SALARY_ANONYMIZED&lt;/FONT&gt;"&lt;/LI&gt;&lt;LI&gt;"&lt;FONT face="courier new,courier"&gt;CREDIT_CARD&lt;/FONT&gt;" will be masked and renamed to "&lt;FONT face="courier new,courier"&gt;CREDIT_CARD_MASKED&lt;/FONT&gt;"&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;In order to execute the expressions to create the target columns, a line with '#EXECUTE#' was created.&lt;BR /&gt;Since the view contains anonymized data, a line with '#ANONYZATION_TYPE#' was s created.&lt;/P&gt;&lt;P&gt;In order to be able to use this table content into an Open SQL Schema, an SQL view in SAP Datasphere needs to be created : &lt;FONT face="courier new,courier"&gt;V_VIEWS_CREATOR_PARAMETERS&lt;/FONT&gt;. This view will contain all the fields from the table.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="V_VIEWS_CREATOR_PARAMETERS.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351738iC4CBA14E8C37B1A5/image-size/large?v=v2&amp;amp;px=999" role="button" title="V_VIEWS_CREATOR_PARAMETERS.png" alt="V_VIEWS_CREATOR_PARAMETERS.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId--440801517"&gt;&amp;nbsp;&lt;/H2&gt;&lt;H2 id="toc-hId--637315022"&gt;2.2 - SQL Procedures&lt;/H2&gt;&lt;P&gt;Three SQL procedures are created:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;FONT face="courier new,courier"&gt;EXEC_VIEWS_CREATOR_CREATE_STATMT&lt;/FONT&gt;: generates a create view statement&amp;nbsp;&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="courier new,courier"&gt;EXEC_VIEWS_CREATOR&lt;/FONT&gt;: with a string parameter used to filter the view &lt;FONT face="courier new,courier"&gt;V_VIEWS_CREATOR_PARAMETERS&lt;/FONT&gt; to create only one target view by calling the procedure&amp;nbsp;&lt;FONT face="courier new,courier"&gt;EXEC_VIEWS_CREATOR_CREATE_STATMT&lt;/FONT&gt;&amp;nbsp;and embedding the code with instructions to drop the view if it already exists and generates the &lt;FONT face="courier new,courier"&gt;REFRESH&lt;/FONT&gt; statement if anonymization is used.&lt;/LI&gt;&lt;LI&gt;&lt;FONT face="courier new,courier"&gt;EXEC_ALL_VIEWS_CREATOR&lt;/FONT&gt;: calls&amp;nbsp;&lt;FONT face="courier new,courier"&gt;EXEC_VIEWS_CREATOR&lt;/FONT&gt; for the distinct values of &lt;FONT face="courier new,courier"&gt;TARGET_VEWS&lt;/FONT&gt;.&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId--1127231534"&gt;2.2.1 - Procedure&amp;nbsp; EXEC_VIEWS_CREATOR_CREATE_STATMT&lt;/H3&gt;&lt;P&gt;This procedure returns the CREATE VIEW statement for one target view defined in the view&amp;nbsp;"&lt;FONT face="courier new,courier"&gt;VIEWS_CREATOR_PARAMETERS&lt;/FONT&gt;" .&lt;/P&gt;&lt;P&gt;In the code below:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;replace DEMO#USER_ANONYMIZE with the name of your Open SQL Schema&lt;/LI&gt;&lt;LI&gt;replace DEMO with your Datasphere space name.&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE PROCEDURE EXEC_VIEWS_CREATOR_CREATE_STATMT (
	IN TARGET_NAME_ VARCHAR(1000),
	IN CURRENT_SPACE_ VARCHAR(1000),
	IN CURRENT_SCHEMA_ VARCHAR(1000),
	IN EXECUTE_ VARCHAR(1000),
	OUT FLAG_ANONYMIZATION_ INTEGER,
	OUT SQL_DDL VARCHAR (2500)
)
AS
BEGIN
    DECLARE PART1 VARCHAR(2500);
    DECLARE PART2 VARCHAR(2500);
    DECLARE PART3 VARCHAR(2500);
    DECLARE PART4 VARCHAR(2500);
    DECLARE PART5 VARCHAR(2500);

	/*
	CREATE VIEW PART 1: begining part to create the target view
	*/
    SELECT TOP 1 'CREATE VIEW '||:CURRENT_SCHEMA_||'.'|| :TARGET_NAME_ AS x
    into PART1 
    FROM DEMO.V_VIEWS_CREATOR_PARAMETERS 
    WHERE "TARGET_VIEW"=:TARGET_NAME_;

	/*
	CREATE VIEW PART 2: list columns for the target view
	*/
	WITH VIEW_PARAMETERS as
		(SELECT
			"TARGET_VIEW" AS "TARGET_VIEW",
			"CONFIGURATION" AS "CONFIGURATION",
			"SEQ" AS "SEQ",
			CASE :EXECUTE_ 
				WHEN 'YES' 
					THEN CASE WHEN IFNULL("ACTIVATE", 'NO')&amp;lt;&amp;gt;'YES'
						THEN "CONFIGURATION"
						ELSE "VALUE"
					END
				WHEN 'ALL' THEN "VALUE"
				WHEN 'RESET' THEN "CONFIGURATION" 
			END AS "VALUE",
			"CREATE" AS "CREATE",
			"RENAME_TO" AS "RENAME_TO"
		FROM DEMO.V_VIEWS_CREATOR_PARAMETERS
		WHERE "CONFIGURATION" NOT IN ('#ANONYMIZATION_TYPE#', '#EXECUTE#', '#SOURCE_NAME#')
			AND "TARGET_VIEW"=:TARGET_NAME_
		)
    SELECT ' ( ' ||
	    string_agg( IFNULL(RENAME_TO,"CONFIGURATION" )
	    	    , ', ' ORDER BY "SEQ" ) ||
	    ' ) as select ' ||
	    string_agg( 
	        IFNULL(
	            ( CASE WHEN "VALUE" LIKE 'PARAMETERS%' 
					THEN NULL 
					ELSE "VALUE" 
	            END ) 
	            , "CONFIGURATION"
	        ) ||
			' as ' ||
			IFNULL( RENAME_TO, "CONFIGURATION" )
			, ', ' ORDER BY "SEQ"
		) 
    AS x 
    INTO PART2
    FROM VIEW_PARAMETERS
    WHERE "CREATE" = 'YES';
    
	/*
	CREATE VIEW PART 3: select expression for the target view
	*/
	SELECT TOP 1 ' from '|| :CURRENT_SPACE_ || '.' || "VALUE" 
	as x 
	into PART3 
	FROM DEMO.V_VIEWS_CREATOR_PARAMETERS 
	WHERE "CONFIGURATION" = '#SOURCE_NAME#' AND "TARGET_VIEW"=:TARGET_NAME_;

	WITH VIEW_PARAMETERS as
		(SELECT
			"TARGET_VIEW" AS "TARGET_VIEW",
			CASE :EXECUTE_ 
				WHEN 'YES' 
					THEN CASE WHEN IFNULL("ACTIVATE", 'NO')&amp;lt;&amp;gt;'YES'
						THEN "CONFIGURATION"
						ELSE "VALUE"
					END
				WHEN 'ALL' THEN "VALUE"
				WHEN 'RESET' THEN "CONFIGURATION" 
			END AS "VALUE"
		FROM DEMO.V_VIEWS_CREATOR_PARAMETERS
		WHERE "CONFIGURATION" NOT IN ('#ANONYMIZATION_TYPE#', '#EXECUTE#', '#SOURCE_NAME#')
			AND "TARGET_VIEW"=:TARGET_NAME_ AND "CREATE"='YES'
			AND EXISTS (SELECT 1 
						FROM DEMO.V_VIEWS_CREATOR_PARAMETERS 
						WHERE UPPER("CONFIGURATION") = '#ANONYMIZATION_TYPE#' AND "TARGET_VIEW"=:TARGET_NAME_ AND :EXECUTE_ in ('YES','ALL')
						)
		)
	SELECT count(*) as x
	INTO FLAG_ANONYMIZATION_
	FROM VIEW_PARAMETERS
	WHERE "VALUE" LIKE 'PARAMETERS%' AND "TARGET_VIEW"=:TARGET_NAME_;
	
	IF :FLAG_ANONYMIZATION_ &amp;lt;&amp;gt; 0 THEN
		/*
		CREATE VIEW PART 4: add predicate for anonymization
		*/
	    SELECT "VALUE" AS x 
	    INTO PART4 
	    FROM DEMO.V_VIEWS_CREATOR_PARAMETERS 
	    WHERE "CONFIGURATION" = '#ANONYMIZATION_TYPE#' AND "TARGET_VIEW"=:TARGET_NAME_;
	
		/*
		CREATE VIEW PART 5: list parameters for anonymization
		*/
		WITH VIEW_PARAMETERS as
		(SELECT
			"TARGET_VIEW" AS "TARGET_VIEW",
			"CONFIGURATION" AS "CONFIGURATION",
			"SEQ" AS "SEQ",
			CASE :EXECUTE_ 
				WHEN 'YES' 
					THEN CASE WHEN IFNULL("ACTIVATE", 'NO')&amp;lt;&amp;gt;'YES'
						THEN "CONFIGURATION"
						ELSE "VALUE"
					END
				WHEN 'ALL' THEN "VALUE"
				WHEN 'RESET' THEN "CONFIGURATION" 
			END AS "VALUE",
			"RENAME_TO" as "RENAME_TO"
		FROM DEMO.V_VIEWS_CREATOR_PARAMETERS
		WHERE "CONFIGURATION" NOT IN ('#ANONYMIZATION_TYPE#', '#EXECUTE#', '#SOURCE_NAME#')
			AND "TARGET_VIEW"=:TARGET_NAME_ AND "CREATE"='YES'
			AND EXISTS (SELECT 1 
						FROM DEMO.V_VIEWS_CREATOR_PARAMETERS 
						WHERE UPPER("CONFIGURATION") = '#ANONYMIZATION_TYPE#' AND "TARGET_VIEW"=:TARGET_NAME_ AND :EXECUTE_ in ('YES','ALL')
						)
		)
		SELECT string_agg('Column ' || IFNULL(RENAME_TO,"CONFIGURATION") || ' ' || "VALUE", ' ' ORDER BY "SEQ") ||' )' AS x
	    INTO PART5
	    FROM VIEW_PARAMETERS
	    WHERE UPPER(LEFT("VALUE",10))='PARAMETERS' AND "TARGET_VIEW"=:TARGET_NAME_;
		
	END IF;	   
	
    select string_agg(x, ' ' order by rn) as x 
    into SQL_DDL from (
	    SELECT :PART1 as x ,1 as rn from DUMMY UNION ALL
	    SELECT :PART2 as x ,2 as rn from DUMMY UNION ALL
	    SELECT :PART3 as x ,3 as rn from DUMMY UNION ALL
	    SELECT :PART4 as x ,4 as rn from DUMMY UNION ALL    
	    SELECT :PART5 as x ,5 as rn from DUMMY
    ) a ;
END&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--1323745039"&gt;2.2.2 - Procedure&amp;nbsp; EXEC_VIEWS_CREATOR&lt;/H3&gt;&lt;P&gt;This procedure creates the SQL instructions to create one target view.&lt;/P&gt;&lt;P&gt;It contains:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;a &lt;FONT face="courier new,courier"&gt;DROP&lt;/FONT&gt; command that will be executed if the &lt;FONT face="courier new,courier"&gt;TARGET_VIEW&lt;/FONT&gt; is already existing&lt;/LI&gt;&lt;LI&gt;a &lt;FONT face="courier new,courier"&gt;CREATE VIEW&lt;/FONT&gt; command to create the &lt;FONT face="courier new,courier"&gt;TARGET_VIEW&lt;/FONT&gt;&lt;/LI&gt;&lt;LI&gt;A &lt;FONT face="courier new,courier"&gt;REFRESH&lt;/FONT&gt; command if &lt;FONT face="courier new,courier"&gt;TARGET_VIEW&lt;/FONT&gt; contains any field that needs to be anonymized&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;In the code below:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;replace DEMO#USER_ANONYMIZE with the name of your Open SQL Schema&lt;/LI&gt;&lt;LI&gt;replace DEMO with your Datasphere space name.&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE PROCEDURE EXEC_VIEWS_CREATOR (IN TARGET_NAME_ VARCHAR (1000)) 
AS
BEGIN
    DECLARE SQL_DROP VARCHAR(2500);
    DECLARE SQL_DDL VARCHAR(2500);
    DECLARE EXECUTE_ VARCHAR(2500);
    DECLARE REFRESH_ VARCHAR(2500);
    DECLARE FLAG_DROP_ INTEGER;
    DECLARE FLAG_ANONYMIZATION_ INTEGER;
    DECLARE CURRENT_SCHEMA_ VARCHAR(2500);
    DECLARE CURRENT_SPACE_ VARCHAR(2500);

SELECT UPPER("VALUE") as x into EXECUTE_ FROM DEMO.V_VIEWS_CREATOR_PARAMETERS WHERE UPPER("CONFIGURATION") = '#EXECUTE#' AND "TARGET_VIEW"=:TARGET_NAME_;

IF :EXECUTE_ IN ('YES', 'RESET', 'ALL') THEN
	SELECT 'DEMO#USER_ANONYMIZE' into CURRENT_SCHEMA_ FROM DUMMY;
	SELECT SUBSTR_BEFORE(:CURRENT_SCHEMA_, '#') into CURRENT_SPACE_ from DUMMY;
    SELECT count (*) INTO FLAG_DROP_ FROM views WHERE schema_name=:CURRENT_SCHEMA_ and view_name=:TARGET_NAME_;
   
    /*
    DROP SQL expression to premare the replacement for the target view.
    */
    SELECT TOP 1 'DROP VIEW '||:CURRENT_SCHEMA_||'.'||:TARGET_NAME_ ||' ; ' as x 
    into SQL_DROP
    from DEMO.V_VIEWS_CREATOR_PARAMETERS WHERE "TARGET_VIEW"=:TARGET_NAME_;

    /*
    CREATE SQL expression to create the target view.
    */
	CALL "DEMO#USER_ANONYMIZE"."EXEC_VIEWS_CREATOR_CREATE_STATMT"(
		TARGET_NAME_ =&amp;gt; :TARGET_NAME_ /*&amp;lt;NVARCHAR(1000)&amp;gt;*/,
		CURRENT_SPACE_ =&amp;gt; :CURRENT_SPACE_ /*&amp;lt;NVARCHAR(1000)&amp;gt;*/,
		CURRENT_SCHEMA_ =&amp;gt; :CURRENT_SCHEMA_ /*&amp;lt;NVARCHAR(1000)&amp;gt;*/,
		EXECUTE_ =&amp;gt; :EXECUTE_/*&amp;lt;NVARCHAR(1000)&amp;gt;*/,
		FLAG_ANONYMIZATION_ =&amp;gt; FLAG_ANONYMIZATION_,
		SQL_DDL =&amp;gt; SQL_DDL
	);
	
	IF :FLAG_ANONYMIZATION_ &amp;lt;&amp;gt; 0 THEN    
	    /*
	    REFRESH SQL expression for anonymization feature.
	    */
	    SELECT 'REFRESH VIEW '|| :CURRENT_SCHEMA_ ||'.'|| :TARGET_NAME_ || ' ANONYMIZATION;'
	    INTO REFRESH_ 
	    FROM DUMMY ;
	END IF;

    IF FLAG_DROP_ &amp;lt;&amp;gt; 0 THEN 
        EXECUTE IMMEDIATE SQL_DROP;
    END IF;

    EXECUTE IMMEDIATE SQL_DDL;
    IF :FLAG_ANONYMIZATION_ &amp;lt;&amp;gt; 0 THEN
    	EXECUTE IMMEDIATE REFRESH_;
    END IF;

END IF;
END&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId--1520258544"&gt;2.2.3 - Procedure&amp;nbsp; EXEC_ALL_VIEWS_CREATOR&lt;/H3&gt;&lt;P&gt;This procedure calls the procedure &lt;FONT face="courier new,courier"&gt;EXEC_VIEWS_CREATOR&lt;/FONT&gt; for all the distinct values for &lt;FONT face="courier new,courier"&gt;TARGET_VIEW&lt;/FONT&gt;.&lt;/P&gt;&lt;P&gt;In the code below:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;replace DEMO#USER_ANONYMIZE with the name of your Open SQL Schema&lt;/LI&gt;&lt;LI&gt;replace DEMO with your Datasphere space name.&lt;/LI&gt;&lt;/UL&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE PROCEDURE EXEC_ALL_VIEWS_CREATOR()
LANGUAGE SQLSCRIPT
AS
BEGIN
	DECLARE CURSOR c_cursor FOR SELECT DISTINCT TARGET_VIEW FROM DEMO.V_VIEWS_CREATOR_PARAMETERS;
	FOR rec as c_cursor
	DO
	    CALL "DEMO#USER_ANONYMIZE"."EXEC_VIEWS_CREATOR" (:rec.TARGET_VIEW);
  END FOR;
END&lt;/code&gt;&lt;/pre&gt;&lt;H2 id="toc-hId--1423369042"&gt;2.3 - Task Chain&lt;/H2&gt;&lt;P&gt;In order to be autonomous to mask, scramble and anonymize data in Datasphere (without accessing to the Open SQL Schema) a task chain can be created to call the SQL procedure &lt;FONT face="courier new,courier"&gt;EXEC_ALL_VIEWS_CREATOR&lt;/FONT&gt;.&lt;/P&gt;&lt;H3 id="toc-hId--1913285554"&gt;2.3.1 - Grant permissions&lt;/H3&gt;&lt;P&gt;Datasphere space needs to view and run the SQL Procedure that was created in the Open SQL Schema, some grants need to be done in SQL Developer by&amp;nbsp; the user&amp;nbsp;DEMO#USER_ANONYMIZE to the Datasphere space user.&lt;/P&gt;&lt;P&gt;In the code below:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;replace DEMO#USER_ANONYMIZE with the name of your Open SQL Schema&lt;/LI&gt;&lt;LI&gt;replace DEMO with your Datasphere space name.&lt;/LI&gt;&lt;/UL&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;PRE&gt;&lt;CODE&gt;CALL "DWC_GLOBAL"."GRANT_PRIVILEGE_TO_SPACE" (
	OPERATION =&amp;gt; 'GRANT', 
	PRIVILEGE =&amp;gt; 'EXECUTE', 
	SCHEMA_NAME =&amp;gt; 'DEMO#USER_ANONYMIZE', 
	OBJECT_NAME =&amp;gt; '', 
	SPACE_ID =&amp;gt; 'DEMO');&lt;/CODE&gt;&lt;/PRE&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;H3 id="toc-hId--1941615368"&gt;2.3.2 - Create a task chain&lt;/H3&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Task Chain RUN_VIEWS_CREATOR.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351742iE79AEE475A8F6B2A/image-size/large?v=v2&amp;amp;px=999" role="button" title="Task Chain RUN_VIEWS_CREATOR.png" alt="Task Chain RUN_VIEWS_CREATOR.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId--2138128873"&gt;2.3.3 - Test&lt;/H3&gt;&lt;P&gt;For testing purposes, we can use the parameters table described in&amp;nbsp;&lt;A href="#toc-hId--244288012" target="_self" rel="nofollow noopener noreferrer"&gt;2.1 - Parameters table&lt;/A&gt;&amp;nbsp;.&lt;/P&gt;&lt;P&gt;After running the task chain, the view V_SALARY_DERIVED was created and can now be imported into the Datasphere space (see&amp;nbsp;&lt;A href="#toc-hId-127080865" target="_self" rel="nofollow noopener noreferrer"&gt;1.2.4 - Import the view into Datasphere&lt;/A&gt;&amp;nbsp;).&lt;/P&gt;&lt;P&gt;Finally your space should contain this list of objects:&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="Data Builder with all the objects.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351743i33EC830A64829E31/image-size/large?v=v2&amp;amp;px=999" role="button" title="Data Builder with all the objects.png" alt="Data Builder with all the objects.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H1 id="toc-hId--1747836364"&gt;&amp;nbsp;&lt;/H1&gt;&lt;P&gt;If you open V_SALARY_DERIVED:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-left" image-alt="V_SALARY_DERIVED.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351744i8582208636574EB2/image-size/large?v=v2&amp;amp;px=999" role="button" title="V_SALARY_DERIVED.png" alt="V_SALARY_DERIVED.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H1 id="toc-hId--1944349869"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H1 id="toc-hId--2140863374"&gt;Conclusion&lt;/H1&gt;&lt;P&gt;If you face some missing features in Datasphere, consider Open SQL Schema, it may offer you the opportunity to implement what you miss using the underlying SAP HANA Cloud database.&lt;/P&gt;&lt;P&gt;If you liked this blog, say it by clicking on the Like button.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/data-masking-data-scrambling-and-data-anonymization-in-business-data-cloud/ba-p/14288934"/>
    <published>2025-12-18T09:57:28.944000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-nlp-and-ai-features-in-sap-hana-cloud-2025-q4/ba-p/14293152</id>
    <title>New Machine Learning, NLP and AI features in SAP HANA Cloud 2025 Q4</title>
    <updated>2025-12-22T08:08:25.334000+01:00</updated>
    <author>
      <name>ChristophMorgen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14106</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;With the&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;SAP HANA Cloud 2025 Q4 release&lt;/STRONG&gt;&lt;SPAN&gt;, several&amp;nbsp;&lt;/SPAN&gt;&lt;STRONG&gt;new embedded Machine Learning / AI functions &lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;have been released with the with the Predictive Analysis Library (PAL), the Automated Predictive Library (APL) and the NLP Services in SAP HANA Cloud.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Key new capabilities to be highlighted include&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;A new unified time series procedure, serving developers to utilize the same interface across different times series algorithms&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;text embedding model enhancements, supporting output vector dimensionality reduction, while maintaining retrieval accuracy&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;a new cross encoder model with the NLP services, for accurately re-ranking search results&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;text column input, text embedding operators with AutoML classification and regression models&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;text tokenization enhancements supporting regular expression token filtering and a new text log parsing function for detecting and determining new log pattern &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;the HANA ML experiment monitor UI now supports visual model monitoring and drift analysis&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;An enhancement summary is available in the &lt;STRONG&gt;What‚Äôs new document&lt;/STRONG&gt; for&amp;nbsp;&lt;A href="https://help.sap.com/whats-new/2495b34492334456a49084831c2bea4e?Category=Predictive+Analysis+Library&amp;amp;Valid_as_Of=2025-12-01:2025-12-31&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;SAP HANA Cloud database 2025.40 (QRC 4/2025)&lt;/A&gt;.&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1767386629"&gt;&amp;nbsp;&lt;/H2&gt;&lt;H2 id="toc-hId-1570873124"&gt;&lt;SPAN&gt;Time series enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Introducing Unified Time Series interfaces&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/unified-time-series?)" target="_blank" rel="noopener noreferrer"&gt;Unified time series&lt;/A&gt; is a newly introduced interface for a simplified use of multiple time series algorithms (ARIMA, Exponential Smoothing, Bayesian Structural Time Series (BSTS) and Additive Model Analysis (aka prophet)). &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;it allows for application developers to flexibly consume different time series analysis algorithms using the same procedure interface and a harmonized the handling of time series data patterns, avoiding algorithm-specific data preparation.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;It also supports massive, data-parallel time series modeling for maximum parallelism and performance when modeling thousands of time series in parallel&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_0-1766163060120.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354281i72B7D8752D9AD268/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_0-1766163060120.png" alt="ChristophMorgen_0-1766163060120.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A more detailed introduction to the new function is given in the following blog post &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/simplifying-time-series-analytics-with-unified-time-series-interface/ba-p/14292218" target="_blank"&gt;https://community.sap.com/t5/technology-blog-posts-by-sap/simplifying-time-series-analytics-with-unified-time-series-interface/ba-p/14292218&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;AutoML time series now support Prediction Intervals&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;AutoML time series predict function, in addition to all regular time series functions, now supports prediction intervals for probabilistic forecasting &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;the uncertainty associated with a forecast is quantified by providing a range (lower/upper bounds) into which a future observation likely falls with a specific confidence level.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;For example a 95% prediction interval contains the true value 95% of the time&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_1-1766163060130.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354280i60475911734D2868/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_1-1766163060130.png" alt="ChristophMorgen_1-1766163060130.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1374359619"&gt;&amp;nbsp;&lt;/H2&gt;&lt;H2 id="toc-hId-1177846114"&gt;&lt;SPAN&gt;Text embedding model enhancements (NLP services)&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Output vector dimension reduction&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The Text Embedding models in SAP HANA Cloud have been enhanced with an attached a linear layer&lt;/SPAN&gt;‚Äã‚Äã&lt;SPAN&gt;, derived from PCA trainings, to allow for the output vector dimensionality reduction&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;The arget dimension cardinality can be flexibly set to 128, 256 384, 512, 768 dimensions using &lt;/SPAN&gt;‚Äã‚Äã&lt;SPAN&gt;PCA_DIM_NUM parameter&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;A near-original retrieval task accuracy is sustained with 256 dimensions, at 1/3rd of the original vector size (768 dimensions)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;While lower dimension values than 128 would lead to significant and critical-level accuracy loss for retrieval tasks, hence 256 dimensions&lt;/SPAN&gt;‚Äã‚Äã&lt;SPAN&gt; is recommended for efficiency &amp;amp; performance&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Now &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;text embeddings of significantly &lt;STRONG&gt;&lt;EM&gt;lower dimensionality can be utilized at a&lt;/EM&gt;&lt;/STRONG&gt; &lt;STRONG&gt;&lt;EM&gt;minimal information loss&lt;/EM&gt;&lt;/STRONG&gt; for retrieval tasks as well as machine learning.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Moreover &lt;STRONG&gt;s&lt;EM&gt;maller vector sizes &lt;/EM&gt;&lt;/STRONG&gt;unlock much &lt;STRONG&gt;&lt;EM&gt;faster machine learning &lt;/EM&gt;&lt;/STRONG&gt;processing times and may also serve &lt;STRONG&gt;&lt;EM&gt;vector retrieval queries&lt;/EM&gt;&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_2-1766163135495.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354283iE2DA5A040F70C036/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_2-1766163135495.png" alt="ChristophMorgen_2-1766163135495.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A more detailed introduction to the output vector dimensionality reduction is given in the following blog post&lt;/SPAN&gt;&amp;nbsp;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-cross-encoder-and-text-embedding-support-dimensionality-reduction-in/ba-p/14293164" target="_blank"&gt;New Cross Encoder and Text Embedding support Dimensionality Reduction in HANA NLP Service 2025 Q4- SAP Community blog post.&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-981332609"&gt;&lt;SPAN&gt;Text feature data support with AutoML models&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text column data and Text Embedding Operator in AutoML models&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;With the introduction of the a new &lt;STRONG&gt;text embedding operator&lt;/STRONG&gt; for AutoML models, &lt;STRONG&gt;text columns&lt;/STRONG&gt; can be directly used as input feature data and benefit from &lt;EM&gt;automatic&lt;/EM&gt;, and &lt;EM&gt;optimized text vectorization&lt;/EM&gt; utilizing SAP HANA Clouds text embedding models.&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Text columns can be processed as feature, specified with the new parameter TEXT_VARIABLE&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;In addition, the new TextEmbedding operator supports the new target dimension reduction with the parameter PCA_DIM_NUM&amp;nbsp; &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;The enhancement are available with the SQL interface as well as hana-ml 2.27 in Python&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;With that, the semantic insights from text columns can get automatically unlocked when building AutoML classification / regression models.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_3-1766163135508.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354284i535154FFAB1373DB/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_3-1766163135508.png" alt="ChristophMorgen_3-1766163135508.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-784819104"&gt;&lt;SPAN&gt;Cross Encoder Model (NLP services)&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Accurate re-ranking of search results&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The family NLP services in SAP HANA Cloud has now been enriched with a new &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/cross-encoder?" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;cross encoder model&lt;/STRONG&gt;&lt;/A&gt; and respective PAL functions. The cross encoder model&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Processes pairs/sets of text sentences (query, candidate results) together&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Therefore allows for a more precise semantic similarity re-ranking of search results, based on the full contextual interaction analysis between the query and the input candidate set (e.g. a an initial result set retrieved from a vector engine similarity search)&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Thus much higher accurate and relevant-ranked similarity search results can be achieved&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_5-1766163220596.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354289iCFA46CCE741FFD81/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_5-1766163220596.png" alt="ChristophMorgen_5-1766163220596.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Moreover the use of cross encoder models allows to combine multiple result sets retrieved from for example classic text search and vector engine similarity search queries into a hybrid search result, which can be passed into the cross encoder for its overall and combined re-ranking.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Custom AI, Retrieval Augmented Generation Applications (RAG) can now fully be served by Text Embedding Models, Vector Engine with Similarity Search and the Cross Encoder model, managing context privacy from the SAP HANA Cloud database.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_6-1766163220604.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354288i5A22ACEECABE4AC3/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_6-1766163220604.png" alt="ChristophMorgen_6-1766163220604.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A more detailed introduction to the new cross encoder model is given in the following blog post&lt;/SPAN&gt;&amp;nbsp;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-cross-encoder-and-text-embedding-support-dimensionality-reduction-in/ba-p/14293164" target="_blank"&gt;New Cross Encoder and Text Embedding support Dimensionality Reduction in HANA NLP Service 2025 Q4- SAP Community blog post.&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-588305599"&gt;&lt;SPAN&gt;Text tokenization enhancements and new automated log text analysis&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Text tokenization support for regular expressions&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The text &lt;EM&gt;pre-processing&lt;/EM&gt; function &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-tokenize?" target="_blank" rel="noopener noreferrer"&gt;Text Tokenize &lt;/A&gt;function for &lt;EM&gt;splitting input text into smaller units called tokens, has now been enhanced and supports r&lt;/EM&gt;egular expression for filtering token output patterns.&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Custom filtering (removal/keeping) of text patterns can be applied&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;List of regular expressions, matching tokens will be kept / excluded&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Typical filtering examples include extracting e-mail addresses, URLs, or other token patterns for domain-specific needs&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_7-1766163220609.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354287i7BC8633CA0DAB217/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_7-1766163220609.png" alt="ChristophMorgen_7-1766163220609.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Automatic pattern detection from log texts&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A new analysis function for log text documents &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-log-parse?" target="_blank" rel="noopener noreferrer"&gt;Text Log Parse&lt;/A&gt; has been added to the Predictive Analysis Library, which allows&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;For an automatic extraction of new log patterns and derive templates for new log patterns&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;High-performant processing of log texts for log classification and automated log analysis, the ability to detect and alert for new log patterns&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_8-1766163220624.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354292iBFB4981D8D6C0303/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_8-1766163220624.png" alt="ChristophMorgen_8-1766163220624.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-391792094"&gt;&lt;SPAN&gt;Real-time prediction performance improvements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Using PAL stateful ML models for real-time prediction performance&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;When a PAL ML model state is created, the model is parsed only once and kept as a runtime in-memory object (see PAL documentation on &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/state-enabled-real-time-scoring-functions" target="_blank" rel="noopener noreferrer"&gt;state-enabled-real-time-scoring-functions&lt;/A&gt;)&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;The actual prediction-function references to the PAL ML model by its STATE_ID&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;The repeated overhead of PAL ML model parsing with every predict-function call can be avoided in scenarios &lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;with rather complex and larger PAL ML models with significant model parsing time proportion&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;the prediction runtime shall be as minimal as possible and near real-time&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;The prediction runtime performance has now been improved from ~100ms to ~20ms in exemplary use cases (see example &lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/PAL-SQL/usage-patterns/PAL%20ML%20model%20state%20for%20real-time%20predictions.sql" target="_blank" rel="nofollow noopener noreferrer"&gt;PAL_ML_model_for_real-time_predictions.sql&lt;/A&gt;)&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_0-1767869320915.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/359353iBBFA7DB11C804EF3/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_0-1767869320915.png" alt="ChristophMorgen_0-1767869320915.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-195278589"&gt;&lt;SPAN&gt;ML experiment tracking and task scheduling enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Experiment tracking enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/pal-track?" target="_blank" rel="noopener noreferrer"&gt;Tracking of experiments&lt;/A&gt;, now supports custom track entity tags&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Standard track entities generated in PAL Training, Forecast, etc. can now be enriched with custom tags like business related information associated with related track entity&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Tag is name-value pair for annotation or note, binding extra information to existing entities&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_9-1766163220625.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354290i96134FE7913A4153/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_9-1766163220625.png" alt="ChristophMorgen_9-1766163220625.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;A more detailed introduction is provided in the following blog post &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217" target="_blank"&gt;comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Moreover the Experiment Monitor in the Python Machine Learning client (hana-ml) supports for visually monitoring ML model performance degradation and drift.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_10-1766163220626.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354291i656B4787F3256EFB/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_10-1766163220626.png" alt="ChristophMorgen_10-1766163220626.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;One-off scheduling of PAL tasks&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/calling-pal-with-schedule?" target="_blank" rel="noopener noreferrer"&gt;PAL procedure scheduling interfaces&lt;/A&gt;&lt;/SPAN&gt; has been enhance with a &lt;SPAN&gt;One-OFF schedule option, allowing for &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;ad-hoc, automatic one-off scheduled execution of PAL task procedures with dynamic setting of time-frequency information based on current UTC timestamp&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;it triggers a scheduled job to execute immediately, and the corresponding one-off schedule is removed right away and doesn‚Äôt require to be manually maintained.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId--1234916"&gt;&lt;SPAN&gt;Python ML client (hana-ml) enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;EM&gt;The full list of new methods and enhancements with hana_ml 2.27&amp;nbsp; is summarized in the &lt;/EM&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/doc/cd94b08fe2e041c2ba778374572ddba9/2025_4_QRC/en-US/change_log.html" target="_blank" rel="noopener noreferrer"&gt;&lt;EM&gt;changelog for hana-ml 2.27&lt;/EM&gt;&lt;/A&gt; &lt;/SPAN&gt;&lt;EM&gt;as part of the documentation.&amp;nbsp; You can find an examples notebook illustrating the highlighted feature enhancements &lt;SPAN&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/pal/notebooks/25QRC04_2.27.ipynb" target="_blank" rel="noopener nofollow noreferrer"&gt;here 25QRC04_2.27.ipynb&lt;/A&gt;.&lt;/SPAN&gt;&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;EM&gt;The key enhancements in this release include the following:&lt;/EM&gt;&lt;EM&gt;&amp;nbsp;&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Time series data outlier detection with threshold support&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The method for time series outlier detection in the Predictive Analysis Library has added support outlier threshold settings, in addition to the outlier voting capability using different outlier evaluation methods incl. &amp;nbsp;Z1 score, Z2 score, IIQR score, MAD score, IsolationForest and DBSCAN &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;If the absolute value of outlier score is beyond the threshold, the respective data point will be considered as an outlier.&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Time series reports for massive, data-parallel model scenarios&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Massive AutoML Time Series modeling scenarios often utilize random-search with hyperband as the fastest optimization, potentially with larger number of time series data segment groups to be processed and forecasted in parallel, each time series segment group again with a significant number of forecast models to be explored.&amp;nbsp; &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Hence the display of forecasts which have been explored by AutoML within each time series segment group is collapsed by default and can be expanded for review. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_11-1766163388491.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354294iEE72CE6111257A87/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_11-1766163388491.png" alt="ChristophMorgen_11-1766163388491.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Classification and regression function enhancements&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Support Vector Machine (SVM)&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt; model training is computationally expensive, and computational costs are specifically sensitive to the number of training points, which makes SVM models often impractical for large datasets. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The SVM algorithm now supports &lt;STRONG&gt;Coreset Sampling&lt;/STRONG&gt; &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;which allows to automatically sample small, representative subsets (the "coreset") from larger datasets, &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;enabling faster, more efficient training and processing while maintaining similar model accuracy as using the full data. &lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;This enhancement significantly reduces SVM training time with minimal impact on accuracy. &lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The&lt;STRONG&gt; model report &lt;/STRONG&gt;for&lt;STRONG&gt; classification &lt;/STRONG&gt;tasks now supports a&lt;STRONG&gt; percentage display &lt;/STRONG&gt;in&lt;STRONG&gt; confusion matrix &lt;/STRONG&gt;for easier visual interpretation of classification results.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_12-1766163388493.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354293i102668E672266574/image-size/large?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_12-1766163388493.png" alt="ChristophMorgen_12-1766163388493.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;High-dimensional feature data reduction using UMAP &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/uniform-manifold-approximation-and-projection?version=LATEST&amp;amp;q=UMAP&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;UMAP (Uniform Manifold Approximation and Projection)&lt;/A&gt; is a non-linear dimensionality reduction algorithm used to simplify complex, high-dimensional feature spaces, while preserving its essential structure. It is widely considered the modern gold standard for visualizing targeted dimension reduction of large-scale datasets, because it balances computational speed with the ability to maintain both local and global relationships.&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;It reduces thousands of variables (dimensions) into 2D or 3D scatter plots that humans can easily interpret.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Unlike comparable methods like t-SNE, UMAP is better at preserving global structure, meaning the relative positions between different clusters remain more meaningful.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;It is significantly faster and more memory-efficient than t-SNE, capable of processing datasets with millions of points in a reasonable timeframe.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;It can be used as a "transformer" preprocessing step in Machine Learning scenarios to reduce large feature spaces before applying clustering (e.g., k-means, HDBSCAN) or classification models, often improving their performance.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Calculating pairwise distances &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Many algorithms, for example clustering algorithms utilize distance matrixes as a preprocessing step, often inbuild the functions. Often there is the wish to decouple though the distance matrix calculation from the follow-up task like the actual clustering. Moreover, if decoupled custom calculated matrixes can be fed into algorithms as input.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Most PAL clustering functions support to feed-in a pre-calculated similarity matrix&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Now, a pairwise &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/distance-md?version=LATEST&amp;amp;q=distance&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;distance calculation function&lt;/A&gt; is provided&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;It supports distance metrics like &lt;EM&gt;Manhattan, Euclidien, Minkowski, Chebyshey&lt;/EM&gt; as well as &lt;EM&gt;Levenshtein&lt;/EM&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;The &lt;STRONG&gt;Levenshtein distance&lt;/STRONG&gt; (or edit distance) is a distance metric specifically targeting distance between text-columns. It calculates the minimum number of single-character edits (insertions, deletions, or substitutions) needed to transform one word into another, acting as a measure of their similarity. A lower distance indicates a higher similarity.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;Applicable use cases&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;It is useful in data cleaning, table column similarity analysis between columns of the same data type.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;After calculating the column similarity across all data types, clustering like K-Means can be applied to group similar fields and propose mappings for fields within the same cluster&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;EM&gt;Again, an incredible set of enhancements in the SAP HANA Cloud database AI engine and NLP services!&lt;/EM&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Enjoy to try out all the enhancements and let us know what you think here!&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-nlp-and-ai-features-in-sap-hana-cloud-2025-q4/ba-p/14293152"/>
    <published>2025-12-22T08:08:25.334000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/converting-property-graphs-to-knowledge-graphs-in-sap-hana-cloud-a-simple/ba-p/14294883</id>
    <title>Converting Property Graphs to Knowledge Graphs in SAP HANA Cloud: A Simple Guide</title>
    <updated>2025-12-22T09:00:00.042000+01:00</updated>
    <author>
      <name>shabana</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/38259</uri>
    </author>
    <content>&lt;P&gt;Graphs are becoming a core part of how businesses understand their data. In SAP HANA Cloud, we already support strong property graph capabilities through the &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-property-graph-engine-reference/sap-hana-cloud-sap-hana-database-property-graph-engine-reference?locale=en-US&amp;amp;version=LATEST" target="_blank" rel="noopener noreferrer"&gt;property graph engine&lt;/A&gt;, and a rich RDF/Knowledge Graph model through the &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-knowledge-graph-guide/sap-hana-cloud-sap-hana-database-knowledge-graph-engine-guide?locale=en-US&amp;amp;version=LATEST" target="_blank" rel="noopener noreferrer"&gt;knowledge graph engine&lt;/A&gt;. Until now, these two worlds lived separately.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;SPAN&gt;With our new built-in graph procedure, we make it possible to turn a property graph&amp;nbsp;into a knowledge graph&amp;nbsp;(RDF) in one step. This gives customers the best of both worlds: the flexibility of property graphs and the semantic richness of RDF. This blog walks through the idea in simple terms and shows how it works behind the scenes.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Before we jump into details, let‚Äôs understand why we would want to convert a property graph to a knowledge graph:&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Customers often start with a property graph because it is easy to model, easy to modify, and great for traversal and analytics.&lt;BR /&gt;Over time, they want additional capabilities like:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;a standardized representation of entities&lt;/LI&gt;&lt;LI&gt;richer semantic modeling&lt;/LI&gt;&lt;LI&gt;SPARQL querying&lt;/LI&gt;&lt;LI&gt;interoperability with external tools&lt;/LI&gt;&lt;LI&gt;grounding their data for AI, LLMs, and RAG pipelines&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Knowledge graphs shine here. By converting property graphs to the RDF format, teams can keep using their familiar structure while unlocking a wider ecosystem.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;The new built-in procedure&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;SAP HANA Cloud introduces a simple, built-in procedure from its QRC4 2025 release: &lt;STRONG&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-property-graph-engine-reference/rdf-graph-from-graph-workspace-stored-procedure?version=LATEST&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;RDF_GRAPH_FROM_GRAPH_WORKSPACE.&lt;/A&gt;&amp;nbsp;&lt;/STRONG&gt;This procedure converts a property graph workspace into an RDF graph (knowledge graph).&lt;BR /&gt;It copies the graph data, but keeps the models independent. This means updates to one don‚Äôt automatically reflect in the other.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;A simple supply chain graph example&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;To make this more tangible, let‚Äôs walk through a small but realistic example.&lt;/P&gt;&lt;P&gt;Imagine a supply chain graph with three main tables:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Suppliers&lt;/STRONG&gt; - Each supplier has attributes like name, country, and risk level.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Materials&lt;/STRONG&gt; - Materials represent the goods being supplied.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Shipments&lt;/STRONG&gt; - Shipments connect suppliers to materials and carry business context such as shipment status and delay days.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;In SAP HANA Cloud, we will first model this as a property graph workspace.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Suppliers and materials are &lt;STRONG&gt;vertex tables&lt;/STRONG&gt;&lt;/LI&gt;&lt;LI&gt;Shipments are an &lt;STRONG&gt;edge table&lt;/STRONG&gt; connecting suppliers to materials&lt;/LI&gt;&lt;LI&gt;Shipment specific attributes remain attached to the edge&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This structure is very natural for operational and analytical use cases. You can easily answer questions like:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Which suppliers provide a given material?&lt;/LI&gt;&lt;LI&gt;Which suppliers are associated with delayed shipments?&lt;/LI&gt;&lt;LI&gt;How does risk propagate through the supply network?&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Creating the property graph&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;At the data level, the graph is built on top of relational tables. Suppliers and materials are modeled as vertex tables, while shipments act as the edge table connecting them. Once the tables are defined, a graph workspace ties everything together:&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 1: Let‚Äôs begin with creating plain relational tables.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Suppliers&lt;/STRONG&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE SCHEMA SCM;
SET SCHEMA SCM;
CREATE TABLE SCM.SUPPLIERS (
  SUPPLIERID NVARCHAR(50) PRIMARY KEY,
  NAME       NVARCHAR(100),
  COUNTRY    NVARCHAR(50),
  RISKLEVEL  NVARCHAR(20)
);&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Materials&lt;/STRONG&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE TABLE SCM.MATERIALS (
  MATERIALID NVARCHAR(50) PRIMARY KEY,
  NAME       NVARCHAR(100)
);&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Shipments (relationship data)&lt;/STRONG&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE TABLE SCM.SHIPMENTS (
  SHIPMENTID NVARCHAR(50) PRIMARY KEY,
  SUPPLIER   NVARCHAR(50) NOT NULL,
  MATERIAL   NVARCHAR(50) NOT NULL,
  STATUS     NVARCHAR(20),
  DELAYDAYS  INTEGER
);&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Step 2: Insert sample data in the created tables&lt;/STRONG&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;--Suppliers
INSERT INTO SCM.SUPPLIERS (SupplierID, Name, Country, RiskLevel)
VALUES ('S1', 'Alpha Metals', 'China', 'High');

INSERT INTO SCM.SUPPLIERS (SupplierID, Name, Country, RiskLevel)
VALUES ('S2', 'Nordic Steel', 'Sweden', 'Low');

INSERT INTO SCM.SUPPLIERS (SupplierID, Name, Country, RiskLevel)
VALUES ('S3', 'TerraChem', 'Brazil', 'Medium');

--Materials
INSERT INTO SCM.MATERIALS (MaterialID, Name)
VALUES ('M1', 'Steel Rods');

INSERT INTO SCM.MATERIALS (MaterialID, Name)
VALUES ('M2', 'Copper Wire');

--Shipments
INSERT INTO SCM.SHIPMENTS (ShipmentID, Supplier, Material, Status, DelayDays)
VALUES ('SH1', 'S1', 'M1', 'Delayed', 12);

INSERT INTO SCM.SHIPMENTS (ShipmentID, Supplier, Material, Status, DelayDays)
VALUES ('SH2', 'S2', 'M1', 'OnTime', 0);

INSERT INTO SCM.SHIPMENTS (ShipmentID, Supplier, Material, Status, DelayDays)
VALUES ('SH3', 'S3', 'M2', 'Delayed', 5);&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;At this point, the data is still relational.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 3: Create a property graph workspace&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Now we turn the above tables into a graph workspace - &lt;STRONG&gt;SUPPLY_GRAPH&lt;/STRONG&gt;.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE GRAPH WORKSPACE SCM.SUPPLY_GRAPH
  VERTEX TABLE SCM.SUPPLIERS
    KEY SUPPLIERID
  VERTEX TABLE SCM.MATERIALS
    KEY MATERIALID
  EDGE TABLE SCM.SHIPMENTS
    KEY SHIPMENTID
    SOURCE SUPPLIER REFERENCES SCM.SUPPLIERS
    TARGET MATERIAL REFERENCES SCM.MATERIALS;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;What this gives us:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Vertices&lt;/LI&gt;&lt;UL&gt;&lt;LI&gt;Suppliers with properties like name, country, risk level&lt;/LI&gt;&lt;LI&gt;Materials with their attributes&lt;/LI&gt;&lt;/UL&gt;&lt;LI&gt;Edges&lt;/LI&gt;&lt;UL&gt;&lt;LI&gt;Shipments connecting suppliers to materials&lt;/LI&gt;&lt;LI&gt;Edge properties such as status and delay days&lt;/LI&gt;&lt;/UL&gt;&lt;/UL&gt;&lt;P&gt;This graph is optimized for traversal and graph algorithms.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 4: What‚Äôs new in QRC4 2025 - Property Graph (PG) to Knowledge Graph (KG) conversion&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This is where the new functionality - &lt;STRONG&gt;RDF_GRAPH_FROM_GRAPH_WORKSPACE&lt;/STRONG&gt; &amp;nbsp;comes in.&amp;nbsp; It converts an existing graph workspace into an RDF knowledge graph - &lt;STRONG&gt;'scmkg'.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The conversion call :&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CALL RDF_GRAPH_FROM_GRAPH_WORKSPACE(
    GRAPH_WORKSPACE_SCHEMA_NAME =&amp;gt; 'SCM',
    GRAPH_WORKSPACE_NAME        =&amp;gt; 'SUPPLY_GRAPH',
    TARGET_GRAPH_URI            =&amp;gt; '&amp;lt;scmkg&amp;gt;',
    MAPPING_MODE                =&amp;gt; 'AUTO',
    MAPPING_OUT                 =&amp;gt; ?
);&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;STRONG&gt;Step 5: How the conversion works (in simple terms)&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The conversion follows a few clear rules.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Vertices become RDF triples - &lt;/STRONG&gt;Each vertex is converted into multiple RDF triples.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;The vertex key becomes the subject&lt;/LI&gt;&lt;LI&gt;Each attribute becomes a predicate&lt;/LI&gt;&lt;LI&gt;Attribute values become objects&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;For example, a supplier like &lt;EM&gt;Alpha Metals&lt;/EM&gt; becomes a set of triples such as:&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;&amp;lt;http://SCM/SUPPLIERS/SUPPLIERID/S1&amp;gt; &amp;lt;http://SCM/SUPPLIERS/NAME&amp;gt; "Alpha Metals" .
&amp;lt;http://SCM/SUPPLIERS/SUPPLIERID/S1&amp;gt; &amp;lt;http://SCM/SUPPLIERS/COUNTRY&amp;gt; "China" .
&amp;lt;http://SCM/SUPPLIERS/SUPPLIERID/S1&amp;gt; &amp;lt;http://SCM/SUPPLIERS/RISKLEVEL&amp;gt; "High" .&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;This directly mirrors the rows in the vertex table.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Vertex types become rdf:type &lt;/STRONG&gt;- Vertex labels are converted into RDF classes.&lt;/P&gt;&lt;P&gt;Conceptually, this means:&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;&amp;lt;Suppliers/S1&amp;gt; rdf:type &amp;lt;Supplier&amp;gt; .
&amp;lt;Materials/M1&amp;gt; rdf:type &amp;lt;Material&amp;gt; .&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;This adds semantic meaning and allows tools and queries to reason about &lt;EM&gt;what kind of thing&lt;/EM&gt; each node represents.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 6: Mapping modes and URI control&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;By default, the system generates URIs automatically. These are predictable, but often not ideal for long term semantic use. To give users full control, the conversion supports an optional mapping table, where you can define: schema, table, attribute, RDF URI, data type, optional language tags.&lt;/P&gt;&lt;P&gt;Using a mapping table allows customers to:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;apply meaningful, business-friendly URIs&lt;/LI&gt;&lt;LI&gt;align with existing vocabularies&lt;/LI&gt;&lt;LI&gt;standardize naming across systems&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;If a mapping table is not provided, the system falls back to sensible defaults:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;URIs are generated in the form - &lt;A href="https://localhost/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://localhost/&lt;/A&gt;&amp;lt;schema&amp;gt;/&amp;lt;table&amp;gt;/&amp;lt;attribute&amp;gt;&lt;/LI&gt;&lt;LI&gt;Vertex labels default to table names&lt;/LI&gt;&lt;LI&gt;Unmapped attributes are handled based on the selected mapping mode&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This makes it easy to get started without extra configuration.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Mapping modes that fit different customer needs&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The conversion supports multiple modes, depending on how strict or exploratory the user wants to be. These modes are also described in the official documentation.&amp;nbsp;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;AUTO (default) - &lt;/STRONG&gt;Uses mapping table entries when provided, otherwise generates system URIs.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;MAPPING_ONLY - &lt;/STRONG&gt;Generates mapping output without creating RDF. Useful for validation.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;IGNORE - &lt;/STRONG&gt;Converts only attributes explicitly listed in the mapping table.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;STRICT - &lt;/STRONG&gt;Requires all attributes to be mapped. Fails if anything is missing.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;You can also supply a mapping table to assign clean, meaningful URIs and prefixes, including standard vocabularies like FOAF. An out-mapping table is generated automatically so users can inspect exactly how attributes were mapped.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Step 7: Query the knowledge graph with SPARQL&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Once the RDF graph is created, it can be queried directly inside SAP HANA Cloud using &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sparql-reference-guide/sparql-table-function?locale=en-US&amp;amp;version=LATEST" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt;SPARQL_TABLE &lt;/STRONG&gt;&lt;/A&gt;or&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sparql-reference-guide/sparql-execute-stored-procedure?locale=en-US&amp;amp;version=LATEST" target="_blank" rel="noopener noreferrer"&gt;&lt;STRONG&gt; SPARQL_EXECUTE &lt;/STRONG&gt;&lt;/A&gt;functions.&lt;/P&gt;&lt;P&gt;View the RDF graph created:&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;SELECT *
FROM SPARQL_TABLE('
PREFIX rdf:&amp;lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&amp;gt;
PREFIX ex:&amp;lt;http://example.org/scm/&amp;gt;

SELECT ?subject ?predicate ?obj
FROM &amp;lt;scmkg&amp;gt;
WHERE {
  ?subject ?predicate ?obj .
}
');&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;The below SPARQL query retrieves which suppliers ship which materials by traversing shipment relationships in the converted knowledge graph.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;SELECT *
FROM SPARQL_TABLE('
SELECT DISTINCT ?supplierName ?materialName
FROM &amp;lt;scmkg&amp;gt;
WHERE {
  # ensure the embedded shipment triple exists
  FILTER EXISTS {
     &amp;lt;&amp;lt; ?supplier &amp;lt;http://SCM/SHIPMENTS/SHIPMENTS&amp;gt; ?material &amp;gt;&amp;gt; ?p ?o .
  }
  # supplier attributes
  ?supplier &amp;lt;http://SCM/SUPPLIERS/NAME&amp;gt; ?supplierName .
  # material attributes
  ?material &amp;lt;http://SCM/MATERIALS/NAME&amp;gt; ?materialName .
}
');&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="shabana_0-1766333515714.png" style="width: 867px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354456iCA3509F124E82A67/image-dimensions/867x163?v=v2" width="867" height="163" role="button" title="shabana_0-1766333515714.png" alt="shabana_0-1766333515714.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The same data you modeled as a property graph is now available through standard SPARQL queries.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Key benefits for customers:&lt;/STRONG&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;Standardized representation - &lt;/STRONG&gt;RDF makes data interoperable across tools, platforms, and organizational boundaries.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Richer semantics - &lt;/STRONG&gt;Customers can define precise meanings through URIs, classes, and vocabularies.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Easy integration with AI -&amp;nbsp;&lt;/STRONG&gt;Knowledge graphs are becoming foundational for RAG systems and reasoning. This conversion gives customers a clean way to prepare their graph data for LLM based applications.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;No need to duplicate data models - &lt;/STRONG&gt;Users start with property graphs and layer semantics later as needed.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Works with existing HANA Cloud graph workspaces - &lt;/STRONG&gt;Nothing special is required on the modeling side.&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;STRONG&gt;Looking ahead&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;This blog is intended as an introduction and starting point for the new Property Graph to Knowledge Graph conversion capability in SAP HANA Cloud. It represents the first step toward deeper interoperability between the property graph engine and the knowledge graph engine. The long-term vision is to reduce barriers between the two and allow users to move freely between graph patterns as their needs evolve. On our roadmap, we also plan to support conversion in the opposite direction, &lt;A href="https://roadmaps.sap.com/board?PRODUCT=73554900100800002881&amp;amp;BC=6EAE8B28C5D91EDA9A993F47E721E0E5&amp;amp;range=CURRENT-LAST#;INNO=000D3AAADBCE1FE09B972B3DBC5D6D4C" target="_blank" rel="noopener noreferrer"&gt;from knowledge graphs back to property graphs&lt;/A&gt;, helping to close the loop.&lt;/P&gt;&lt;P&gt;As graph workloads continue to grow inside SAP HANA Cloud, customers increasingly want both modeling flexibility and semantic power. With this new PG to KG conversion feature, we provide an easy entry point into the world of knowledge graphs without changing how data is modeled or stored today.&lt;/P&gt;&lt;P&gt;This blog focuses on introducing the core concepts and mechanics in simpler terms. In a follow-up blog, I look forward to diving deeper into a real-world use case example and exploring advanced mappings and scenarios that this capability is designed to handle.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/converting-property-graphs-to-knowledge-graphs-in-sap-hana-cloud-a-simple/ba-p/14294883"/>
    <published>2025-12-22T09:00:00.042000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/new-cross-encoder-and-text-embedding-support-dimensionality-reduction-in/ba-p/14293164</id>
    <title>New Cross Encoder and Text Embedding support Dimensionality Reduction in HANA NLP Service 2025 Q4</title>
    <updated>2025-12-22T09:17:23.118000+01:00</updated>
    <author>
      <name>Jay_Wu16</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2271304</uri>
    </author>
    <content>&lt;DIV class=""&gt;&lt;H1 id="toc-hId-1638303943"&gt;New Cross Encoder and Text Embedding support Dimensionality Reduction in HANA NLP Service 2025 Q4&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/H1&gt;&lt;/DIV&gt;&lt;P&gt;With the SAP HANA Cloud 2025 Q4 release, several new embedded Machine Learning / AI and NLP functions have been released with the SAP HANA Cloud Predictive Analysis Library (PAL). Key new capabilities to be highlighted are introduction of cross-encoder and dimensionality reduction supported in embedding models. An enhancement summary is available in the What‚Äôs new document for SAP HANA Cloud database &lt;A href="https://help.sap.com/whats-new/2495b34492334456a49084831c2bea4e?locale=en-US&amp;amp;state=DRAFT&amp;amp;clear=all&amp;amp;Valid_as_Of=2023-01-01:2026-06-18&amp;amp;Category=Predictive+Analysis+Library" target="_blank" rel="noopener noreferrer"&gt;2025.40 (QRC 4/2025)&lt;/A&gt;.&lt;/P&gt;&lt;DIV class=""&gt;&lt;H2 id="toc-hId-1570873157"&gt;Cross Encoder Model&lt;/H2&gt;&lt;/DIV&gt;&lt;P&gt;The NLP service has been enhanced with the addition of a new ‚Äãcross-encoder model. The existing embedding model in the service can be considered a ‚Äãbi-encoder model. These two model architectures differ in their design and application. In general, ‚Äãbi-encoder models are faster but less accurate than cross-encoder models, making them suitable for the retrieval phase. In contrast, cross-encoder models offer higher accuracy at the cost of slower speed, making them ideal for the re-ranking stage.&lt;/P&gt;&lt;P&gt;A cross encoder is a neural network model that processes two inputs, such as a query and a document, together to determine their relationship or similarity, outputting a relevance score. Unlike bi-encoders, which encode inputs separately into vectors, cross encoders analyze the interaction between the input pair simultaneously, allowing for precise semantic understanding and high-accuracy results, particularly in re-ranking tasks within information retrieval.&lt;/P&gt;&lt;DIV class=""&gt;&lt;H3 id="toc-hId-1503442371"&gt;Advantages&lt;/H3&gt;&lt;/DIV&gt;&lt;UL&gt;&lt;LI&gt;High Accuracy: Their ability to model interactions directly results in superior accuracy for semantic comparison tasks compared to bi-encoders.&lt;/LI&gt;&lt;LI&gt;Precision: They excel at tasks where precise relevance assessment is crucial, such as re-ranking.&lt;/LI&gt;&lt;/UL&gt;&lt;DIV class=""&gt;&lt;H3 id="toc-hId-1306928866"&gt;Disadvantages&lt;/H3&gt;&lt;/DIV&gt;&lt;UL&gt;&lt;LI&gt;Computational Cost: Due to the need to process the query and each document together, cross encoders are computationally expensive and slow for large-scale search applications.&lt;/LI&gt;&lt;LI&gt;Limited to Pairs: They can only process input pairs, meaning they cannot be used to generate individual embeddings for each document.&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="BiEncoder_vs_CrossEncoder.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354018i26662E33A6B9FD08/image-size/large?v=v2&amp;amp;px=999" role="button" title="BiEncoder_vs_CrossEncoder.png" alt="BiEncoder_vs_CrossEncoder.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;DIV class=""&gt;&lt;H2 id="toc-hId-981332642"&gt;Advanced RAG&lt;/H2&gt;&lt;/DIV&gt;&lt;P&gt;The cross-encoder model can be combined with an existing embedding model to form a retrieve and rerank pipeline, which can be referred to as an ‚ÄãAdvanced RAG‚Äã architecture. In this pipeline, the ‚Äãbi-encoder model is responsible for screening the candidate set, while the ‚Äãcross-encoder model performs re-ranking on this candidate set to deliver superior results‚Äã.&lt;/P&gt;&lt;P&gt;The detailed steps are as follows:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;‚ÄãPassages are pre-vectorized and stored: The passages(documents/chunks) are converted into vectors in advance using the embedding model and stored in vector database (HANA).&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;‚ÄãQuery vectorization and initial retrieval (normal RAG)‚Äã: When a query arrives, it is also converted into a vector using the same embedding model. A vector search (e.g., using cosine similarity) is then performed to find the top-K most similar passages as the candidate set. If these top-K results are directly used for subsequent text generation, this constitutes what is generally considered normal RAG.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;‚ÄãRe-ranking with Cross-Encoder (The Advanced RAG step)‚Äã: The candidate set serves as input to the cross-encoder model. The cross-encoder jointly processes the query with each candidate passage to compute a more precise relevance score. It then re-ranks the candidate set based on these scores. These re-ranked results are returned for text generation, completing all the steps of Advanced RAG.&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="advanced_RAG.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354019i91F6FE7A14F1C9CD/image-size/large?v=v2&amp;amp;px=999" role="button" title="advanced_RAG.png" alt="advanced_RAG.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;DIV class=""&gt;&lt;H2 id="toc-hId-784819137"&gt;benchmark&lt;/H2&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;H3 id="toc-hId-717388351"&gt;vs bi-encoder benchmark&lt;/H3&gt;&lt;/DIV&gt;&lt;P&gt;A benchmark evaluation of the re-ranking capability using a cross-encoder is conducted. The test was performed on English retrieval tasks from the MTEB benchmark. An embedding model was first used to retrieve an initial candidate set of size 40, which was then re-ranked by the cross-encoder. The results are shown in the figure below.&lt;/P&gt;&lt;P&gt;It can be observed that for all datasets under the retrieval task, the cross-encoder demonstrated a significant improvement over the embedding model. Using the metric NDCG@10, the most substantial improvement was observed on one dataset, where the score increased from 0.57 to 0.8. The average value across all datasets improved from 0.47 to 0.55.&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="benchmark_on_MTEB.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354020i4A4E47D466951100/image-size/large?v=v2&amp;amp;px=999" role="button" title="benchmark_on_MTEB.png" alt="benchmark_on_MTEB.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;DIV class=""&gt;&lt;H3 id="toc-hId-520874846"&gt;vs opensource models&lt;/H3&gt;&lt;/DIV&gt;&lt;P&gt;We conducted a comprehensive benchmark evaluation by selecting six popular open-source cross-encoder models from HuggingFace, including models such as MS-MARCO and BGE-Reranker, along with several larger-scale variants. The evaluation methodology involved using the same bi-encoder model to generate candidate sets for all cross-encoders, and comparing their re-ranking performance across varying candidate pool sizes.&lt;/P&gt;&lt;P&gt;The results indicate that, across different candidate set sizes, the model in question achieves the highest performance among all evaluated models. Furthermore, we extended the comparison to include several bi-encoders built on large language models (LLMs) with over 7 billion parameters. Notably, the proposed pipeline demonstrates competitive performance compared to these LLM-based bi-encoders, despite utilizing a base-sized model with less than 3% of the parameter count.&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="vs_opensource_models.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354021iA03CB6CA98D8F988/image-size/large?v=v2&amp;amp;px=999" role="button" title="vs_opensource_models.png" alt="vs_opensource_models.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;DIV class=""&gt;&lt;H2 id="toc-hId-195278622"&gt;Use with Python&lt;/H2&gt;&lt;/DIV&gt;&lt;P&gt;Cross encoder API is available in our python package &lt;A href="https://sap.github.io/generative-ai-toolkit-for-sap-hana-cloud/" target="_blank" rel="nofollow noopener noreferrer"&gt;hana_ai&lt;/A&gt;. Here is an example of advanced RAG, the query is:&lt;/P&gt;&lt;P&gt;&lt;EM&gt;"when did athens emerges as wealthiest greek city state"&lt;/EM&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Use the following code to load the &lt;EM&gt;PALCrossEncoder&lt;/EM&gt; model class.&lt;/LI&gt;&lt;/OL&gt;&lt;DIV class=""&gt;&lt;PRE&gt;&lt;SPAN class=""&gt;from&lt;/SPAN&gt; &lt;SPAN class=""&gt;hana_ai&lt;/SPAN&gt;.&lt;SPAN class=""&gt;vectorstore&lt;/SPAN&gt;.&lt;SPAN class=""&gt;pal_cross_encoder&lt;/SPAN&gt; &lt;SPAN class=""&gt;import&lt;/SPAN&gt; &lt;SPAN class=""&gt;PALCrossEncoder&lt;/SPAN&gt;&lt;/PRE&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/DIV&gt;&lt;OL&gt;&lt;LI&gt;Establish a connection with the HANA database.&lt;/LI&gt;&lt;/OL&gt;&lt;DIV class=""&gt;&lt;PRE&gt;&lt;SPAN class=""&gt;from&lt;/SPAN&gt; &lt;SPAN class=""&gt;hana_ml&lt;/SPAN&gt; &lt;SPAN class=""&gt;import&lt;/SPAN&gt; &lt;SPAN class=""&gt;dataframe&lt;/SPAN&gt;
&lt;SPAN class=""&gt;conn&lt;/SPAN&gt; &lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;dataframe&lt;/SPAN&gt;.&lt;SPAN class=""&gt;ConnectionContext&lt;/SPAN&gt;(&lt;SPAN class=""&gt;address&lt;/SPAN&gt;&lt;SPAN class=""&gt;=&lt;/SPAN&gt;&lt;SPAN class=""&gt;host&lt;/SPAN&gt;,
                                   &lt;SPAN class=""&gt;port&lt;/SPAN&gt;&lt;SPAN class=""&gt;=&lt;/SPAN&gt;&lt;SPAN class=""&gt;port&lt;/SPAN&gt;,
                                   &lt;SPAN class=""&gt;user&lt;/SPAN&gt;&lt;SPAN class=""&gt;=&lt;/SPAN&gt;&lt;SPAN class=""&gt;user&lt;/SPAN&gt;,
                                   &lt;SPAN class=""&gt;password&lt;/SPAN&gt;&lt;SPAN class=""&gt;=&lt;/SPAN&gt;&lt;SPAN class=""&gt;password&lt;/SPAN&gt;)&lt;/PRE&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/DIV&gt;&lt;OL&gt;&lt;LI&gt;Load the corpus vector table.&lt;/LI&gt;&lt;/OL&gt;&lt;DIV class=""&gt;&lt;PRE&gt;&lt;SPAN class=""&gt;corpus_vecs_df&lt;/SPAN&gt; &lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;conn&lt;/SPAN&gt;.&lt;SPAN class=""&gt;table&lt;/SPAN&gt;(&lt;SPAN class=""&gt;'NQ_CORPUS_EMBEDDING'&lt;/SPAN&gt;)
&lt;SPAN class=""&gt;corpus_vecs_df&lt;/SPAN&gt;.&lt;SPAN class=""&gt;head&lt;/SPAN&gt;(&lt;SPAN class=""&gt;3&lt;/SPAN&gt;).&lt;SPAN class=""&gt;collect&lt;/SPAN&gt;()&lt;/PRE&gt;&lt;DIV class=""&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="python_demo_1.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354026iF7A56BE5AB7DB274/image-size/large?v=v2&amp;amp;px=999" role="button" title="python_demo_1.png" alt="python_demo_1.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;OL&gt;&lt;LI&gt;Retrieve the top-K candidate set for the query. At this stage, the target document is ranked 14th, which is relatively low. Therefore, using these results for text generation often yields limited outcomes or consumes a significant number of tokens.&lt;/LI&gt;&lt;/OL&gt;&lt;DIV class=""&gt;&lt;PRE&gt;&lt;SPAN class=""&gt;retrieve_results&lt;/SPAN&gt; &lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;corpus_vecs_df&lt;/SPAN&gt;.&lt;SPAN class=""&gt;sort_by_similarity&lt;/SPAN&gt;(&lt;SPAN class=""&gt;'embedding'&lt;/SPAN&gt;, &lt;SPAN class=""&gt;query&lt;/SPAN&gt; &lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;nq_query&lt;/SPAN&gt;[&lt;SPAN class=""&gt;query_id_index&lt;/SPAN&gt;][&lt;SPAN class=""&gt;'text'&lt;/SPAN&gt;], &lt;SPAN class=""&gt;model_version&lt;/SPAN&gt;&lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;"SAP_GXY.20250407"&lt;/SPAN&gt;).&lt;SPAN class=""&gt;head&lt;/SPAN&gt;(&lt;SPAN class=""&gt;k&lt;/SPAN&gt;).&lt;SPAN class=""&gt;collect&lt;/SPAN&gt;()&lt;/PRE&gt;&lt;DIV class=""&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="python_demo_2.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354027i4460B7FBD606C337/image-size/large?v=v2&amp;amp;px=999" role="button" title="python_demo_2.png" alt="python_demo_2.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="python_demo_3.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354028i9D4F3240A9D036DF/image-size/large?v=v2&amp;amp;px=999" role="button" title="python_demo_3.png" alt="python_demo_3.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;P&gt;5. Use the cross encoder model to re-rank the candidate set. After re-ranking, the target text moves to the first position, significantly improving the retrieval outcome.&lt;/P&gt;&lt;DIV class=""&gt;&lt;PRE&gt;&lt;SPAN class=""&gt;cross_encoder&lt;/SPAN&gt; &lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;PALCrossEncoder&lt;/SPAN&gt;(&lt;SPAN class=""&gt;conn&lt;/SPAN&gt;)
&lt;SPAN class=""&gt;pairs&lt;/SPAN&gt; &lt;SPAN class=""&gt;=&lt;/SPAN&gt; [[&lt;SPAN class=""&gt;query&lt;/SPAN&gt;, &lt;SPAN class=""&gt;passage&lt;/SPAN&gt;] &lt;SPAN class=""&gt;for&lt;/SPAN&gt; &lt;SPAN class=""&gt;passage&lt;/SPAN&gt; &lt;SPAN class=""&gt;in&lt;/SPAN&gt; &lt;SPAN class=""&gt;retrieve_results&lt;/SPAN&gt;[&lt;SPAN class=""&gt;'text'&lt;/SPAN&gt;]]
&lt;SPAN class=""&gt;cross_encoder_results&lt;/SPAN&gt; &lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;cross_encoder&lt;/SPAN&gt;.&lt;SPAN class=""&gt;predict&lt;/SPAN&gt;(&lt;SPAN class=""&gt;pairs&lt;/SPAN&gt;)&lt;/PRE&gt;&lt;DIV class=""&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="python_demo_4.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354029i1CD1B5FE90262B69/image-size/large?v=v2&amp;amp;px=999" role="button" title="python_demo_4.png" alt="python_demo_4.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;H2 id="toc-hId--1234883"&gt;use with SQL&lt;/H2&gt;&lt;/DIV&gt;&lt;P&gt;Here shows how to use the cross encoder model in SQL with our SQL function &lt;EM&gt;PAL_CROSSENCODER&lt;/EM&gt;.&lt;/P&gt;&lt;DIV class=""&gt;&lt;PRE&gt;&lt;SPAN class=""&gt;SET&lt;/SPAN&gt; SCHEMA DM_PAL;

&lt;SPAN class=""&gt;DROP&lt;/SPAN&gt; &lt;SPAN class=""&gt;TABLE&lt;/SPAN&gt; CROSS_ENCODER_TEXT_TBL;
CREATE COLUMN TABLE CROSS_ENCODER_TEXT_TBL (
    &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;ID&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; &lt;SPAN class=""&gt;INTEGER&lt;/SPAN&gt;,
    &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;TEXT1&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; NCLOB,
    &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;TEXT2&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; NCLOB
);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; &lt;SPAN class=""&gt;DM_PAL&lt;/SPAN&gt;.&lt;SPAN class=""&gt;CROSS_ENCODER_TEXT_TBL&lt;/SPAN&gt; &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;0&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; &lt;SPAN class=""&gt;DM_PAL&lt;/SPAN&gt;.&lt;SPAN class=""&gt;CROSS_ENCODER_TEXT_TBL&lt;/SPAN&gt; &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;1&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics. Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; &lt;SPAN class=""&gt;DM_PAL&lt;/SPAN&gt;.&lt;SPAN class=""&gt;CROSS_ENCODER_TEXT_TBL&lt;/SPAN&gt; &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;2&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Interstellar relies heavily on practical and miniature models, while digital effects were enhanced by the visual effects studio Double Negative.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);


&lt;SPAN class=""&gt;DROP&lt;/SPAN&gt; &lt;SPAN class=""&gt;TABLE&lt;/SPAN&gt; PAL_CROSS_ENCODER_PARAMETER_TBL;
CREATE COLUMN TABLE PAL_CROSS_ENCODER_PARAMETER_TBL(
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;PARAM_NAME&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; NVARCHAR(&lt;SPAN class=""&gt;256&lt;/SPAN&gt;), 
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;INT_VALUE&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; &lt;SPAN class=""&gt;INTEGER&lt;/SPAN&gt;, 
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;DOUBLE_VALUE&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; DOUBLE,
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;STRING_VALUE&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; NVARCHAR(&lt;SPAN class=""&gt;1000&lt;/SPAN&gt;)
);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; PAL_CROSS_ENCODER_PARAMETER_TBL &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt;(&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;MODEL_VERSION&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;, &lt;SPAN class=""&gt;NULL&lt;/SPAN&gt;, &lt;SPAN class=""&gt;NULL&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;SAP_CER.20250701&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);

CALL &lt;SPAN class=""&gt;_SYS_AFL&lt;/SPAN&gt;.&lt;SPAN class=""&gt;PAL_CROSSENCODER&lt;/SPAN&gt;(CROSS_ENCODER_TEXT_TBL, PAL_CROSS_ENCODER_PARAMETER_TBL, ?, ?);&lt;/PRE&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;H2 id="toc-hId-149505969"&gt;Text Embedding Service supports Dimensionality Reduction&lt;/H2&gt;&lt;/DIV&gt;&lt;P&gt;Now text embedding service supports dimensionality reduction. When using the embedding service, you only need to specify the specific dimension to obtain the low-dimensional version of the vector. Detailed introduction to embedding models that support dimensionality reduction can be found &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-embedding-model?version=2025_4_QRC&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;here&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;The model enhances a standard embedding model by incorporating a trained linear layer optimized via Principal Component Analysis (PCA). This layer performs vector dimensionality reduction and is trained on a large-scale dataset comprising over 700 million samples.&lt;/P&gt;&lt;P&gt;Key features of the model include: ‚ÄãLightweight and flexible dimensionality reduction‚Äã that can be deployed as an integrated component following an embedding model or used independently to process pre-computed vectors (e.g., within SAP HANA). Support for ‚Äãdynamic output dimension selection, though we strongly recommend a reduction to ‚Äã256 dimensions‚Äã for optimal balance between size and accuracy. Experimental results demonstrate that reducing embeddings to 256 dimensions retains retrieval accuracy comparable to the full-dimensional vectors, while reducing storage footprint to approximately one-third and improving vector search speed. However, further reduction below 128 dimensions leads to significant degradation in accuracy. It is recommended to use 256 dimensions.&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="embedding_pca_1.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354030i06D47D47BE84B6B4/image-size/large?v=v2&amp;amp;px=999" role="button" title="embedding_pca_1.png" alt="embedding_pca_1.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Embedding models supporting ‚Äãdimensionality reduction‚Äã can be effectively combined with the latest ‚Äãcross‚Äëencoder models‚Äã to form a complementary ‚Äãretrieve‚Äëand‚Äërerank pipeline. Test results show that this combined approach delivers ‚Äãnearly identical accuracy‚Äã compared to using full‚Äëdimensional embedding models together with cross‚Äëencoder rerankers. At the same time, the resulting ‚Äãvector database is only one‚Äëthird the original size, and the ‚Äãcomputational load of retrieval is also reduced to one‚Äëthird. This strategy achieves an ‚Äãoptimal balance among speed, efficiency, and accuracy.&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="embedding_pca_2.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354031i476A431A771CAA8E/image-size/large?v=v2&amp;amp;px=999" role="button" title="embedding_pca_2.png" alt="embedding_pca_2.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;DIV class=""&gt;&lt;H3 id="toc-hId--340410543"&gt;Usage&lt;/H3&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;H4 id="toc-hId--830327055"&gt;Python&lt;/H4&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;PRE&gt;&lt;SPAN class=""&gt;from&lt;/SPAN&gt; &lt;SPAN class=""&gt;hana_ml&lt;/SPAN&gt;.&lt;SPAN class=""&gt;text&lt;/SPAN&gt;.&lt;SPAN class=""&gt;pal_embeddings&lt;/SPAN&gt; &lt;SPAN class=""&gt;import&lt;/SPAN&gt; &lt;SPAN class=""&gt;PALEmbeddings&lt;/SPAN&gt;
&lt;SPAN class=""&gt;embedder&lt;/SPAN&gt; &lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;PALEmbeddings&lt;/SPAN&gt;(
    &lt;SPAN class=""&gt;model_version&lt;/SPAN&gt;&lt;SPAN class=""&gt;=&lt;/SPAN&gt;&lt;SPAN class=""&gt;'SAP_GXY.20250407'&lt;/SPAN&gt;, &lt;SPAN class=""&gt;# SAP_NEB.20240715 is also supported&lt;/SPAN&gt;
    &lt;SPAN class=""&gt;pca_dim_num&lt;/SPAN&gt;&lt;SPAN class=""&gt;=&lt;/SPAN&gt;&lt;SPAN class=""&gt;256&lt;/SPAN&gt; &lt;SPAN class=""&gt;#support dim: 64, 128, 256, 384, 512, 768&lt;/SPAN&gt;
    )
&lt;SPAN class=""&gt;result&lt;/SPAN&gt; &lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;embedder&lt;/SPAN&gt;.&lt;SPAN class=""&gt;fit_transform&lt;/SPAN&gt;(
    &lt;SPAN class=""&gt;data&lt;/SPAN&gt;&lt;SPAN class=""&gt;=&lt;/SPAN&gt;&lt;SPAN class=""&gt;text&lt;/SPAN&gt;, &lt;SPAN class=""&gt;# text is a hana_ml.dataframe.DataFrame object&lt;/SPAN&gt;
    &lt;SPAN class=""&gt;key&lt;/SPAN&gt;&lt;SPAN class=""&gt;=&lt;/SPAN&gt;&lt;SPAN class=""&gt;'id'&lt;/SPAN&gt;, &lt;SPAN class=""&gt;# the key in thee dataframe&lt;/SPAN&gt;
    &lt;SPAN class=""&gt;target&lt;/SPAN&gt;&lt;SPAN class=""&gt;=&lt;/SPAN&gt;&lt;SPAN class=""&gt;'text'&lt;/SPAN&gt; &lt;SPAN class=""&gt;# the column needed to be embedded, also supported multi-columns, for example: ['text1','text2']&lt;/SPAN&gt;
    )&lt;/PRE&gt;&lt;DIV class=""&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;H4 id="toc-hId--1026840560"&gt;SQL&lt;/H4&gt;&lt;/DIV&gt;&lt;DIV class=""&gt;&lt;PRE&gt;&lt;SPAN class=""&gt;DROP&lt;/SPAN&gt; &lt;SPAN class=""&gt;TABLE&lt;/SPAN&gt; SAMPLE_TEXT_TAB;
CREATE COLUMN TABLE SAMPLE_TEXT_TAB(
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;ID&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; &lt;SPAN class=""&gt;INTEGER&lt;/SPAN&gt;, 
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;TEXT&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; NCLOB
);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;0&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;1&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;2&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;3&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;4&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;5&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;6&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;7&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;8&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Interstellar premiered on October 26, 2014, in Los Angeles.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;9&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;In the United States, it was first released on film stock, expanding to venues using digital projectors.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;10&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;11&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;12&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics. Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time.&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; SAMPLE_TEXT_TAB &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;13&lt;/SPAN&gt;, &lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;);
 
&lt;SPAN class=""&gt;DROP&lt;/SPAN&gt; &lt;SPAN class=""&gt;TABLE&lt;/SPAN&gt; PAL_TEXT_EMB_PARAMETER_TBL;
CREATE COLUMN TABLE PAL_TEXT_EMB_PARAMETER_TBL(
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;PARAM_NAME&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; NVARCHAR(&lt;SPAN class=""&gt;256&lt;/SPAN&gt;), 
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;INT_VALUE&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; &lt;SPAN class=""&gt;INTEGER&lt;/SPAN&gt;, 
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;DOUBLE_VALUE&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; DOUBLE,
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;STRING_VALUE&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; NVARCHAR(&lt;SPAN class=""&gt;1000&lt;/SPAN&gt;)
);
&lt;SPAN class=""&gt;--specify the specific dimension, recommended to set 256&lt;/SPAN&gt;
&lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; PAL_TEXT_EMB_PARAMETER_TBL &lt;SPAN class=""&gt;VALUES&lt;/SPAN&gt; (&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;'&lt;/SPAN&gt;PCA_DIM_NUM&lt;SPAN class=""&gt;'&lt;/SPAN&gt;&lt;/SPAN&gt;, &lt;SPAN class=""&gt;256&lt;/SPAN&gt;, &lt;SPAN class=""&gt;NULL&lt;/SPAN&gt;, &lt;SPAN class=""&gt;NULL&lt;/SPAN&gt;);
 
&lt;SPAN class=""&gt;DROP&lt;/SPAN&gt; &lt;SPAN class=""&gt;TABLE&lt;/SPAN&gt; PAL_TEXT_EMB_VEC_RESULT_TBL;
CREATE COLUMN TABLE PAL_TEXT_EMB_VEC_RESULT_TBL(
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;ID&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; nvarchar(&lt;SPAN class=""&gt;5000&lt;/SPAN&gt;),
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;VECTOR&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; REAL_VECTOR,
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;EXT&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; nvarchar(&lt;SPAN class=""&gt;5000&lt;/SPAN&gt;)
);
 
&lt;SPAN class=""&gt;DROP&lt;/SPAN&gt; &lt;SPAN class=""&gt;TABLE&lt;/SPAN&gt; PAL_TEXT_EMB_VEC_STAT_TBL;
CREATE COLUMN TABLE PAL_TEXT_EMB_VEC_STAT_TBL(
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;KEY&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; nvarchar(&lt;SPAN class=""&gt;5000&lt;/SPAN&gt;),
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;VALUE&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; nvarchar(&lt;SPAN class=""&gt;5000&lt;/SPAN&gt;),
	&lt;SPAN class=""&gt;&lt;SPAN class=""&gt;"&lt;/SPAN&gt;EXT&lt;SPAN class=""&gt;"&lt;/SPAN&gt;&lt;/SPAN&gt; nvarchar(&lt;SPAN class=""&gt;5000&lt;/SPAN&gt;)
);
 
DO &lt;SPAN class=""&gt;BEGIN&lt;/SPAN&gt;
  tv_data &lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;select&lt;/SPAN&gt; &lt;SPAN class=""&gt;*&lt;/SPAN&gt; &lt;SPAN class=""&gt;FROM&lt;/SPAN&gt; SAMPLE_TEXT_TAB;
  tv_param &lt;SPAN class=""&gt;=&lt;/SPAN&gt; &lt;SPAN class=""&gt;SELECT&lt;/SPAN&gt; &lt;SPAN class=""&gt;*&lt;/SPAN&gt; &lt;SPAN class=""&gt;FROM&lt;/SPAN&gt; PAL_TEXT_EMB_PARAMETER_TBL;
  CALL &lt;SPAN class=""&gt;_SYS_AFL&lt;/SPAN&gt;.&lt;SPAN class=""&gt;PAL_TEXTEMBEDDING&lt;/SPAN&gt;(:tv_data, :tv_param, tv_out, tv_out2);
  &lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; PAL_TEXT_EMB_VEC_RESULT_TBL &lt;SPAN class=""&gt;SELECT&lt;/SPAN&gt; &lt;SPAN class=""&gt;*&lt;/SPAN&gt; &lt;SPAN class=""&gt;FROM&lt;/SPAN&gt; :tv_out;
  &lt;SPAN class=""&gt;INSERT INTO&lt;/SPAN&gt; PAL_TEXT_EMB_VEC_STAT_TBL &lt;SPAN class=""&gt;select&lt;/SPAN&gt; &lt;SPAN class=""&gt;*&lt;/SPAN&gt; &lt;SPAN class=""&gt;from&lt;/SPAN&gt; :tv_out2;
END;
&lt;SPAN class=""&gt;--select * from PAL_TEXT_EMB_VEC_RESULT_TBL;&lt;/SPAN&gt;
&lt;SPAN class=""&gt;select&lt;/SPAN&gt; ID,TO_NVARCHAR(VECTOR) &lt;SPAN class=""&gt;from&lt;/SPAN&gt; PAL_TEXT_EMB_VEC_RESULT_TBL;
&lt;SPAN class=""&gt;select&lt;/SPAN&gt; ID,cardinality(VECTOR) &lt;SPAN class=""&gt;from&lt;/SPAN&gt; PAL_TEXT_EMB_VEC_RESULT_TBL;
&lt;SPAN class=""&gt;select&lt;/SPAN&gt; &lt;SPAN class=""&gt;*&lt;/SPAN&gt; &lt;SPAN class=""&gt;from&lt;/SPAN&gt; PAL_TEXT_EMB_VEC_STAT_TBL;&lt;/PRE&gt;&lt;DIV class=""&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="embedding_pca_256_1.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354032iD4566627C54C8FDD/image-size/large?v=v2&amp;amp;px=999" role="button" title="embedding_pca_256_1.png" alt="embedding_pca_256_1.png" /&gt;&lt;/span&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;P&gt;The dimensitionality of the vectors is 256.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="embedding_pca_256_2.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354034i5FEEB99D4463624C/image-size/large?v=v2&amp;amp;px=999" role="button" title="embedding_pca_256_2.png" alt="embedding_pca_256_2.png" /&gt;&lt;/span&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="embedding_pca_256_3.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354033i42BC3E9194576642/image-size/large?v=v2&amp;amp;px=999" role="button" title="embedding_pca_256_3.png" alt="embedding_pca_256_3.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;DIV class=""&gt;&lt;H2 id="toc-hId--636548051"&gt;related links&lt;/H2&gt;&lt;/DIV&gt;&lt;OL&gt;&lt;LI&gt;&lt;A href="https://pypi.org/project/hana-ai/" target="_blank" rel="nofollow noopener noreferrer"&gt;hana.ai python package&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://pypi.org/project/hana-ml/" target="_blank" rel="nofollow noopener noreferrer"&gt;hana-ml python package&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/whats-new/2495b34492334456a49084831c2b6965?state=DRAFT&amp;amp;locale=en-US&amp;amp;clear=all&amp;amp;Category=Predictive+Analysis+Library" target="_blank" rel="noopener noreferrer"&gt;what's new in SAP HANA Cloud PAL 2025.40 (QRC 4/2025)&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/cross-encoder?version=2025_4_QRC&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;cross encoder help doc&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/text-embedding?version=2025_4_QRC&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;text embedding help doc&lt;/A&gt;&lt;/LI&gt;&lt;/OL&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-cross-encoder-and-text-embedding-support-dimensionality-reduction-in/ba-p/14293164"/>
    <published>2025-12-22T09:17:23.118000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/accelerating-your-analytics-with-delta-table-replication-into-sap-hana/ba-p/14290281</id>
    <title>Accelerating Your Analytics with Delta Table Replication into SAP HANA Cloud</title>
    <updated>2025-12-22T16:11:26.667000+01:00</updated>
    <author>
      <name>SeungjoonLee</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/204092</uri>
    </author>
    <content>&lt;TABLE border="1" width="100%"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD&gt;&lt;STRONG&gt;Related Blogs:&lt;BR /&gt;&lt;/STRONG&gt;&lt;UL&gt;&lt;LI&gt;&lt;A href="https://community.sap.com/t5/technology-blogs-by-sap/unlocking-the-true-potential-of-data-in-files-with-sap-hana-database-sql-on/ba-p/13861585" target="_self"&gt;Unlocking the True Potential of Data in Files with SAP HANA Database SQL on Files in SAP HANA Cloud&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/exploring-new-sql-on-files-use-cases-with-sap-hana-cloud-qrc-04-2024-and/ba-p/14076223" target="_self"&gt;Exploring New SQL on Files Use Cases with SAP HANA Cloud QRC 04/2024 and QRC 01/2025&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;The way we innovate with data is constantly evolving. Since SAP HANA Cloud QRC 04/2024, SAP HANA Cloud has supported read-only access to external Delta Sharing with a dedicated &lt;EM&gt;deltasharing&lt;/EM&gt; adapter, as I introduced in my previous &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/exploring-new-sql-on-files-use-cases-with-sap-hana-cloud-qrc-04-2024-and/ba-p/14076223" target="_self"&gt;blog&lt;/A&gt;. This capability has been instrumental in enabling real-time analytics without physically moving data, unlocking efficiency and delivering faster insights. But what if your business cases demand not just seamless access but also replication of critical datasets into SAP HANA Cloud for deeper analysis, faster queries, or advanced integration?&lt;/P&gt;&lt;P&gt;That‚Äôs where Delta table-to-HANA replication comes in. Starting with SAP HANA Cloud QRC 04/2025, I‚Äôm glad to introduce this new capability, which provides more flexibility to replicate your Delta table directly into the SAP HANA database in SAP HANA Cloud, empowering your analytics with greater speed, reliability, and robust data management.&lt;/P&gt;&lt;P&gt;In a nutshell, the new Delta table-to-HANA replication has the following capabilities and characteristics:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Remote subscription-based initial load and Change Data Capture (CDC) for both &lt;EM&gt;file&lt;/EM&gt; adapter and &lt;EM&gt;deltasharing&lt;/EM&gt; adapter.&lt;/LI&gt;&lt;LI&gt;Support for either chunk-based, user-driven initial load or streamlined, one-step initial load.&lt;/LI&gt;&lt;LI&gt;Support for either user-driven CDC or system-scheduled CDC using the replication job scheduler.&lt;/LI&gt;&lt;LI&gt;Offer both column-wise and row-wise sub-table replication while enabling source-side schema changes (adding columns only).&lt;/LI&gt;&lt;LI&gt;In addition to normal load behavior, UPSERT load behavior with three additional metadata columns: type, last-processed time, and Delta table version.&lt;/LI&gt;&lt;LI&gt;Simplified replication with virtual table toggling and Data Replication UI for the &lt;EM&gt;deltasharing&lt;/EM&gt; adapter in addition to the remote subscription-based replication.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Overview.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351959iDFF5837625A9F808/image-size/large?v=v2&amp;amp;px=999" role="button" title="Overview.png" alt="Overview.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;As depicted in the diagram above, the following four combinations can be considered based on the business use case:&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Chunk-based Initial Load ‚Üí User-driven CDC&lt;/LI&gt;&lt;LI&gt;Chunk-based Initial Load ‚Üí Scheduled CDC&lt;/LI&gt;&lt;LI&gt;One-step Initial Load ‚Üí User-driven CDC&lt;/LI&gt;&lt;LI&gt;One-step initial Load ‚Üí Scheduled CDC&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;While the one-step initial load is more straightforward and intuitive, chunk-based initial load is useful when the data volume during the initial load is large. With chunk-based initial load, users can have more granular control over the process by splitting the data into multiple chunks and loading them separately. This approach makes the initial load more manageable and easier to handle, especially when dealing with a vast volume of data.&lt;/P&gt;&lt;P&gt;Once the initial load is complete, Change Data Capture (CDC) is required to reflect any data changes on the source side. User-driven CDC allows users to replicate data based on a specific version. This can be particularly useful when the exact Delta table version for replication is known, and there is no need to automatically replicate all the latest changes. Alternatively, scheduled CDC can be used if the use case involves automatic replication at specific time intervals. In this scenario, the default time interval is 3,600 seconds (1 hour), but custom values can be configured as needed.&lt;/P&gt;&lt;P&gt;Now, let‚Äôs dive deeper into the details with some examples. For this, I will use the combination of chunk-based initial load and scheduled CDC with Delta Sharing as the remote source, which is expected to be the most common scenario. However, as explained, other combinations or setups with direct object storage access can also be easily configured by following the linked documentation.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H3 id="toc-hId-1896381028"&gt;Chunk-based Initial Load&lt;/H3&gt;&lt;P&gt;As the focus of this blog is Delta table-to-HANA replication, let‚Äôs assume that the remote source to Delta Sharing has already been created and data is accessible via a virtual table. If you‚Äôre not familiar with this, please refer to my previous blogs.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="V_ORDERS.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351960iB62FD076F4331B12/image-size/large?v=v2&amp;amp;px=999" role="button" title="V_ORDERS.png" alt="V_ORDERS.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="V_ORDERS Records.png" style="width: 410px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351961i5126C9098FA11E22/image-size/large?v=v2&amp;amp;px=999" role="button" title="V_ORDERS Records.png" alt="V_ORDERS Records.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;In this example, a virtual table, V_ORDERS, is created by pointing to the remote shared table within Delta Sharing, and it contains 1,500,000 records.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;The first step is to create an empty table as the replication target, using the virtual table schema for its definition.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;-- create a target table using the virtual table schema for the definition
CREATE TABLE DEMO.R_ORDERS LIKE DEMO.V_ORDERS;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;With this, a remote subscription can now be created as shown below.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;-- create a remote subscription
CREATE REMOTE SUBSCRIPTION DEMO.DELTA_SUBSCRIPTION ON DEMO.V_ORDERS TARGET TABLE DEMO.R_ORDERS;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Here, if needed, as briefly mentioned, column-wise or row-wise sub-table replication can be configured by using a subquery with the &lt;CODE&gt;CREATE REMOTE SUBSCRIPTION ... ON ... AS &amp;lt;subquery&amp;gt; TARGET TABLE ...;&lt;/CODE&gt;. Additionally, enabling source-side schema changes (adding columns only) or&amp;nbsp;defining load behaviors can also be done together.&lt;/P&gt;&lt;P&gt;Once a remote subscription is created, we now have two options: the chunk-based initial load and the one-step initial load. In this example, I will use the chunk-based initial load.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;-- prepare the initial load by defining the chunk size
ALTER REMOTE SUBSCRIPTION DEMO.DELTA_SUBSCRIPTION INITIAL LOAD PREPARE CHUNK SIZE 10;

-- retrieve the chunk information
SELECT * FROM M_REMOTE_SUBSCRIPTION_INITIAL_LOADS;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;In this example, I set the chunk size to 10, which is 10 MiB. However, it is also possible not to define the chunk size here, as in the statement &lt;CODE&gt;ALTER REMOTE SUBSCRIPTION DEMO.DELTA_SUBSCRIPTION INITIAL LOAD PREPARE;&lt;/CODE&gt;. If the chunk size is not specified, the default size of 100 MiB will be used.&lt;/P&gt;&lt;P&gt;If I check the chunk information in the M_REMOTE_SUBSCRIPTION_INITIAL_LOADS monitoring view, the result is as follows.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Chunk Information.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351964iB6FE45F0168C5F1A/image-size/large?v=v2&amp;amp;px=999" role="button" title="Chunk Information.png" alt="Chunk Information.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;As you can see, three chunks with CHUNK_IDs 1, 2, and 3 are defined, and each chunk contains approximately 430,000 to 537,000 records, respectively. The EXECUTION_STATUS column indicates whether a chunk has been loaded or not. Since I haven‚Äôt loaded any of them yet, all of them show as PREPARED.&lt;/P&gt;&lt;P&gt;Now, let me load chunks 1 and 2 first.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;-- load chunks 1 and 2
ALTER REMOTE SUBSCRIPTION DEMO.DELTA_SUBSCRIPTION INITIAL LOAD EXECUTE CHUNK 1, 2;

-- retrieve the chunk information
SELECT * FROM M_REMOTE_SUBSCRIPTION_INITIAL_LOADS;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;Since only chunks 1 and 2 are loaded, the EXECUTION_STATUS in the monitoring view now shows LOADED for those two chunks, as shown below.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Chunk 1 and 2.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351965iF88EE837C1664D40/image-size/large?v=v2&amp;amp;px=999" role="button" title="Chunk 1 and 2.png" alt="Chunk 1 and 2.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;In this way, each chunk can be loaded as desired, and its status can be monitored. With that, let me load the last chunk and finalize the initial load.&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;-- load the chunk 3
ALTER REMOTE SUBSCRIPTION DEMO.DELTA_SUBSCRIPTION INITIAL LOAD EXECUTE CHUNK 3;

-- finalize the initial load
ALTER REMOTE SUBSCRIPTION DEMO.DELTA_SUBSCRIPTION INITIAL LOAD FINALIZE;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;SPAN&gt;All chunks must be marked as LOADED in EXECUTION_STATUS to finalize the initial load. FINALIZE will also delete all corresponding rows in the M_REMOTE_SUBSCRIPTION_INITIAL_LOADS monitoring view. Now, I can see that all data has been loaded into the R_ORDERS table.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="R_ORDERS.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351966i569AE2EB3813D86F/image-size/large?v=v2&amp;amp;px=999" role="button" title="R_ORDERS.png" alt="R_ORDERS.png" /&gt;&lt;/span&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Please refer to the links below for further details on the initial load.&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;SAP HANA Cloud, SAP HANA Database SQL on Files Guide: &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sql-on-files-guide/setting-up-data-replication" target="_self" rel="noopener noreferrer"&gt;Configuring Delta Table Replication&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;SAP HANA Cloud, SAP HANA Database SQL on Files Guide: &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sql-on-files-guide/performing-initial-load" target="_self" rel="noopener noreferrer"&gt;Performing an Initial Load&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1699867523"&gt;&lt;SPAN&gt;Scheduled CDC&lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;Once the initial load is finalized, CDC can be achieved in two ways: user-driven CDC or scheduled CDC. In this example, I will use the scheduled CDC.&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;-- scheduled CDC with a 30-minute interval (1,800 seconds)
ALTER REMOTE SUBSCRIPTION DEMO.DELTA_SUBSCRIPTION DISTRIBUTE INTERVAL 1800;

-- retrieve the replication jobs
SELECT * FROM M_REMOTE_REPLICATION_JOBS;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;SPAN&gt;If the interval is not specified, the default time interval of 3,600 seconds (1 hour) will be used. In this example, completed and planned replication jobs can be retrieved via the M_REMOTE_REPLICATION_JOBS monitoring view.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Replication Jobs.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/351969iBA4F4D01C53FA09C/image-size/large?v=v2&amp;amp;px=999" role="button" title="Replication Jobs.png" alt="Replication Jobs.png" /&gt;&lt;/span&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;As shown above, the first CDC job was planned for 05:35:19 and completed successfully. The next job is planned for 06:05:19, which is 30 minutes later, as expected. One important note is that, to execute the DISTRIBUTE, the &lt;EM&gt;enableChangeDataFeed&lt;/EM&gt; property must be set on the source Delta table.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Please refer to the links below for further details on the CDC.&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;SAP HANA Cloud, SAP HANA Database SQL on Files Guide: &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sql-on-files-guide/performing-system-scheduled-delta-replication" target="_self" rel="noopener noreferrer"&gt;Performing System-scheduled CDC Replication&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;SAP HANA Cloud, SAP HANA Database SQL on Files Guide: &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sql-on-files-guide/performing-user-driven-delta-replication" target="_self" rel="noopener noreferrer"&gt;Performing User-driven CDC Replication&lt;/A&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1503354018"&gt;&lt;SPAN&gt;Deactivate and Drop Remote Subscription&lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;If needed, the configured remote subscription can be deactivated and dropped using the statements below.&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;-- deactivate the remote subscription
ALTER REMOTE SUBSCRIPTION DEMO.DELTA_SUBSCRIPTION RESET;

-- drop the remote subscription 
DROP REMOTE SUBSCRIPTION DEMO.DELTA_SUBSCRIPTION;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;SPAN&gt;Deactivating the remote subscription will cancel all planned replication jobs from the scheduled CDC. However, since the remote subscription itself remains active, you can start again from the initial load step. Please note that the replica table, R_ORDERS in this example, will still contain replicated data. Therefore, truncating the replica table is required to start over.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Dropping the remote subscription will delete all entries, including the monitoring views. However, the replica table, R_ORDERS in this example, will remain with the replicated data and can be used as a normal table.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Please refer to the links below for further details on the deactivation and drop.&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;SAP HANA Cloud, SAP HANA Database SQL on Files Guide: &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sql-on-files-guide/setting-up-data-replication" target="_self" rel="noopener noreferrer"&gt;Configuring Delta Table Replication&lt;/A&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1306840513"&gt;&lt;SPAN&gt;Other Interfaces&lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;The remote subscription-based initial load and CDC combination mentioned above is the primary interface used for Delta table-to-HANA replication. However, there are a couple of other interfaces with simplified steps.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The first option involves toggling between federation and replication for the virtual table. Toggling has been supported previously, but only with snapshot replication. Starting with QRC 04/2025, toggling now supports real-time replication as well, as shown below.&lt;/SPAN&gt;&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;-- add a system-owned replica to a virtual table with a 30-minute interval
ALTER VIRTUAL TABLE V_ORDERS ADD SHARED REPLICA REFRESH INTERVAL 1800;

-- delete a replica
ALTER VIRTUAL TABLE V_ORDERS DROP REPLICA;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;SPAN&gt;In this approach, any queries on the virtual table will retrieve data from the replica instead of fetching data on-the-fly from the remote table. Since this is a simplified one-step process designed to offer better performance while maintaining the target object as a virtual table, it does not support granular controls such as chunk-based initial load or sub-table replication. The above example illustrates a system-owned replica, but a user-owned replica is also supported. Here, as with the remote subscription-based approach, if REFRESH INTERVAL is not specified, the default time interval of 3,600 seconds (1 hour) will be used.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Please refer to the links below for further details on the toggling.&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;SAP HANA Cloud, SAP HANA Database SQL on Files Guide: &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-sql-on-files-guide/toggle-between-virtual-tables-and-replica-tables" target="_self" rel="noopener noreferrer"&gt;Toggling Between Virtual Tables and Replica Tables&lt;/A&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;Another interface involves using the SAP HANA Cloud Central UI. In SAP HANA Cloud Central, Data Replication has been utilized for hybrid scenarios, such as replicating data from SAP HANA Platform 2.0 to SAP HANA Cloud. Starting with QRC 04/2025, Data Replication now also supports replicating data from Delta Sharing to SAP HANA Cloud.&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Data Replication UI.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/352441iFCD45B6FDED11C67/image-size/large?v=v2&amp;amp;px=999" role="button" title="Data Replication UI.png" alt="Data Replication UI.png" /&gt;&lt;/span&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Connection Type.png" style="width: 960px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/352442i865149D5728D6148/image-size/large?v=v2&amp;amp;px=999" role="button" title="Connection Type.png" alt="Connection Type.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;In this UI, either an existing remote source for Delta Sharing can be used or a new remote source can be created while configuring replication.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Connection Properties.png" style="width: 960px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/352443i99DAF8C767F2D63A/image-size/large?v=v2&amp;amp;px=999" role="button" title="Connection Properties.png" alt="Connection Properties.png" /&gt;&lt;/span&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Unlike other interfaces, it only supports the Delta Sharing remote source, which is based on the &lt;/SPAN&gt;&lt;EM&gt;deltasharing&lt;/EM&gt;&lt;SPAN&gt; adapter.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Data-Object Replication.png" style="width: 960px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/352445i99BF9C3CA75CF340/image-size/large?v=v2&amp;amp;px=999" role="button" title="Data-Object Replication.png" alt="Data-Object Replication.png" /&gt;&lt;/span&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;As shown above, once the data objects to be replicated are selected, the replication schedule can be set to either 'Real Time', which uses scheduled CDC, or 'None', which performs only a one-time initial load.&amp;nbsp;For 'Real Time', as explained above, the &lt;EM&gt;enableChangeDataFeed&lt;/EM&gt; property must be set on the source Delta table.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Replication Monitoring.png" style="width: 960px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/352451iA1336FB6F22BCD6E/image-size/large?v=v2&amp;amp;px=999" role="button" title="Replication Monitoring.png" alt="Replication Monitoring.png" /&gt;&lt;/span&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;SPAN&gt;Once confirmed, the replication status can now be monitored. For example, 'Completed', which means the one-time initial load is finished, or 'Loading...', which indicates that scheduled CDC is being activated.&lt;/SPAN&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Similar to toggling, as it is a simplified approach, it does not support granular controls such as chunk-based initial load, sub-table replication, or setting time intervals. However, like existing SAP HANA Platform 2.0-to-SAP HANA Cloud hybrid scenarios, it provides a way to configure the replication schedule, storage type, and a consolidated view of all replication tasks. Please refer to the links below for further details on using the SAP HANA Cloud Central UI.&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;SAP HANA Cloud, SAP HANA Database Data Access Guide: &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-data-access-guide/data-replication-in-sap-hana-cloud-central" target="_self" rel="noopener noreferrer"&gt;Data Replication in SAP HANA Cloud Central&lt;/A&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1110327008"&gt;&lt;SPAN&gt;Conclusion&lt;/SPAN&gt;&lt;/H3&gt;&lt;P&gt;&lt;SPAN&gt;To wrap things up, the Delta table replication capability introduced with SAP HANA Cloud QRC 04/2025 represents a transformative step forward in data integration and analytics. This advanced functionality provides businesses with the flexibility to address diverse use cases, enabling deeper insights and streamlined data management. Whether the focus is on real-time updates or managing large-scale initial data loads, these features deliver tailored solutions designed to optimize performance and efficiency. With SAP HANA Cloud at the forefront of innovation, the possibilities for unlocking the true power of your data are boundless. Be sure to explore these exciting capabilities to elevate your enterprise to the next level.&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/accelerating-your-analytics-with-delta-table-replication-into-sap-hana/ba-p/14290281"/>
    <published>2025-12-22T16:11:26.667000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/calculation-view-features-of-2025-qrc4/ba-p/14284865</id>
    <title>Calculation View Features of 2025 QRC4</title>
    <updated>2025-12-23T09:38:09.233000+01:00</updated>
    <author>
      <name>jan_zwickel</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/239612</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;Within the time frame of 2025 Q4, several new calculation view features have been released in SAP Business Application Studio when connected to SAP HANA Cloud database QRC4. Some of these features are highlighted below. You can find examples that illustrate the individual features&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://github.com/SAP-samples/hana-cloud-learning/tree/main/CV_2025_QRC4_Selected_Calculation_View_Modeling_Features" target="_blank" rel="nofollow noopener noreferrer"&gt;here&lt;/A&gt;&lt;SPAN&gt;. An overview of features of other releases can be found&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://blogs.sap.com/2022/08/25/new-calculation-view-modeling-features-in-sap-hana-cloud/" target="_blank" rel="noopener noreferrer"&gt;here&lt;/A&gt;&lt;SPAN&gt;.&lt;/SPAN&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1895582379"&gt;&lt;SPAN&gt;Key Indicators&lt;/SPAN&gt;&lt;/H3&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;To support the decision on which columns a join should be defined or which cardinality should be set the key column indicator highlights columns that belong to the key of a data source:&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="jan_zwickel_0-1764949347536.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349023i9EDE41A95959DCFC/image-size/medium?v=v2&amp;amp;px=400" role="button" title="jan_zwickel_0-1764949347536.png" alt="jan_zwickel_0-1764949347536.png" /&gt;&lt;/span&gt;&lt;DIV&gt;&lt;BR /&gt;&lt;DIV&gt;&lt;SPAN&gt;Information about key columns is shown in &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-modeling-guide-for-sap-business-application-studio/create-joins" target="_self" rel="noopener noreferrer"&gt;join nodes&lt;/A&gt; and derived from underlying data sources. For table data sources the information is taken from the primary key information of the table. For calculation view data sources the key information is taken from the Semantics node.&amp;nbsp;&lt;/SPAN&gt;&lt;/DIV&gt;&lt;BR /&gt;&lt;DIV&gt;&lt;SPAN&gt;The key information is propagated within a model but not to the Semantics node, so that the decision about the Semantics node key can be done explicitly.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;EM&gt;Use the key information to decide about join columns and join cardinality&lt;/EM&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;H3 id="toc-hId-1699068874"&gt;&lt;SPAN&gt;Option to Control Column Pruning Behavior&lt;/SPAN&gt;&lt;/H3&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;The &lt;/SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-modeling-guide-for-sap-business-application-studio/9ed48614318a4831a8a6b3e3222a05f0.html" target="_self" rel="noopener noreferrer"&gt;&lt;SPAN&gt;instantiation logic&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-modeling-guide-for-sap-business-application-studio/9ed48614318a4831a8a6b3e3222a05f0.html" target="_self" rel="noopener noreferrer"&gt;&amp;nbsp;of calculation views&lt;/A&gt; reduces the number of processed columns and data sources based on the query. If instead a relational behavior similar to SQL views is intended all columns can be tagged with the property "&lt;/SPAN&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/HANA_CLOUD_DATABASE/d625b46ef0b445abb2c2fd9ba008c265/f0e101a7641340708f0b098206210d9c.html" target="_self" rel="noopener noreferrer"&gt;Keep Flag&lt;/A&gt;"&lt;/SPAN&gt;&lt;SPAN&gt;. To simplify this, the option "&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-modeling-guide-for-sap-business-application-studio/control-column-pruning-in-calculation-view" target="_self" rel="noopener noreferrer"&gt;Column Pruning Behavior&lt;/A&gt;" can be set to "OFF" which automatically sets the Keep Flag property for all columns:&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="jan_zwickel_1-1764949791789.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349025i37D6970B010364CD/image-size/medium?v=v2&amp;amp;px=400" role="button" title="jan_zwickel_1-1764949791789.png" alt="jan_zwickel_1-1764949791789.png" /&gt;&lt;/span&gt;&lt;DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;Forcing additional columns into the aggregations can change the results, lead to higher resource consumption, and a decrease in performance. Therefore, Column Pruning Behavior should only be set to "OFF" if SQL view behavior is required.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;BR /&gt;&lt;DIV&gt;&lt;EM&gt;Use this option to quickly compare the results with and without instantiation logic or if you want to mimic SQL behavior.&lt;/EM&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;H3 id="toc-hId-1502555369"&gt;&lt;SPAN&gt;Open objects in Data Lineage and Impact Analysis Display&lt;/SPAN&gt;&lt;/H3&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;When analyzing the consumed objects of a calculation view (&lt;/SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-modeling-guide-for-sap-business-application-studio/13538ddb57924150b3ca62a53749dc99.html" target="_self" rel="noopener noreferrer"&gt;&lt;SPAN&gt;data lineage)&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;&amp;nbsp;or the consumers of a calculation view (&lt;/SPAN&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-modeling-guide-for-sap-business-application-studio/df9ca3197a6544ff90c7b37eb4280404.html" target="_self" rel="noopener noreferrer"&gt;impact analysis&lt;/A&gt;)&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;the displayed objects of the same HDI container can now be opened in their associated editors:&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;H6 id="toc-hId-1693290021"&gt;&lt;SPAN&gt;Data Lineage&lt;/SPAN&gt;&lt;/H6&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="jan_zwickel_2-1764949984579.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349026i28BE692CC19DD254/image-size/medium?v=v2&amp;amp;px=400" role="button" title="jan_zwickel_2-1764949984579.png" alt="jan_zwickel_2-1764949984579.png" /&gt;&lt;/span&gt;&lt;H6 id="toc-hId-1496776516"&gt;Impact Analysis&lt;/H6&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="jan_zwickel_3-1764950018659.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349027iC4F25C07870BEDD5/image-size/medium?v=v2&amp;amp;px=400" role="button" title="jan_zwickel_3-1764950018659.png" alt="jan_zwickel_3-1764950018659.png" /&gt;&lt;/span&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;Data Lineage and Impact Analysis are available via the context menu of calculation view files:&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="jan_zwickel_4-1764950063714.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349028i73128A0F84ED643E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="jan_zwickel_4-1764950063714.png" alt="jan_zwickel_4-1764950063714.png" /&gt;&lt;/span&gt;&lt;DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;EM&gt;Use this option to better understand the objects that are involved in lineage and impact analysis&lt;/EM&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;H3 id="toc-hId-913014854"&gt;Column Lineage SQL Function&lt;/H3&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;Function &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-modeling-guide-for-sap-business-application-studio/using-built-in-table-function-to-analyze-column-lineage" target="_self" rel="noopener noreferrer"&gt;SYS.GET_CALC_VIEW_COLUMN_DEPENDENCIES&lt;/A&gt; returns the base columns of individual calculation view columns. With this it becomes easy to track, for example, from which table a certain measure is coming.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;H6 id="toc-hId-1103749506"&gt;IN Parameters&lt;/H6&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;The parameters of the SQL function are: &lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;SPAN&gt;-&lt;/SPAN&gt;&lt;SPAN&gt; schema name of the calculation view to analyze&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;SPAN&gt;-&lt;/SPAN&gt;&lt;SPAN&gt; the calculation view name&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;SPAN&gt;-&lt;/SPAN&gt;&lt;SPAN&gt; the column to track or an empty string &lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;SPAN&gt;-&lt;/SPAN&gt;&lt;SPAN&gt; the option 'BASE' that defines the output details of the function&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;If the column name is left empty (''), all columns are treated as target columns.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;Currently only the option BASE is available which omits intermediate objects and reports the underlying tables only.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;System privilege CATALOG READ is required to execute the function.&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;EM&gt;Use this function to increase the insights into the behavior of the calculation view and to answer data auditing questions&lt;/EM&gt;&lt;/DIV&gt;&lt;H3 id="toc-hId-519987844"&gt;MDS Cubes&lt;/H3&gt;&lt;P&gt;Input parameters can now be used as client values during currency or unit conversion:&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="jan_zwickel_0-1765200589464.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349796i168D58FCE8383F3A/image-size/medium?v=v2&amp;amp;px=400" role="button" title="jan_zwickel_0-1765200589464.png" alt="jan_zwickel_0-1765200589464.png" /&gt;&lt;/span&gt;&lt;P&gt;The input parameters do not have to be materialized when the mode Query Execution is selected.&lt;/P&gt;&lt;P&gt;The star joins can now include left outer joins:&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="jan_zwickel_0-1764952628030.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349037iD46C40A9CCEA4489/image-size/medium?v=v2&amp;amp;px=400" role="button" title="jan_zwickel_0-1764952628030.png" alt="jan_zwickel_0-1764952628030.png" /&gt;&lt;/span&gt;&lt;P&gt;and also restricted columns can be added to the MDS Cube:&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="jan_zwickel_1-1764952656167.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349038i755D838B37C5CEBF/image-size/medium?v=v2&amp;amp;px=400" role="button" title="jan_zwickel_1-1764952656167.png" alt="jan_zwickel_1-1764952656167.png" /&gt;&lt;/span&gt;&lt;H3 id="toc-hId-323474339"&gt;Option Keep MDS Cube During Deployment&lt;/H3&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;Per default MDS Cubes are newly created during deployment. This means that data that have been loaded into MDS Cubes will be deleted. &lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;Set the &lt;/SPAN&gt;&lt;SPAN&gt;Keep MDS Cube During Deployment&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;flag if you want to keep the MDS Cube and thus the data also during redeployment:&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="jan_zwickel_2-1764952794903.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/349040i9B8D4E5E6BC8202C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="jan_zwickel_2-1764952794903.png" alt="jan_zwickel_2-1764952794903.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/DIV&gt;&lt;BR /&gt;&lt;DIV&gt;&lt;SPAN&gt;This &lt;/SPAN&gt;&lt;SPAN&gt;ensures that reporting on and loading of the MDS Cube can continue as before the redeployment.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;Deployment of the calculation view is still possible as long as the calculation view changes would not lead to a situation in which the MDS Cube could not be loaded anymore. A redeployment will fail if it would lead to a MDS Cube that is not loadable anymore,&amp;nbsp; e.g., a column used in the MDS Cube is removed from the calculation view. &lt;/SPAN&gt;&lt;/DIV&gt;&lt;BR /&gt;&lt;DIV&gt;&lt;SPAN&gt;While the MDS Cube itself will not be modified by a successful redeployment of the calculation view when the flag is set, changed meta data such as changed hierarchies will be reflected when using the MDS Cube in SAP Analytics Cloud.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;If the &lt;/SPAN&gt;&lt;SPAN&gt;Keep MDS Cube During Deployment&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;flag is set no changes to the MDS Cube are allowed and editing of the MDS Cube is blocked. If you want to edit the MDS Cube, unset the flag. Future redeployments will delete the data.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;EM&gt;Use flag to ensure continuous reporting on MDS Cubes across deployments&lt;/EM&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/DIV&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/calculation-view-features-of-2025-qrc4/ba-p/14284865"/>
    <published>2025-12-23T09:38:09.233000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/what-s-new-in-sap-hana-cloud-december-2025/ba-p/14295366</id>
    <title>What‚Äôs New in SAP HANA Cloud ‚Äì December 2025</title>
    <updated>2025-12-23T12:03:33.133000+01:00</updated>
    <author>
      <name>thomashammer</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/122781</uri>
    </author>
    <content>&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;As the year draws to a close and the holiday season is approaching, we‚Äôre excited to share one more set of updates before 2025 wraps up. The Q4 release of SAP HANA Cloud delivers a focused set of innovations designed to further improve operational efficiency, resilience, developer productivity, and more.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="thumbq42025.png" style="width: 532px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/354730iC5716F44B7055295/image-dimensions/532x274?v=v2" width="532" height="274" role="button" title="thumbq42025.png" alt="thumbq42025.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Let‚Äôs deep dive into key innovations included in the December 2025 release:&lt;/P&gt;&lt;H1 id="toc-hId-1638365449"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H1 id="toc-hId-1441851944"&gt;&lt;STRONG&gt;SQL Tools for Administration in SAP HANA Cloud Central&lt;/STRONG&gt;&lt;/H1&gt;&lt;H2 id="toc-hId-1374421158"&gt;&lt;STRONG&gt;Property Graph Viewer in Database Administration Tooling&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;With the Q4 release, SAP HANA Cloud Central introduces a property graph viewer directly within the database administration tooling. This viewer allows you to visually explore property graphs, where entities are represented as vertices and relationships as edges. A common example is modeling airports as vertices and flight routes as directed edges, including properties such as distance. You can apply filters to vertices and edges and enhance their analysis by applying built-in graph algorithms like neighborhood exploration, shortest path, or Cypher-based filtering.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="Picture 1.png" style="width: 600px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/355128i1D1C4BE0BE0E35B5/image-size/large?v=v2&amp;amp;px=999" role="button" title="Picture 1.png" alt="Picture 1.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The main value of the property graph viewer is faster understanding of complex relationships stored in graph structures. Instead of relying on raw query results, you can visually explore how entities are connected and quickly identify patterns, dependencies, or anomalies. This makes graph data more accessible not only to technical experts but also to solution architects and analysts who benefit from an intuitive, visual representation of relationships.&lt;/P&gt;&lt;H2 id="toc-hId-1177907653"&gt;&lt;STRONG&gt;SQL Console Background Activities&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;SQL console background activities enable long-running SQL statements to continue executing independently of the browser session. You can now start a statement, close the browser, and return later to review the results without interrupting execution. This capability is fully integrated into the database administration tooling in SAP HANA Cloud Central.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="backghr.png" style="width: 699px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/355112iF6BCDD5E50FF1B45/image-dimensions/699x334?v=v2" width="699" height="334" role="button" title="backghr.png" alt="backghr.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This feature removes a long-standing friction point when working with complex or time-consuming SQL workloads. Administrators and developers no longer need to keep browser sessions open or worry about accidental disconnects. As a result, productivity increases, and operational tasks such as data preparation, analysis, or maintenance queries become more reliable and less disruptive.&lt;/P&gt;&lt;H2 id="toc-hId-981394148"&gt;&lt;STRONG&gt;Automatic Saving and Loading of SQL Statements&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;The SQL console now automatically saves its contents and connection details and restores them when you return. This behavior can be configured in the settings, allowing you to decide how persistent their SQL console sessions should be.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="thomashammer_0-1766481067179.png" style="width: 547px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/355082i2F49709DBC0F936A/image-dimensions/547x253?v=v2" width="547" height="253" role="button" title="thomashammer_0-1766481067179.png" alt="thomashammer_0-1766481067179.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This enhancement provides continuity when switching tasks or sessions. You can pick up exactly where you left off, without re-establishing connections or recovering lost SQL statements. It improves day-to-day efficiency and reduces context switching, especially for administrators and developers working across multiple systems.&lt;/P&gt;&lt;H2 id="toc-hId-784880643"&gt;&lt;STRONG&gt;Application for Schemas and Deployment Infrastructure Containers&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;A new application in the database administration tooling provides a consolidated view of schemas and SAP HANA deployment infrastructure (HDI) containers within a subaccount. These can optionally be grouped by their associated SAP HANA database instance. You can examine detailed metadata, including Cloud Foundry organization and space information, instance IDs, and links to the associated database. From there, you can directly navigate to the database instance or open a SQL Console or database explorer connection.&lt;/P&gt;&lt;P&gt;This application simplifies landscape transparency for administrators. Instead of piecing together information across tools, you can quickly identify where schemas and containers live, understand their context, and jump directly into analysis or troubleshooting. This is especially valuable in larger environments with many applications and database instances.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="thomashammer_1-1766481113280.png" style="width: 576px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/355084i83AFC32E03CB90F6/image-dimensions/576x272?v=v2" width="576" height="272" role="button" title="thomashammer_1-1766481113280.png" alt="thomashammer_1-1766481113280.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;H1 id="toc-hId-459284419"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H1 id="toc-hId-262770914"&gt;&lt;STRONG&gt;Multi-Model and Machine Learning Updates&lt;/STRONG&gt;&lt;/H1&gt;&lt;P&gt;&lt;SPAN&gt;With the Q4 2025 release of SAP HANA Cloud, we continue to strengthen embedded Machine Learning and AI capabilities across the Predictive Analysis Library (PAL), the Automated Predictive Library (APL), and the Natural Language Processing (NLP) Services. These enhancements focus on making advanced analytics easier to use, more consistent across scenarios, and better suited for real-world business data.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Key highlights of this release are:&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;A new unified time series procedure, serving developers to utilize the same interface across different times series algorithms&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;text embedding model enhancements, supporting output vector dimensionality reduction, while maintaining retrieval accuracy&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;a new cross encoder model with the NLP services, for accurately re-ranking search results&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;text column input, text embedding operators with AutoML classification and regression models&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;text tokenization enhancements supporting regular expression token filtering and a new text log parsing function for detecting and determining new log pattern&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;the HANA ML experiment monitor UI now supports visual model monitoring and drift analysis&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-784819104" id="toc-hId-195340128"&gt;&lt;SPAN&gt;Cross Encoder Model (NLP services)&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;SAP HANA Cloud has enhanced its NLP services with a new cross-encoder model and related PAL functions to significantly improve the accuracy of search result re-ranking. Unlike traditional embedding-based similarity search, the cross encoder jointly processes the query and candidate results, enabling deep contextual interaction analysis and producing much more precise and relevant ranking outcomes.&lt;/P&gt;&lt;P&gt;This approach also supports hybrid search, allowing results from classic text search and vector similarity search to be combined into a single candidate set and re-ranked together by the cross encoder.&lt;/P&gt;&lt;P&gt;These capabilities strengthen Retrieval Augmented Generation (RAG) and custom AI applications by integrating text embedding models, vector engines, similarity search, and cross encoders within SAP HANA Cloud, while maintaining data privacy directly inside the database.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_6-1766163220604.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/359522iCC588CF0E94BA913/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_6-1766163220604.png" alt="ChristophMorgen_6-1766163220604.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;A more detailed introduction to the new cross encoder model is given in the following blog post: &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-cross-encoder-and-text-embedding-support-dimensionality-reduction-in/ba-p/14293164" target="_blank"&gt;here&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;To learn more about this and more Multi-Model and Machine Learning updates, check out &lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/14106"&gt;@ChristophMorgen&lt;/a&gt;‚Äòs blogpost &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-nlp-and-ai-features-in-sap-hana-cloud-2025-q4/ba-p/14293152" target="_blank"&gt;here.&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId--1173377"&gt;&lt;STRONG&gt;Transforming Property Graphs into Knowledge Graphs&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;With the Q4 2025 release, SAP HANA Cloud introduces the ability to transform property graphs into knowledge graphs. This capability allows you to convert existing graph structures into a semantic, knowledge-graph representation without redesigning your data models from scratch. It enables you to work with different graph paradigms on top of the same underlying data.&lt;/P&gt;&lt;P&gt;This innovation helps you maximize data utility by seamlessly switching between property graph and knowledge graph models depending on your needs. You are no longer restricted to a single data representation and can choose the most appropriate graph model for analytics, reasoning, or integration scenarios. As a result, you gain greater operational efficiency, improved interoperability between graph models, and more flexibility in how you explore and reuse graph-based data.&lt;/P&gt;&lt;P&gt;Learn more about transforming property graphs into knowledge graphs on &lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/converting-property-graphs-to-knowledge-graphs-in-sap-hana-cloud-a-simple/ba-p/14294883" target="_blank"&gt;this blogpost&lt;/A&gt;&lt;/SPAN&gt; by &lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/38259"&gt;@shabana&lt;/a&gt;&amp;nbsp;&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/user/viewprofilepage/user-id/38259" target="_blank"&gt;.&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H1 id="toc-hId-442970482"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H1 id="toc-hId-246456977"&gt;&lt;STRONG&gt;Calculation View Modeling Updates&lt;/STRONG&gt;&lt;/H1&gt;&lt;H2 id="toc-hId--243459535"&gt;&lt;STRONG&gt;Column Lineage Insights for Graphical Calculation Views&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;SAP HANA Cloud now allows you to gain column lineage insights for graphically modeled calculation views by calling an SQL table function. This capability provides transparency into how output columns are derived from underlying sources, with lineage tracked across graphical modeling steps and stopping at functions or procedures.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;By making lineage information easily accessible, this feature improves model quality and trust. Developers can better understand complex models, speed up enhancements, and reduce errors during refactoring. For architects and analysts, clearer lineage increases confidence in the data and supports governance and audit requirements.&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId--439973040"&gt;&lt;STRONG&gt;Input Parameters for Currency and Unit Conversion in MDS Cubes&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;Input parameters can now be used to specify client values for currency and unit conversion when working with multidimensional services (MDS) cubes. These values no longer need to be materialized, and conversions can be defined dynamically at query runtime.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;This enhancement increases flexibility in analytical scenarios. You can adapt conversions based on runtime context without redesigning models or creating additional persisted data. It enables more dynamic reporting and simplifies scenarios where conversion logic depends on user input or business context.&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId--636486545"&gt;&lt;STRONG&gt;Restricted Columns in MDS Cubes&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;With Q4, restricted columns can be added to MDS cubes and evaluated at query execution time. If runtime evaluation is not possible, deployment fails with a clear notification. This approach avoids mandatory materialization of input parameters while still ensuring correctness.&lt;/P&gt;&lt;P&gt;The key value lies in greater runtime control and reduced data preparation overhead. You can now influence how restricted columns are processed without forcing early decisions during modeling, leading to more flexible cubes and more efficient execution.&lt;/P&gt;&lt;H2 id="toc-hId--833000050"&gt;&lt;STRONG&gt;Visibility of Key Columns When Modeling Joins&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;When defining joins in calculation views, key columns are now visually indicated. This makes it easier to understand join semantics and identify important relationships directly in the modeling UI.&lt;/P&gt;&lt;P&gt;By highlighting key columns, this feature helps you create star joins with greater confidence and accuracy. It reduces modeling errors, improves data consistency, and ultimately results in higher-quality analytical models.&lt;/P&gt;&lt;H2 id="toc-hId--1029513555"&gt;&lt;STRONG&gt;Left Outer Joins in Star Joins of MDS Cubes&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;SAP HANA Cloud now supports left outer joins in star joins for MDS cubes. This expands the range of scenarios that can be modeled using multidimensional services.&lt;/P&gt;&lt;P&gt;The benefit is faster adoption of MDS cubes in additional analytical use cases. You gain more flexibility in how dimensions and facts are combined, without having to fall back to alternative modeling approaches.&lt;/P&gt;&lt;P&gt;If you are interested in discovering more about Calculation View modeling updates, check out &lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/calculation-view-features-of-2025-qrc4/ba-p/14284865" target="_blank"&gt;this blogpost&lt;/A&gt;&lt;/SPAN&gt; by @&lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/user/viewprofilepage/user-id/239612" target="_blank"&gt;JanZwickel.&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H1 id="toc-hId--932624053"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H1 id="toc-hId--1129137558"&gt;&lt;STRONG&gt;Cloud Reliability and Total Cost of Ownership&lt;/STRONG&gt;&lt;/H1&gt;&lt;P&gt;The Q4 release of SAP HANA Cloud is also introducing significant enhancements to strengthen the service's reliability while reduction the overal total cost of ownership at the same time.&lt;/P&gt;&lt;H2 id="toc-hId--1619054070"&gt;&lt;STRONG&gt;Multi-Region Disaster Recovery&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;In early Q4 we extended disaster recovery capabilities beyond multiple availability zones within a single region to selected, distant regions. The initial scope focused on North America, using Amazon Web Services with a pairing between US East (VA) and US West (Oregon). Support includes SAP HANA Cloud Data Lake Files, while multi-tenancy is excluded in the initial phase.&lt;/P&gt;&lt;P&gt;This innovation significantly improves resilience against regional outages. By maintaining a secondary system in a distant region, customers can better protect critical workloads and ensure business continuity. The offering starts with a defined scope and will expand stepwise to additional regions, cloud providers, and features.&lt;/P&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;DIV class=""&gt;&lt;P&gt;We're happy to share, that we will be extending our offering to Europe, early in January 2026. Customers will then be able to protect SAP HANA Cloud workloads across EU Central (Frankfurt) and EU South (Milan), improving resilience against regional outages with a secondary system in a predefined, geographically distant region. This expansion will help EU-based and global customers strengthen business continuity while meeting regional availability and data residency needs, with additional regions and enhancements planned based on demand.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="metrodr.png" style="width: 349px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/355114i8DEB72E39F104DCD/image-dimensions/349x207?v=v2" width="349" height="207" role="button" title="metrodr.png" alt="metrodr.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Active/Active Read-Enabled High Availability&lt;/STRONG&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;P&gt;Synchronous replicas in a "high availability" configuration ensure increased reliability via autonomous failover capabilities to standby systems, in case of outages or other incidents.&lt;BR /&gt;But, such high availability setups require redundant resources, which traditionally remain idle during normal operations. With the new active/active read-enabled option, SAP HANA Cloud allows these secondary systems to actively handle read-intensive analytical workloads. In the initial scope, client-side statement routing enables applications to direct analytical queries to these replicas.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="active.png" style="width: 414px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/355117i1E383A134E6BADC7/image-dimensions/414x304?v=v2" width="414" height="304" role="button" title="active.png" alt="active.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This approach improves cost efficiency and performance at the same time. You can offload analytical workloads from the primary system while still preserving full high-availability readiness. The same resources that ensure resilience now also deliver day-to-day business value.&lt;/P&gt;&lt;H2 id="toc-hId--1647383884"&gt;&lt;STRONG&gt;Automatic Up-Scaling Storage&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;SAP HANA Cloud now supports automatic storage upscaling to prevent disk-full situations. When enabled by administrators, the system can double the initially provisioned storage size - up to a customer-defined maximum - once usage reaches 98%. Alerts notify administrators, and a minimum cycle time of six hours applies between scaling events.&lt;/P&gt;&lt;P&gt;This capability helps avoid critical outages caused by full disks while still keeping costs under control. Administrators gain more time to react to growing storage needs and can define clear boundaries for automatic scaling, balancing safety and predictability.&lt;/P&gt;&lt;H1 id="toc-hId--1550494382"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H1 id="toc-hId--1747007887"&gt;&lt;STRONG&gt;Seamless Integration with&amp;nbsp; SAP Business Data Cloud&lt;/STRONG&gt;&lt;/H1&gt;&lt;P&gt;As &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/what-s-next-with-sap-hana-cloud-sap-teched-2025/ba-p/14258163" target="_blank"&gt;announced at SAP TechEd 2025&lt;/A&gt;, SAP HANA Cloud will integrate in a bi-directional manner with SAP Business Data Cloud, to consume and produce data products and thereby combine the best out of two solutions. While the production of data products will become available in early 2026, the consumption is now possible with our latest release.&lt;/P&gt;&lt;H2 id="toc-hId-2058042897"&gt;&lt;STRONG&gt;Native Consumption of Data Products&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;SAP HANA Cloud can now directly consume data products from SAP Business Data Cloud. Virtual table connections are created automatically, enabling seamless access from SAP HANA Cloud to the data product source.&lt;/P&gt;&lt;P&gt;This integration allows customers to extend SAP line-of-business applications with custom logic while relying on governed, reusable data products. It reduces integration effort and accelerates innovation by making enterprise data easier to access and combine.&lt;/P&gt;&lt;H1 id="toc-hId--2140034897"&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="data products.png" style="width: 731px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/355118i194F372AC38FE6CC/image-dimensions/731x317?v=v2" width="731" height="317" role="button" title="data products.png" alt="data products.png" /&gt;&lt;/span&gt;&lt;/H1&gt;&lt;H1 id="toc-hId-1958418894"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H1 id="toc-hId-1761905389"&gt;&lt;STRONG&gt;Enhancements to SQL on Files&lt;/STRONG&gt;&lt;/H1&gt;&lt;H2 id="toc-hId-1271988877"&gt;&lt;STRONG&gt;Delta Table Replication&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;&lt;SPAN&gt;Direct read-only access to Delta tables in&amp;nbsp;the object&amp;nbsp;storage or through Delta Sharing, which has been introduced since QRC&amp;nbsp;04/2024, has offered real-time analytics on the vast volume of data in files, without moving them into SAP HANA Cloud.&amp;nbsp;With QRC 04/2025, it evolves further by offering replication capability for critical datasets, enabling faster queries with greater flexibility and robust data management.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;This new Delta&amp;nbsp;table-to-HANA replication offers granular controls, such as chunk-based&amp;nbsp;initial&amp;nbsp;load, which allows splitting the data into multiple chunks and loading them separately to make the&amp;nbsp;initial&amp;nbsp;load more manageable. Furthermore, when it comes to Change Data Capture (CDC), it allows either user-driven, version-based CDC or system-driven, scheduled CDC for full automation.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;To learn more about SAP HANA Cloud‚Äôs&amp;nbsp;new Delta table-to-HANA replication,&amp;nbsp;take a look at &lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/204092"&gt;@SeungjoonLee&lt;/a&gt;'s blog post&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/accelerating-your-analytics-with-delta-table-replication-into-sap-hana/ba-p/14290281" target="_blank"&gt;&lt;SPAN&gt;here&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;STRONG&gt;Smart Data Access:&amp;nbsp;Support&amp;nbsp;for two new remote&amp;nbsp;sources through Data Access Agent&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Additionally, based on the newly introduced Smart Data Access (SDA) Data Access Agent from the last QRC&amp;nbsp;03/2025, read-only access to two new remote sources, Google Sheets and Oracle Database in the cloud, will be available from QRC&amp;nbsp;04/2025.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;The way of configuring and using them&amp;nbsp;remains&amp;nbsp;the same&amp;nbsp;as for&amp;nbsp;other previously supported remote sources, and for newly provisioned Data Access Agents, all new adapters are activated by default. To activate new adapters for a Data Access Agent that has already been provisioned and is currently in use, please refer to&amp;nbsp;&lt;A href="https://me.sap.com/notes/2600176" target="_blank" rel="noopener noreferrer"&gt;SAP Note 2600176 - SAP HANA Smart Data Access Supported Remote Sources&lt;/A&gt;&amp;nbsp;for further details on how to activate them, as well as&amp;nbsp;additional&amp;nbsp;information on support.&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;H1 id="toc-hId-1368878379"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H1 id="toc-hId-1172364874"&gt;&lt;STRONG&gt;Datacenter Updates&lt;/STRONG&gt;&lt;/H1&gt;&lt;P&gt;&lt;SPAN&gt;In Q4 2025, we are announcing the availability of SAP HANA Cloud in these new BTP regions:&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Italy (Milan) on AWS&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Germany (St. Leon-Rot) on SCI&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;United Arab Emirates (Dubai) on SCI&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;US West (Colorado) on SCI*&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Australia (Sydney) on SCI*&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;* General availability is expected by the end of Q4 2025, when the respective BTP regions are planned to go live. See&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;&lt;A href="https://roadmaps.sap.com/board?PRODUCT=73554900100800002881&amp;amp;range=CURRENT-LAST&amp;amp;q=data%20center" target="_blank" rel="noopener noreferrer"&gt;SAP Roadmap Explorer&lt;/A&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;for details.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;We continue our journey to give customers the freedom to choose their preferred infrastructure cloud provider by investing in regions on both&amp;nbsp;hyperscalers&amp;nbsp;and SAP Cloud Infrastructure (SCI).&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;On AWS, we are announcing the availability of SAP HANA Cloud in a second European region: Italy (Milan). This&amp;nbsp;establishes&amp;nbsp;the technical foundation for multi-region disaster recovery within European borders.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;The first SCI region ‚Äî Germany (Frankfurt) ‚Äî was announced in Q3 2025, see&amp;nbsp;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/introducing-sap-hana-cloud-on-sap-cloud-infrastructure/ba-p/14223782" target="_blank"&gt;blog post&lt;/A&gt;&lt;U&gt;.&lt;/U&gt; Now, we are making SAP HANA Cloud available globally on SCI, by offering a second SCI region in Germany (with EU Access), as well as SCI regions in the U.S., Australia, and the UAE.&lt;/SPAN&gt;&lt;/P&gt;&lt;H1 id="toc-hId-1144035060"&gt;&amp;nbsp;&lt;/H1&gt;&lt;H1 id="toc-hId-947521555"&gt;&lt;STRONG&gt;Further Updates&lt;/STRONG&gt;&lt;/H1&gt;&lt;H2 id="toc-hId-457605043"&gt;&lt;STRONG&gt;Native Multi-Tenancy: Tenant Move with Reduced Downtime&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;The enhanced tenant move process for SAP HANA Cloud native multi-tenancy splits the operation into a preparation phase and a short cutover phase. During preparation, tenant data is copied while the source tenant remains fully operational. Only during the final cutover is brief downtime required to apply delta changes and switch over.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;This significantly reduces business downtime and gives you control over scheduling the cutover in low-impact time windows. It improves operational flexibility and minimizes risk during tenant reorganization.&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-261091538"&gt;&lt;STRONG&gt;Selective, Incremental Migration to SAP HANA Cloud&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;Selective, incremental migration allows you to migrate chosen parts of an SAP HANA 2.0 database to SAP HANA Cloud instead of moving everything at once. Migrations can be performed in smaller, manageable steps based on schemas or deployment infrastructure containers.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="migrationpatterns.png" style="width: 492px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/355125i42F1B3310D03273A/image-dimensions/492x276?v=v2" width="492" height="276" role="button" title="migrationpatterns.png" alt="migrationpatterns.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;This approach reduces downtime, avoids migrating unused components, and makes large migrations more predictable. It allows you to better plan the transition to the cloud, while minimizing disruption.&lt;/P&gt;&lt;H2 id="toc-hId-64578033"&gt;&lt;STRONG&gt;Rule-Based Index Advisor&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;The new rule-based Index Advisor analyzes query usage patterns to identify index optimization opportunities. It recommends creating or dropping indexes for single-table filter queries and provides ready-to-execute SQL statements.&lt;/P&gt;&lt;P&gt;By automating index analysis, this feature improves performance while helping control costs. Administrators gain actionable insights without deep manual analysis, making database tuning more accessible and efficient.&lt;/P&gt;&lt;HR /&gt;&lt;P&gt;Thanks for taking the time to explore the What‚Äôs New in SAP HANA Cloud on Q4 2025 innovations!&lt;/P&gt;&lt;P&gt;If you‚Äôd like to go deeper into the technical details of the December 2025 release, we recommend visiting the &lt;SPAN&gt;&lt;A href="https://help.sap.com/whats-new/2495b34492334456a49084831c2bea4e" target="_blank" rel="noopener noreferrer"&gt;What‚Äôs New Viewer&lt;/A&gt;&lt;/SPAN&gt; in the technical documentation. It provides a comprehensive overview of the full release scope. To stay informed about upcoming innovations, announcements, and best practices, follow the &lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/c-khhcw49343/SAP+HANA+Cloud/pd-p/73554900100800002881" target="_blank"&gt;SAP HANA Cloud tag&lt;/A&gt;&lt;/SPAN&gt;.&lt;/P&gt;&lt;P&gt;You can also find our latest blog posts by searching for the &lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/tag/whatsnewinsaphanacloud/tg-p" target="_blank"&gt;&lt;STRONG&gt;#whatsnewinsaphanacloud&lt;/STRONG&gt;&lt;/A&gt;&lt;/SPAN&gt; hashtag.&lt;/P&gt;&lt;P&gt;If you missed earlier What‚Äôs New webinars, you‚Äôll find recordings of past sessions and upcoming events in our &lt;SPAN&gt;&lt;A href="https://www.youtube.com/playlist?list=PL3ZRUb1AKkpTDZQgENtRcupp6vsNg8NHN" target="_blank" rel="noopener nofollow noreferrer"&gt;YouTube playlist&lt;/A&gt;&lt;/SPAN&gt;. Our What‚Äôs New webinar covering the Q4 2025 innovations will be posted on this playlist very soon.&lt;/P&gt;&lt;P&gt;Do you have questions about SAP HANA Cloud or want to share your thoughts on the new features?&lt;BR /&gt;Join the conversation in the &lt;SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-q-a/qa-p/technology-questions" target="_blank"&gt;SAP HANA Cloud Community Q&amp;amp;A&lt;/A&gt;&lt;/SPAN&gt; or leave a comment below. We‚Äôd love to hear from you!&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Enjoy the holidays and have a great start into 2026!&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/what-s-new-in-sap-hana-cloud-december-2025/ba-p/14295366"/>
    <published>2025-12-23T12:03:33.133000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/good-to-know-full-system-info-dump-fsid-vs-runtime-dump-rte-in-context-of/ba-p/14300165</id>
    <title>Good to know: Full System Info Dump (FSID) vs Runtime Dump (RTE) in context of SAP HANA database</title>
    <updated>2026-01-02T08:34:53.309000+01:00</updated>
    <author>
      <name>Laszlo_Thoma</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/170406</uri>
    </author>
    <content>&lt;P&gt;&lt;ul =""&gt;&lt;li style="list-style-type:disc; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/good-to-know-full-system-info-dump-fsid-vs-runtime-dump-rte-in-context-of/ba-p/14300165#toc-hId-1658532033"&gt;Why was this blog post created?&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/good-to-know-full-system-info-dump-fsid-vs-runtime-dump-rte-in-context-of/ba-p/14300165#toc-hId-1462018528"&gt;Where can I find the most important information about the FSID and RTE?&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/good-to-know-full-system-info-dump-fsid-vs-runtime-dump-rte-in-context-of/ba-p/14300165#toc-hId-1265505023"&gt;How to collect both FSID and RTE together to get the most detailed trace for complete investigation?&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/good-to-know-full-system-info-dump-fsid-vs-runtime-dump-rte-in-context-of/ba-p/14300165#toc-hId-1068991518"&gt;What is the conclusion?&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/good-to-know-full-system-info-dump-fsid-vs-runtime-dump-rte-in-context-of/ba-p/14300165#toc-hId-872478013"&gt;Other article&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/good-to-know-full-system-info-dump-fsid-vs-runtime-dump-rte-in-context-of/ba-p/14300165#toc-hId-675964508"&gt;Do you have further questions?&lt;/a&gt;&lt;/li&gt;&lt;li style="list-style-type:disc; margin-left:0px; margin-bottom:1px;"&gt;&lt;a href="https://community.sap.com/t5/technology-blog-posts-by-sap/good-to-know-full-system-info-dump-fsid-vs-runtime-dump-rte-in-context-of/ba-p/14300165#toc-hId-479451003"&gt;Contribution&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="banner_SAP_HANA.png" style="width: 800px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/357491i80E0ED9930C07694/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="banner_SAP_HANA.png" alt="banner_SAP_HANA.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P class="lia-align-right" style="text-align : right;"&gt;&lt;FONT color="#FF0000"&gt;last updated: 2026-01-02&lt;/FONT&gt;&lt;/P&gt;&lt;H1 id="toc-hId-1658532033"&gt;Why was this blog post created?&lt;/H1&gt;&lt;P&gt;There is a lot of confusion about the different types of trace files.&amp;nbsp;When troubleshooting a problem, in many case the wrong trace file is collected.&lt;/P&gt;&lt;P&gt;It is important to be aware and understand that different trace types can be collected from the SAP HANA database and that they are suitable for identifying different problems.&amp;nbsp;In some cases only &lt;STRONG&gt;Full System Info Dump (FSID)&lt;/STRONG&gt; is needed, while in other cases &lt;STRONG&gt;Runtime Dump (RTE)&lt;/STRONG&gt; is needed.&amp;nbsp;In special cases, &lt;STRONG&gt;both&lt;/STRONG&gt; may be needed.&lt;/P&gt;&lt;H1 id="toc-hId-1462018528"&gt;Where can I find the most important information about the FSID and RTE?&lt;/H1&gt;&lt;P&gt;&lt;SPAN&gt;SAP Community Article:&amp;nbsp;&lt;A class="" href="https://blogs.sap.com/2023/03/29/where-can-i-find-knowledge-and-information-belongs-to-sap-hana/" target="_blank" rel="noopener noreferrer"&gt;Where can I find knowledge and information belongs to SAP HANA?&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;section&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/where-can-i-find-knowledge-and-information-belongs-to-sap-hana/ba-p/13562344#toc-hId-174109642" target="_blank"&gt;Full System Info Dump (FSID)&lt;/A&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;section&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/where-can-i-find-knowledge-and-information-belongs-to-sap-hana/ba-p/13562344#toc-hId--22403863" target="_blank"&gt;Runtime Dump (RTE)&lt;/A&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;TABLE border="1" width="100%"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="33.333333333333336%"&gt;&amp;nbsp;&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;&lt;STRONG&gt;Full System Info Dump (FSID)&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;&lt;STRONG&gt;Runtime Dump (RTE)&lt;/STRONG&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;&lt;STRONG&gt;Issue time&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD&gt;Happened in the past.&lt;/TD&gt;&lt;TD&gt;Happens in real time.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="33.333333333333336%"&gt;&lt;STRONG&gt;When to use?&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;Root Cause Analysis (RCA)&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;Real-Time&amp;nbsp;Analysis (RTA)&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="33.333333333333336%"&gt;&lt;STRONG&gt;When to collect?&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;Anytime (but &lt;STRONG&gt;must include&lt;/STRONG&gt; the time when the problem occurred, e.g. collected last 7 days of trace while issue occurred 3 days ago).&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;Real time, when the issue occurs actually.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="33.333333333333336%"&gt;&lt;STRONG&gt;Examples&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;System crash, oom - out of memory issue, etc.&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;High CPU, slow system, slow execution, unresponsive or hung system, blocked transaction, general performance issue, etc.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD width="33.333333333333336%"&gt;&lt;STRONG&gt;How to analyze?&lt;/STRONG&gt;&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;Mainly manual trace checking/reviewing but there are tools also.&lt;/TD&gt;&lt;TD width="33.333333333333336%"&gt;&lt;P&gt;&lt;A href="https://launchpad.support.sap.com/#/notes/2498739" target="_blank" rel="noopener noreferrer"&gt;2498739&lt;/A&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;- How-To: Analyzing Runtime Dumps with SAP HANA Dump Analyzer&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H1 id="toc-hId-1265505023"&gt;How to collect both FSID and RTE together to get the most detailed trace for complete investigation?&lt;/H1&gt;&lt;P&gt;The following scenario explains the proper order of the trace collection activity.&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;Collecting &lt;STRONG&gt;RTE &lt;/STRONG&gt;files (during the issue exists, while the system &lt;STRONG&gt;slow&lt;/STRONG&gt;, &lt;STRONG&gt;unresponsive,&lt;/STRONG&gt;&amp;nbsp;&lt;STRONG&gt;hung &lt;/STRONG&gt;or &lt;STRONG&gt;high CPU utilization&lt;/STRONG&gt;&amp;nbsp;, etc. observed).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Restart the system manually&lt;/STRONG&gt; (to bring the system back to normal/stable/working state) or &lt;STRONG&gt;wait until it performs well again&lt;/STRONG&gt; (issue solved on its own, e.g. cause of the performance issue solved, long running execution finally finished, CPU usage dropped).&lt;/LI&gt;&lt;LI&gt;Collecting &lt;STRONG&gt;FSID &lt;/STRONG&gt;files (after the system restarted successfully or performance issue solved on its own and the system is up and running normally again).&lt;/LI&gt;&lt;/OL&gt;&lt;H1 id="toc-hId-1068991518"&gt;What is the conclusion?&lt;/H1&gt;&lt;P&gt;While issue reported to SAP it is&amp;nbsp;&lt;SPAN&gt;a good practice to upload the relevant traces right away. This will speed up the case handling process.&lt;/SPAN&gt;&lt;/P&gt;&lt;H1 id="toc-hId-872478013"&gt;&lt;SPAN&gt;Other article&lt;/SPAN&gt;&lt;/H1&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":writing_hand:"&gt;‚úçÔ∏è&lt;/span&gt;&amp;nbsp;&lt;A href="https://blogs.sap.com/2023/03/29/where-can-i-find-knowledge-and-information-belongs-to-sap-hana/" target="_blank" rel="noopener noreferrer"&gt;Where can I find knowledge and information belongs to SAP HANA?&lt;/A&gt;&lt;BR /&gt;&lt;span class="lia-unicode-emoji" title=":writing_hand:"&gt;‚úçÔ∏è&lt;/span&gt;&amp;nbsp;&lt;A href="https://blogs.sap.com/2023/06/02/where-can-i-find-information-about-the-available-tools-for-sap-hana-all-types-of-use/" target="_blank" rel="noopener noreferrer"&gt;Where can I find information about the available tools for SAP HANA (all types of use)?&lt;/A&gt;&lt;/P&gt;&lt;H1 id="toc-hId-675964508"&gt;Do you have further questions?&lt;/H1&gt;&lt;P&gt;Please do not hesitate to contact me if you have question or observation regarding the article.&lt;BR /&gt;Q&amp;amp;A link for SAP HANA:&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;A href="https://answers.sap.com/tags/73554900100700000996" target="_blank" rel="noopener noreferrer"&gt;https://answers.sap.com/tags/73554900100700000996&lt;/A&gt;&amp;nbsp;&lt;/P&gt;&lt;H1 id="toc-hId-479451003"&gt;Contribution&lt;/H1&gt;&lt;P&gt;If you find any missing information belongs to the topic, please let me know. I am happy to add the new content. My intention is to maintain the content continuously to keep the info up-to-date.&lt;/P&gt;&lt;P&gt;&lt;FONT color="#999999"&gt;&lt;STRONG&gt;Release Information&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;TABLE width="100%" cellspacing="1"&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD height="58px"&gt;&lt;FONT color="#999999"&gt;Release Date&lt;/FONT&gt;&lt;/TD&gt;&lt;TD height="58px"&gt;&lt;FONT color="#999999"&gt;Description&lt;/FONT&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="30px"&gt;&lt;FONT color="#999999"&gt;2026.01.02&lt;/FONT&gt;&lt;/TD&gt;&lt;TD height="30px"&gt;&lt;FONT color="#999999"&gt;First/initial Release of the SAP Blog Post documentation (Technical Article).&lt;/FONT&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/good-to-know-full-system-info-dump-fsid-vs-runtime-dump-rte-in-context-of/ba-p/14300165"/>
    <published>2026-01-02T08:34:53.309000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/enhancing-sap-hana-database-development-with-generative-ai-support-for-hdi/ba-p/14294318</id>
    <title>Enhancing SAP HANA Database Development with Generative AI Support for HDI Artifacts</title>
    <updated>2026-01-05T11:48:26.474000+01:00</updated>
    <author>
      <name>Sushil01</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/160869</uri>
    </author>
    <content>&lt;DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;STRONG&gt;Introduction&lt;/STRONG&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;Authoring HDI (HANA Deployment Infrastructure) artifacts‚Äîsuch &lt;/SPAN&gt;&lt;SPAN&gt;as&lt;/SPAN&gt;&lt;SPAN&gt; tables, views, roles, and synonyms‚Äîoften starts &lt;/SPAN&gt;&lt;SPAN&gt;with&lt;/SPAN&gt;&lt;SPAN&gt; a specification and ends &lt;/SPAN&gt;&lt;SPAN&gt;with&lt;/SPAN&gt;&lt;SPAN&gt; carefully structured definitions. This update streamlines the journey by adding a Joule icon directly &lt;/SPAN&gt;&lt;SPAN&gt;in&lt;/SPAN&gt;&lt;SPAN&gt; the editor. One click opens Joule &lt;/SPAN&gt;&lt;SPAN&gt;with&lt;/SPAN&gt;&lt;SPAN&gt; the /hdi-gen slash command preselected, so you can describe what you need &lt;/SPAN&gt;&lt;SPAN&gt;in&lt;/SPAN&gt;&lt;SPAN&gt; natural language and receive a ready-to-use HDI artifact definition.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;STRONG&gt;What‚Äôs new&lt;/STRONG&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Joule icon &lt;/SPAN&gt;&lt;SPAN&gt;in&lt;/SPAN&gt;&lt;SPAN&gt; the editor: Visible when a supported HDI artifact file is active&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;One-click, context-aware start: Opens Joule &lt;/SPAN&gt;&lt;SPAN&gt;with&lt;/SPAN&gt;&lt;SPAN&gt; /hdi-gen preselected for HDI generation&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Natural language to HDI: Describe the artifact you want and receive a valid HDI definition&lt;/LI&gt;&lt;LI&gt;Clear, safe application: Options to append to your file or replace its content&lt;/LI&gt;&lt;/UL&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;STRONG&gt;How it works&lt;/STRONG&gt;&lt;/DIV&gt;&lt;BR /&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Open a supported HDI artifact file (for example, a table, view, role, or synonym).&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&amp;nbsp;Click the Joule icon &lt;SPAN&gt;in&lt;/SPAN&gt;&lt;SPAN&gt; the editor title bar.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Joule opens &lt;SPAN&gt;with&lt;/SPAN&gt;&lt;SPAN&gt; /hdi-gen preselected.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Describe what you want (for example: ‚ÄúCreate a ROW table CUSTOMERS with ID INTEGER primary key and NAME NVARCHAR(&lt;SPAN&gt;100&lt;/SPAN&gt;&lt;SPAN&gt;)‚Äù).&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Joule returns a definition aligned &lt;SPAN&gt;with&lt;/SPAN&gt;&lt;SPAN&gt; HDI best practices and your current file context.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Apply the result:&lt;UL&gt;&lt;LI&gt;Append adds content to the end &lt;SPAN&gt;of&lt;/SPAN&gt;&lt;SPAN&gt; your file&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Replace substitutes the entire file content&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;The experience covers a broad range &lt;/SPAN&gt;&lt;SPAN&gt;of&lt;/SPAN&gt;&lt;SPAN&gt; HDI artifacts, including (but not limited to) tables, views, roles, synonyms, sequences, structured privileges, triggers, table data (hdbtabledata/csv), logical schemas, virtual tables, and related configuration files. The icon appears only when a supported file &lt;/SPAN&gt;&lt;SPAN&gt;type&lt;/SPAN&gt;&lt;SPAN&gt; is active and is opened in &lt;U&gt;&lt;STRONG&gt;Code Editor&lt;/STRONG&gt;&lt;/U&gt;.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;STRONG&gt;Built-in guardrails&lt;/STRONG&gt;&lt;/DIV&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Native HDI syntax: No CREATE/DROP statements; output follows HDI file conventions&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Identifier style: Uppercase identifiers by &lt;SPAN&gt;default&lt;/SPAN&gt;&lt;SPAN&gt;, unless you specify otherwise&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Table data: For hdbtabledata/csv, sample rows are generated without header lines&lt;/LI&gt;&lt;/UL&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;STRONG&gt;Why this matters&lt;/STRONG&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;OL&gt;&lt;LI&gt;&lt;SPAN&gt;Reduce time from requirement to definition &lt;/SPAN&gt;&lt;SPAN&gt;using&lt;/SPAN&gt;&lt;SPAN&gt; natural language&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Keep control: You decide when and how the result is applied&lt;/LI&gt;&lt;LI&gt;Maintain clarity: Generated content is visibly sectioned for quick review and versioning&lt;/LI&gt;&lt;LI&gt;Improve consistency: Definitions follow HDI best practices&lt;/LI&gt;&lt;/OL&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;STRONG&gt;Getting started&lt;/STRONG&gt;&lt;/DIV&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Open a supported HDI artifact file &lt;/SPAN&gt;&lt;SPAN&gt;in&lt;/SPAN&gt;&lt;SPAN&gt; your editor&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;Click the in-editor Joule icon(appears on top-right corner of the editor)&lt;/LI&gt;&lt;LI&gt;Describe your requirement and apply the result&lt;/LI&gt;&lt;/UL&gt;&lt;DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;This enhancement brings conversational HDI generation directly into your editor. With the Joule icon and /hdi-gen preselected, you can move from intent to artifact faster‚Äîwithout sacrificing clarity, safety, or control.&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;STRONG&gt;Supported artifacts&lt;/STRONG&gt;&lt;/DIV&gt;&lt;DIV&gt;&amp;nbsp;&lt;/DIV&gt;&lt;DIV&gt;&lt;FONT color="#808080"&gt;&lt;EM&gt;csv, hdbapplicationtime, hdbcollection, hdbconstraint, hdbdropcreatetable, hdbeshconfig, hdbfunction, hdbgraphworkspace, hdbgrants, hdbindex, hdblibrary, hdblogicalschema, hdblogicalschemaconfig, hdbmigrationtable, hdbprocedure, hdbprojectionview, hdbprojectionviewconfig, hdbpublicsynonym, hdbresultcache, hdbrole, hdbroleconfig, hdbsequence, hdbstatistics, hdbstructuredprivilege, hdbsynonym, hdbsynonymconfig, hdbsystemversioning, hdbtable, hdbtabledata, hdbtabletype, hdbtrigger, hdbview, hdbvirtualprocedure, hdbvirtualtable, hdbvirtualtableconfig, hdinamespace, properties&lt;/EM&gt;&lt;/FONT&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;STRONG&gt;&amp;nbsp;&lt;/STRONG&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;&lt;/DIV&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/enhancing-sap-hana-database-development-with-generative-ai-support-for-hdi/ba-p/14294318"/>
    <published>2026-01-05T11:48:26.474000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/artificial-intelligence-blogs-posts/beyond-vectors-the-next-evolution-of-rag-on-sap-btp-using-sap-hana-cloud/ba-p/14301103</id>
    <title>Beyond Vectors: The Next Evolution of RAG on SAP BTP using SAP HANA Cloud</title>
    <updated>2026-01-05T16:24:19.911000+01:00</updated>
    <author>
      <name>Gunter</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/727</uri>
    </author>
    <content>&lt;H2 id="toc-hId-1787644355"&gt;&lt;STRONG&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Gemini_Generated_Image_y4jpb8y4jpb8y4jp.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/358043i322E944DE1F47984/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Gemini_Generated_Image_y4jpb8y4jpb8y4jp.png" alt="Gemini_Generated_Image_y4jpb8y4jpb8y4jp.png" /&gt;&lt;/span&gt;&lt;/STRONG&gt;&lt;/H2&gt;&lt;H2 id="toc-hId-1591130850"&gt;&lt;STRONG&gt;Introduction&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;We are all familiar with Retrieval-Augmented Generation (RAG) by now. It has become the standard architecture for bringing enterprise data to Large Language Models (LLMs). The pattern is simple: chunk your documents, create vector embeddings, and perform a similarity search.&lt;/P&gt;&lt;P&gt;But as we move from "Proof of Concept" to production, we are hitting a ceiling.&lt;/P&gt;&lt;P&gt;Standard Vector RAG is excellent at finding things that "sound like" your query (semantic similarity), but it struggles with &lt;STRONG&gt;structure&lt;/STRONG&gt; and &lt;STRONG&gt;reasoning&lt;/STRONG&gt;. It can tell you that "Alice works at SAP," but it often fails at multi-hop questions like "Who works in the same department as the person who wrote the Q3 report?"&lt;/P&gt;&lt;P&gt;This is where &lt;STRONG&gt;GraphRAG&lt;/STRONG&gt; enters the picture. And the best part? If you are on SAP BTP, you already have one of the most powerful engines for this architecture: &lt;STRONG&gt;SAP HANA Cloud&lt;/STRONG&gt;.&lt;/P&gt;&lt;H2 id="toc-hId-1394617345"&gt;&lt;STRONG&gt;The Limitations of "Flat" Data&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;In a standard Vector Store, your data is essentially a pile of isolated chunks. When you search, you grab the top 5 chunks from the pile. You lose the context of how those chunks relate to one another.&lt;/P&gt;&lt;P&gt;This becomes even more critical when dealing with &lt;STRONG&gt;Multimodal Data&lt;/STRONG&gt;. Real-world enterprise documents aren't just text; they are PDFs containing diagrams, flowcharts, and architecture schematics. In a standard vector process, these images are often ignored or separated from the text that explains them.&lt;/P&gt;&lt;H2 id="toc-hId-1198103840"&gt;&lt;STRONG&gt;The Solution: Hybrid GraphRAG&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;The next evolution of AI on SAP BTP isn't about choosing between Vector Search or Knowledge Graphs. It is about using &lt;STRONG&gt;both&lt;/STRONG&gt;. I have been exploring a "Hybrid" approach where we use:&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;The Vector Engine&lt;/STRONG&gt; (built into SAP HANA Cloud) for fuzzy, semantic search.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;The Graph Engine&lt;/STRONG&gt; (RDF/SPARQL in SAP HANA Cloud) for precise, structured relationships.&lt;/P&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;Imagine SAP HANA Cloud as a "Super Librarian." It has a messy pile of fuzzy ideas (Vectors) and a neat corkboard of connected facts (The Knowledge Graph). To answer a complex business question, the system checks the fuzzy pile to understand the &lt;I&gt;intent&lt;/I&gt;, but validates the answer against the corkboard to ensure &lt;I&gt;factual accuracy&lt;/I&gt;.&lt;/P&gt;&lt;H2 id="toc-hId-1001590335"&gt;&lt;STRONG&gt;Multimodal RAG: Keeping Context Intact&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;One of the most exciting capabilities of this hybrid approach is handling mixed media.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Gemini_Generated_Image_a8g428a8g428a8g4.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/358044i5A20DB269351B91F/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="Gemini_Generated_Image_a8g428a8g428a8g4.png" alt="Gemini_Generated_Image_a8g428a8g428a8g4.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;When processing complex documentation (like technical manuals or financial reports), we can use the graph to create &lt;STRONG&gt;structural links&lt;/STRONG&gt;. We can index a diagram or an image not just by what is inside it, but by &lt;I&gt;where it sits in the document&lt;/I&gt;.&lt;/P&gt;&lt;P&gt;By modeling the document structure in the Knowledge Graph (e.g., &lt;CODE&gt;TextChunk A&lt;/CODE&gt; -&amp;gt; &lt;CODE&gt;ADJACENT_TO&lt;/CODE&gt; -&amp;gt; &lt;CODE&gt;Image B&lt;/CODE&gt;), we ensure that when an LLM retrieves the text explanation, it automatically pulls the relevant diagram along with it. This creates a true Multimodal RAG experience that "sees" the document the way a human does.&lt;/P&gt;&lt;H2 id="toc-hId-805076830"&gt;&lt;STRONG&gt;Why SAP HANA Cloud?&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;Usually, building this architecture requires a complex stack: a vector database (like Pinecone), a graph database (like Neo4j), and a relational database to glue them together.&lt;/P&gt;&lt;P&gt;SAP HANA Cloud is unique because it is truly &lt;STRONG&gt;multi-model &lt;/STRONG&gt;(yes it's also multimodal with this library). You can store your vectors, your RDF triples, and your relational metadata all in the same persistence layer. This simplifies the architecture immensely and reduces data movement, which is critical for enterprise security and latency.&lt;/P&gt;&lt;H2 id="toc-hId-608563325"&gt;&lt;STRONG&gt;A New Framework for SAP Developers&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;To prove this concept, I have developed a TypeScript framework designed specifically for Node.js environments on SAP BTP. It acts as a bridge, orchestrating the interaction between the LLM (via LiteLLM) and SAP HANA Cloud‚Äôs dual engines.&lt;/P&gt;&lt;P&gt;The framework handles:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Schema-Guided Extraction:&lt;/STRONG&gt; Using LLMs to turn unstructured text into clean Knowledge Graph entities (Nodes and Edges).&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Hybrid Retrieval:&lt;/STRONG&gt; Performing a vector search and then traversing the graph to find related context (including images).&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Unified Storage:&lt;/STRONG&gt; Managing both the &lt;CODE&gt;REAL_VECTOR&lt;/CODE&gt; data and RDF Triples in a single connection.&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-412049820"&gt;&lt;STRONG&gt;Learn More&lt;/STRONG&gt;&lt;/H2&gt;&lt;P&gt;If you are interested in building the next generation of context-aware AI agents on SAP BTP, I invite you to read the full technical breakdown here (collaboration on the repo welcome!):&lt;/P&gt;&lt;P&gt;&lt;span class="lia-unicode-emoji" title=":backhand_index_pointing_right:"&gt;üëâ&lt;/span&gt; &lt;STRONG&gt;&lt;A class="" href="https://medium.com/@techandfun/beyond-vectors-building-powerful-graph-rag-on-sap-btp-with-hana-cloud-50da841bb31f" target="_blank" rel="noopener nofollow noreferrer"&gt;Read the full article on Medium: Beyond Vectors - Building Powerful Graph RAG on SAP BTP&lt;/A&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Let‚Äôs move beyond simple similarity search and start building AI that truly understands the structure of our enterprise data.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/artificial-intelligence-blogs-posts/beyond-vectors-the-next-evolution-of-rag-on-sap-btp-using-sap-hana-cloud/ba-p/14301103"/>
    <published>2026-01-05T16:24:19.911000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/simplifying-time-series-analytics-with-unified-time-series-interface/ba-p/14292218</id>
    <title>Simplifying Time Series Analytics with Unified Time Series Interface</title>
    <updated>2026-01-08T23:36:27.942000+01:00</updated>
    <author>
      <name>zhengwang</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/893377</uri>
    </author>
    <content>&lt;P&gt;Time series analysis is fundamental in industries ranging from retail to finance, helping businesses forecast trends, predict anomalies, and optimize operations. Traditional approaches, however, often require complex preprocessing, data conversion, and algorithm selection, posing challenges for less technical users.&lt;/P&gt;&lt;P&gt;To address these issues, &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/sap-hana-cloud-sap-hana-database-predictive-analysis-library-pal" target="_self" rel="noopener noreferrer"&gt;SAP HANA Predictive Analysis Library (PAL)&lt;/A&gt; has introduced a unified interface for time series algorithms. Following the successful implementation of its unified classification and regression interfaces, this update aims to make time series analysis more efficient and user-friendly.&lt;/P&gt;&lt;P&gt;In this blog post, we explore the latest features of this unified interface and showcase an example to illustrate its usage.&lt;/P&gt;&lt;H1 id="toc-hId-1638274962"&gt;Key Highlights&lt;/H1&gt;&lt;P&gt;Let‚Äôs dive into new interface's key features in detail:&lt;/P&gt;&lt;H3 id="toc-hId-1699926895"&gt;Unified Workflow&lt;/H3&gt;&lt;P&gt;The unified interface streamlines the management of PAL algorithms by providing a standardized structure for invoking them. This simplifies parameter handling and data preparation for individual algorithms, enhancing efficiency and ease of use. Supported algorithms include Additive Model Time Series Analysis (AMTSA), Auto Regressive Integrated Moving Average (ARIMA), Bayesian Structural Time Series (BSTS), and Exponential Smoothing (SMOOTH).&lt;/P&gt;&lt;H3 id="toc-hId-1503413390"&gt;Automatic Timestamp Conversion&lt;/H3&gt;&lt;P&gt;The datasets of different time series analysis tasks can have diverse time formats, therefore automatic timestamp conversion is introduced in new unified interface. This feature automatically detects and converts between integer timepoints and timestamp types.&amp;nbsp;To convert timepoints to timestamps, users must define START_POINT and INTERVAL. INTERVAL represents the spacing between timestamps, measured in the smallest unit of the target type (TARGET_TYPE). For instance, if the target type is DAYDATE and a weekly interval is desired, the INTERVAL value would be set to 7. Conversely, converting timestamps to timepoints is automated, with the system generating consecutive integers based on input timestamps. However, the input timestamps should be evenly spaced for this conversion to function effectively.&lt;/P&gt;&lt;H3 id="toc-hId-1306899885"&gt;Pivoted Input Data Format Support&lt;/H3&gt;&lt;P&gt;Traditionally, additional steps are required to transform the pivoted data into a usable format. To simplify this data preparation process, the new unified interface directly supports pivoted input data formats. This feature is particularly beneficial for complex, multidimensional time series data. The&amp;nbsp;structure of input data is&amp;nbsp;&lt;SPAN&gt;defined&lt;/SPAN&gt; in the metadata table,&amp;nbsp; as&amp;nbsp;&lt;SPAN&gt;illustrated&amp;nbsp;&lt;/SPAN&gt;below.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;CREATE COLUMN TABLE PAL_META_DATA_TBL (
    "VARIABLE_NAME" NVARCHAR (50),
    "VARIABLE_TYPE" NVARCHAR (50)
);
INSERT INTO PAL_META_DATA_TBL VALUES ('TIMESTAMP', 'CONTINUOUS');
INSERT INTO PAL_META_DATA_TBL VALUES ('Y', 'TARGET');&lt;/code&gt;&lt;/pre&gt;&lt;H3 id="toc-hId-1110386380"&gt;Massive Mode Capability&lt;/H3&gt;&lt;P&gt;When dealing with vast datasets, users can leverage "massive mode" in unified interface. This mode enables algorithms to process multiple datasets simultaneously, with each dataset being executed independently and in parallel. To learn more about massive mode, visit the page on &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/massive-execution-of-pal-functions" target="_self" rel="noopener noreferrer"&gt;Massive Execution of PAL Functions&lt;/A&gt;.&lt;/P&gt;&lt;H1 id="toc-hId-655707437"&gt;Example&lt;/H1&gt;&lt;P&gt;Let‚Äôs demonstrate the new interface with an example. Note that the code provided is purely for illustrative purposes and is not intended for production use.&lt;/P&gt;&lt;P&gt;The dataset is the &lt;A href="https://archive.ics.uci.edu/dataset/381/beijing+pm2+5+data" target="_self" rel="nofollow noopener noreferrer"&gt;Beijing PM2.5&lt;/A&gt; data from the UCI Machine Learning Repository. It comprises hourly recordings of PM2.5 levels (airborne particles with aerodynamic diameters less than 2.5‚ÄâŒºm) collected by the US Embassy in Beijing between January 1, 2010, and December 31, 2014. Additionally, meteorological data from Beijing Capital International Airport is included. The objective is to predict PM2.5 concentrations using various input features.&lt;/P&gt;&lt;P&gt;This dataset contains 43,824 rows and 11 columns. During preprocessing, the year, month, day, and hour columns were merged into a single 'date' column, and rows with missing values were addressed. The restructured dataset included the following 9 columns.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;date: Timestamp of the record&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;pollution: PM2.5 concentration (ug/m^3)&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;dew: Dew Point&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;temp: Temperature&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;press: Pressure (hPa)&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;wnd_dir: Combined wind direction&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;wnd_spd: Cumulated wind speed (m/s)&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;snow: Cumulated hours of snow&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;rain: Cumulated hours of rain&lt;/P&gt;&lt;P&gt;To make it more manageable for demonstration purposes, we selected the first 1,000 instances. From this selection, we allocated 990 instances to the training set and reserved the final 10 for the testing set. Here's a glimpse at the first five rows of the training set.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="UnifiedTimeSeries_1_TrainingData.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/352976iC62DF756524E4971/image-size/large?v=v2&amp;amp;px=999" role="button" title="UnifiedTimeSeries_1_TrainingData.png" alt="UnifiedTimeSeries_1_TrainingData.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Once the data is loaded, the model can be trained, and results can be obtained using the following annotated SQL script.&lt;/P&gt;&lt;pre class="lia-code-sample language-sql"&gt;&lt;code&gt;--########## COLUMN TABLE CREATION ##########
CREATE COLUMN TABLE PAL_PARAMETER_TBL__0 ("PARAM_NAME" NVARCHAR(256), "INT_VALUE" INTEGER, "DOUBLE_VALUE" DOUBLE, "STRING_VALUE" NVARCHAR(1000));
CREATE COLUMN TABLE PAL_MODEL_TBL__0 ("INDEX" NVARCHAR (50), "CONTENT" NCLOB);
CREATE COLUMN TABLE PAL_STATISTICS_TBL__0 ("NAME" NVARCHAR (50), "VALUE_1" DOUBLE, "VALUE_2" DOUBLE, "VALUE_3" DOUBLE, "VALUE_4" DOUBLE, "VALUE_5" DOUBLE, "REASON" NVARCHAR (50));
CREATE COLUMN TABLE PAL_DECOMPOSE_TBL__0 ("TIME_STAMP" NVARCHAR (50), "TREND" DOUBLE, "SEASONAL" DOUBLE, "REGRESSION" DOUBLE, "RANDOM" DOUBLE);
CREATE COLUMN TABLE PAL_PLACE_HOLDER_TBL__0 ("OBJECT" NVARCHAR (10), "KEY" NVARCHAR (10), "VALUE" NVARCHAR (10));
CREATE COLUMN TABLE PAL_PREDICT_PARAMETER_TBL__0 ("PARAM_NAME" NVARCHAR(256), "INT_VALUE" INTEGER, "DOUBLE_VALUE" DOUBLE, "STRING_VALUE" NVARCHAR(1000));
CREATE COLUMN TABLE PAL_PREDICT_RESULT_TBL__0 ("TIME_STAMP" NVARCHAR (50), "FORECAST" DOUBLE, "VALUE_1" DOUBLE, "VALUE_2" DOUBLE, "VALUE_3" DOUBLE, "VALUE_4" DOUBLE, "VALUE_5" DOUBLE);
CREATE COLUMN TABLE PAL_PREDICT_DECOMPOSITION_TBL__0 ("TIME_STAMP" NVARCHAR (50), "VALUE_1" DOUBLE, "VALUE_2" NCLOB, "VALUE_3" NCLOB, "VALUE_4" NCLOB, "VALUE_5" NCLOB);
CREATE COLUMN TABLE PAL_PREDICT_PLACE_HOLDER_TBL__0 ("OBJECT" NVARCHAR (50), "KEY" NVARCHAR (50), "VALUE" NVARCHAR (50));

--########## TABLE INSERTS ##########
-- The training data is stored in PAL_DATA_TBL__0, and the prediction data in PAL_PREDICT_DATA_TBL__0.
--########## PAL_PARAMETER_TBL__0 DATA INSERTION ##########
-- Specify algorithm type, 0: AMTSA, 1: ARIMA, 2: BSTS, 3: SMOOTH
INSERT INTO PAL_PARAMETER_TBL__0 VALUES ('FUNCTION', 0, NULL, NULL);

--########## UNIFIED INTERFACE FOR TIME SERIES CALL ##########
DO BEGIN
  lt_data = SELECT * FROM PAL_DATA_TBL__0;
  lt_param = SELECT * FROM PAL_PARAMETER_TBL__0;
  CALL _SYS_AFL.PAL_UNIFIED_TIMESERIES (:lt_data, :lt_param, lt_model, lt_stat, lt_decom, lt_ph);
  lt_pdata = SELECT * FROM PAL_PREDICT_DATA_TBL__0;
  lt_pparam = SELECT * FROM PAL_PREDICT_PARAMETER_TBL__0;
  CALL _SYS_AFL.PAL_UNIFIED_TIMESERIES_PREDICT (:lt_pdata, :lt_model, :lt_pparam, lt_result, lt_decomp, lt_pph);
  INSERT INTO PAL_PREDICT_RESULT_TBL__0 SELECT * FROM :lt_result;
  INSERT INTO PAL_PREDICT_DECOMPOSITION_TBL__0 SELECT * FROM :lt_decomp;
END;

--########## SELECT * TABLES ##########
SELECT * FROM PAL_PREDICT_RESULT_TBL__0;
SELECT * FROM PAL_PREDICT_DECOMPOSITION_TBL__0;

--########## TABLES CLEANUP ##########
DROP TABLE PAL_PARAMETER_TBL__0;
DROP TABLE PAL_MODEL_TBL__0;
DROP TABLE PAL_STATISTICS_TBL__0;
DROP TABLE PAL_DECOMPOSE_TBL__0;
DROP TABLE PAL_PLACE_HOLDER_TBL__0;
DROP TABLE PAL_PREDICT_PARAMETER_TBL__0;
DROP TABLE PAL_PREDICT_RESULT_TBL__0;
DROP TABLE PAL_PREDICT_DECOMPOSITION_TBL__0;
DROP TABLE PAL_PREDICT_PLACE_HOLDER_TBL__0;&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;You can view the model, prediction results, and decomposition in the output tables. Below are illustrative snapshots of the output tables.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="UnifiedTimeSeries_2_Result.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/352977iF0ECDD0DEB22037E/image-size/large?v=v2&amp;amp;px=999" role="button" title="UnifiedTimeSeries_2_Result.png" alt="UnifiedTimeSeries_2_Result.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="UnifiedTimeSeries_3_Decomposition.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/352978i0276F55EC34A8260/image-size/large?v=v2&amp;amp;px=999" role="button" title="UnifiedTimeSeries_3_Decomposition.png" alt="UnifiedTimeSeries_3_Decomposition.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The composition of the resulting tables depends on the selected algorithm. For AMTSA, the result table includes the predicted values along with the lower and upper bounds of the uncertainty intervals. Additionally, the decomposition table provides various components, such as trend, seasonality, and others.&lt;/P&gt;&lt;H1 id="toc-hId-459193932"&gt;Summary&lt;/H1&gt;&lt;P&gt;The unified interface is introduced to simplify the usage of PAL algorithms. This blog post highlights the key features addressing challenges in time series analysis, such as varied time formats, pivoted data structures, and handling large data volumes. This new interface makes it easier for users to unlock the potential of their temporal data.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Recent topics on HANA machine learning:&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/comprehensive-guide-to-mltrack-in-sap-hana-cloud-end-to-end-machine/ba-p/14134217" target="_self"&gt;Comprehensive Guide to MLTrack in SAP HANA Cloud: End-to-End Machine Learning Experiment Tracking&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-and-ai-features-in-sap-hana-cloud-2025-q2/ba-p/14136079" target="_self"&gt;New Machine Learning and AI features in SAP HANA Cloud 2025 Q2&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-and-ai-features-in-sap-hana-cloud-2025-q1/ba-p/14078615" target="_self"&gt;New Machine Learning and AI features in SAP HANA Cloud 2025 Q1&lt;/A&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/simplifying-time-series-analytics-with-unified-time-series-interface/ba-p/14292218"/>
    <published>2026-01-08T23:36:27.942000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-nlp-and-ai-features-in-sap-hana-cloud-2025-q3/ba-p/14304443</id>
    <title>New Machine Learning, NLP and AI features in SAP HANA Cloud 2025 Q3</title>
    <updated>2026-01-09T12:54:46.437000+01:00</updated>
    <author>
      <name>ChristophMorgen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/14106</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;With the SAP HANA Cloud 2025 Q3 release, several new embedded Machine Learning / AI functions&amp;nbsp;have been released with the SAP HANA Cloud Predictive Analysis Library (PAL) and the Automated Predictive Library (APL). &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;An enhancement summary is available in the What‚Äôs new document for &lt;A href="https://help.sap.com/whats-new/2495b34492334456a49084831c2bea4e?Category=Predictive+Analysis+Library&amp;amp;Valid_as_Of=2025-09-01:2025-09-30&amp;amp;locale=en-US" target="_self" rel="noopener noreferrer"&gt;SAP HANA Cloud database 2025.28 (QRC 3/2025)&lt;/A&gt;.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H2 id="toc-hId-1787736735"&gt;&amp;nbsp;&lt;/H2&gt;&lt;H2 id="toc-hId-1591223230"&gt;&lt;SPAN&gt;Time series analysis and forecasting function enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Threshold support in timeseries outlier detection &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;In time series, an outlier is a data point that is different from the general behavior of remaining data points.&amp;nbsp; In the PAL &lt;STRONG&gt;&lt;EM&gt;time series outlier detection&lt;/EM&gt;&lt;/STRONG&gt; function, the outlier detection task is divided into two steps&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;In step 1 the residual values are derived from the original series, &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;In step 2, the outliers are detected from the residual values.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;Multiple methods are available to evaluate a data point to be an outlier or not. &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Including Z1 score, Z2 score, IIQR score, MAD score, IsolationForest, DBSCAN&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;If used in combination, outlier voting can be applied for a combined evaluation.&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;Now, &lt;STRONG&gt;new&lt;/STRONG&gt; and in addition, &lt;STRONG&gt;&lt;EM&gt;thresholds values for outlier scores&lt;/EM&gt;&lt;/STRONG&gt; are supported&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;New parameter OUTPUT_OUTLIER_THRESHOLD &lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Based on the given threshold value, if the time series value is beyond the (upper and lower) outlier threshold for the time series, the corresponding data point as an outlier.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Only valid when outlier_method = 'iqr', 'isolationforest', 'mad', 'z1', 'z2'.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_0-1767958753257.jpeg" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/359750iE20F7716FF87FA07/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_0-1767958753257.jpeg" alt="ChristophMorgen_0-1767958753257.jpeg" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;H2 id="toc-hId-1394709725"&gt;&lt;SPAN&gt;Classification and regression function enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Corset sampling support with SVM models&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Coreset sampling&lt;/STRONG&gt;&amp;nbsp;is a machine learning technique to&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;select a small, representative subset (the "coreset") from larger datasets,&lt;/LI&gt;&lt;LI&gt;enabling faster, more efficient training and processing while maintaining similar model accuracy as using the full data.&lt;/LI&gt;&lt;LI&gt;It works by identifying the most "informative" samples, filtering out redundant or noisy data, and allowing complex algorithms to run on a manageable dataset sizes.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Support Vector Machine (SVM)&lt;/STRONG&gt;&amp;nbsp;model training is computationally expensive, and computational costs are specifically sensitive to the number of training points, which makes SVM models often impractical for large datasets.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Therefore SVM in the Predictive Analysis Library has been enhanced and now&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;offers&amp;nbsp;&lt;STRONG&gt;embedded coreset sampling&lt;/STRONG&gt;&amp;nbsp;capabilities&lt;/LI&gt;&lt;LI&gt;enabled with the new parameters USE_CORESET and CORESET_SCALE as the &lt;SPAN&gt;sampling ratio when constructing coreset&lt;/SPAN&gt;.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;This enhancement significantly reduces SVM training time with minimal impact on accuracy.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="ChristophMorgen_1-1767958753264.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/359751iDA955B4D29D2C3A9/image-size/large/is-moderation-mode/true?v=v2&amp;amp;px=999" role="button" title="ChristophMorgen_1-1767958753264.png" alt="ChristophMorgen_1-1767958753264.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-1198196220"&gt;&lt;SPAN&gt;AutoML and pipeline function enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Target encoding support in&amp;nbsp;AutoML&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The PAL AutoML framework introduces a new pipeline operator for target encoding of categorial features&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Categorical data is often required to be preprocessed and required to get converted from non-numerical features into formats suitable for the respective machine learning algorithm, i.e. numeric values&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Examples features: text labels (e.g., ‚Äúred,‚Äù ‚Äúblue‚Äù) or discrete categories (e.g., ‚Äúhigh,‚Äù ‚Äúmedium,‚Äù ‚Äúlow‚Äù)&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;One-hot encoding converts each categorial feature value &amp;nbsp;into a binary column (0 or 1), which works well for features with a limited number of unique values. PAL already applies an optimized one-hot encoding method aggregating very low frequent values.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Target encoding replaces the categorial values with the mean of the target / label column for high-cardinality features, which avoids to create large and sparse one-hot encoded feature matrices&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Example of a high cardinality feature: ‚Äúcity‚Äù column with hundreds-thousands of unique values, postal code, product IDs etc.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The PAL AutoML engine will analyze the input feature cardinality and then automatically decide if to apply target encoding or another encoding method. For medium to high cardinality categorial features, target encoding may improve the performance significantly.&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;By automating target encoding, the PAL AutoML engine aims to improve model performance and generalization, especially when dealing with complex, high-cardinality categorical features, without requiring manual intervention.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;In addition, the AutoML and pipeline function now also support columns of type half precision vector.&lt;/P&gt;&lt;H2 id="toc-hId-1001682715"&gt;&amp;nbsp;&lt;/H2&gt;&lt;H2 id="toc-hId-805169210"&gt;&lt;SPAN&gt;Misc. Machine Learning and statistics function enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;High-dimensional feature data reduction using UMAP&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;UMAP (Uniform Manifold Approximation and Projection) is a non-linear dimensionality reduction algorithm used to simplify complex, high-dimensional feature spaces, while preserving its essential structure. It is widely considered the modern gold standard for visualizing targeted dimension reduction of large-scale datasets, because it balances computational speed with the ability to maintain both local and global relationships.&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;It reduces thousands of variables (dimensions) into 2D or 3D scatter plots that humans can easily interpret.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Unlike comparable methods like t-SNE, UMAP is better at preserving global structure, meaning the relative positions between different clusters remain more meaningful.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;It is significantly faster and more memory-efficient than t-SNE, capable of processing datasets with millions of points in a reasonable timeframe.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;It can be used as a "transformer" preprocessing step in Machine Learning scenarios to reduce large feature spaces before applying clustering (e.g., k-means, HDBSCAN) or classification models, often improving their performance.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;The following new functions are introduced&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;_SYS_AFL.PAL_UMAP&lt;/SPAN&gt;‚Äã with the most important &lt;SPAN&gt;parameters N_NEIGHBORS, MIN_DIST, N_COMPONENTS, DISTANCE_LEVEL&lt;/SPAN&gt;‚Äã&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;_SYS_AFL.PAL_TRUSTWORTHINESS&lt;/SPAN&gt;‚Äã, u&lt;SPAN&gt;sed to measure the structure similarity between original high dimensional space and embedded low dimensional space based on K nearest neighbors.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Calculating pairwise distances&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Many algorithms, for example clustering algorithms utilize distance matrixes as a preprocessing step, often inbuild to the functions. While often there is the wish to decouple though the distance matrix calculation from the follow-up task like the actual clustering. Moreover, if decoupled custom calculated matrixes can be fed into algorithms as input.&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Most PAL clustering functions support to feed-in a pre-calculated similarity matrix&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;Now, a dedicated &lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-predictive-analysis-library/distance-md?version=LATEST&amp;amp;q=distance&amp;amp;locale=en-US" target="_blank" rel="noopener noreferrer"&gt;pairwise distance calculation&lt;/A&gt; function is provided &lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;It supports distance metrics like &lt;EM&gt;Manhattan, Euclidien, Minkowski, Chebyshey&lt;/EM&gt; as well as &lt;STRONG&gt;Levenshtein&lt;/STRONG&gt;&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;The &lt;STRONG&gt;&lt;EM&gt;Levenshtein distance&lt;/EM&gt;&lt;/STRONG&gt; (or ‚Äúedit distance‚Äù) is a distance metric specifically targeting distance between text-columns. &lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;It calculates the minimum number of single-character edits (insertions, deletions, or substitutions) needed to transform one word into another, acting as a measure of their similarity. A lower distance indicates a higher similarity.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;Applicable use cases&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;It is useful in data cleaning, table column similarity analysis between columns of the same data type.&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;After calculating the column similarity across all data types, clustering like K-Means can be applied to group similar fields and propose mappings for fields within the same cluster&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Real Vector data type support&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;The following PAL functions have been enhanced to support columns of type real vector&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Spectral Clustering&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Cluster Assignment&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Decision tree&lt;/SPAN&gt;&lt;/LI&gt;&lt;LI&gt;&lt;SPAN&gt;Sampling&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;In addition the AutoML and pipeline function now also support columns of type half precision vector.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-608655705"&gt;&lt;SPAN&gt;Creating Vector Embeddings enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;SPAN&gt;The SAP HANA Database Vector Engine function VECTOR_EMBEDDING()&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;has added support for remote, SAP AI Core exposed embedding models. Detailed instruction are given in the documentation at&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/creating-text-embeddings-with-sap-ai-core" target="_blank" rel="noopener noreferrer"&gt;Creating Text Embeddings with SAP AI Core | SAP Help Portal&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;H2 id="toc-hId-412142200"&gt;&lt;SPAN&gt;Python ML client (hana-ml) enhancements&lt;/SPAN&gt;&lt;/H2&gt;&lt;P&gt;&lt;EM&gt;The full list of new methods and enhancements with hana_ml 2.26&amp;nbsp; is summarized in the &lt;/EM&gt;&lt;SPAN&gt;&lt;A href="https://help.sap.com/doc/cd94b08fe2e041c2ba778374572ddba9/2025_3_QRC/en-US/change_log.html" target="_blank" rel="noopener noreferrer"&gt;&lt;EM&gt;changelog for hana-ml 2.26&lt;/EM&gt;&lt;/A&gt; &lt;/SPAN&gt;&lt;EM&gt;as part of the documentation. The key enhancements in this release include&lt;/EM&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;New&amp;nbsp;Functions&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Added text tokenization API.&lt;/LI&gt;&lt;LI&gt;Added explainability support with IsolationForest Outlier Detection&lt;/LI&gt;&lt;LI&gt;Added constrained clustering API.&lt;/LI&gt;&lt;LI&gt;Added intermittent time series data test in time series report.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Enhancements&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Support time series SHAP visualizations for AutoML Timeseries model explanations&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;You can find an examples notebook illustrating the highlighted feature enhancements &lt;SPAN&gt;&lt;A href="https://github.com/SAP-samples/hana-ml-samples/blob/main/Python-API/pal/notebooks/25QRC03_2.26.ipynb" target="_blank" rel="nofollow noopener noreferrer"&gt;here 25QRC03_2.26.ipynb&lt;/A&gt;.&amp;nbsp; &lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-blog-posts-by-sap/new-machine-learning-nlp-and-ai-features-in-sap-hana-cloud-2025-q3/ba-p/14304443"/>
    <published>2026-01-09T12:54:46.437000+01:00</published>
  </entry>
</feed>
