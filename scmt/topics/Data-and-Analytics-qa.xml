<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/Data-and-Analytics-qa.xml</id>
  <title>SAP Community - Data and Analytics</title>
  <updated>2025-12-17T00:00:15.482194+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/Data and Analytics/pd-p/87817424-f4e7-46f2-af14-88bf0f4ba034" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>Data and Analytics Q&amp;A in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/some-duplicated-values-on-sac-export/qaq-p/14214955</id>
    <title>Some duplicated values on SAC export</title>
    <updated>2025-09-11T17:15:24.026000+02:00</updated>
    <author>
      <name>NewLearner1</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2042646</uri>
    </author>
    <content>&lt;P&gt;Hello, I'm kinda stumped by something and need any help I could get.&amp;nbsp;&lt;/P&gt;&lt;P&gt;I've built a dashoard on SAC which is a big inventory table. When I export the table to Excel, some rows (around 2 or 3% of the total) display duplicated values on Excel. However, on the SAC interface and on DSP, they're showing the correct values.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Any idea what is happening?&amp;nbsp;&lt;/P&gt;&lt;P&gt;EDIT: Thank you for responses, I figured out what was the origin of the issue: I had two calculated dimension using the same field, when I took these off, my export was correct. We suspect it might be related to language translation on those fileds, we will be opening a case with SAP.&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/some-duplicated-values-on-sac-export/qaq-p/14214955"/>
    <published>2025-09-11T17:15:24.026000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/dataphere-and-custom-cds-views/qaq-p/14215931</id>
    <title>Dataphere and Custom CDS views</title>
    <updated>2025-09-12T16:32:36.493000+02:00</updated>
    <author>
      <name>exoyanniiyeze</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2007898</uri>
    </author>
    <content>&lt;P&gt;Hello,&lt;/P&gt;&lt;P&gt;I'm wondering, is it possible to use Datasphere delta refresh option with custom CDS views ?&lt;BR /&gt;If yes what should I do first ?&lt;/P&gt;&lt;P&gt;Thanks for your help.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/dataphere-and-custom-cds-views/qaq-p/14215931"/>
    <published>2025-09-12T16:32:36.493000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/cds-view-which-annotations-do-i-need-for-bw-extraction-cds-entity/qaq-p/14217580</id>
    <title>CDS view: Which annotations do I need for BW extraction? (CDS entity)</title>
    <updated>2025-09-15T15:30:22.087000+02:00</updated>
    <author>
      <name>yj</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/245738</uri>
    </author>
    <content>&lt;P&gt;Dear all,&lt;/P&gt;&lt;P&gt;I need to extract data from a custom table in S/4HANA to BW/4HANA. To achieve this, I've created a CDS view defined as view entity.&lt;BR /&gt;When adding the annotation&amp;nbsp; Analytics.dataExtraction.enabled = true , the message "data extraction for CDS entity is not possible" is shown. I have read, that I should change the property "API state" of the CDS view to enable the use as "Remote API (Contract C2)". But when activating this, the following warnings are shown:&lt;/P&gt;&lt;P&gt;Use of annotation ABAPCATALOG.VIEWENHANCEMENTCATEGORY is not allowed.&lt;BR /&gt;Use of annotation ANALYTICS.DATACATEGORY is not allowed.&lt;BR /&gt;Use of annotation ANALYTICS.DATAEXTRACTION.DELTA.CHANGEDATACAPTURE.AUTOMATIC is not allowed.&lt;BR /&gt;Use of annotation ANALYTICS.DATAEXTRACTION.ENABLED is not allowed.&lt;/P&gt;&lt;P&gt;This is my CDS coding:&lt;/P&gt;&lt;P&gt;&lt;FONT face="courier new,courier"&gt;&lt;SPAN&gt;@AbapCatalog.viewEnhancementCategory:&lt;/SPAN&gt; &lt;SPAN&gt;[#NONE]&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;@AccessControl.authorizationCheck:&lt;/SPAN&gt; &lt;SPAN&gt;#NOT_REQUIRED&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;@EndUserText.label:&lt;/SPAN&gt; &lt;SPAN&gt;'CDS-based BW extraction: table Zxxx_ABC'&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;@Metadata.ignorePropagatedAnnotations:&lt;/SPAN&gt; &lt;SPAN&gt;false&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;@ObjectModel.usageType:{&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp; &amp;nbsp; serviceQuality:&lt;/SPAN&gt; &lt;SPAN&gt;#D,&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp; &amp;nbsp; sizeCategory&lt;/SPAN&gt;&lt;SPAN&gt;:&lt;/SPAN&gt; &lt;SPAN&gt;#L,&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp; &amp;nbsp; dataClass:&lt;/SPAN&gt; &lt;SPAN&gt;#MIXED&lt;/SPAN&gt; &lt;SPAN&gt;}&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&lt;a href="https://community.sap.com/t5/user/viewprofilepage/user-id/15206"&gt;@analytics&lt;/a&gt;:&lt;/SPAN&gt; &lt;SPAN&gt;{&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp; &amp;nbsp; dataCategory:&lt;/SPAN&gt; &lt;SPAN&gt;#FACT,&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp; &amp;nbsp; dataExtraction:&lt;/SPAN&gt; &lt;SPAN&gt;{&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp; &amp;nbsp; enabled:&lt;/SPAN&gt; &lt;SPAN&gt;true&lt;/SPAN&gt;&lt;SPAN&gt;,&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp; &amp;nbsp; delta.changeDataCapture.automatic:&lt;/SPAN&gt; &lt;SPAN&gt;true&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;}&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;}&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;DIV&gt;&lt;P&gt;&lt;FONT face="courier new,courier"&gt;&lt;SPAN&gt;define&lt;/SPAN&gt; &lt;SPAN&gt;view&lt;/SPAN&gt; &lt;SPAN&gt;entity&lt;/SPAN&gt; &lt;SPAN&gt;ZC_BW_Zxxx_ABC&lt;/SPAN&gt; &lt;SPAN&gt;as&lt;/SPAN&gt; &lt;SPAN&gt;select&lt;/SPAN&gt; &lt;SPAN&gt;from&lt;/SPAN&gt; &lt;SPAN&gt;Zxxx_ABC&lt;BR /&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&lt;FONT face="courier new,courier"&gt;&lt;SPAN&gt;{&lt;BR /&gt;&lt;/SPAN&gt;...&lt;/FONT&gt;&lt;BR /&gt;&lt;FONT face="courier new,courier"&gt;&lt;SPAN&gt;}&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;/DIV&gt;&lt;P&gt;What is my mistake? Should I ignore the warning messages?&lt;/P&gt;&lt;P&gt;Thanks &amp;amp; kind regards,&lt;BR /&gt;Yvonne&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/cds-view-which-annotations-do-i-need-for-bw-extraction-cds-entity/qaq-p/14217580"/>
    <published>2025-09-15T15:30:22.087000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/integrated-financial-planning-capex-delta-planning-data-action/qaq-p/14219055</id>
    <title>Integrated Financial Planning CAPEX Delta Planning Data Action</title>
    <updated>2025-09-16T19:26:03.963000+02:00</updated>
    <author>
      <name>SANA11</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1696282</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;Hello All,&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;Could anyone please help me with this? I’m reviewing the standard code for the data action &lt;EM&gt;Delta Planning&lt;/EM&gt; in CAPEX. While executing the first part of the code using trace points/debugging, I’m unable to understand the logic behind the value that appears in the &lt;STRONG&gt;AMOUNT_DELTA&lt;/STRONG&gt; measure (750).&lt;/P&gt;&lt;P&gt;Can someone assist me in figuring out how this value is being derived?&lt;/P&gt;&lt;P&gt;this is the logic I am debugging in standard code of calculating depreciation delta amount&amp;nbsp;&lt;/P&gt;&lt;DIV&gt;//-----------------------------------------------------------------------------------&lt;/DIV&gt;&lt;DIV&gt;//Set Configurations Definitions for the Advanced Formulas.&lt;/DIV&gt;&lt;DIV&gt;//------------------------------------------------------------------------------------&lt;/DIV&gt;&lt;DIV&gt;CONFIG.HIERARCHY.INCLUDE_MEMBERS_NOT_IN_HIERARCHY = [d/SAP_ALL_COMPANY_CODE], [d/SAP_FI_IFP_GLACCOUNT], [d/t.S:SAP_ALL_COSTCENTER], [d/t.S:SAP_ALL_PROFITCENTER]&lt;/DIV&gt;&lt;DIV&gt;//-----------------------------------------------------------------------------------&lt;/DIV&gt;&lt;DIV&gt;//The data region against which the formulas will be executed.&lt;/DIV&gt;&lt;DIV&gt;//-----------------------------------------------------------------------------------&lt;/DIV&gt;&lt;DIV&gt;MEMBERSET [d/Measures] = "AMOUNT_DELTA"&lt;/DIV&gt;&lt;DIV&gt;MEMBERSET [d/Date] = [d/Version].[p/StartDate] TO [d/Version].[p/EndDate]&lt;/DIV&gt;&lt;DIV&gt;VARIABLEMEMBER #RESIDUAL_VALUE OF [d/Measures]&lt;/DIV&gt;&lt;DIV&gt;VARIABLEMEMBER #CUMMUL_VALUE OF [d/Measures]&lt;/DIV&gt;&lt;DIV&gt;//-----------------------------------------------------------------------------------&lt;/DIV&gt;&lt;DIV&gt;//Calculation and Data Writing&lt;/DIV&gt;&lt;DIV&gt;//-----------------------------------------------------------------------------------&lt;/DIV&gt;&lt;DIV&gt;//FOREACH [d/Date]&lt;/DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;// Staight-Line Depreciation Method: Cummulative Acquisition Value * Depriciation Percentage / 12 Periods&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;IF RESULTLOOKUP([d/Measures] = "DEPR_METHOD", [d/Date] = [d/Version].[p/StartDate], [d/t.S:SAP_ALL_COSTCENTER] = "#") = 1 THEN&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;DATA([d/Measures] = "AMOUNT_DELTA",[d/SAP_FI_IFP_GLACCOUNT] = [d/SAP_FI_IFP_GLACCOUNT].[p/DepreciationAccount]) =&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;RESULTLOOKUP([d/Measures] = #CUMMUL_VALUE, [d/Date] = PREVIOUS(1)) *&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;RESULTLOOKUP([d/Measures] = "DEPR_PERCENTAGE", [d/Date] = [d/Version].[p/StartDate], [d/t.S:SAP_ALL_COSTCENTER] = "#") / 12&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;SPAN&gt;ENDIF&lt;/SPAN&gt;&lt;/DIV&gt;&lt;DIV&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="SANA11_0-1758042578121.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/315353iBA01A88F7B303DC9/image-size/medium?v=v2&amp;amp;px=400" role="button" title="SANA11_0-1758042578121.png" alt="SANA11_0-1758042578121.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/DIV&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/integrated-financial-planning-capex-delta-planning-data-action/qaq-p/14219055"/>
    <published>2025-09-16T19:26:03.963000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/unable-to-find-defect-table-history-in-cloud-alm-api-integration/qaq-p/14220015</id>
    <title>Unable to Find Defect Table History in Cloud ALM API Integration</title>
    <updated>2025-09-17T14:02:24.272000+02:00</updated>
    <author>
      <name>paulo_nery_avv</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2254905</uri>
    </author>
    <content>&lt;P&gt;Hi everyone,&lt;/P&gt;&lt;P&gt;We’ve successfully established a connection to the SAP Cloud ALM API and are able to retrieve data. However, we’re currently facing an issue: we cannot locate the historical data for the defect table.&lt;/P&gt;&lt;P&gt;We’ve checked the available endpoints and documentation, but haven’t found a clear way to access past defect records or any kind of change history.&lt;/P&gt;&lt;P&gt;Has anyone encountered this before or knows if there’s a specific API endpoint or configuration needed to retrieve defect history?&lt;/P&gt;&lt;P&gt;Any guidance would be greatly appreciated!&lt;/P&gt;&lt;P&gt;Thanks in advance.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/unable-to-find-defect-table-history-in-cloud-alm-api-integration/qaq-p/14220015"/>
    <published>2025-09-17T14:02:24.272000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/ndc-converter-2-0-automating-your-journey-from-businessobjects-to-cloud/qaq-p/14226676</id>
    <title>NDC Converter 2.0: Automating Your Journey from BusinessObjects to Cloud Analytics</title>
    <updated>2025-09-24T11:39:08.590000+02:00</updated>
    <author>
      <name>JurajKysel4</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2254330</uri>
    </author>
    <content>&lt;P&gt;SAP Business Data Cloud (BDC) provides a unified platform for data ingestion, semantic modeling, governance and analytics. For teams migrating from SAP BusinessObjects (BO), BDC enables:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;A governed semantic layer in SAP Datasphere that faithfully reproduces and extends your existing BO universes with standardized naming conventions, hierarchies and calculated measures.&lt;/LI&gt;&lt;LI&gt;Cloud-native analytics in SAC for reporting, planning and predictive scenarios, powered by either live data connections or scheduled replication jobs.&lt;/LI&gt;&lt;LI&gt;A clear modernization path for SAP BW/4HANA artifacts and non-SAP sources, preserving embedded business logic while consolidating disparate models.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;By porting Web Intelligence (WebI) content into BDC, you can retire legacy BO infrastructure and establish a sustainable foundation built on remote or replicated tables, graphical and SQL views and published semantic models that are fully consumable in SAC.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-center" image-alt="JurajKysel4_0-1758706198184.png" style="width: 739px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/319400i4235957EF39EDA56/image-dimensions/739x229?v=v2" width="739" height="229" role="button" title="JurajKysel4_0-1758706198184.png" alt="JurajKysel4_0-1758706198184.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;In this follow-up to our NDC Converter &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/accelerate-migration-of-sap-businessobjects-web-intelligence-reports-to-sap/ba-p/13580516" target="_blank"&gt;introduction&lt;/A&gt;, we’ll showcase its newest capabilities and zoom in on how REST APIs, RPA and the SAP BDC stack work together to fully automate your migration workflow and eliminate uncertainty that is often associated with these sorts of projects.&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Analysis &amp;amp; clean-up&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;Migration kicks off with a thorough source analysis powered by our enhanced scanning engine. After installing a lightweight Windows executable in your environment, NDC Converter uses the BusinessObjects REST API to perform a repository-wide scan - cataloging WebI documents, variables, filters and data sources. Parallel processing enables multiple report structures to be inventoried simultaneously, cutting traditional analysis times from days to hours.&lt;/P&gt;&lt;P&gt;If BO access is restricted, you can export a full content catalog instead and NDC Converter will generate a self-service metadata report for rapid sizing and compliance checks. These automated scans deliver hard metrics on:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Volume: total reports, pages, charts and objects&lt;/LI&gt;&lt;LI&gt;Complexity: calculations, variables, dimensions and interactive features&lt;/LI&gt;&lt;LI&gt;Usage: inactive or overlapping content&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Armed with this detailed data, we can scope migration efforts accurately within days rather than weeks, giving prospects immediate insight into their BI landscape without manual, time-consuming analysis.&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Automated report migration&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;Once WebI queries are identified, the next step is to align them with target system (usually SAP Datasphere but other options available too – for reference see previous blog &lt;A href="https://community.sap.com/t5/technology-blog-posts-by-sap/accelerate-migration-of-sap-businessobjects-web-intelligence-reports-to-sap/ba-p/13580516" target="_blank"&gt;post&lt;/A&gt;). Steps here include:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;Linking each WebI query to its target system&lt;/LI&gt;&lt;LI&gt;Generating the necessary migration definitions&lt;/LI&gt;&lt;LI&gt;Automatically provisioning and deploying the corresponding tables&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;If you’re working with many tables, the “mass deploy” feature lets you push them live in bulk—no tedious one-by-one clicks.&lt;/P&gt;&lt;P&gt;After tables are deployed, we configure on-demand or scheduled data replication to maintain synchronization between target and source systems, followed by creating graphical and SQL-based views to implement calculation logic. The final step is to publish these views to SAP Analytics Cloud where up-to-date data can be accessed.&lt;/P&gt;&lt;P&gt;The data source layer migration involves analyzing the BO repository, migrating universe metadata and/or transitioning live models based on BEx queries. Upon completion of the initial data migration, a comprehensive semantic model is introduced that mirrors your original WebI structures including dimensions, measures, hierarchies and data. This transformation provides a cloud-ready foundation for all SAP Analytics Cloud initiatives.&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;NDC Converter 2.0&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;With your semantic model live, we proceed with WebI reports migration into SAP Analytics Cloud as interactive stories with new high functional coverage. NDC Converter retrieves each report’s layout, structures, tables, charts, filters and visual elements via the BusinessObjects REST API. A blueprint compatible with RPA processing is produced, covering:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Layout &amp;amp; structure&lt;/STRONG&gt;: multi‑page documents, IDs, descriptions, pages/tabs.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Tables &amp;amp; crosstabs&lt;/STRONG&gt;: calculated and restricted measures, variables and common WebI calculations.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Charts&lt;/STRONG&gt;: Bar/Column, Line, Numeric Point, Pie, Donut, Heat Map, Tree Map, Bubble, Scatterplot.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Formatting &amp;amp; UX&lt;/STRONG&gt;: predefined template stories, titles, text, headers/footers, icons.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Filters &amp;amp; interactivity&lt;/STRONG&gt;: input controls, query filters, single object filters, drill, hyperlinks.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;The RPA bot, delivered as a Chrome extension, reads this blueprint and automates the reconstruction of each report in SAC Story 2.0, preserving original tables, crosstabs, charts, parameters and filters. The resulting SAC Stories mirror your WebI reports while leveraging cloud-native data models.&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;What stays manual (and why)&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;NDC Converter automates routine migration tasks, allowing your team to focus on strategic design and governance – here are cases where automation does not bring added value:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;STRONG&gt;Data model (business semantics) design:&lt;/STRONG&gt; turning technical structures into robust semantic layer requires continuous alignment on reporting vision.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Edge cases &amp;amp; redesign:&lt;/STRONG&gt; in situations where 1:1 replication isn’t optimal, we propose a workaround solution to comply with business and technical needs.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Environment setup:&lt;/STRONG&gt; Migrating users, roles and platform configurations using a mix of guided best practices and selective automation.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;FONT size="5"&gt;&lt;STRONG&gt;Collaborate end-end delivery&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;NDC Converter is an ideal tool for complex migration scenarios, automating the transfer of every structural element—from metadata and queries to filters and visual object definitions. Once the converter has recreated the report skeletons in SAC, your BI team can take over the final steps: refining layouts, adjusting chart properties and validating calculation logic. This collaborative workflow ensures that the most time-consuming technical migrations are handled automatically, while you retain full control over presentation, branding and business requirements.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/ndc-converter-2-0-automating-your-journey-from-businessobjects-to-cloud/qaq-p/14226676"/>
    <published>2025-09-24T11:39:08.590000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/moving-rolling-sum-for-specific-amount-of-dates-in-sac/qaq-p/14226887</id>
    <title>moving/rolling sum for specific amount of dates in SAC</title>
    <updated>2025-09-24T15:24:54.722000+02:00</updated>
    <author>
      <name>ChrisVC</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1442397</uri>
    </author>
    <content>&lt;P&gt;Hello community,&lt;/P&gt;&lt;P&gt;I have a requirement to calculate a rolling sum over 7 days in this case. And I want to visualize this value over time in a chart.&lt;/P&gt;&lt;P&gt;Here is an example of how the calculation should look like:&lt;/P&gt;&lt;TABLE border="0" width="270" cellspacing="0" cellpadding="0"&gt;&lt;COLGROUP&gt;&lt;COL width="90" /&gt;&lt;/COLGROUP&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD width="90" height="17"&gt;Date&lt;/TD&gt;&lt;TD width="90"&gt;sales&lt;/TD&gt;&lt;TD width="90"&gt;7 day sum&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="17"&gt;01.09.2025&lt;/TD&gt;&lt;TD&gt;125&lt;/TD&gt;&lt;TD&gt;125&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="17"&gt;02.09.2025&lt;/TD&gt;&lt;TD&gt;100&lt;/TD&gt;&lt;TD&gt;225&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="17"&gt;03.09.2025&lt;/TD&gt;&lt;TD&gt;75&lt;/TD&gt;&lt;TD&gt;300&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="17"&gt;04.09.2025&lt;/TD&gt;&lt;TD&gt;250&lt;/TD&gt;&lt;TD&gt;550&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="17"&gt;05.09.2025&lt;/TD&gt;&lt;TD&gt;100&lt;/TD&gt;&lt;TD&gt;650&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="17"&gt;06.09.2025&lt;/TD&gt;&lt;TD&gt;350&lt;/TD&gt;&lt;TD&gt;1000&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="17"&gt;07.09.2025&lt;/TD&gt;&lt;TD&gt;275&lt;/TD&gt;&lt;TD&gt;1275&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="17"&gt;08.09.2025&lt;/TD&gt;&lt;TD&gt;150&lt;/TD&gt;&lt;TD&gt;1300&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="17"&gt;09.09.2025&lt;/TD&gt;&lt;TD&gt;100&lt;/TD&gt;&lt;TD&gt;1300&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD height="17"&gt;10.09.2025&lt;/TD&gt;&lt;TD&gt;110&lt;/TD&gt;&lt;TD&gt;1335&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;The calculation function for running total does not really work here, because of the missing option to restrict the time period to 7 days. I have also tried this formula:&amp;nbsp;ResultLookup([sales] ;[date]= PREVIOUS(90; "DAY";[date]))&amp;nbsp; but unfortunately the system does not allow the function PREVIOUS to be used in this context.&amp;nbsp;&lt;/P&gt;&lt;P&gt;I am using an analytical model from SAP Datasphere as source.&lt;/P&gt;&lt;P&gt;Does anybody know a solution to this problem?&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/moving-rolling-sum-for-specific-amount-of-dates-in-sac/qaq-p/14226887"/>
    <published>2025-09-24T15:24:54.722000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/supply-chain-management-q-a/cds-view-for-monitor-purchase-order-items/qaq-p/14227487</id>
    <title>CDS View for Monitor Purchase Order Items</title>
    <updated>2025-09-25T08:41:29.574000+02:00</updated>
    <author>
      <name>AdamHorne</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1478876</uri>
    </author>
    <content>&lt;P&gt;Hello All&amp;nbsp;&lt;/P&gt;&lt;P&gt;Im creating a CDS report and want to replicate some of the details in the "Monitor Purchase Order Items" app. I can see most of the fields required in the CDS&amp;nbsp;&lt;A class="" href="https://my411853.s4hana.cloud.sap/ui?RelayState=oucfxcadufqoafwvoreefoyufbosyvaeeerrzau#" target="_blank" rel="noopener noreferrer nofollow"&gt;&lt;SPAN class=""&gt;I_PurOrdScheduleLineAPI01&lt;/SPAN&gt;&lt;/A&gt;&amp;nbsp;but it doesn't have the Delivered Value and Invoiced Value.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Can anyone assist with what views I can include into my custom CDS to get these values included?&amp;nbsp;&lt;/P&gt;&lt;P&gt;Thanks&lt;/P&gt;&lt;P&gt;Adam&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/supply-chain-management-q-a/cds-view-for-monitor-purchase-order-items/qaq-p/14227487"/>
    <published>2025-09-25T08:41:29.574000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/supply-chain-management-q-a/can-you-link-join-the-matdoc-table-to-the-corresponding-idoc-record-for/qaq-p/14233001</id>
    <title>Can you link/join the MATDOC table to the corresponding idoc record for that matdoc entry?</title>
    <updated>2025-10-01T21:51:14.176000+02:00</updated>
    <author>
      <name>johnfirebaugh</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2257411</uri>
    </author>
    <content>&lt;P&gt;Is there a link/join that would allow for matching a matdoc record to the corresponding idoc record for that matdoc record?&amp;nbsp; Something linking the MATDOC and EDIDC tables?&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/supply-chain-management-q-a/can-you-link-join-the-matdoc-table-to-the-corresponding-idoc-record-for/qaq-p/14233001"/>
    <published>2025-10-01T21:51:14.176000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-q-a/can-you-link-join-a-matdoc-record-to-the-corresponding-idoc-record/qaq-p/14233006</id>
    <title>Can you link/join a MATDOC record to the corresponding idoc record</title>
    <updated>2025-10-01T21:54:05.429000+02:00</updated>
    <author>
      <name>johnfirebaugh</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2257411</uri>
    </author>
    <content>&lt;P&gt;Can you link/join a MATDOC table record to the corresponding idoc record for that MATDOC entry?&amp;nbsp; Looking for a way to positively identify which idoc record is responsible for any given entry in the MATDOC table.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-q-a/can-you-link-join-a-matdoc-record-to-the-corresponding-idoc-record/qaq-p/14233006"/>
    <published>2025-10-01T21:54:05.429000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/https-on-restful-web-service-running-on-tomcat/qaq-p/14240697</id>
    <title>HTTPS on RESTful web service running on tomcat</title>
    <updated>2025-10-10T18:09:04.571000+02:00</updated>
    <author>
      <name>wallbertelicot</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/612125</uri>
    </author>
    <content>&lt;P&gt;Currently we have this setup. RESTful web service running on WACS (&lt;A href="http://server:6405/biprws" target="_blank" rel="nofollow noopener noreferrer"&gt;http://server:6405/biprws&lt;/A&gt;), BI and CMC application running on tomcat (&lt;A href="https://server:8443/BOE/BI" target="_blank" rel="nofollow noopener noreferrer"&gt;https://server:8443/BOE/BI&lt;/A&gt;). Server is SSL configured and we have a 8080 reroute to 8443.&lt;/P&gt;&lt;P&gt;We want to decouple RESTful web service from WACS and have it running on tomcat instead. Changing the RESTful url to &lt;A href="http://server:8080/biprws" target="_blank" rel="nofollow noopener noreferrer"&gt;http://server:8080/biprws&lt;/A&gt;&amp;nbsp;doesn't work. It gives us a HTTP 500 error. Same if changed to &lt;A href="https://server:8443/biprws" target="_blank" rel="nofollow noopener noreferrer"&gt;https://server:8443/biprws&lt;/A&gt;.&lt;/P&gt;&lt;P&gt;Any ideas on this?&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/https-on-restful-web-service-running-on-tomcat/qaq-p/14240697"/>
    <published>2025-10-10T18:09:04.571000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-can-organizations-architect-a-scalable-data-engineering-pipeline-to/qaq-p/14243300</id>
    <title>How Can Organizations Architect a Scalable Data Engineering Pipeline to Support Real-Time AI-Driven</title>
    <updated>2025-10-14T11:47:51.530000+02:00</updated>
    <author>
      <name>aliveallen360</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2258698</uri>
    </author>
    <content>&lt;P&gt;How Can Organizations Architect a Scalable Data Engineering Pipeline to Support Real-Time AI-Driven Decision Making Across Multiple Domains?&lt;/P&gt;&lt;P&gt;Hello everyone,&lt;/P&gt;&lt;P&gt;I’m working on designing a data engineering pipeline that can support real-time AI analytics across multiple business domains, including marketing, operations, and supply chain. I want to ensure that our architecture is scalable, resilient, and compliant with data privacy regulations.&lt;/P&gt;&lt;P&gt;Specifically, I’m looking for insights on:&lt;/P&gt;&lt;P&gt;Data Ingestion &amp;amp; Streaming: What are the best practices for ingesting large-scale structured and unstructured data in near real-time? Which tools or frameworks are most effective for multi-source streaming pipelines?&lt;/P&gt;&lt;P&gt;Data Storage &amp;amp; Modeling: How can we efficiently store both batch and streaming data while maintaining a single source of truth for AI models? Are there recommended data lake or warehouse strategies?&lt;/P&gt;&lt;P&gt;Feature Engineering for AI: How can feature pipelines be automated and monitored to ensure high-quality inputs for machine learning models without introducing bias?&lt;/P&gt;&lt;P&gt;Real-Time Model Deployment: What architecture patterns (e.g., event-driven, micro-batching, or hybrid) best support real-time AI inference while minimizing latency?&lt;/P&gt;&lt;P&gt;Governance &amp;amp; Compliance: How do organizations ensure data privacy, lineage, and regulatory compliance while enabling agile AI experimentation?&lt;/P&gt;&lt;P&gt;Has anyone implemented a production-ready solution that addresses these challenges? I’d love to hear about architectural choices, tool recommendations, pitfalls, and lessons learned from real-world implementations.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-can-organizations-architect-a-scalable-data-engineering-pipeline-to/qaq-p/14243300"/>
    <published>2025-10-14T11:47:51.530000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/cds-analytical-query-to-be-published-as-a/qaq-p/14243953</id>
    <title>CDS analytical Query to be published as a</title>
    <updated>2025-10-14T20:07:41.002000+02:00</updated>
    <author>
      <name>kumail_saif</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2188673</uri>
    </author>
    <content>&lt;P&gt;&lt;SPAN&gt;Hello Experts,&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Can you help me with the correct steps to setup a CDS view analytical query as a tile in Catalog/Group so that other users can access it?&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;I am using the format as below:&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;#AnalyticQuery-analyze?XQUERY=2C&amp;lt;SQL Name of CDS&amp;gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;However, I am getting the error - "App could not be opened either due to an incorrect SAP Fiori launchpad configuration or a missing role assignment."&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/cds-analytical-query-to-be-published-as-a/qaq-p/14243953"/>
    <published>2025-10-14T20:07:41.002000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-q-a/what-are-the-most-effective-approaches-for-planning-and-executing-a-large/qaq-p/14245755</id>
    <title>What are the most effective approaches for planning and executing a large-scale application moderniz</title>
    <updated>2025-10-16T12:47:14.414000+02:00</updated>
    <author>
      <name>aliveallen360</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2258698</uri>
    </author>
    <content>&lt;P&gt;"I'm part of an IT leadership team at a mid-sized organization, and we’re starting to explore application modernization to improve scalability, agility, and overall business efficiency. Many of our critical systems are legacy applications that have been in place for over a decade, and we’re facing challenges with performance, integration, and maintaining outdated code. We’ve heard a lot about strategies like containerization, microservices, DevOps practices, and cloud-native architecture, but it’s overwhelming to decide where to start.&lt;/P&gt;&lt;P&gt;My question to the forum is: &lt;STRONG&gt;What are the most effective approaches for planning and executing a large-scale application modernization initiative?&lt;/STRONG&gt; How should we prioritize which applications to modernize first, and what are the key pitfalls to avoid during the process? Additionally, how can we ensure a smooth transition to cloud environments and modern architectures while keeping ongoing operations stable and secure?"&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-q-a/what-are-the-most-effective-approaches-for-planning-and-executing-a-large/qaq-p/14245755"/>
    <published>2025-10-16T12:47:14.414000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/financial-management-q-a/sales-order-report/qaq-p/14249894</id>
    <title>Sales Order Report</title>
    <updated>2025-10-22T05:27:45.335000+02:00</updated>
    <author>
      <name>AdamHorne</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1478876</uri>
    </author>
    <content>&lt;P&gt;Hello&amp;nbsp;&lt;/P&gt;&lt;P&gt;Im looing at how other users of SAP 4/HANA Public Cloud do a sales report (that shows sales for month by sales order with their respective costs) that reconciles to the GL (revenue and costs).&amp;nbsp;&lt;/P&gt;&lt;P&gt;We have normal trading goods but also MTO/MTS products. At present our report is coming from billing (custom CDS) and reconciles to the revenue in the GL but its the COGS that dont match (especially for the MTO/MTS products).&amp;nbsp;&lt;/P&gt;&lt;P&gt;How do others report on their sales/COGS in on report that reconciles to their GL? If a custom CDS what views do you use?&lt;/P&gt;&lt;P&gt;This is for public cloud.&amp;nbsp;&lt;/P&gt;&lt;P&gt;Thanks&lt;/P&gt;&lt;P&gt;&lt;BR /&gt;Adam&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/financial-management-q-a/sales-order-report/qaq-p/14249894"/>
    <published>2025-10-22T05:27:45.335000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/integration-of-sap-cpi-and-sap-datasphere-using-jdbc/qaq-p/14256172</id>
    <title>Integration of SAP CPI and SAP DataSphere using JDBC</title>
    <updated>2025-10-29T13:26:11.173000+01:00</updated>
    <author>
      <name>MUGILAN_KANAGARAJ</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2190179</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Integration Between SAP CPI and SAP DataSphere (JDBC Connection)&lt;/SPAN&gt;&lt;/STRONG&gt; &lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;JDBC – JAVA DATABASE CONNECTIVITY&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;Why Recommendation for JDBC Over OData API :&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;JDBC is recommended over OData when consuming large-scale records (e.g., 100,000+) because JDBC streams data directly from the database with better performance and less overhead, while OData is optimized for lightweight, paginated, service-based access.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;Problem statement: &lt;/SPAN&gt;&lt;A href="https://userapps.support.sap.com/sap/support/knowledge/en/3337495" target="_blank" rel="noopener noreferrer"&gt;&lt;SPAN&gt;3337495 - OData API returns less records than expected due paging&lt;/SPAN&gt;&lt;/A&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;Pagination limits in OData and Ariba APIs can be handled in SAP CPI using a looping process call.&amp;nbsp;&lt;/SPAN&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;STRONG&gt;G&lt;SPAN&gt;oal:&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt; Connect CPI to a database used by DataSphere (JDBC) and run a simple read data from the (Analytical Model / Table /View). &lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;For the Write / Delete / Update method, the attached SAP Help Portal Link has syntax in the reference section.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN&gt;Prerequisites:&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;SAP DataSphere&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt; – Subscribed account (⚠ Trial has limited features, JDBC not supported)&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;OL&gt;&lt;LI&gt;&lt;STRONG&gt;&lt;SPAN&gt;SAP Integration Suite&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt; – Subscribed or Trial (JDBC actions supported)&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/OL&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;SAP DataSphere Step by Step Guide :&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Step&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Action / Notes&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;1. Create a Space&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;DataSphere → Space Management → &lt;/SPAN&gt;&lt;I&gt;&lt;SPAN&gt;New Space&lt;/SPAN&gt;&lt;/I&gt;&lt;SPAN&gt; → Name it → Create.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;2. Create Table / Analytical Model&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;Data Builder → In your Space → &lt;/SPAN&gt;&lt;I&gt;&lt;SPAN&gt;New&lt;/SPAN&gt;&lt;/I&gt;&lt;SPAN&gt; → Table or Analytical Model → define fields &amp;amp; data types → Save &amp;amp; Publish.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;*Verify Table/Model Deployed Successfully. *&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;3. Prepare / Load Data&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;Load data manually for testing cases. Otherwise load CSV/import to table via Data Builder/Data Integration.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;4. Note Schema &amp;amp; Object Names&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;Record schema name, table name, and view names for JDBC SQL use.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;* Created space name is the SCHEMA name and Collect Table / Model name *&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;5. Decide Where to Create DB User&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;If HANA Cloud → use HANA Cockpit/DB Explorer. If on-prem DB → use DB admin tools or contact DB Admin.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;* We are using the HANA cloud system for practical session*&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;6. Create JDBC DB User&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;DB admin tool → Security/Users → &lt;/SPAN&gt;&lt;I&gt;&lt;SPAN&gt;New User&lt;/SPAN&gt;&lt;/I&gt;&lt;SPAN&gt; → set username &amp;amp; strong password → Save.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;*Check Active status of User*&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;7. Grant Privileges for the DB user&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;Assign only required privileges (e.g., &lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN&gt;SELECT&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt; for read; add &lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN&gt;INSERT/UPDATE/DELETE&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt; for CRUD). Best practice: create role &lt;/SPAN&gt;&lt;SPAN&gt;JDBC_ROLE&lt;/SPAN&gt;&lt;SPAN&gt; and assign.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;8. Prepare JDBC Connection Details&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;TD&gt;&lt;P&gt;&lt;SPAN&gt;Gather JDBC URL (e.g.&amp;nbsp; sample URL from datasphere: &lt;/SPAN&gt;&lt;SPAN&gt;z*********-abc.hana.prod-eu10.hanacloud.ondemand.com&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;Format for CPI JDBC Material:&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;jdbc:sap://&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/?encrypt=true&amp;amp;validateCertificate=true&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN&gt;SAP Integration Suite Step by Step Guide :&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;STRONG&gt;&lt;SPAN&gt;Create a Package &amp;amp; Artifact&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;In CPI → &lt;/SPAN&gt;&lt;I&gt;&lt;SPAN&gt;Design&lt;/SPAN&gt;&lt;/I&gt;&lt;SPAN&gt; → Create a new package → Add an integration flow artifact.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;&lt;span class="lia-unicode-emoji" title=":white_heavy_check_mark:"&gt;✅&lt;/span&gt; Make sure your CPI user has the required roles to create and access design-time artifacts.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;&lt;SPAN&gt;Go to Monitoring → JDBC Material&lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;In CPI → &lt;/SPAN&gt;&lt;I&gt;&lt;SPAN&gt;Monitor&lt;/SPAN&gt;&lt;/I&gt;&lt;SPAN&gt; → Integrations and APIs → Manage Security → JDBC Material&lt;/SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_8-1761739908075.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333854iBF07D54D3EAFAD2E/image-size/medium?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_8-1761739908075.png" alt="MUGILAN_KANAGARAJ_8-1761739908075.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;→&lt;/SPAN&gt;&lt;SPAN&gt; Add &lt;/SPAN&gt;&lt;I&gt;&lt;SPAN&gt;JDBC Data Source. &lt;/SPAN&gt;&lt;/I&gt;&lt;SPAN&gt;→ Select HANA cloud &lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_9-1761739908079.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333856i94B13CC1D5FE2429/image-size/medium?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_9-1761739908079.png" alt="MUGILAN_KANAGARAJ_9-1761739908079.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Provide JDBC URL in the correct format (e.g., &lt;/SPAN&gt;&lt;SPAN&gt;jdbc:sap://&amp;lt;hana-host&amp;gt;:443/?encrypt=true&amp;amp;validateCertificate=true&lt;/SPAN&gt;&lt;SPAN&gt;).&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_10-1761739908083.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333855i646872A9D1D66236/image-size/medium?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_10-1761739908083.png" alt="MUGILAN_KANAGARAJ_10-1761739908083.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Enter DB username and password (use the dedicated JDBC user created earlier in DataSphere).&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;BR /&gt;&lt;/SPAN&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_11-1761739908085.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333857iF765C15BBE45063F/image-size/medium?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_11-1761739908085.png" alt="MUGILAN_KANAGARAJ_11-1761739908085.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;UL&gt;&lt;LI&gt;&lt;SPAN&gt;Save and deploy the JDBC material.&lt;/SPAN&gt;&lt;SPAN&gt;&amp;nbsp;&lt;/SPAN&gt;&lt;UL&gt;&lt;LI&gt;&amp;nbsp;&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Apply JDBC Material in iFlow&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;In your integration flow, configure the JDBC receiver adapter → select the JDBC data source created.&lt;/LI&gt;&lt;LI&gt;Use SQL queries (SELECT) in the &lt;EM&gt;Processing tab&lt;/EM&gt; or provide XML query body. &lt;SPAN&gt;Here, I’m using SQL &lt;/SPAN&gt;SELECT * to&lt;SPAN&gt; fetch all records from the table.&lt;/SPAN&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_12-1761739969784.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333861i2719779EFA58AE2C/image-size/medium?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_12-1761739969784.png" alt="MUGILAN_KANAGARAJ_12-1761739969784.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;STRONG&gt;Step 1: &lt;SPAN&gt;Timer Start &lt;/SPAN&gt;&lt;/STRONG&gt;&lt;SPAN&gt;&lt;BR /&gt;&amp;nbsp;In this iFlow, the Start Timer is configured with a Simple Schedule → None → On Deployment, which means the integration flow automatically triggers immediately after deployment.&lt;/SPAN&gt;&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_13-1761739969791.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333859i1B0F73BEDFB06AAD/image-size/medium?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_13-1761739969791.png" alt="MUGILAN_KANAGARAJ_13-1761739969791.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;STRONG&gt;Step 2: Content Modifier&lt;/STRONG&gt;&lt;BR /&gt;Use this SQL query to fetch all records with the body operation.&lt;BR /&gt;&amp;nbsp;SELECT * FROM "&amp;lt;Schema&amp;gt;"."&amp;lt;Model/TableName&amp;gt;"&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_14-1761739969798.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333860i7C0D9253A2EC2E2B/image-size/medium?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_14-1761739969798.png" alt="MUGILAN_KANAGARAJ_14-1761739969798.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;STRONG&gt;Step 3: Request Reply &amp;amp; JDBC Receiver Adapter&lt;/STRONG&gt;&lt;BR /&gt;&amp;nbsp;&lt;/SPAN&gt;→&lt;SPAN&gt; Use the deployed JDBC Data Source alias in the JDBC Material in the previous step and set Max records count based on your requirement.&lt;BR /&gt;&lt;/SPAN&gt;→ JDBC Maximum Records per call:&amp;nbsp; 2,147,483,647&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_15-1761739969804.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333862i55C1C176CB297E63/image-size/medium?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_15-1761739969804.png" alt="MUGILAN_KANAGARAJ_15-1761739969804.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;Sample data Response from JDBC Connection:&lt;BR /&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="MUGILAN_KANAGARAJ_16-1761739969807.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/333863i1040E68119C788E0/image-size/medium?v=v2&amp;amp;px=400" role="button" title="MUGILAN_KANAGARAJ_16-1761739969807.png" alt="MUGILAN_KANAGARAJ_16-1761739969807.png" /&gt;&lt;/span&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;References :&lt;SPAN&gt;&lt;BR /&gt;&lt;BR /&gt;&lt;/SPAN&gt;CPI JDBC – XML Query in Body for CRUD Operations (Syntax Guide)&lt;SPAN&gt;&lt;BR /&gt;&lt;/SPAN&gt;&amp;nbsp;link: &lt;SPAN&gt;&lt;BR /&gt;&lt;A href="https://help.sap.com/docs/cloud-integration/sap-cloud-integration/payload-and-operation" target="_blank" rel="noopener noreferrer"&gt;https://help.sap.com/docs/cloud-integration/sap-cloud-integration/payload-and-operation&lt;/A&gt;&lt;/SPAN&gt;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/integration-of-sap-cpi-and-sap-datasphere-using-jdbc/qaq-p/14256172"/>
    <published>2025-10-29T13:26:11.173000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/what-architectural-frameworks-mlops-practices-or-data-orchestration-tools/qaq-p/14261149</id>
    <title>What architectural frameworks, MLOps practices, or data orchestration tools would you recommend?</title>
    <updated>2025-11-05T11:11:15.921000+01:00</updated>
    <author>
      <name>aliveallen360</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2258698</uri>
    </author>
    <content>&lt;P&gt;&lt;STRONG&gt;Q:&lt;/STRONG&gt; What architectural frameworks, MLOps practices, or data orchestration tools would you recommend to ensure continuous learning, low-latency predictions, and trustworthy analytics outputs in production environments?&lt;/P&gt;&lt;P&gt;Our organization is currently implementing enterprise-level &lt;STRONG&gt;Data and AI solutions&lt;/STRONG&gt; to enhance predictive analytics and automate business intelligence processes. However, we’re facing several technical obstacles during the integration phase. Specifically, we’re struggling to design a robust data pipeline that can efficiently handle large-scale, heterogeneous data sources — including IoT streams, ERP systems, and cloud databases — while maintaining data quality, lineage, and governance. Additionally, our AI models trained on historical data aren’t performing well in real-time scenarios due to inconsistent feature updates and model drift. We’ve been experimenting with tools like Azure Machine Learning, Power BI, and Databricks, but syncing these components into a seamless Data and AI solutions architecture has proven difficult. Has anyone here tackled similar challenges in building a scalable, automated AI-driven ecosystem?&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/what-architectural-frameworks-mlops-practices-or-data-orchestration-tools/qaq-p/14261149"/>
    <published>2025-11-05T11:11:15.921000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-q-a/automatic-creation-of-reports-in-s4hana-public-cloud/qaq-p/14272392</id>
    <title>Automatic creation of reports in S4Hana Public Cloud</title>
    <updated>2025-11-19T07:57:04.656000+01:00</updated>
    <author>
      <name>KeLaw</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1480621</uri>
    </author>
    <content>&lt;P&gt;Hello,&lt;/P&gt;&lt;P&gt;We were interested in the possibility to configure the automatic creation of reports (such as the Purchase order list) directly from S4Hana Public Cloud. Is there any possibility that we can configure a rule by which the system creates reports extracted from apps in the cloud environment on a specific date, for example monthly, weekly etc?&lt;/P&gt;&lt;P&gt;There is a similar request for the automatic mailing, but this time we are looking specifically for the creation (before mailing):&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;A href="https://community.sap.com/t5/enterprise-resource-planning-q-a/automatic-mailing-of-reports-in-s4hana-cloud/qaq-p/12377826" target="_blank"&gt;Solved: Automatic mailing of reports in S4Hana Cloud - SAP Community&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&lt;A href="https://influence.sap.com/sap/ino/#/idea/272236/?section=sectionDetails" target="_blank" rel="noopener noreferrer"&gt;Improvement Request Details - Customer Influence&lt;/A&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Thanks in advance for your help.&lt;/P&gt;&lt;P&gt;Best regards,&lt;/P&gt;&lt;P&gt;Kerisha&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-q-a/automatic-creation-of-reports-in-s4hana-public-cloud/qaq-p/14272392"/>
    <published>2025-11-19T07:57:04.656000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/sap-datasphere-replication-flow-load-type-initial-and-delta-schedule/qaq-p/14286270</id>
    <title>SAP Datasphere - Replication Flow Load Type Initial and Delta Schedule</title>
    <updated>2025-12-08T20:42:38.284000+01:00</updated>
    <author>
      <name>Lauryn_Harvey</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/2237640</uri>
    </author>
    <content>&lt;P&gt;&lt;FONT size="6"&gt;Is there any feature for Datasphere Replication Flows with load type "Initial and Delta" to be scheduled?&lt;/FONT&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;Scenario 1&lt;/FONT&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;We want a replication flow with load type "Initial and Delta" to start at 9PM. In this scenario, the initial has not yet been loaded. Is there any way to trigger the replication flow&amp;nbsp;to begin at 9PM without having a user log in and manually click a button at 9PM?&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;Attempting to a schedule on the replication flow with load type "Initial and Delta" results in the error below.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;&lt;EM&gt;"&lt;SPAN&gt;For replication flows that contain objects with load type "Initial and Delta/Delta Only", no schedule can be created."&lt;/SPAN&gt;&lt;/EM&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;Attempting to add the replication flow with load type&amp;nbsp;"Initial and Delta"&amp;nbsp; to a task chain results in the error below.&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;&lt;STRONG&gt;&lt;EM&gt;"Object '&amp;lt;ReplicationFlowName&amp;gt;' cannot be part of a task chain because it does not have an end (as it includes objects with load type Initial and Delta/Delta Only)."&lt;/EM&gt;&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&lt;FONT size="5"&gt;Scenario 2&lt;/FONT&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;We want the replication flow with load type "Initial and Delta" to check for new delta records at 9PM every day. The delta load may take anywhere from 15 minutes up to 1 hour depending on the number of the changes observed. &lt;U&gt;Is there any way to ensure that the replication flow will start to load deltas every day at 9PM?&lt;/U&gt;&lt;/P&gt;&lt;P class="lia-indent-padding-left-30px" style="padding-left : 30px;"&gt;If the frequency is set to 24 hours, we observe that the next delta will begin to be loaded 24 hours &lt;U&gt;after the previous delta load had finished&lt;/U&gt;. After some time, the timing will no longer be close to 9PM. We are aware we can change the update frequency to twice daily, or hourly. Updating on that frequency is not necessary for the use case and there is concern for efficiency.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/sap-datasphere-replication-flow-load-type-initial-and-delta-schedule/qaq-p/14286270"/>
    <published>2025-12-08T20:42:38.284000+01:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/human-capital-management-q-a/story-report-in-onobarding-query-design/qaq-p/14290693</id>
    <title>Story Report in Onobarding Query Design</title>
    <updated>2025-12-15T16:29:39.684000+01:00</updated>
    <author>
      <name>piotr_retecki</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/49706</uri>
    </author>
    <content>&lt;P&gt;Hi All,&lt;/P&gt;&lt;P&gt;I am facing the issue with the story report which I am building for my client.&lt;/P&gt;&lt;P&gt;They want to include a lot of data, i.e. personal information, biographical information, job information and data gathered during the additional data collection.&lt;/P&gt;&lt;P&gt;I managed to build the query which includes all of the data tables which are needed to meet the business requirement. But I am facing the following issue: not all data which is there in the onboarding dashboard, is in the report. I was modyfying the query multiple times but there is always something missing. I managed to determine that there are following issues:&lt;/P&gt;&lt;P&gt;- the query which contains the biographical information and linked tables (country-specific Information, dependents, email information, phone information).&lt;/P&gt;&lt;P&gt;- the report has the filter for legal entity used for the country which data should be visible in the report.&lt;/P&gt;&lt;P&gt;Removing the above from makes all the data which is missing appeared in the report. However it appears with empty rows, only the process ID is visivble, but all the rest (i.e. user ID) is empty. User ID should be there as the data collection steps are in most of the cases completed. Moreover, keeping them is needed to meet the business requirement.&lt;/P&gt;&lt;P&gt;I raised the support ticket with SAP, but they replied that this is due to the query design and does not fall under the scope of the product support team. There seems to be no clear documentation on how to design the query to make it working correctly.&lt;/P&gt;&lt;P&gt;Any feedback will be much appreciated.&lt;/P&gt;&lt;P&gt;I attached the screen shot of the query for your reference.&lt;/P&gt;&lt;P&gt;Thank you in advance.&lt;/P&gt;&lt;P&gt;Piotr Retecki&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/human-capital-management-q-a/story-report-in-onobarding-query-design/qaq-p/14290693"/>
    <published>2025-12-15T16:29:39.684000+01:00</published>
  </entry>
</feed>
