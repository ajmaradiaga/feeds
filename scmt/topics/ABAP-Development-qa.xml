<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://raw.githubusercontent.com/ajmaradiaga/feeds/main/scmt/topics/ABAP-Development-qa.xml</id>
  <title>SAP Community - ABAP Development</title>
  <updated>2025-09-29T14:00:04.521336+00:00</updated>
  <link href="https://community.sap.com/t5/c-khhcw49343/ABAP Development/pd-p/833755570260738661924709785639136" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <subtitle>ABAP Development Q&amp;A in SAP Community</subtitle>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/security-related-atc-checks-nonsense-of-pseudo-comments/qaq-p/14224194</id>
    <title>Security related ATC checks, nonsense of pseudo comments</title>
    <updated>2025-09-22T14:41:02.812000+02:00</updated>
    <author>
      <name>patrick_weber11</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/215409</uri>
    </author>
    <content>&lt;P&gt;Hi all,&lt;/P&gt;&lt;P&gt;I want to use ATC security checks to identify certain security vulnerables like usage of GENERATE REPORT, GENERATE SUBROUINE POOL and others. I found there are already ATC checks available for, but they can be easily suppressed by pseudo comment&lt;/P&gt;&lt;P&gt;"#EC CI_GENERATE&lt;SPAN&gt;.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;In my opinion, it absolutely makes no sense to be able supress certain ATC checks by pseudo comments. In some cases it makes sense (like BAPI call with material length check). But for security related topics, it is dangerous in my opinion. Instead, ATC exemption should be used for this imo.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;If you employ unfriendly/enemy developers (i.e., by external partner), they simply add pseudo comments to cheat on ATC check. This makes it more challenging in identifying vulnerable code as I can't trust ATC checks here.&lt;/SPAN&gt;&lt;/P&gt;&lt;P&gt;&lt;SPAN&gt;Is there a way to overcome this issue (beside replacing developers)&lt;/SPAN&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/security-related-atc-checks-nonsense-of-pseudo-comments/qaq-p/14224194"/>
    <published>2025-09-22T14:41:02.812000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/supply-chain-management-q-a/create-z-program-to-update-edpar-entries/qaq-p/14224461</id>
    <title>Create Z program to update EDPAR entries</title>
    <updated>2025-09-22T18:06:34.703000+02:00</updated>
    <author>
      <name>abap_learner1</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1398911</uri>
    </author>
    <content>&lt;P&gt;Hello team,&amp;nbsp;&lt;/P&gt;&lt;P&gt;We currently update EDPAR entries using transaction VOE4 , but each time we have to ask the Basis team to open the client after approval. This process takes time. We would like to create a Z program to handle this instead.&lt;/P&gt;&lt;P&gt;Can anyone advise? Should we use BDC for VOE4, or is there a relevant function module available?&lt;/P&gt;&lt;P&gt;Thank you very much.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/supply-chain-management-q-a/create-z-program-to-update-edpar-entries/qaq-p/14224461"/>
    <published>2025-09-22T18:06:34.703000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-create-record-technical-object-in-change-sales-order-va02/qaq-p/14224764</id>
    <title>How to create record Technical Object in Change Sales Order (VA02)</title>
    <updated>2025-09-23T05:29:02.823000+02:00</updated>
    <author>
      <name>Phuhs</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1483297</uri>
    </author>
    <content>&lt;P&gt;Dear Expert,&lt;/P&gt;&lt;P&gt;In Change Sales Order (VA02), I want to create record in Technical Object -&amp;gt; Maintain Serial Number with Custom Logic, or BADI after/before Sales Order save.&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Phuhs_0-1758597998205.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/318247i63F97EFA54FCD806/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Phuhs_0-1758597998205.png" alt="Phuhs_0-1758597998205.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="Phuhs_1-1758598009990.png" style="width: 400px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/318248iB5BA616BEC7FFE49/image-size/medium?v=v2&amp;amp;px=400" role="button" title="Phuhs_1-1758598009990.png" alt="Phuhs_1-1758598009990.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Please help me&lt;/P&gt;&lt;P&gt;Thanks and best Regards&lt;/P&gt;&lt;P&gt;Daroi&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-create-record-technical-object-in-change-sales-order-va02/qaq-p/14224764"/>
    <published>2025-09-23T05:29:02.823000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/is-there-an-abap-equivalent-of-javadocs-for-sap-classes-and-methods/qaq-p/14225126</id>
    <title>Is there an ABAP equivalent of JavaDocs for SAP classes and methods?</title>
    <updated>2025-09-23T08:02:09.561000+02:00</updated>
    <author>
      <name>peter_munt4</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/267001</uri>
    </author>
    <content>&lt;P&gt;Hi all,&lt;/P&gt;&lt;P&gt;In Java, they have &lt;STRONG&gt;Javadocs &lt;/STRONG&gt;&amp;nbsp;that provide a complete API reference for classes, listing all methods, parameters, return types, and usage examples. I’m looking for something similar in ABAP.&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;Specifically, is there an &lt;U&gt;&lt;FONT color="#0000FF"&gt;&lt;STRONG&gt;official SAP documentation&lt;/STRONG&gt;&lt;/FONT&gt;&lt;/U&gt;&amp;nbsp;page that provides a &lt;STRONG&gt;Javadoc-style API reference&lt;/STRONG&gt; for standard ABAP classes? i.e. the equivalent of&amp;nbsp;&lt;A href="https://docs.oracle.com/javase/8/docs/api/" target="_blank" rel="noopener nofollow noreferrer"&gt;https://docs.oracle.com/javase/8/docs/api/&lt;/A&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/is-there-an-abap-equivalent-of-javadocs-for-sap-classes-and-methods/qaq-p/14225126"/>
    <published>2025-09-23T08:02:09.561000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-q-a/fiori-app-extensibility/qaq-p/14225454</id>
    <title>FIORI APP extensibility</title>
    <updated>2025-09-23T11:36:57.982000+02:00</updated>
    <author>
      <name>LXBEL</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1448775</uri>
    </author>
    <content>&lt;P&gt;I need to extend a standard Fiori application with a custom field. Normally, the recommended approach would be to use the Custom Fields and Logic app, which automatically creates a new field (with the ZZ1_ prefix) in the relevant table and exposes it to Fiori.&lt;/P&gt;&lt;P&gt;However, in my case, the situation is different:&lt;/P&gt;&lt;P&gt;The customer has already added a custom field ZCLASS in table MARD using an append structure and this field is already in use across multiple forms, reports (so it’s business critical)&lt;/P&gt;&lt;P&gt;If I use the Custom Fields and Logic app now, it will create a new field ZZ1_CLASS in MARD, which would lead to &lt;STRONG&gt;redundant fields for the same purpose&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;My question is what is the correct approach to resolve this issue?&lt;BR /&gt;&lt;BR /&gt;Thank you In advance&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-q-a/fiori-app-extensibility/qaq-p/14225454"/>
    <published>2025-09-23T11:36:57.982000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-delete-local-tmp-objects-from-prd/qaq-p/14225834</id>
    <title>How to delete Local ($TMP) objects from PRD.</title>
    <updated>2025-09-23T15:37:12.672000+02:00</updated>
    <author>
      <name>spinellll</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/425584</uri>
    </author>
    <content>&lt;P&gt;During a recent ECC-to-S4 build, many Local objects were somehow migrated to our PRD environment. They should not exist there and I need to delete them.&lt;/P&gt;&lt;P&gt;I saw a post suggesting the use of program&amp;nbsp;SEO_REMOVE_FROM_TADIR, but that program appears to only affect types CLAS and INTF.&lt;/P&gt;&lt;P&gt;Since transports are not assigned to $TMP objects, I can't use a transport landscape to delete them via the DEV-QAS-PRD route.&lt;/P&gt;&lt;P&gt;Any suggestions?&lt;/P&gt;&lt;P&gt;Thanks, Leo&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-delete-local-tmp-objects-from-prd/qaq-p/14225834"/>
    <published>2025-09-23T15:37:12.672000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/incident-with-fm-sd-vbpa-read-with-vbeln-in-s4hana/qaq-p/14225886</id>
    <title>Incident with FM SD_VBPA_READ_WITH_VBELN in S4HANA</title>
    <updated>2025-09-23T16:11:34.142000+02:00</updated>
    <author>
      <name>ediciones-sm_usuariogenri</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/364247</uri>
    </author>
    <content>&lt;P&gt;Good afternoon,&lt;/P&gt;&lt;P&gt;We have an incident with the FM&amp;nbsp;&lt;STRONG&gt;SD_VBPA_READ_WITH_VBELN&lt;/STRONG&gt;.&lt;/P&gt;&lt;P&gt;We use it in a Client Transaction that creates a delivery and in S4/HANA does not work. That is because of this form, &lt;STRONG&gt;VBPA_BP_AND_ADDRTYPE_GET.&lt;/STRONG&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;These are the details of the code:&lt;/P&gt;&lt;P&gt;&lt;U&gt;S4HANA (lines 95-107)&lt;/U&gt;&lt;/P&gt;&lt;P&gt;SELECT&amp;nbsp;*&amp;nbsp;FROM&amp;nbsp;VBPA&amp;nbsp;INTO&amp;nbsp;TABLE&amp;nbsp;LB_VBPAVB&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;WHERE&amp;nbsp;VBELN&amp;nbsp;=&amp;nbsp;I_VBELN&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;ORDER&amp;nbsp;BY&amp;nbsp;PRIMARY&amp;nbsp;KEY.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;IF&amp;nbsp;SY-SUBRC&amp;nbsp;EQ&amp;nbsp;0.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;STRONG&gt;PERFORM&amp;nbsp;VBPA_BP_AND_ADDRTYPE_GET&lt;/STRONG&gt;&lt;BR /&gt;&lt;STRONG&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;TABLES&amp;nbsp;LB_VBPAVB.&lt;/STRONG&gt;&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;IF&amp;nbsp;VBPA_LINES&amp;nbsp;EQ&amp;nbsp;0.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;VBPA_LINES&amp;nbsp;=&amp;nbsp;SY-DBCNT.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;BF_VBPAVB[]&amp;nbsp;=&amp;nbsp;LB_VBPAVB[].&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;ELSE.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;VBPA_LINES&amp;nbsp;=&amp;nbsp;VBPA_LINES&amp;nbsp;+&amp;nbsp;SY-DBCNT.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;INSERT&amp;nbsp;LINES&amp;nbsp;OF&amp;nbsp;LB_VBPAVB&amp;nbsp;INTO&amp;nbsp;BF_VBPAVB&amp;nbsp;INDEX&amp;nbsp;BF_TABIX.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;ENDIF.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;U&gt;ECC (lines 95-105)&lt;/U&gt;&lt;/P&gt;&lt;P&gt;SELECT&amp;nbsp;*&amp;nbsp;FROM&amp;nbsp;VBPA&amp;nbsp;INTO&amp;nbsp;TABLE&amp;nbsp;LB_VBPAVB&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;WHERE&amp;nbsp;VBELN&amp;nbsp;=&amp;nbsp;I_VBELN&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;ORDER&amp;nbsp;BY&amp;nbsp;PRIMARY&amp;nbsp;KEY.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;IF&amp;nbsp;SY-SUBRC&amp;nbsp;EQ&amp;nbsp;0.&lt;BR /&gt;&amp;nbsp; &amp;nbsp; IF VBPA_LINES EQ 0.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;VBPA_LINES&amp;nbsp;=&amp;nbsp;SY-DBCNT.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;BF_VBPAVB[]&amp;nbsp;=&amp;nbsp;LB_VBPAVB[].&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;ELSE.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;VBPA_LINES&amp;nbsp;=&amp;nbsp;VBPA_LINES&amp;nbsp;+&amp;nbsp;SY-DBCNT.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;INSERT&amp;nbsp;LINES&amp;nbsp;OF&amp;nbsp;LB_VBPAVB&amp;nbsp;INTO&amp;nbsp;BF_VBPAVB&amp;nbsp;INDEX&amp;nbsp;BF_TABIX.&lt;BR /&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;ENDIF.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;This form appears in the new system and reset the value of SY-DBCNT. Then, the delivery is not create.&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The only way to force it to work is having an item in KNVK with the code of the partner. We do not create this codes as a Contact Partner and if we would start to do it we need to change all of our processes involve.&lt;/P&gt;&lt;P&gt;Do you know how to handle this? Have anyone this problem?&lt;/P&gt;&lt;P&gt;Thanks in advance&lt;/P&gt;&lt;P&gt;Kind regards&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/incident-with-fm-sd-vbpa-read-with-vbeln-in-s4hana/qaq-p/14225886"/>
    <published>2025-09-23T16:11:34.142000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/how-to-handle-rv61axx-price-condition-rules-these-days/qaq-p/14226406</id>
    <title>How to handle RV61Axx price condition rules these days?</title>
    <updated>2025-09-24T08:21:39.766000+02:00</updated>
    <author>
      <name>patrick_weber11</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/215409</uri>
    </author>
    <content>&lt;P&gt;Hi all,&lt;/P&gt;&lt;P&gt;as part of our clean core journey, we try to get rid of as many modifications as possible. One of the most modified module is SD and especially all these RV61Axx reports. These are price condition rules, you know. In case we need a new rule (and we use hundrets), we always need to modify the system.&lt;/P&gt;&lt;P&gt;To my knowledge, modifications are not allowed in public cloud scenario. But SAP customers will still need to use price condition rules. So what is the alternative in public cloud and are we able to use them in our S/4 HANA 2023 FP1 on-premise system as well?&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/how-to-handle-rv61axx-price-condition-rules-these-days/qaq-p/14226406"/>
    <published>2025-09-24T08:21:39.766000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/custom-include-inside-exit-saplcjwb-004-returns-an-error-statement-quot/qaq-p/14226720</id>
    <title>Custom Include inside EXIT_SAPLCJWB_004 returns an error statement "Statement not accessible</title>
    <updated>2025-09-24T12:06:40.046000+02:00</updated>
    <author>
      <name>bigflatfoot</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/887707</uri>
    </author>
    <content>&lt;P&gt;I have created an include ZXCN1U21 inside EXIT_SAPLCJWB_004 and tried to put a statement BREAK-POINT for testing purposes.&amp;nbsp;&lt;BR /&gt;&lt;BR /&gt;However, upon trying to activate it, it returns an error "Statement not accessible". How do I address this kind of error?&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/custom-include-inside-exit-saplcjwb-004-returns-an-error-statement-quot/qaq-p/14226720"/>
    <published>2025-09-24T12:06:40.046000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/need-badi-user-exit-migo-update-batch-classification/qaq-p/14226817</id>
    <title>Need Badi/user exit-migo-update batch classification</title>
    <updated>2025-09-24T14:16:36.793000+02:00</updated>
    <author>
      <name>tafkap95</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/634466</uri>
    </author>
    <content>&lt;P&gt;Hello,&lt;/P&gt;&lt;P&gt;I'm looking for a user exit/BADI/enhancement in MIGO that would allow me to update the classifications for a material after entering the Batch/Vendor Batch or when saving the document (provided there are no existing classifications).&lt;/P&gt;&lt;P&gt;To be more precise:&lt;/P&gt;&lt;P&gt;1. Launch MIGO and enter a Purchase Order&lt;BR /&gt;2. Then, for the selected line, go to the Batch tab&lt;BR /&gt;3. Enter a Batch number, and by pressing Enter, you populate the classifications for Material/Batch without clicking the "Classification" button&lt;BR /&gt;4. If step 3 is not possible, populate the classifications for Material/Batch when saving the document&lt;/P&gt;&lt;P&gt;Thank you for your help&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/need-badi-user-exit-migo-update-batch-classification/qaq-p/14226817"/>
    <published>2025-09-24T14:16:36.793000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-q-a/business-area-in-s-alr-87012082-report/qaq-p/14227433</id>
    <title>Business Area in S_ALR_87012082 report</title>
    <updated>2025-09-25T08:03:48.915000+02:00</updated>
    <author>
      <name>soumyodeep</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/682802</uri>
    </author>
    <content>&lt;P&gt;Is there any possible way to add Business Area in&amp;nbsp;S_ALR_87012082 standard report in ECC?&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-q-a/business-area-in-s-alr-87012082-report/qaq-p/14227433"/>
    <published>2025-09-25T08:03:48.915000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/when-using-xco-libraries-i-obtain-the-error-message-quot-put-operation/qaq-p/14227583</id>
    <title>When using xco libraries I obtain the error message "PUT operation failed"</title>
    <updated>2025-09-25T10:03:00.891000+02:00</updated>
    <author>
      <name>Andre_Fischer</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/55</uri>
    </author>
    <content>&lt;P&gt;When developing a helper class to solve a customer problem I used the xco libraries to generate several packages.&amp;nbsp;&amp;nbsp;&lt;/P&gt;&lt;P&gt;The creation of the packages initially failed and in the try catch block I only received the error message&amp;nbsp;&lt;/P&gt;&lt;P&gt;"PUT operation failed"&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;TRY.
        DATA(lo_specification) = put_operation-&amp;gt;add_object( i_package_name )-&amp;gt;create_form_specification( ).
        lo_specification-&amp;gt;set_short_description( short_description ).
        lo_specification-&amp;gt;properties-&amp;gt;set_super_package( i_super_package_name )-&amp;gt;set_software_component( co_dmo_sap_package ).
        DATA(lo_result) = put_operation-&amp;gt;execute( ).
        " handle findings
        DATA(lo_findings) = lo_result-&amp;gt;findings.
        findings = lo_findings-&amp;gt;get( ).
      CATCH cx_root  INTO DATA(generation_exception).
        exception_text = generation_exception-&amp;gt;get_text(  ).
ENDTRY.&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&amp;nbsp;So how I am able to find out the root cause?&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/when-using-xco-libraries-i-obtain-the-error-message-quot-put-operation/qaq-p/14227583"/>
    <published>2025-09-25T10:03:00.891000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/cds-view-casting-to-data-element-but-field-name-is-missing-in-se16n/qaq-p/14227730</id>
    <title>CDS View - Casting to Data Element but Field Name is Missing in SE16N</title>
    <updated>2025-09-25T11:52:17.383000+02:00</updated>
    <author>
      <name>volkansen</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/882824</uri>
    </author>
    <content>&lt;P&gt;Hello,&lt;/P&gt;&lt;P&gt;Edit: I have changed the language to English as suggested for better understanding but to my surprise now it's working!&lt;BR /&gt;I don't know what the problem was but I will drop the whole code here just in case.&lt;BR /&gt;&lt;BR /&gt;The CDS:&lt;/P&gt;&lt;pre class="lia-code-sample language-abap"&gt;&lt;code&gt;@AbapCatalog.viewEnhancementCategory: [#NONE]
@AccessControl.authorizationCheck: #NOT_REQUIRED
@EndUserText.label: 'Alış Faturaları'
@Metadata.ignorePropagatedAnnotations: true
@ObjectModel.usageType:{
    serviceQuality: #X,
    sizeCategory: #S,
    dataClass: #MIXED
}
define view entity ZMM_DDL_PUR_INV
  as select from    rseg
    inner join      rbkp   on  rbkp.belnr = rseg.belnr
                           and rbkp.gjahr = rseg.gjahr
    left outer join but000 on but000.partner = rbkp.lifnr
    left outer join mara   on rseg.matnr = mara.matnr
    left outer join t023t  on  t023t.matkl = mara.matkl
                           and t023t.spras = $session.system_language
    left outer join t134t  on  t134t.mtart = mara.mtart
                           and t134t.spras = $session.system_language
    inner join      a003   on  a003.mwskz = rseg.mwskz
                           and a003.kappl = 'TX'
                           and a003.aland = 'TR'
                           and a003.kschl = 'MWVS'
    inner join      konp   on konp.knumh = a003.knumh
{
  key rbkp.bukrs,
  key rbkp.blart,
  key rbkp.belnr,
  key rseg.buzei,
      rseg.shkzg,
      rbkp.xblnr,
      rbkp.budat,
      rbkp.lifnr,
      but000.name_org1,
      rseg.ebeln,
      rseg.ebelp,
      mara.mtart,
      t134t.mtbez,
      mara.matkl,
      t023t.wgbez,
      rseg.matnr,
      @Semantics.quantity.unitOfMeasure: 'bstme'
      rseg.menge,
      rseg.bstme,
      @Semantics.amount.currencyCode: 'waers'
      cast(
       cast(
         case when rseg.menge &amp;lt;&amp;gt; 0 then cast(rseg.wrbtr as abap.dec(11,2)) / cast(rseg.menge as abap.dec(11,2)) else 0 end
       as abap.dec(11,4))
      as zfi_e_birim_fiyat) as birim_fiyat,
      @Semantics.amount.currencyCode: 'waers'
      rseg.wrbtr,
      @Semantics.amount.currencyCode: 'waers'
      cast(
        cast(
          case when konp.kbetr &amp;lt;&amp;gt; 0 then (cast(rseg.wrbtr as abap.dec(11,4)) * cast(konp.kbetr as abap.dec(11,4))) / cast(1000 as abap.dec(11,4)) else 0 end
        as abap.dec(11,4)) 
      as zfi_e_kdv_tutari) as kdv_tutari,
      rbkp.waers
}
where
      rbkp.vgart != 'RS'
  and rbkp.stblg =  ''&lt;/code&gt;&lt;/pre&gt;&lt;P&gt;&lt;BR /&gt;In Turkish the field label in the table after I run SE16N query was missing:&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="volkansen_1-1758870276094.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320144iDC018676381A5EA1/image-size/large?v=v2&amp;amp;px=999" role="button" title="volkansen_1-1758870276094.png" alt="volkansen_1-1758870276094.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="volkansen_2-1758870469685.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320145i6CB7DBE3435550A1/image-size/large?v=v2&amp;amp;px=999" role="button" title="volkansen_2-1758870469685.png" alt="volkansen_2-1758870469685.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;But now I translated the data element in English and logged in with English and now it's showing:&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="volkansen_3-1758870583800.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320146i3E19CD9FF42BFACB/image-size/large?v=v2&amp;amp;px=999" role="button" title="volkansen_3-1758870583800.png" alt="volkansen_3-1758870583800.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Field Labels are entered in both languages:&lt;BR /&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="volkansen_4-1758870628676.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320147i60B338303A643828/image-size/large?v=v2&amp;amp;px=999" role="button" title="volkansen_4-1758870628676.png" alt="volkansen_4-1758870628676.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="volkansen_5-1758870659205.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320148iBD55AAE7FB3D50D1/image-size/large?v=v2&amp;amp;px=999" role="button" title="volkansen_5-1758870659205.png" alt="volkansen_5-1758870659205.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;Edit2: After I entered the English translation to the data element to show you the error, I logged back in Turkish again and now it's working in Turkish too.&amp;nbsp;¯\_(ツ)_/¯&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/cds-view-casting-to-data-element-but-field-name-is-missing-in-se16n/qaq-p/14227730"/>
    <published>2025-09-25T11:52:17.383000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/mdg-replication-of-field-not-successful/qaq-p/14228332</id>
    <title>MDG replication of field not successful</title>
    <updated>2025-09-26T02:41:43.796000+02:00</updated>
    <author>
      <name>newguy_cloud</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1492327</uri>
    </author>
    <content>&lt;P&gt;Dear Experts,&lt;/P&gt;&lt;P&gt;I am newbie in Webservices and need some second opinions from you guys.&lt;/P&gt;&lt;P&gt;My Business Analyst told me that the field KNA1-RPMKR should be copied from source system to target system. We use the transaction DRFOUT to perform this.&lt;/P&gt;&lt;P&gt;No errors were found in SRT_MONI and DRFOUT as well.&lt;/P&gt;&lt;P&gt;Unfortunately, the field does not get copied even though it has a value in the source system.&lt;/P&gt;&lt;P&gt;The question is, should I ask for help from SAP since this standard class CL_MDG_BP_RPLCTRQ and standard method BP_SUITEBULK_REPL_REQ_IN also in SPROXY the service definition is SAP standard BusinessPartnerSUITEBulkReplic?&lt;/P&gt;&lt;P&gt;If not, then what will be my next step?&lt;/P&gt;&lt;P&gt;Please help.&lt;/P&gt;&lt;P&gt;Newguy_cloud&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/mdg-replication-of-field-not-successful/qaq-p/14228332"/>
    <published>2025-09-26T02:41:43.796000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/trial-integration-suite-not-authorized/qaq-p/14228579</id>
    <title>Trial Integration suite not authorized</title>
    <updated>2025-09-26T10:16:20.080000+02:00</updated>
    <author>
      <name>deepak_h3</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/214031</uri>
    </author>
    <content>&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;I am getting not authorized on launching Integration suite for Hana trial account.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="deepak_h3_0-1758874325454.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320165i43B63151C8D9E309/image-size/large?v=v2&amp;amp;px=999" role="button" title="deepak_h3_0-1758874325454.png" alt="deepak_h3_0-1758874325454.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;The role is present for my user.&amp;nbsp;&lt;/P&gt;&lt;P&gt;&lt;span class="lia-inline-image-display-wrapper lia-image-align-inline" image-alt="deepak_h3_2-1758874464510.png" style="width: 999px;"&gt;&lt;img src="https://community.sap.com/t5/image/serverpage/image-id/320167i75D74705102C57B8/image-size/large?v=v2&amp;amp;px=999" role="button" title="deepak_h3_2-1758874464510.png" alt="deepak_h3_2-1758874464510.png" /&gt;&lt;/span&gt;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;P&gt;What could be missing ?&amp;nbsp;&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/trial-integration-suite-not-authorized/qaq-p/14228579"/>
    <published>2025-09-26T10:16:20.080000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/missing-idatype-in-usr21/qaq-p/14228689</id>
    <title>Missing IDATYPE in USR21</title>
    <updated>2025-09-26T11:22:51.697000+02:00</updated>
    <author>
      <name>No_Name2</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1863187</uri>
    </author>
    <content>&lt;P&gt;Hi SAP Community,&lt;/P&gt;&lt;P&gt;We’re currently using the Fiori app “Manage Teams and Responsibilities” and have encountered an issue when trying to add employees to a team.&lt;/P&gt;&lt;P&gt;The app displays a list of users eligible to be added, and we’ve identified that the key criterion for inclusion is the IDTYPE field in table USR21. Specifically, only users with IDTYPE = 2 or 4 appear in the selection list.&lt;/P&gt;&lt;P&gt;However, we’ve noticed that some users have no IDTYPE set at all (the field is blank in USR21), which means they’re excluded from the app’s selection list.&lt;/P&gt;&lt;P&gt;We’ve already tried assigning a workplace to these users via SU01, hoping that would trigger the IDTYPE to be set to 4 — but unfortunately, it didn’t change anything.&lt;/P&gt;&lt;P&gt;Our question: How can we set or populate the IDTYPE for these users so they become visible in the app?&lt;/P&gt;&lt;P&gt;Thanks in advance!&lt;/P&gt;&lt;P&gt;&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/missing-idatype-in-usr21/qaq-p/14228689"/>
    <published>2025-09-26T11:22:51.697000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/1-500-faster-abap-cloud-api-with-just-gzip/qaq-p/14229207</id>
    <title>1,500× Faster: ABAP Cloud API with “Just” Gzip</title>
    <updated>2025-09-26T16:36:17.362000+02:00</updated>
    <author>
      <name>natanael1</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/1557162</uri>
    </author>
    <content>&lt;H3 id="toc-hId-1890184258"&gt;The 3-hours to 7-Second Story&lt;/H3&gt;&lt;P&gt;We had a weekly data integration form ABAP in Cloud, via an OData service, that took about &lt;STRONG&gt;3 hours&lt;/STRONG&gt;(10800 seconds) and nearly &lt;STRONG&gt;600 requests&lt;/STRONG&gt; to finish. After a small redesign, the same data now arrives in &lt;STRONG&gt;~7 seconds(instead of 10800 seconds)&lt;/STRONG&gt; using just &lt;STRONG&gt;3 requests&lt;/STRONG&gt;. So a dramatic x1500 reduction. No new servers, no fancy tools, just smarter packaging of the data, but of course with some drawback.&lt;/P&gt;&lt;P&gt;The full PDF paper, and code is available in this GitHub repo:&amp;nbsp;&lt;A href="https://github.com/legonmarian/abap-btp-api-optimization" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/legonmarian/abap-btp-api-optimization&lt;/A&gt;&lt;/P&gt;&lt;H3 id="toc-hId-1693670753"&gt;Quick Context&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Where:&lt;/STRONG&gt; ABAP in Cloud on SAP BTP.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;What:&lt;/STRONG&gt; A big, flat table (around 3 million rows) needed once a week.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Old approach: &lt;/STRONG&gt;OData service exposing this table, called 600 times,&amp;nbsp;5,000 rows per call → slow and expensive, the extraction workflow took ~3 hours&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Constraint:&lt;/STRONG&gt; We can’t stream chunks; each response is built on the server, then sent.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Goal:&lt;/STRONG&gt; Deliver everything fast, simple, and cheap for both sides.&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1497157248"&gt;The Simple Change&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;Goal:&lt;/STRONG&gt; make a big weekly export feel like a single, quick download. No fancy infra, no special client libraries.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;Why not OData for this job&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;OData shines for interactive reads: $filter, $expand, small pages, typed entities.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Our use case was the opposite: &lt;STRONG&gt;one flat dataset, all of it, as fast as possible&lt;/STRONG&gt;.&lt;/LI&gt;&lt;LI&gt;With OData we’d still pay the cost of many small pages and per-entity overhead the client didn’t need.&lt;/LI&gt;&lt;LI&gt;Most consumers wanted a simple file-like payload they could ingest with generic tools.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Why a plain HTTP service instead&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;A plain GET endpoint gives us &lt;STRONG&gt;full control over the wire format&lt;/STRONG&gt; (JSON/CSV), headers, and compression.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;It’s easier for any consumer to adopt (curl, Python, Node, SAP or non-SAP).&lt;/LI&gt;&lt;LI&gt;We can define a &lt;STRONG&gt;predictable paging contract&lt;/STRONG&gt; (e.g., offset/count) and let the client fetch pages in parallel.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Why “just HTTP” still wasn’t enough&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;In ABAP Cloud, we don’t stream chunked responses; the server assembles the response first, then sends it.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;If we naïvely send a huge JSON array, the &lt;STRONG&gt;payload is too big&lt;/STRONG&gt; and &lt;STRONG&gt;too slow&lt;/STRONG&gt;.&lt;/LI&gt;&lt;LI&gt;If we keep tiny pages, we fix size but suffer &lt;STRONG&gt;hundreds of roundtrips&lt;/STRONG&gt;.&lt;/LI&gt;&lt;LI&gt;Conclusion: we needed to &lt;STRONG&gt;keep HTTP simple but make each response compact and each request count&lt;/STRONG&gt;.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;What we explored&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Formats:&lt;/STRONG&gt; JSON vs CSV vs newline-delimited JSON. CSV is smaller raw, but…&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Serialization:&lt;/STRONG&gt; /ui2/cl_json, XCO, and CALL TRANSFORMATION for speed and stability.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Compression:&lt;/STRONG&gt; no compression vs gzip; single gzip member vs multiple members inside one response.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Delivery patterns:&lt;/STRONG&gt; direct download vs staging to storage; server-side streaming ideas (ruled out).&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Paging shapes:&lt;/STRONG&gt; many small pages vs a few big pages; client parallelism vs server complexity.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;What we landed on (the pattern)&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Keep JSON&lt;/STRONG&gt; for compatibility, but &lt;STRONG&gt;generate it fast&lt;/STRONG&gt; (use the fastest serializer available to you).&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Compress every response&lt;/STRONG&gt; and signal it with Content-Encoding: gzip. One &lt;STRONG&gt;single gzip member&lt;/STRONG&gt; per response so common clients auto-decompress reliably.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Use coarse paging&lt;/STRONG&gt; (few big pages) to cut roundtrips. Expose simple params (e.g., offset and count) and a “count only” helper so clients can plan pages.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Let clients parallelize&lt;/STRONG&gt; safely: stable ordering, idempotent reads, and clear retry rules.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Stay boring on the protocol:&lt;/STRONG&gt; plain HTTP GET, clear headers, predictable JSON shape. No streaming tricks, no custom encodings that break tools.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Why this works?&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;We &lt;STRONG&gt;remove protocol overhead&lt;/STRONG&gt; we don’t need (OData features) and &lt;STRONG&gt;add the two things we do need&lt;/STRONG&gt; for bulk: fast serialization + compression.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Coarse pages shift the bottleneck from “too many calls” to “a few efficient transfers”.&lt;/LI&gt;&lt;LI&gt;Gzip neutralizes JSON’s key overhead, so we keep a &lt;STRONG&gt;friendly format&lt;/STRONG&gt; without paying a size penalty.&lt;/LI&gt;&lt;LI&gt;The approach is &lt;STRONG&gt;portable and observable&lt;/STRONG&gt;: easy to test locally, easy to monitor in production, and easy for partners to adopt.&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId-1300643743"&gt;Before vs After&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;TL;DR:&lt;/STRONG&gt; We didn’t change the data, only the delivery: coarse pages, fast JSON, and gzip over a plain HTTP contract.&lt;BR /&gt;&lt;BR /&gt;&lt;/P&gt;&lt;P&gt;Dimension Before (many small pages) After (few big pages + gzip) Why it matters&lt;/P&gt;&lt;TABLE&gt;&lt;TBODY&gt;&lt;TR&gt;&lt;TD&gt;Dataset&lt;/TD&gt;&lt;TD&gt;~3,000,000 rows (flat, ~12 columns)&lt;/TD&gt;&lt;TD&gt;Same&lt;/TD&gt;&lt;TD&gt;Same data, new delivery.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Page size&lt;/TD&gt;&lt;TD&gt;5,000 rows/page&lt;/TD&gt;&lt;TD&gt;~1,000,000 rows/page (tunable)&lt;/TD&gt;&lt;TD&gt;Fewer roundtrips, less latency.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Number of requests&lt;/TD&gt;&lt;TD&gt;~593&lt;/TD&gt;&lt;TD&gt;3&lt;/TD&gt;&lt;TD&gt;Network overhead drops dramatically.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;End-to-end time&lt;/TD&gt;&lt;TD&gt;~3 hours (sequential pulls)&lt;/TD&gt;&lt;TD&gt;~6-7 seconds (3 parallel pulls)&lt;/TD&gt;&lt;TD&gt;Parallelizable, near “single download” feel.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Format on the wire&lt;/TD&gt;&lt;TD&gt;JSON (uncompressed)&lt;/TD&gt;&lt;TD&gt;JSON (gzipped)&lt;/TD&gt;&lt;TD&gt;Keep JSON for compatibility; shrink it with gzip.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Total transfer&lt;/TD&gt;&lt;TD&gt;~0.6 GB&lt;/TD&gt;&lt;TD&gt;~9 MB&lt;/TD&gt;&lt;TD&gt;Bandwidth and cost fall off a cliff.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Payload per page&lt;/TD&gt;&lt;TD&gt;~1.15 MB per 5k rows (raw)&lt;/TD&gt;&lt;TD&gt;~3 MB per 1M rows (gzipped)&lt;/TD&gt;&lt;TD&gt;Gzip beats key overhead; size scales well.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Serialization&lt;/TD&gt;&lt;TD&gt;Generic JSON serializer&lt;/TD&gt;&lt;TD&gt;Fast serializer (CALL TRANSFORMATION)&lt;/TD&gt;&lt;TD&gt;Server can build big pages quickly.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Protocol&lt;/TD&gt;&lt;TD&gt;OData-style paging&lt;/TD&gt;&lt;TD&gt;Plain HTTP GET with offset/count&lt;/TD&gt;&lt;TD&gt;Simple contract any client can call.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Compression&lt;/TD&gt;&lt;TD&gt;None&lt;/TD&gt;&lt;TD&gt;Content-Encoding: gzip (single member)&lt;/TD&gt;&lt;TD&gt;Works out-of-the-box with common tools/SDKs.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Client pattern&lt;/TD&gt;&lt;TD&gt;Sequential loop&lt;/TD&gt;&lt;TD&gt;Fetch pages in parallel, then merge&lt;/TD&gt;&lt;TD&gt;Easy speed-up without server tricks.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Retry model&lt;/TD&gt;&lt;TD&gt;Many small retries&lt;/TD&gt;&lt;TD&gt;Few coarse, idempotent retries&lt;/TD&gt;&lt;TD&gt;Fewer moving parts, simpler error handling.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Server behavior&lt;/TD&gt;&lt;TD&gt;Build JSON, send raw&lt;/TD&gt;&lt;TD&gt;Build JSON → gzip → send single member&lt;/TD&gt;&lt;TD&gt;Reliable auto-decompression on client side.&lt;/TD&gt;&lt;/TR&gt;&lt;TR&gt;&lt;TD&gt;Limits to watch&lt;/TD&gt;&lt;TD&gt;Too many roundtrips; egress cost&lt;/TD&gt;&lt;TD&gt;Client RAM per page; choose page size wisely&lt;/TD&gt;&lt;TD&gt;Balance page size vs client capacity.&lt;/TD&gt;&lt;/TR&gt;&lt;/TBODY&gt;&lt;/TABLE&gt;&lt;H3 id="toc-hId-1104130238"&gt;How to reproduce this in three simple steps&lt;/H3&gt;&lt;BLOCKQUOTE&gt;&lt;P&gt;Heads-up: in here I will refer to an Appendix, you can find it in the detailed PDF paper about the optimization, the paper and some code is available on GitHub&lt;/P&gt;&lt;/BLOCKQUOTE&gt;&lt;HR /&gt;&lt;H4 id="toc-hId-1036699452"&gt;Step 1. Define a tiny HTTP contract&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Endpoint:&lt;/STRONG&gt; GET /entity?offset=…&amp;amp;count=…&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Helper:&lt;/STRONG&gt; GET /entity?get_only_count=true returns a small pagination object with totals and suggested pages, for example:&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;PRE&gt;{
  "number_of_records": 2496434,
  "batch_size": { "maximum": 1500000, "recommended": 1000000 },
  "recommended_pages": [
    "/entity?offset=0&amp;amp;count=1000000",
    "/entity?offset=1000000&amp;amp;count=1000000",
    "/entity?offset=2000000&amp;amp;count=1000000"
  ]
}&lt;/PRE&gt;&lt;P&gt;This keeps clients simple and lets them plan parallel pulls.&lt;/P&gt;&lt;HR /&gt;&lt;H4 id="toc-hId-840185947"&gt;Step 2. Build one big page, serialize fast, and gzip it on the server&lt;/H4&gt;&lt;P&gt;&lt;STRONG&gt;a) Fast JSON generation with CALL TRANSFORMATION&lt;/STRONG&gt;&lt;BR /&gt;Appendix C shows the lean serializer that won your benchmarks:&lt;/P&gt;&lt;PRE&gt;METHOD convert_json_transformation.
  DATA(lo_writer) = cl_sxml_string_writer⇒create( type = if_sxml⇒co_xt_json ).
  CALL TRANSFORMATION id
    SOURCE itab = data
    RESULT XML lo_writer.
  string = lo_writer-&amp;gt;get_output( ).
ENDMETHOD.&lt;/PRE&gt;&lt;P&gt;Use this to turn your internal table into JSON quickly.&lt;/P&gt;&lt;P&gt;&lt;STRONG&gt;b) Minimal HTTP handler that serves one gzipped page&lt;/STRONG&gt;&lt;BR /&gt;Appendix I demonstrates the pattern: set headers, read a deterministic slice, serialize, gzip once, send bytes.&lt;/P&gt;&lt;PRE&gt;METHOD gzip_json_single_page.
  response-&amp;gt;set_status( 200 ).
  response-&amp;gt;set_content_type( 'application/gzip' ).
  response-&amp;gt;set_header_field(
    i_name = 'Content-Disposition'
    i_value = |attachment; filename="data_subset.gz"| ).
  response-&amp;gt;set_compression(
    options = if_web_http_response⇒co_compress_none ).
  response-&amp;gt;set_header_field(
    i_name = 'Content-Encoding'
    i_value = |deflate| ).

  SELECT column_1, column_2, ... , column_12
    FROM dbtable
    ORDER BY column_2
    INTO TABLE @DATA(page)
    UP TO @page_size ROWS.

  cl_abap_gzip⇒compress_binary(
    EXPORTING raw_in = convert_json_transformation( page )
    IMPORTING gzip_out = DATA(gzip) ).

  response-&amp;gt;set_binary( gzip ).
ENDMETHOD.&lt;/PRE&gt;&lt;P&gt;&lt;STRONG&gt;c) Where the handler is wired&lt;/STRONG&gt;&lt;BR /&gt;Appendix F shows the entry point choosing which implementation to run:&lt;/P&gt;&lt;PRE&gt;METHOD if_http_service_extension~handle_request.
  " choose one of these
  gzip_json_single_page( CHANGING request = request response = response ).
  " only for demonstration
  "gzip_csv_single_page( CHANGING request = request response = response ).
  " only for demonstration
  "gzip_csv_multiple_pages( CHANGING request = request response = response ).
ENDMETHOD.&lt;/PRE&gt;&lt;P&gt;Keep it simple in production and call the JSON + single-member gzip method.&lt;/P&gt;&lt;HR /&gt;&lt;H4 id="toc-hId-643672442"&gt;Step 3. Let the client pull a few big pages in parallel&lt;/H4&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;Ask get_only_count first to get total and recommended pages.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Fire 2–4 page requests in parallel, then merge locally.&lt;/LI&gt;&lt;LI&gt;Most clients auto-decompress when Content-Encoding is set, which is exactly why the server returns a single gzip response.&lt;/LI&gt;&lt;/UL&gt;&lt;HR /&gt;&lt;H4 id="toc-hId-447158937"&gt;Optional: CSV variant from the appendix&lt;/H4&gt;&lt;P&gt;If you ever need CSV, Appendix H shows the single-page CSV + gzip flow. The JSON path above stayed as our final choice because gzip erases most of JSON’s key overhead while keeping tooling friendly.&lt;/P&gt;&lt;H3 id="toc-hId-121562713"&gt;When to use this pattern and when not to&lt;/H3&gt;&lt;P&gt;&lt;STRONG&gt;Use it when&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;You need to deliver a large, flat dataset fast, usually for batch or analytics.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;Your consumers are happy with a plain HTTP GET that returns JSON.&lt;/LI&gt;&lt;LI&gt;You can sort by a unique key and read stable slices with offset and count.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;&lt;STRONG&gt;Think twice when&lt;/STRONG&gt;&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Consumers need rich OData features&lt;/STRONG&gt; like server-side filtering and $expand. You will be giving those up and implementing only what you need in plain HTTP.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Clients cannot hold the decompressed page in memory.&lt;/STRONG&gt; A 1,000,000 row page is roughly a few hundred MB once decompressed, so plan for that on the client side.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;You require true streaming.&lt;/STRONG&gt; ABAP ICF in the cloud does not support HTTP/1.1 chunked transfer, so streaming is out of scope here.&lt;P&gt;&amp;nbsp;&lt;/P&gt;&lt;/LI&gt;&lt;/UL&gt;&lt;H3 id="toc-hId--150182161"&gt;Gotchas to avoid&lt;/H3&gt;&lt;UL&gt;&lt;LI&gt;&lt;P&gt;&lt;STRONG&gt;Do not concatenate multiple gzip members&lt;/STRONG&gt; in one HTTP response if you expect tools like Postman to auto-decompress. Many clients only unpack the first member. Prefer one contiguous gzip stream per response.&lt;/P&gt;&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Set the right headers.&lt;/STRONG&gt; Send Content-Encoding: gzip for the single member response. If you build a multi-member payload, clients may not decode it automatically, which is why your final solution avoided that.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Keep ordering stable.&lt;/STRONG&gt; Always ORDER BY a unique key to make pages deterministic and retries idempotent. (Your examples order by a key column before slicing.)&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Pick a page size both sides can hold.&lt;/STRONG&gt; You found that 1,000,000 rows per page hits a good balance. Results and size scale with total rows, not so much with page count.&lt;/LI&gt;&lt;LI&gt;&lt;STRONG&gt;Stick to one gzip pass per response.&lt;/STRONG&gt; Compress after you generate JSON for the page, not per record or per mini-chunk inside the same response. It keeps clients simple.&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;For the full PDF paper, and code please check this GitHub repo:&amp;nbsp;&lt;A href="https://github.com/legonmarian/abap-btp-api-optimization" target="_blank" rel="noopener nofollow noreferrer"&gt;https://github.com/legonmarian/abap-btp-api-optimization&lt;/A&gt;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/1-500-faster-abap-cloud-api-with-just-gzip/qaq-p/14229207"/>
    <published>2025-09-26T16:36:17.362000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/partial-unpacking-of-handling-unit-for-outbound-delivery-orders/qaq-p/14229435</id>
    <title>Partial Unpacking of Handling Unit for Outbound delivery orders</title>
    <updated>2025-09-27T00:21:48.742000+02:00</updated>
    <author>
      <name>jctx15</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/889959</uri>
    </author>
    <content>&lt;P&gt;Hello - I was curious if there are function modules that can allow us to do a partial unpacking of a item for an HU. We have a SAP program that utilizes the FM "HU_UNPACK" which unpacks the entire item quantity.&amp;nbsp;&lt;/P&gt;&lt;P&gt;If for example, a HU had an item of quantity 10, would I be able to unpack only a quantity of 2 from the HU? I was poking around in VL02N&amp;nbsp; and we can do a partial item quantity to pack, but it did not seem we can do it for unpacking.&amp;nbsp;&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/partial-unpacking-of-handling-unit-for-outbound-delivery-orders/qaq-p/14229435"/>
    <published>2025-09-27T00:21:48.742000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/enterprise-resource-planning-q-a/bapi-fm-to-get-gl-account-line-items/qaq-p/14230485</id>
    <title>BAPI/FM to get GL account line items</title>
    <updated>2025-09-29T13:49:21.095000+02:00</updated>
    <author>
      <name>jan_turek</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/188867</uri>
    </author>
    <content>&lt;P&gt;Hi all,&lt;/P&gt;&lt;P&gt;I'm looking for a BAPI / FM to get GL account line items. My need is only for PL accounts (no OI management), primary key must be account number, limitation by period / posting date.&amp;nbsp;New GL active. CO object is needed.&lt;/P&gt;&lt;P&gt;Sorry if it is obvious but I was not able to find a suitable solution. Before I go for something like BKPF-&amp;gt;BSEG, I'd like to use some systematic solution.&lt;/P&gt;&lt;P&gt;thanks to all!&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/enterprise-resource-planning-q-a/bapi-fm-to-get-gl-account-line-items/qaq-p/14230485"/>
    <published>2025-09-29T13:49:21.095000+02:00</published>
  </entry>
  <entry>
    <id>https://community.sap.com/t5/technology-q-a/any-api-to-get-all-users-which-would-respond-positively-to-a-given/qaq-p/14230612</id>
    <title>Any API to get all users which would respond positively to a given AUTHORITY-CHECK?</title>
    <updated>2025-09-29T15:57:27.136000+02:00</updated>
    <author>
      <name>Sandra_Rossi</name>
      <uri>https://community.sap.com/t5/user/viewprofilepage/user-id/145194</uri>
    </author>
    <content>&lt;P&gt;Hi,&lt;/P&gt;&lt;P&gt;In the flexible workflow, I'm asked to implement the method RESPONSIBILITY_RULE of the BAdI RSM_BADI_STATIC_RULE, to return the agents who have a given authorization e.g., AUTHORITY-CHECK 'ZZZZZ' FOR USER user ID field1 FIELD value1 ID field2 FIELD value2, etc. The workflow task can then be processed by any of these agents.&lt;/P&gt;&lt;P&gt;For information, our authorization values contain wildcards (values *, CX3101*) or are fixed (CX32). No intervals.&lt;/P&gt;&lt;P&gt;Is there any official (released) API which does that, or do you have any other recommendation?&lt;/P&gt;&lt;P&gt;I have searched a little bit:&lt;/P&gt;&lt;UL&gt;&lt;LI&gt;The only API authorization query I know, CL_AUTH_OBJECTS_TO_SQL (cf. ABAP Keyword documentation) is not relevant for this query. It transforms some authorizations of the current user into a WHERE clause to select the values from a given database table (to avoid selecting all the lines and then removing the forbidden values by LOOP AT + AUTHORITY-CHECK).&lt;/LI&gt;&lt;LI&gt;The function module&amp;nbsp;SUSR_GET_PROFS_WITH_SPEC_OBJCT (followed by LOOP AT + AUTHORITY-CHECK) can do the job but is not released and is a little bit slow. Its logic is:&lt;UL&gt;&lt;LI&gt;All accesses to the database tables is without buffer&lt;/LI&gt;&lt;LI&gt;Get all the authorizations corresponding to the authorization object (USR12)&lt;/LI&gt;&lt;LI&gt;LOOP AT the authorizations&lt;UL&gt;&lt;LI&gt;Get the profiles corresponding to these authorizations (UST10S)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;Get the subprofiles of these profiles via FOR ALL ENTRIES (UST10C)&lt;/LI&gt;&lt;LI&gt;Get all the users corresponding to these profiles and subprofiles via FOR ALL ENTRIES (UST04)&lt;/LI&gt;&lt;/UL&gt;&lt;/LI&gt;&lt;LI&gt;Reading directly the database tables above, with a join. I just did a test and it's faster (with HANA)&lt;/LI&gt;&lt;/UL&gt;&lt;P&gt;Thanks.&lt;/P&gt;&lt;P&gt;Sandra&lt;/P&gt;&lt;P&gt;PS: my system is S/4HANA On Premises, ABAP 7.58.&lt;/P&gt;</content>
    <link href="https://community.sap.com/t5/technology-q-a/any-api-to-get-all-users-which-would-respond-positively-to-a-given/qaq-p/14230612"/>
    <published>2025-09-29T15:57:27.136000+02:00</published>
  </entry>
</feed>
